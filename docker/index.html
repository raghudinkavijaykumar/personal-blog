<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><meta name="generator" content="Gatsby 2.31.1"/><style data-styled="" data-styled-version="5.2.1">.UDybk{text-align:left;margin:1em 0;padding:0.5em;overflow-x:auto;border-radius:3px;font-family:"Consolas",Consolas;font-size:11px;}/*!sc*/
.UDybk .token-line{line-height:1.1em;height:1.1em;}/*!sc*/
data-styled.g1[id="Code__Pre-gy960v-0"]{content:"UDybk,"}/*!sc*/
.llUIua{position:inherit;border:0;border-radius:3px;margin:0.25em;opacity:0.3;}/*!sc*/
.llUIua:hover{opacity:1;}/*!sc*/
data-styled.g2[id="Code__CopyCode-gy960v-1"]{content:"llUIua,"}/*!sc*/
</style><link rel="sitemap" type="application/xml" href="/personal-blog/sitemap.xml"/><style type="text/css">
    .anchor.before {
      position: absolute;
      top: 0;
      left: 0;
      transform: translateX(-100%);
      padding-right: 4px;
    }
    .anchor.after {
      display: inline-block;
      padding-left: 4px;
    }
    h1 .anchor svg,
    h2 .anchor svg,
    h3 .anchor svg,
    h4 .anchor svg,
    h5 .anchor svg,
    h6 .anchor svg {
      visibility: hidden;
    }
    h1:hover .anchor svg,
    h2:hover .anchor svg,
    h3:hover .anchor svg,
    h4:hover .anchor svg,
    h5:hover .anchor svg,
    h6:hover .anchor svg,
    h1 .anchor:focus svg,
    h2 .anchor:focus svg,
    h3 .anchor:focus svg,
    h4 .anchor:focus svg,
    h5 .anchor:focus svg,
    h6 .anchor:focus svg {
      visibility: visible;
    }
  </style><script>
    document.addEventListener("DOMContentLoaded", function(event) {
      var hash = window.decodeURI(location.hash.replace('#', ''))
      if (hash !== '') {
        var element = document.getElementById(hash)
        if (element) {
          var scrollTop = window.pageYOffset || document.documentElement.scrollTop || document.body.scrollTop
          var clientTop = document.documentElement.clientTop || document.body.clientTop || 0
          var offset = element.getBoundingClientRect().top + scrollTop - clientTop
          // Wait for the browser to finish rendering before scrolling.
          setTimeout((function() {
            window.scrollTo(0, offset - 0)
          }), 0)
        }
      }
    })
  </script><link as="script" rel="preload" href="/personal-blog/webpack-runtime-500034a3e408444d0cae.js"/><link as="script" rel="preload" href="/personal-blog/framework-2601ed29d039b1458055.js"/><link as="script" rel="preload" href="/personal-blog/app-eeb4193423903187a951.js"/><link as="script" rel="preload" href="/personal-blog/ce5c1ec6b0c5670e22550a7ef5fd5c2de8a4bdeb-f3cc52c60397f69658d6.js"/><link as="script" rel="preload" href="/personal-blog/component---src-templates-blog-post-template-tsx-a3788de39add0692b44b.js"/><link as="fetch" rel="preload" href="/personal-blog/page-data\docker\page-data.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/personal-blog/page-data/sq/d/4080856488.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/personal-blog/page-data\app-data.json" crossorigin="anonymous"/></head><body><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><div class="MuiContainer-root MuiContainer-maxWidthLg"><div class="MuiContainer-root MuiContainer-maxWidthLg"><div class="MuiToolbar-root MuiToolbar-regular jss1 MuiToolbar-gutters"><button class="MuiButtonBase-root MuiIconButton-root jss2 MuiIconButton-colorInherit MuiIconButton-edgeStart" tabindex="0" type="button" aria-label="menu"><span class="MuiIconButton-label"><svg class="MuiSvgIcon-root" focusable="false" viewBox="0 0 24 24" aria-hidden="true"><path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"></path></svg></span></button><h5 class="MuiTypography-root jss3 MuiTypography-h5 MuiTypography-noWrap MuiTypography-alignCenter"><a class="jss4" href="/personal-blog/">Raghu&#x27;s Blog</a></h5><button class="MuiButtonBase-root MuiIconButton-root" tabindex="0" type="button"><span class="MuiIconButton-label"><svg class="MuiSvgIcon-root" focusable="false" viewBox="0 0 24 24" aria-hidden="true"><path d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"></path></svg></span></button></div><h1>Docker</h1><p>2021 January 19th</p><div style="font-size:30px">Docker</div><h1>Contents</h1><ul><li><a href="#important-links">Important Links</a></li><li><a href="#code-links">Code Links</a></li><li><a href="#get-started-with-docker">Get Started with Docker</a><ul><li><a href="#get-docker">Get Docker</a><ul><li><a href="#supported-platforms">Supported platforms</a></li><li><a href="#time-based-release-schedule">Time-based release schedule</a></li><li><a href="#updates-and-patches">Updates, and patches</a></li><li><a href="#prior-releases">Prior releases</a></li><li><a href="#install">Install</a><ul><li><a href="#manage-docker-as-a-non-root-user">Manage Docker as a non-root user</a></li><li><a href="#configure-docker-to-start-on-boot">Configure Docker to start on boot</a></li><li><a href="#use-a-different-storage-engine">Use a different storage engine</a></li><li><a href="#configure-where-the-docker-daemon-listens-for-connections">Configure where the Docker daemon listens for connections</a></li><li><a href="#enable-ipv6-on-the-docker-daemon">Enable IPv6 on the Docker daemon</a></li><li><a href="#troubleshooting">Troubleshooting</a><ul><li><a href="#kernel-compatibility">Kernel compatibility</a></li><li><a href="#ip-forwarding-problems">IP forwarding problems</a></li></ul></li><li><a href="#specify-dns-servers-for-docker">Specify DNS servers for Docker</a></li><li><a href="#allow-access-to-the-remote-api-through-a-firewall">Allow access to the remote API through a firewall</a></li></ul></li></ul></li><li><a href="#docker-ce-edge-documentation">Docker CE Edge documentation</a><ul><li><a href="#docker-ce-edge-resources">Docker CE Edge resources</a></li></ul></li><li><a href="#get-docker-compose">Get Docker-Compose</a><ul><li><a href="#prerequisites">Prerequisites</a></li><li><a href="#install-compose">Install Compose</a><ul><li><a href="#install-compose-on-linux-systems">Install Compose on Linux systems</a></li></ul></li><li><a href="#master-builds">Master builds</a></li><li><a href="#upgrading">Upgrading</a></li><li><a href="#uninstallation">Uninstallation</a></li></ul></li><li><a href="#docker----get-started">Docker -- Get Started</a><ul><li><a href="#images-and-containers">Images and containers</a></li><li><a href="#containers-and-virtual-machines">Containers and virtual machines</a></li><li><a href="#orientation-and-setup">Orientation and Setup</a><ul><li><a href="#test-docker-version">Test Docker version</a></li><li><a href="#build-the-app">Build the app</a></li><li><a href="#run-the-app">Run the app</a></li><li><a href="#share-your-image">Share your image</a></li><li><a href="#log-in-with-your-docker-id">Log in with your Docker ID</a></li><li><a href="#tag-the-image">Tag the image</a></li><li><a href="#publish-the-image">Publish the image</a></li><li><a href="#pull-and-run-the-image-from-the-remote-repository">Pull and run the image from the remote repository</a></li></ul></li></ul></li><li><a href="#docker-compose">Docker Compose</a><ul><li><a href="#your-firstdocker-composeymlfile">Your first docker-compose.yml file</a></li></ul></li></ul></li><li><a href="#replace-usernamerepotag-with-your-name-and-image-details">replace username/repo:tag with your name and image details</a><ul><li><a href="#run-your-new-load-balanced-app">Run your new load-balanced app</a></li><li><a href="#scale-the-app">Scale the app</a><ul><li><a href="#take-down-the-app-and-the-swarm">Take down the app and the swarm</a></li></ul></li><li><a href="#recap-and-cheat-sheet">Recap and cheat sheet</a></li><li><a href="#docker-swarm">Docker Swarm</a><ul><li><a href="#understanding-swarm-clusters">Understanding Swarm clusters</a></li><li><a href="#set-up-your-swarm">Set up your swarm</a><ul><li><a href="#create-a-cluster">Create a cluster</a><ul><li><a href="#vms-on-your-local-machine-mac-linux-windows-7-and-8">VMS ON YOUR LOCAL MACHINE (MAC, LINUX, WINDOWS 7 AND 8)</a></li><li><a href="#list-the-vms-and-get-their-ip-addresses">LIST THE VMS AND GET THEIR IP ADDRESSES</a></li><li><a href="#initialize-the-swarm-and-add-nodes">INITIALIZE THE SWARM AND ADD NODES</a></li></ul></li></ul></li><li><a href="#deploy-your-app-on-the-swarm-cluster">Deploy your app on the swarm cluster</a><ul><li><a href="#docker-machine-shell-environment-on-mac-or-linux">DOCKER MACHINE SHELL ENVIRONMENT ON MAC OR LINUX</a></li><li><a href="#deploy-the-app-on-the-swarm-manager">Deploy the app on the swarm manager</a></li><li><a href="#accessing-your-cluster">Accessing your cluster</a></li></ul></li><li><a href="#iterating-and-scaling-your-app">Iterating and scaling your app</a></li><li><a href="#cleanup-and-reboot">Cleanup and reboot</a><ul><li><a href="#stacks-and-swarms">Stacks and swarms</a></li><li><a href="#unsetting-docker-machine-shell-variable-settings">Unsetting docker-machine shell variable settings</a></li><li><a href="#restarting-docker-machines">Restarting Docker machines</a></li></ul></li><li><a href="#recap-and-cheat-sheet-optional">Recap and cheat sheet (optional)</a></li></ul></li><li><a href="#stacks">Stacks</a><ul><li><a href="#introduction">Introduction</a></li><li><a href="#add-a-new-service-and-redeploy">Add a new service and redeploy</a></li></ul></li></ul></li><li><a href="#replace-usernamerepotag-with-your-name-and-image-details-1">replace username/repo:tag with your name and image details</a><ul><li><a href="#persist-the-data">Persist the data</a></li></ul></li><li><a href="#replace-usernamerepotag-with-your-name-and-image-details-2">replace username/repo:tag with your name and image details</a><ul><li><a href="#docker-overview">Docker overview</a><ul><li><a href="#the-docker-platform">The Docker platform</a></li><li><a href="#docker-engine">Docker Engine</a></li><li><a href="#what-can-i-use-docker-for">What can I use Docker for?</a></li><li><a href="#docker-architecture">Docker architecture</a><ul><li><a href="#the-docker-daemon">The Docker daemon</a></li><li><a href="#the-docker-client">The Docker client</a></li><li><a href="#docker-registries">Docker registries</a></li><li><a href="#docker-objects">Docker objects</a><ul><li><a href="#images">IMAGES</a></li><li><a href="#containers">CONTAINERS</a><ul><li><a href="#exampledocker-runcommand">Example <strong>docker run</strong> command</a></li></ul></li><li><a href="#services">Services</a></li></ul></li></ul></li><li><a href="#the-underlying-technology">The underlying technology</a><ul><li><a href="#namespaces">Namespaces</a></li><li><a href="#control-groups">Control groups</a></li><li><a href="#union-file-systems">Union file systems</a></li><li><a href="#container-format">Container format</a></li></ul></li></ul></li></ul></li><li><a href="#develop-with-docker">Develop with Docker</a><ul><li><a href="#develop-new-apps-on-docker">Develop new apps on Docker</a></li><li><a href="#learn-about-language-specific-app-development-with-docker">Learn about language-specific app development with Docker</a></li><li><a href="#advanced-development-with-the-sdk-or-api">Advanced development with the SDK or API</a></li><li><a href="#docker-development-best-practices">Docker development best practices</a><ul><li><a href="#how-to-keep-your-images-small">How to keep your images small</a></li><li><a href="#where-and-how-to-persist-application-data">Where and how to persist application data</a></li><li><a href="#use-swarm-services-when-possible">Use swarm services when possible</a></li><li><a href="#use-cicd-for-testing-and-deployment">Use CI/CD for testing and deployment</a></li><li><a href="#differences-in-development-and-production-environments">Differences in development and production environments</a></li></ul></li><li><a href="#develop-images">Develop Images</a><ul><li><a href="#best-practices-for-writing-dockerfiles">Best practices for writing Dockerfiles</a><ul><li><a href="#general-guidelines-and-recommendations">General guidelines and recommendations</a><ul><li><a href="#containers-should-be-ephemeral">Containers should be ephemeral</a><ul><li><a href="#use-a-dockerignore-file">Use a .dockerignore file</a></li></ul></li><li><a href="#use-multi-stage-builds">Use multi-stage builds</a></li></ul></li></ul></li></ul></li></ul></li><li><a href="#install-tools-required-to-build-the-project">Install tools required to build the project</a></li><li><a href="#we-need-to-run-docker-build---no-cache--to-update-those-dependencies">We need to run <code>docker build --no-cache .</code> to update those dependencies</a></li><li><a href="#gopkgtoml-and-gopkglock-lists-project-dependencies">Gopkg.toml and Gopkg.lock lists project dependencies</a></li><li><a href="#these-layers-are-only-re-built-when-gopkg-files-are-updated">These layers are only re-built when Gopkg files are updated</a></li><li><a href="#install-library-dependencies">Install library dependencies</a></li><li><a href="#copy-all-project-and-build-it">Copy all project and build it</a></li><li><a href="#this-layer-is-rebuilt-when-ever-a-file-has-changed-in-the-project-directory">This layer is rebuilt when ever a file has changed in the project directory</a></li><li><a href="#this-results-in-a-single-layer-image">This results in a single layer image</a><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-undefined" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [Avoid installing unnecessary packages](#avoid-installing-unnecessary-packages)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [Each container should have only one concern](#each-container-should-have-only-one-concern)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [Minimize the number of layers](#minimize-the-number-of-layers)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [Sort multi-line arguments](#sort-multi-line-arguments)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [Build cache](#build-cache)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [The Dockerfile instructions](#the-dockerfile-instructions)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [FROM](#from)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [LABEL](#label)</span></div></pre></div></li><li><a href="#set-one-or-more-individual-labels">Set one or more individual labels</a></li><li><a href="#set-multiple-labels-on-one-line">Set multiple labels on one line</a></li><li><a href="#set-multiple-labels-at-once-using-line-continuation-characters-to-break-long-lines">Set multiple labels at once, using line-continuation characters to break long lines</a><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-undefined" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [RUN](#run)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [APT-GET](#apt-get)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [USING PIPES](#using-pipes)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [CMD](#cmd)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [EXPOSE](#expose)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [ENV](#env)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [ADD or COPY](#add-or-copy)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [ENTRYPOINT](#entrypoint)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [VOLUME](#volume)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [USER](#user)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [WORKDIR](#workdir)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [ONBUILD](#onbuild)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [Examples for Official Repositories](#examples-for-official-repositories)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [Additional resources](#additional-resources)</span></div></pre></div><ul><li><a href="#create-a-base-image">Create a base image</a><ul><li><a href="#create-a-full-image-using-tar">Create a full image using tar</a></li><li><a href="#create-a-simple-parent-image-using-scratch">Create a simple parent image using scratch</a></li><li><a href="#more-resources">More resources</a></li></ul></li><li><a href="#use-multi-stage-builds-1">Use multi-stage builds</a><ul><li><a href="#before-multi-stage-builds">Before multi-stage builds</a></li><li><a href="#use-multi-stage-builds-2">Use multi-stage builds</a></li><li><a href="#name-your-build-stages">Name your build stages</a></li><li><a href="#stop-at-a-specific-build-stage">Stop at a specific build stage</a></li><li><a href="#use-an-external-image-as-a-stage">Use an external image as a &quot;stage&quot;</a></li></ul></li><li><a href="#dockerfile-reference-unread-ref">Dockerfile reference (Unread) (REF)</a><ul><li><a href="#usage">Usage</a></li><li><a href="#format">Format</a></li></ul></li></ul></li><li><a href="#comment">Comment</a></li><li><a href="#comment-1">Comment</a><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-undefined" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [Parser directives](#parser-directives)</span></div></pre></div></li><li>[direc <!-- -->]<!-- -->(#direc-)</li><li><a href="#directivevalue1">directive=value1</a></li><li><a href="#directivevalue2">directive=value2</a></li><li><a href="#directivevalue">directive=value</a></li><li><a href="#about-my-dockerfile">About my dockerfile</a></li><li><a href="#directivevalue-1">directive=value</a></li><li><a href="#unknowndirectivevalue">unknowndirective=value</a></li><li><a href="#knowndirectivevalue">knowndirective=value</a></li><li><a href="#directive-value">directive =value</a></li><li><a href="#directive-value-1">directive= value</a></li><li><a href="#directive--value">directive = value</a></li><li><a href="#directivevalue-2">dIrEcTiVe=value</a><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-undefined" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [escape](#escape)</span></div></pre></div></li><li><a href="#escape-backslash">escape=\ (backslash)</a></li><li><a href="#escape-backtick">escape=` (backtick)</a></li><li><a href="#escape-1">escape=`</a><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-undefined" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [Environment replacement](#environment-replacement)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [.dockerignore file](#dockerignore-file)</span></div></pre></div></li><li><a href="#comment-2">comment</a></li><li><a href="#comment-----ignored">comment     Ignored.</a><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-undefined" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [FROM](#from-1)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [Understand how ARG and FROM interact](#understand-how-arg-and-from-interact)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [RUN](#run-1)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [Known issues (RUN)](#known-issues-run)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [CMD](#cmd-1)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [LABEL](#label-1)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [MAINTAINER (deprecated)](#maintainer-deprecated)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [EXPOSE](#expose-1)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [ENV](#env-1)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [ADD](#add)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [COPY](#copy)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [ENTRYPOINT](#entrypoint-1)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [Exec form ENTRYPOINT example](#exec-form-entrypoint-example)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [Shell form ENTRYPOINT example](#shell-form-entrypoint-example)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [Understand how CMD and ENTRYPOINT interact](#understand-how-cmd-and-entrypoint-interact)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [VOLUME](#volume-1)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [Notes about specifying volumes](#notes-about-specifying-volumes)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [USER](#user-1)</span></div></pre></div></li><li><a href="#create-windows-user-in-the-container">Create Windows user in the container</a></li><li><a href="#set-it-for-subsequent-commands">Set it for subsequent commands</a><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-undefined" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [WORKDIR](#workdir-1)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [ARG](#arg)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [Default values](#default-values)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [Scope](#scope)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [Using ARG variables](#using-arg-variables)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [Predefined ARGs](#predefined-args)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [Impact on build caching](#impact-on-build-caching)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [ONBUILD](#onbuild-1)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [STOPSIGNAL](#stopsignal)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [HEALTHCHECK](#healthcheck)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [SHELL](#shell)</span></div></pre></div></li><li><a href="#executed-as-cmd-s-c-echo-default">Executed as cmd /S /C echo default</a></li><li><a href="#executed-as-cmd-s-c-powershell--command-write-host-default">Executed as cmd /S /C powershell -command Write-Host default</a></li><li><a href="#executed-as-powershell--command-write-host-hello">Executed as powershell -command Write-Host hello</a></li><li><a href="#executed-as-cmd-s-c-echo-hello">Executed as cmd /S /C echo hello</a></li><li><a href="#escape-2">escape=`</a><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-undefined" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [Dockerfile examples](#dockerfile-examples)</span></div></pre></div></li><li><a href="#nginx">Nginx</a></li><li><a href="#version-001">VERSION 0.0.1</a></li><li><a href="#firefox-over-vnc">Firefox over VNC</a></li><li><a href="#version-03">VERSION 0.3</a></li><li><a href="#install-vnc-xvfb-in-order-to-create-a-fake-display-and-firefox">Install vnc, xvfb in order to create a \&#x27;fake\&#x27; display and firefox</a></li><li><a href="#setup-a-password">Setup a password</a></li><li><a href="#autostart-firefox-might-not-be-the-best-way-but-it-does-the-trick">Autostart firefox (might not be the best way, but it does the trick)</a></li><li><a href="#multiple-images-example">Multiple images example</a></li><li><a href="#version-01">VERSION 0.1</a></li><li><a href="#will-output-something-like--907ad6c2736f">Will output something like ===&gt; 907ad6c2736f</a></li><li><a href="#will-output-something-like--695d7793cbe4">Will output something like ===&gt; 695d7793cbe4</a></li><li><a href="#youll-now-have-two-images-907ad6c2736f-with-bar-and-695d7793cbe4-with">You\&#x27;ll now have two images, 907ad6c2736f with /bar, and 695d7793cbe4 with</a></li><li><a href="#oink">/oink.</a><ul><li><a href="#manage-images">Manage images</a><ul><li><a href="#docker-hub">Docker Hub</a></li><li><a href="#docker-registry">Docker Registry</a></li><li><a href="#docker-trusted-registry">Docker Trusted Registry</a></li><li><a href="#content-trust">Content Trust</a></li></ul></li><li><a href="#samples-to-be-done">Samples (To Be Done)</a><ul><li><a href="#tutorial-labs">Tutorial labs</a></li><li><a href="#library-references">Library references</a></li><li><a href="#sample-applications">Sample applications</a></li></ul></li><li><a href="#develop-with-docker-engine-sdks-and-api">Develop with Docker Engine SDKs and API</a><ul><li><a href="#install-the-sdks">Install the SDKs</a><ul><li><a href="#go-sdk">Go SDK</a></li><li><a href="#python-sdk">Python SDK</a></li></ul></li><li><a href="#view-the-api-reference">View the API reference</a></li><li><a href="#versioned-api-and-sdk">Versioned API and SDK</a><ul><li><a href="#docker-ee-and-ce-api-mismatch">Docker EE and CE API mismatch</a></li><li><a href="#api-version-matrix">API version matrix</a></li><li><a href="#choose-the-sdk-or-api-version-to-use">Choose the SDK or API version to use</a></li></ul></li><li><a href="#sdk-and-api-quickstart">SDK and API quickstart</a></li><li><a href="#unofficial-libraries">Unofficial libraries</a></li></ul></li><li><a href="#examples-using-the-docker-engine-sdks-and-docker-api">Examples using the Docker Engine SDKs and Docker API</a></li></ul></li><li><a href="#configuring-networks">Configuring Networks</a><ul><li><a href="#network-overview">Network Overview</a><ul><li><a href="#scope-of-this-topic">Scope of this topic</a></li><li><a href="#network-drivers">Network drivers</a><ul><li><a href="#network-driver-summary">Network driver summary</a></li></ul></li><li><a href="#docker-ee-networking-features">Docker EE networking features</a></li><li><a href="#networking-tutorials">Networking tutorials</a></li></ul></li><li><a href="#use-bridge-networks">Use bridge networks</a><ul><li><a href="#differences-between-user-defined-bridges-and-the-default-bridge">Differences between user-defined bridges and the default bridge</a></li><li><a href="#manage-a-user-defined-bridge">Manage a user-defined bridge</a></li><li><a href="#connect-a-container-to-a-user-defined-bridge">Connect a container to a user-defined bridge</a></li><li><a href="#disconnect-a-container-from-a-user-defined-bridge">Disconnect a container from a user-defined bridge</a></li><li><a href="#use-ipv6">Use IPv6</a></li><li><a href="#enable-forwarding-from-docker-containers-to-the-outside-world">Enable forwarding from Docker containers to the outside world</a></li><li><a href="#use-the-default-bridge-network">Use the default bridge network</a><ul><li><a href="#connect-a-container-to-the-default-bridge-network">Connect a container to the default bridge network</a></li><li><a href="#configure-the-default-bridge-network">Configure the default bridge network</a></li><li><a href="#use-ipv6-with-the-default-bridge-network">Use IPv6 with the default bridge network</a></li></ul></li><li><a href="#next-steps">Next steps</a></li></ul></li><li><a href="#use-overlay-networks">Use overlay networks</a><ul><li><a href="#operations-for-all-overlay-networks">Operations for all overlay networks</a><ul><li><a href="#create-an-overlay-network">Create an overlay network</a></li><li><a href="#encrypt-traffic-on-an-overlay-network">Encrypt traffic on an overlay network</a><ul><li><a href="#swarm-mode-overlay-networks-and-standalone-containers"><strong>SWARM MODE OVERLAY NETWORKS AND STANDALONE CONTAINERS</strong></a></li></ul></li><li><a href="#customize-the-default-ingress-network">Customize the default ingress network</a></li><li><a href="#customize-the-docker_gwbridge-interface">Customize the docker_gwbridge interface</a></li></ul></li><li><a href="#operations-for-swarm-services">Operations for swarm services</a><ul><li><a href="#publish-ports-on-an-overlay-network">Publish ports on an overlay network</a></li><li><a href="#bypass-the-routing-mesh-for-a-swarm-service">Bypass the routing mesh for a swarm service</a></li><li><a href="#separate-control-and-data-traffic">Separate control and data traffic</a></li></ul></li><li><a href="#operations-for-standalone-containers-on-overlay-networks">Operations for standalone containers on overlay networks</a><ul><li><a href="#attach-a-standalone-container-to-an-overlay-network">Attach a standalone container to an overlay network</a></li><li><a href="#publish-ports">Publish ports</a></li></ul></li><li><a href="#next-steps-1">Next steps</a></li></ul></li><li><a href="#use-host-networking">Use host networking</a><ul><li><a href="#next-steps-2">Next steps</a></li></ul></li><li><a href="#use-macvlan-networks">Use Macvlan networks</a><ul><li><a href="#create-a-macvlan-network">Create a macvlan network</a><ul><li><a href="#bridge-mode">Bridge mode</a></li><li><a href="#8021q-trunk-bridge-mode">802.1q trunk bridge mode</a></li><li><a href="#use-an-ipvlan-instead-of-macvlan">Use an ipvlan instead of macvlan</a></li></ul></li><li><a href="#use-ipv6-1">Use IPv6</a></li><li><a href="#next-steps-3">Next steps</a></li></ul></li><li><a href="#disable-networking-for-a-container">Disable networking for a container</a><ul><li><a href="#next-steps-4">Next steps</a></li></ul></li><li><a href="#networing-tutorials">Networing Tutorials</a><ul><li><a href="#networking-with-standalone-containers">Networking with standalone containers</a><ul><li><a href="#use-the-default-bridge-network-1">Use the default bridge network</a></li></ul></li></ul></li></ul></li><li><a href="#ip-addr-show">ip addr show</a></li><li><a href="#ping--c-2-alpine2">ping -c 2 alpine2</a><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-undefined" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [Use user-defined bridge networks](#use-user-defined-bridge-networks)</span></div></pre></div></li><li><a href="#ping--c-2-1721702">ping -c 2 172.17.0.2</a><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-undefined" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [Other networking tutorials](#other-networking-tutorials)</span></div></pre></div><ul><li><a href="#networking-using-the-host-network">Networking using the host network</a><ul><li><a href="#goal">Goal</a></li><li><a href="#prerequisites-1">Prerequisites</a></li><li><a href="#procedure">Procedure</a></li><li><a href="#other-networking-tutorials-1">Other networking tutorials</a></li></ul></li><li><a href="#networking-with-overlay-networks">Networking with overlay networks</a><ul><li><a href="#prerequisites-2">Prerequisites</a></li><li><a href="#use-the-default-overlay-network">Use the default overlay network</a><ul><li><a href="#prerequisites-3"><strong>Prerequisites</strong></a></li><li><a href="#walkthrough"><strong>Walkthrough</strong></a><ul><li><a href="#create-the-swarm"><strong>CREATE THE SWARM</strong></a></li><li><a href="#create-the-services"><strong>CREATE THE SERVICES</strong></a></li></ul></li></ul></li><li><a href="#use-a-user-defined-overlay-network">Use a user-defined overlay network</a><ul><li><a href="#prerequisites-4"><strong>Prerequisites</strong></a></li><li><a href="#walkthrough-1"><strong>Walkthrough</strong></a></li></ul></li><li><a href="#use-an-overlay-network-for-standalone-containers">Use an overlay network for standalone containers</a><ul><li><a href="#prerequisites-5"><strong>Prerequisites</strong></a></li><li><a href="#walk-through"><strong>Walk-through</strong></a></li></ul></li></ul></li></ul></li><li><a href="#ping--c-2-alpine1">ping -c 2 alpine1</a><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-undefined" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [Communicate between a container and a swarm service](#communicate-between-a-container-and-a-swarm-service)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Prerequisites**](#prerequisites-6)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Walkthrough**](#walkthrough-2)</span></div></pre></div></li><li><a href="#ip-addr-show-1">ip addr show</a></li><li><a href="#ping--c-2-alpine2-1">ping -c 2 alpine2</a><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-undefined" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [Other networking tutorials](#other-networking-tutorials-2)</span></div></pre></div><ul><li><a href="#networking-using-a-macvlan-network">Networking using a macvlan network</a><ul><li><a href="#goal-1">Goal</a></li><li><a href="#prerequisites-7">Prerequisites</a></li><li><a href="#bridge-example">Bridge example</a></li><li><a href="#8021q-trunked-bridge-example">802.1q trunked bridge example</a></li><li><a href="#other-networking-tutorials-3">Other networking tutorials</a></li></ul></li><li><a href="#configure-the-daemon-and-the-containers">Configure the Daemon and the Containers</a><ul><li><a href="#enable-ipv6-support">Enable IPv6 support</a><ul><li><a href="#next-steps-5"><strong>Next steps</strong></a></li></ul></li><li><a href="#docker-and-iptables">Docker and iptables</a><ul><li><a href="#add-iptables-policies-before-dockers-rules"><strong>Add iptables policies before Docker&#x27;s rules</strong></a><ul><li><a href="#restrict-connections-to-the-docker-daemon"><strong>Restrict connections to the Docker daemon</strong></a></li></ul></li><li><a href="#prevent-docker-from-manipulating-iptables"><strong>Prevent Docker from manipulating iptables</strong></a></li><li><a href="#next-steps-6"><strong>Next steps</strong></a></li></ul></li><li><a href="#container-networking">Container networking</a><ul><li><a href="#published-ports"><strong>Published ports</strong></a></li><li><a href="#ip-address-and-hostname"><strong>IP address and hostname</strong></a></li><li><a href="#dns-services"><strong>DNS services</strong></a></li><li><a href="#proxy-server"><strong>Proxy server</strong></a></li></ul></li><li><a href="#configure-docker-to-use-a-proxy-server">Configure Docker to use a proxy server</a><ul><li><a href="#configure-the-docker-client"><strong>Configure the Docker client</strong></a></li><li><a href="#use-environment-variables"><strong>Use environment variables</strong></a><ul><li><a href="#set-the-environment-variables-manually"><strong>Set the environment variables manually</strong></a></li></ul></li></ul></li></ul></li><li><a href="#legacy-networing-content">Legacy Networing Content</a><ul><li><a href="#legacy-container-links">Legacy container links</a><ul><li><a href="#connect-using-network-port-mapping">Connect using network port mapping</a></li><li><a href="#connect-with-the-linking-system">Connect with the linking system</a><ul><li><a href="#the-importance-of-naming"><strong>The importance of naming</strong></a></li></ul></li><li><a href="#communication-across-links">Communication across links</a><ul><li><a href="#environment-variables"><strong>Environment variables</strong></a></li><li><a href="#important-notes-on-docker-environment-variables"><strong>Important notes on Docker environment variables</strong></a></li><li><a href="#updating-theetchostsfile"><strong>Updating the /etc/hosts file</strong></a></li></ul></li></ul></li><li><a href="#multi-host-networking-with-standalone-swarms">Multi-host networking with standalone swarms</a><ul><li><a href="#standalone-swarm-only">Standalone swarm only!</a></li><li><a href="#overlay-networking-with-an-external-key-value-store">Overlay networking with an external key-value store</a><ul><li><a href="#prerequisites-8"><strong>Prerequisites</strong></a></li><li><a href="#set-up-a-key-value-store"><strong>Set up a key-value store</strong></a></li><li><a href="#create-a-swarm-cluster"><strong>Create a swarm cluster</strong></a></li><li><a href="#create-the-overlay-network"><strong>Create the overlay network</strong></a></li><li><a href="#run-an-application-on-your-network"><strong>Run an application on your network</strong></a></li><li><a href="#check-external-connectivity"><strong>Check external connectivity</strong></a></li></ul></li><li><a href="#use-docker-compose-with-swarm-classic">Use Docker Compose with swarm classic</a></li><li><a href="#next-steps-7">Next steps</a></li></ul></li></ul></li></ul></li><li><a href="#manage-data-in-docker">Manage data in Docker</a><ul><li><a href="#choose-the-right-type-of-mount">Choose the right type of mount</a><ul><li><a href="#more-details-about-mount-types">More details about mount types</a></li><li><a href="#good-use-cases-for-volumes">Good use cases for volumes</a></li><li><a href="#good-use-cases-for-bind-mounts">Good use cases for bind mounts</a></li><li><a href="#good-use-cases-for-tmpfs-mounts">Good use cases for tmpfs mounts</a></li><li><a href="#tips-for-using-bind-mounts-or-volumes">Tips for using bind mounts or volumes</a></li><li><a href="#next-steps-8">Next steps</a></li></ul></li><li><a href="#use-volumes">Use volumes</a><ul><li><a href="#choose-the--v-or---mount-flag">Choose the -v or --mount flag</a><ul><li><a href="#differences-between-vand--mountbehavior">Differences between -v and --mount behavior</a></li></ul></li><li><a href="#create-and-manage-volumes">Create and manage volumes</a></li><li><a href="#start-a-container-with-a-volume">Start a container with a volume</a><ul><li><a href="#start-a-service-with-volumes">Start a service with volumes</a><ul><li><a href="#syntax-differences-for-services"><strong>SYNTAX DIFFERENCES FOR SERVICES</strong></a></li></ul></li><li><a href="#populate-a-volume-using-a-container">Populate a volume using a container</a></li></ul></li><li><a href="#use-a-read-only-volume">Use a read-only volume</a></li><li><a href="#use-a-volume-driver">Use a volume driver</a><ul><li><a href="#initial-set-up">Initial set-up</a></li><li><a href="#create-a-volume-using-a-volume-driver">Create a volume using a volume driver</a></li><li><a href="#start-a-container-which-creates-a-volume-using-a-volume-driver">Start a container which creates a volume using a volume driver</a></li></ul></li><li><a href="#next-steps-9">Next steps</a></li></ul></li><li><a href="#use-bind-mounts">Use bind mounts</a><ul><li><a href="#choosing-the--v-or---mount-flag">Choosing the -v or --mount flag</a><ul><li><a href="#differences-between-vand--mountbehavior-1">Differences between -v and --mount behavior</a></li></ul></li><li><a href="#start-a-container-with-a-bind-mount">Start a container with a bind mount</a><ul><li><a href="#mounting-into-a-non-empty-directory-on-the-container">Mounting into a non-empty directory on the container</a></li></ul></li><li><a href="#use-a-read-only-bind-mount">Use a read-only bind mount</a></li><li><a href="#configure-bind-propagation">Configure bind propagation</a></li><li><a href="#configure-the-selinux-label">Configure the selinux label</a></li><li><a href="#configure-mount-consistency-for-macos">Configure mount consistency for macOS</a></li><li><a href="#next-steps-10">Next steps</a></li></ul></li><li><a href="#use-tmpfs-mounts">Use tmpfs mounts</a><ul><li><a href="#choosing-the---tmpfs-or---mount-flag">Choosing the --tmpfs or --mount flag</a><ul><li><a href="#differences-between--tmpfsand--mountbehavior">Differences between --tmpfs and --mount behavior</a></li></ul></li><li><a href="#limitations-of-tmpfs-containers">Limitations of tmpfs containers</a></li><li><a href="#use-a-tmpfs-mount-in-a-container">Use a tmpfs mount in a container</a><ul><li><a href="#specify-tmpfs-options">Specify tmpfs options</a></li></ul></li><li><a href="#next-steps-11">Next steps</a></li></ul></li><li><a href="#troubleshoot-volume-errors">Troubleshoot volume errors</a><ul><li><a href="#error-unable-to-remove-filesystem">Error: Unable to remove filesystem</a></li></ul></li><li><a href="#store-data-within-containers">Store Data within Containers</a><ul><li><a href="#about-storage-drivers">About storage drivers</a><ul><li><a href="#images-and-layers">Images and layers</a></li><li><a href="#container-and-layers">Container and layers</a></li><li><a href="#container-size-on-disk">Container size on disk</a></li><li><a href="#the-copy-on-write-cow-strategy">The copy-on-write (CoW) strategy</a><ul><li><a href="#sharing-promotes-smaller-images"><strong>Sharing promotes smaller images</strong></a></li><li><a href="#copying-makes-containers-efficient"><strong>Copying makes containers efficient</strong></a></li></ul></li><li><a href="#data-volumes-and-the-storage-driver">Data volumes and the storage driver</a></li><li><a href="#related-information">Related information</a></li></ul></li><li><a href="#docker-storage-drivers">Docker storage drivers</a><ul><li><a href="#supported-storage-drivers-per-linux-distribution">Supported storage drivers per Linux distribution</a><ul><li><a href="#docker-ee-and-cs-engine"><strong>Docker EE and CS-Engine</strong></a></li><li><a href="#docker-ce"><strong>Docker CE</strong></a></li><li><a href="#docker-for-mac-and-docker-for-windows"><strong>Docker for Mac and Docker for Windows</strong></a></li></ul></li><li><a href="#supported-backing-filesystems">Supported backing filesystems</a></li><li><a href="#other-considerations">Other considerations</a><ul><li><a href="#suitability-for-your-workload"><strong>Suitability for your workload</strong></a></li><li><a href="#shared-storage-systems-and-the-storage-driver"><strong>Shared storage systems and the storage driver</strong></a></li><li><a href="#stability"><strong>Stability</strong></a></li><li><a href="#experience-and-expertise"><strong>Experience and expertise</strong></a></li><li><a href="#test-with-your-own-workloads"><strong>Test with your own workloads</strong></a></li></ul></li><li><a href="#check-your-current-storage-driver">Check your current storage driver</a></li><li><a href="#related-information-1">Related information</a></li></ul></li><li><a href="#use-the-aufs-storage-driver">Use the AUFS storage driver</a><ul><li><a href="#prerequisites-9">Prerequisites</a></li><li><a href="#configure-docker-with-theaufsstorage-driver">Configure Docker with the aufs storage driver</a></li><li><a href="#how-theaufsstorage-driver-works">How the aufs storage driver works</a><ul><li><a href="#example-image-and-container-on-disk-constructs"><strong>Example: Image and container on-disk constructs</strong></a><ul><li><a href="#the-image-layers"><strong>THE IMAGE LAYERS</strong></a></li><li><a href="#the-container-layer"><strong>THE CONTAINER LAYER</strong></a></li></ul></li></ul></li><li><a href="#how-container-reads-and-writes-work-withaufs">How container reads and writes work with aufs</a><ul><li><a href="#reading-files"><strong>Reading files</strong></a></li><li><a href="#modifying-files-or-directories"><strong>Modifying files or directories</strong></a></li></ul></li><li><a href="#aufs-and-docker-performance">AUFS and Docker performance</a><ul><li><a href="#performance-best-practices"><strong>Performance best practices</strong></a></li></ul></li><li><a href="#related-information-2">Related information</a></li></ul></li><li><a href="#use-the-btrfs-storage-driver">Use the BTRFS storage driver</a><ul><li><a href="#prerequisites-10">Prerequisites</a></li><li><a href="#configure-docker-to-use-the-btrfs-storage-driver">Configure Docker to use the btrfs storage driver</a></li><li><a href="#manage-a-btrfs-volume">Manage a Btrfs volume</a></li><li><a href="#how-thebtrfsstorage-driver-works">How the btrfs storage driver works</a><ul><li><a href="#image-and-container-layers-on-disk"><strong>Image and container layers on-disk</strong></a></li></ul></li><li><a href="#how-container-reads-and-writes-work-withbtrfs">How container reads and writes work with btrfs</a><ul><li><a href="#reading-files-1"><strong>Reading files</strong></a></li><li><a href="#writing-files"><strong>Writing files</strong></a></li></ul></li><li><a href="#btrfs-and-docker-performance">Btrfs and Docker performance</a></li><li><a href="#related-information-3">Related Information</a></li></ul></li><li><a href="#use-the-device-mapper-storage-driver">Use the Device Mapper storage driver</a><ul><li><a href="#prerequisites-11">Prerequisites</a></li><li><a href="#configure-docker-with-thedevicemapperstorage-driver">Configure Docker with the devicemapper storage driver</a><ul><li><a href="#configureloop-lvmmode-for-testing"><strong>Configure loop-lvm mode for testing</strong></a></li><li><a href="#configure-direct-lvm-mode-for-production"><strong>Configure direct-lvm mode for production</strong></a><ul><li><a href="#allow-docker-to-configure-direct-lvm-mode"><strong>ALLOW DOCKER TO CONFIGURE DIRECT-LVM MODE</strong></a></li><li><a href="#configure-direct-lvm-mode-manually"><strong>CONFIGURE DIRECT-LVM MODE MANUALLY</strong></a></li></ul></li></ul></li><li><a href="#manage-devicemapper">Manage devicemapper</a><ul><li><a href="#monitor-the-thin-pool"><strong>Monitor the thin pool</strong></a></li><li><a href="#increase-capacity-on-a-running-device"><strong>Increase capacity on a running device</strong></a><ul><li><a href="#resize-a-loop-lvm-thin-pool"><strong>RESIZE A LOOP-LVM THIN POOL</strong></a></li><li><a href="#resize-a-direct-lvm-thin-pool"><strong>RESIZE A DIRECT-LVM THIN POOL</strong></a></li></ul></li><li><a href="#activate-thedevicemapperafter-reboot"><strong>Activate the devicemapper after reboot</strong></a></li></ul></li><li><a href="#how-thedevicemapperstorage-driver-works">How the devicemapper storage driver works</a><ul><li><a href="#image-and-container-layers-on-disk-1"><strong>Image and container layers on-disk</strong></a></li><li><a href="#image-layering-and-sharing"><strong>Image layering and sharing</strong></a><ul><li><a href="#snapshots"><strong>SNAPSHOTS</strong></a></li><li><a href="#devicemapper-workflow"><strong>DEVICEMAPPER WORKFLOW</strong></a></li></ul></li></ul></li><li><a href="#how-container-reads-and-writes-work-withdevicemapper">How container reads and writes work with devicemapper</a><ul><li><a href="#reading-files-2"><strong>Reading files</strong></a></li><li><a href="#writing-files-1"><strong>Writing files</strong></a></li></ul></li><li><a href="#device-mapper-and-docker-performance">Device Mapper and Docker performance</a><ul><li><a href="#performance-best-practices-1"><strong>Performance best practices</strong></a></li></ul></li><li><a href="#related-information-4">Related Information</a></li></ul></li><li><a href="#use-the-overlayfs-storage-driver">Use the OverlayFS storage driver</a><ul><li><a href="#prerequisites-12">Prerequisites</a></li><li><a href="#configure-docker-with-theoverlayoroverlay2storage-driver">Configure Docker with the overlay or overlay2storage driver</a></li><li><a href="#how-theoverlay2driver-works">How the overlay2 driver works</a><ul><li><a href="#image-and-container-layers-on-disk-2"><strong>Image and container layers on-disk</strong></a></li></ul></li><li><a href="#how-theoverlaydriver-works">How the overlay driver works</a><ul><li><a href="#image-and-container-layers-on-disk-3"><strong>Image and container layers on-disk</strong></a><ul><li><a href="#the-image-layers-1"><strong>THE IMAGE LAYERS</strong></a></li><li><a href="#the-container-layer-1"><strong>THE CONTAINER LAYER</strong></a></li></ul></li></ul></li><li><a href="#how-container-reads-and-writes-work-withoverlayoroverlay2">How container reads and writes work with overlayor overlay2</a><ul><li><a href="#reading-files-3"><strong>Reading files</strong></a></li><li><a href="#modifying-files-or-directories-1"><strong>Modifying files or directories</strong></a></li></ul></li><li><a href="#overlayfs-and-docker-performance">OverlayFS and Docker Performance</a><ul><li><a href="#performance-best-practices-2"><strong>Performance best practices</strong></a></li></ul></li><li><a href="#limitations-on-overlayfs-compatibility">Limitations on OverlayFS compatibility</a></li></ul></li><li><a href="#use-the-zfs-storage-driver">Use the ZFS storage driver</a><ul><li><a href="#prerequisites-13">Prerequisites</a></li><li><a href="#configure-docker-with-thezfsstorage-driver">Configure Docker with the zfs storage driver</a></li><li><a href="#managezfs">Manage zfs</a><ul><li><a href="#increase-capacity-on-a-running-device-1"><strong>Increase capacity on a running device</strong></a></li><li><a href="#limit-a-containers-writable-storage-quota"><strong>Limit a container&#x27;s writable storage quota</strong></a></li></ul></li><li><a href="#how-thezfsstorage-driver-works">How the zfs storage driver works</a><ul><li><a href="#image-and-container-layers-on-disk-4"><strong>Image and container layers on-disk</strong></a></li><li><a href="#image-layering-and-sharing-1"><strong>Image layering and sharing</strong></a></li></ul></li><li><a href="#how-container-reads-and-writes-work-withzfs">How container reads and writes work with zfs</a><ul><li><a href="#reading-files-4"><strong>Reading files</strong></a></li><li><a href="#writing-files-2"><strong>Writing files</strong></a></li></ul></li><li><a href="#zfs-and-docker-performance">ZFS and Docker performance</a><ul><li><a href="#performance-best-practices-3"><strong>Performance best practices</strong></a></li></ul></li></ul></li><li><a href="#use-the-vfs-storage-driver">Use the VFS storage driver</a><ul><li><a href="#configure-docker-with-thevfsstorage-driver">Configure Docker with the vfs storage driver</a></li><li><a href="#how-thevfsstorage-driver-works">How the vfs storage driver works</a><ul><li><a href="#example-image-and-container-on-disk-constructs-1"><strong>Example: Image and container on-disk constructs</strong></a></li></ul></li><li><a href="#related-information-5">Related information</a></li><li><a href="#run-your-app-in-production">Run Your App in Production</a></li></ul></li></ul></li><li><a href="#configure-all-objects">Configure All Objects</a><ul><li><a href="#docker-object-labels">Docker object labels</a><ul><li><a href="#label-keys-and-values">Label keys and values</a><ul><li><a href="#key-format-recommendations"><strong>Key format recommendations</strong></a></li><li><a href="#value-guidelines"><strong>Value guidelines</strong></a></li></ul></li><li><a href="#manage-labels-on-objects">Manage labels on objects</a></li></ul></li><li><a href="#prune-unused-docker-objects">Prune unused Docker objects</a><ul><li><a href="#prune-images">Prune images</a></li><li><a href="#prune-containers">Prune containers</a></li><li><a href="#prune-volumes">Prune volumes</a></li><li><a href="#prune-networks">Prune networks</a></li><li><a href="#prune-everything">Prune everything</a></li></ul></li><li><a href="#format-command-and-log-output">Format command and log output</a><ul><li><a href="#join">join</a></li><li><a href="#json">json</a></li><li><a href="#lower">lower</a></li><li><a href="#split">split</a></li><li><a href="#title">title</a></li><li><a href="#upper">upper</a></li><li><a href="#println">println</a></li></ul></li></ul></li><li><a href="#configure-the-daemon">Configure the Daemon</a><ul><li><a href="#configure-and-troubleshoot-the-docker-daemon">Configure and troubleshoot the Docker daemon</a><ul><li><a href="#start-the-daemon-using-operating-system-utilities">Start the daemon using operating system utilities</a></li><li><a href="#start-the-daemon-manually">Start the daemon manually</a></li><li><a href="#configure-the-docker-daemon">Configure the Docker daemon</a><ul><li><a href="#troubleshoot-conflicts-between-thedaemonjsonand-startup-scripts"><strong>Troubleshoot conflicts between the daemon.json and startup scripts</strong></a><ul><li><a href="#use-the-hosts-key-in-daemonjson-with-systemd"><strong>USE THE HOSTS KEY IN DAEMON.JSON WITH SYSTEMD</strong></a></li></ul></li></ul></li><li><a href="#troubleshoot-the-daemon">Troubleshoot the daemon</a><ul><li><a href="#out-of-memory-exceptions-oome"><strong>Out Of Memory Exceptions (OOME)</strong></a></li><li><a href="#read-the-logs"><strong>Read the logs</strong></a></li><li><a href="#enable-debugging"><strong>Enable debugging</strong></a></li><li><a href="#force-a-stack-trace-to-be-logged"><strong>Force a stack trace to be logged</strong></a></li><li><a href="#view-stack-traces"><strong>View stack traces</strong></a></li></ul></li><li><a href="#check-whether-docker-is-running">Check whether Docker is running</a></li></ul></li><li><a href="#control-docker-with-systemd">Control Docker with systemd</a><ul><li><a href="#start-the-docker-daemon">Start the Docker daemon</a><ul><li><a href="#start-manually"><strong>Start manually</strong></a></li><li><a href="#start-automatically-at-system-boot"><strong>Start automatically at system boot</strong></a></li></ul></li><li><a href="#custom-docker-daemon-options">Custom Docker daemon options</a><ul><li><a href="#runtime-directory-and-storage-driver"><strong>Runtime directory and storage driver</strong></a></li><li><a href="#httphttps-proxy"><strong>HTTP/HTTPS proxy</strong></a></li></ul></li><li><a href="#configure-where-the-docker-daemon-listens-for-connections-1">Configure where the Docker daemon listens for connections</a></li><li><a href="#manually-create-the-systemd-unit-files">Manually create the systemd unit files</a></li></ul></li><li><a href="#collect-docker-metrics-with-prometheus">Collect Docker metrics with Prometheus</a><ul><li><a href="#configure-docker">Configure Docker</a></li><li><a href="#configure-and-run-prometheus">Configure and run Prometheus</a></li></ul></li></ul></li></ul></li><li><a href="#my-global-config">my global config</a></li><li><a href="#scrape_timeout-is-set-to-the-global-default-10s">scrape_timeout is set to the global default (10s).</a></li><li><a href="#attach-these-labels-to-any-time-series-or-alerts-when-communicating-with">Attach these labels to any time series or alerts when communicating with</a></li><li><a href="#external-systems-federation-remote-storage-alertmanager">external systems (federation, remote storage, Alertmanager).</a></li><li><a href="#load-rules-once-and-periodically-evaluate-them-according-to-the-global-evaluation_interval">Load rules once and periodically evaluate them according to the global \&#x27;evaluation_interval\&#x27;.</a></li><li><a href="#--firstrules">- &quot;first.rules&quot;</a></li><li><a href="#--secondrules">- &quot;second.rules&quot;</a></li><li><a href="#a-scrape-configuration-containing-exactly-one-endpoint-to-scrape">A scrape configuration containing exactly one endpoint to scrape:</a></li><li><a href="#here-its-prometheus-itself">Here it\&#x27;s Prometheus itself.</a></li><li><a href="#the-job-name-is-added-as-a-label-jobjob_name-to-any-timeseries-scraped-from-this-config">The job name is added as a label <code>job=</code>&lt;job_name&gt;`` to any timeseries scraped from this config.</a></li><li><a href="#metrics_path-defaults-to-metrics">metrics_path defaults to \&#x27;/metrics\&#x27;</a></li><li><a href="#scheme-defaults-to-http">scheme defaults to \&#x27;http\&#x27;.</a></li><li><a href="#metrics_path-defaults-to-metrics-1">metrics_path defaults to \&#x27;/metrics\&#x27;</a></li><li><a href="#scheme-defaults-to-http-1">scheme defaults to \&#x27;http\&#x27;.</a><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-undefined" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [Use Prometheus](#use-prometheus)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [Next steps](#next-steps-12)</span></div></pre></div><ul><li><a href="#configure-containers">Configure Containers</a><ul><li><a href="#start-containers-automatically">Start containers automatically</a><ul><li><a href="#use-a-restart-policy">Use a restart policy</a><ul><li><a href="#restart-policy-details"><strong>Restart policy details</strong></a></li></ul></li><li><a href="#use-a-process-manager">Use a process manager</a><ul><li><a href="#using-a-process-manager-inside-containers"><strong>Using a process manager inside containers</strong></a></li></ul></li></ul></li><li><a href="#keep-containers-alive-during-daemon-downtime">Keep containers alive during daemon downtime</a><ul><li><a href="#enable-live-restore">Enable live restore</a></li><li><a href="#live-restore-during-upgrades">Live restore during upgrades</a></li><li><a href="#live-restore-upon-restart">Live restore upon restart</a></li><li><a href="#impact-of-live-restore-on-running-containers">Impact of live restore on running containers</a></li><li><a href="#live-restore-and-swarm-mode">Live restore and swarm mode</a></li></ul></li><li><a href="#run-multiple-services-in-a-container">Run multiple services in a container</a></li><li><a href="#runtime-metrics">Runtime metrics</a><ul><li><a href="#docker-stats">Docker stats</a></li><li><a href="#control-groups-1">Control groups</a><ul><li><a href="#enumerate-cgroups"><strong>Enumerate cgroups</strong></a></li><li><a href="#find-the-cgroup-for-a-given-container"><strong>Find the cgroup for a given container</strong></a></li><li><a href="#metrics-from-cgroups-memory-cpu-block-io"><strong>Metrics from cgroups: memory, CPU, block I/O</strong></a><ul><li><a href="#memory-metricsmemorystat"><strong>MEMORY METRICS: MEMORY.STAT</strong></a></li></ul></li><li><a href="#cpu-metricscpuacctstat"><strong>CPU metrics: cpuacct.stat</strong></a><ul><li><a href="#block-io-metrics"><strong>BLOCK I/O METRICS</strong></a></li></ul></li><li><a href="#network-metrics"><strong>Network metrics</strong></a><ul><li><a href="#iptables"><strong>IPTABLES</strong></a></li><li><a href="#interface-level-counters"><strong>INTERFACE-LEVEL COUNTERS</strong></a></li></ul></li></ul></li><li><a href="#tips-for-high-performance-metric-collection">Tips for high-performance metric collection</a></li><li><a href="#collect-metrics-when-a-container-exits">Collect metrics when a container exits</a></li></ul></li><li><a href="#limit-a-containers-resources">Limit a container\&#x27;s resources</a><ul><li><a href="#memory">Memory</a><ul><li><a href="#understand-the-risks-of-running-out-of-memory"><strong>Understand the risks of running out of memory</strong></a></li><li><a href="#limit-a-containers-access-to-memory"><strong>Limit a container&#x27;s access to memory</strong></a></li><li><a href="#--memory-swapdetails"><strong>--memory-swap details</strong></a><ul><li><a href="#prevent-a-container-from-using-swap"><strong>PREVENT A CONTAINER FROM USING SWAP</strong></a></li></ul></li><li><a href="#--memory-swappinessdetails"><strong>--memory-swappiness details</strong></a></li><li><a href="#--kernel-memorydetails"><strong>--kernel-memory details</strong></a></li></ul></li><li><a href="#cpu">CPU</a><ul><li><a href="#configure-the-default-cfs-scheduler"><strong>Configure the default CFS scheduler</strong></a></li><li><a href="#configure-the-realtime-scheduler"><strong>Configure the realtime scheduler</strong></a><ul><li><a href="#configure-the-host-machines-kernel"><strong>CONFIGURE THE HOST MACHINE&#x27;S KERNEL</strong></a></li><li><a href="#configure-the-docker-daemon-1"><strong>CONFIGURE THE DOCKER DAEMON</strong></a></li><li><a href="#configure-individual-containers"><strong>CONFIGURE INDIVIDUAL CONTAINERS</strong></a></li></ul></li></ul></li></ul></li><li><a href="#logging">Logging</a><ul><li><a href="#view-logs-for-a-container-or-service">View logs for a container or service</a><ul><li><a href="#next-steps-13"><strong>Next steps</strong></a></li></ul></li><li><a href="#configure-logging-drivers">Configure logging drivers</a><ul><li><a href="#configure-the-default-logging-driver"><strong>Configure the default logging driver</strong></a></li><li><a href="#configure-the-logging-driver-for-a-container"><strong>Configure the logging driver for a container</strong></a></li><li><a href="#configure-the-delivery-mode-of-log-messages-from-container-to-log-driver"><strong>Configure the delivery mode of log messages from container to log driver</strong></a><ul><li><a href="#use-environment-variables-or-labels-with-logging-drivers"><strong>Use environment variables or labels with logging drivers</strong></a></li></ul></li><li><a href="#supported-logging-drivers"><strong>Supported logging drivers</strong></a></li><li><a href="#limitations-of-logging-drivers"><strong>Limitations of logging drivers</strong></a></li></ul></li><li><a href="#use-a-logging-driver-plugin">Use a logging driver plugin</a><ul><li><a href="#install-the-logging-driver-plugin"><strong>Install the logging driver plugin</strong></a></li><li><a href="#configure-the-plugin-as-the-default-logging-driver"><strong>Configure the plugin as the default logging driver</strong></a></li><li><a href="#configure-a-container-to-use-the-plugin-as-the-logging-driver"><strong>Configure a container to use the plugin as the logging driver</strong></a></li></ul></li><li><a href="#customize-log-driver-output">Customize log driver output</a></li><li><a href="#logging-driver-details">Logging Driver Details</a><ul><li><a href="#logentries-logging-driver"><strong>Logentries logging driver</strong></a><ul><li><a href="#usage-1"><strong>Usage</strong></a></li><li><a href="#options"><strong>Options</strong></a></li></ul></li></ul></li><li><a href="#json-file-logging-driver">JSON File logging driver</a><ul><li><a href="#usage-2"><strong>Usage</strong></a><ul><li><a href="#options-1"><strong>Options</strong></a></li><li><a href="#examples"><strong>Examples</strong></a></li></ul></li></ul></li><li><a href="#graylog-extended-format-logging-driver">Graylog Extended Format logging driver</a><ul><li><a href="#usage-3"><strong>Usage</strong></a><ul><li><a href="#gelf-options"><strong>GELF options</strong></a></li><li><a href="#examples-1"><strong>Examples</strong></a></li></ul></li></ul></li><li><a href="#syslog-logging-driver">Syslog logging driver</a><ul><li><a href="#usage-4"><strong>Usage</strong></a></li><li><a href="#options-2"><strong>Options</strong></a></li></ul></li><li><a href="#amazon-cloudwatch-logs-logging-driver">Amazon CloudWatch Logs logging driver</a><ul><li><a href="#usage-5"><strong>Usage</strong></a></li><li><a href="#amazon-cloudwatch-logs-options"><strong>Amazon CloudWatch Logs options</strong></a><ul><li><a href="#awslogs-region"><strong>awslogs-region</strong></a></li><li><a href="#awslogs-group"><strong>awslogs-group</strong></a></li><li><a href="#awslogs-stream"><strong>awslogs-stream</strong></a></li><li><a href="#awslogs-create-group"><strong>awslogs-create-group</strong></a></li><li><a href="#awslogs-datetime-format"><strong>awslogs-datetime-format</strong></a></li></ul></li></ul></li></ul></li></ul></li></ul></li><li><a href="#first-event">First event</a></li><li><a href="#second-event">Second event</a></li><li><a href="#third-event">Third event</a><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-undefined" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [**awslogs-multiline-pattern**](#awslogs-multiline-pattern)</span></div></pre></div></li><li><a href="#first-event-1">First event</a></li><li><a href="#second-event-1">Second event</a></li><li><a href="#third-event-1">Third event</a><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-undefined" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [**tag**](#tag)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Credentials**](#credentials)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [ETW logging driver](#etw-logging-driver)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Usage**](#usage-6)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [Fluentd logging driver](#fluentd-logging-driver)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Usage**](#usage-7)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Options**](#options-3)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**fluentd-address**](#fluentd-address)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**tag**](#tag-1)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**labels, env, and env-regex**](#labels-env-and-env-regex)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**fluentd-async-connect**](#fluentd-async-connect)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**fluentd-buffer-limit**](#fluentd-buffer-limit)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**fluentd-retry-wait**](#fluentd-retry-wait)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**fluentd-max-retries**](#fluentd-max-retries)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**fluentd-sub-second-precision**](#fluentd-sub-second-precision)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Fluentd daemon management with Docker**](#fluentd-daemon-management-with-docker)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Test container loggers**](#test-container-loggers)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [Google Cloud Logging driver](#google-cloud-logging-driver)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Usage**](#usage-8)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**gcplogs options**](#gcplogs-options)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [Journald logging driver](#journald-logging-driver)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Usage**](#usage-9)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Options**](#options-4)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Note regarding container names**](#note-regarding-container-names)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Retrieve log messages with journalctl**](#retrieve-log-messages-withjournalctl)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**View logs for a container with a TTY enabled**](#view-logs-for-a-container-with-a-tty-enabled)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Retrieve log messages with the journal API**](#retrieve-log-messages-with-thejournalapi)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [Splunk logging driver](#splunk-logging-driver)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Usage**](#usage-10)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Splunk options**](#splunk-options)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Message formats**](#message-formats)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Advanced options**](#advanced-options)</span></div></pre></div><ul><li><a href="#registry-as-a-pull-through-cache">Registry as a pull through cache</a><ul><li><a href="#use-case">Use-case</a><ul><li><a href="#alternatives"><strong>Alternatives</strong></a></li><li><a href="#gotcha"><strong>Gotcha</strong></a></li><li><a href="#solution"><strong>Solution</strong></a></li></ul></li><li><a href="#how-does-it-work">How does it work?</a><ul><li><a href="#what-if-the-content-changes-on-the-hub"><strong>What if the content changes on the Hub?</strong></a></li><li><a href="#what-about-my-disk"><strong>What about my disk?</strong></a></li></ul></li><li><a href="#run-a-registry-as-a-pull-through-cache">Run a Registry as a pull-through cache</a><ul><li><a href="#configure-the-cache"><strong>Configure the cache</strong></a></li><li><a href="#configure-the-docker-daemon-2"><strong>Configure the Docker daemon</strong></a></li></ul></li><li><a href="#use-case-the-china-registry-mirror">Use case: the China registry mirror</a></li></ul></li><li><a href="#work-with-external-tools">Work with external tools</a><ul><li><a href="#use-powershell-dsc">Use PowerShell DSC</a><ul><li><a href="#requirements"><strong>Requirements</strong></a></li><li><a href="#installation"><strong>Installation</strong></a></li><li><a href="#usage-11"><strong>Usage</strong></a><ul><li><a href="#install-docker"><strong>Install Docker</strong></a></li><li><a href="#images-1"><strong>Images</strong></a></li><li><a href="#containers-1"><strong>Containers</strong></a></li></ul></li></ul></li><li><a href="#chef">Chef</a><ul><li><a href="#docker-cookbook"><strong>Docker Cookbook</strong></a><ul><li><a href="#scope-1"><strong>Scope</strong></a></li><li><a href="#requirements-1"><strong>Requirements</strong></a></li><li><a href="#platform-support"><strong>Platform Support</strong></a></li><li><a href="#cookbook-dependencies"><strong>Cookbook Dependencies</strong></a></li><li><a href="#docker-group"><strong>Docker Group</strong></a></li><li><a href="#usage-12"><strong>Usage</strong></a></li><li><a href="#test-cookbooks-as-examples"><strong>Test Cookbooks as Examples</strong></a></li><li><a href="#resources-overview"><strong>Resources Overview</strong></a></li><li><a href="#getting-started"><strong>Getting Started</strong></a></li></ul></li></ul></li></ul></li></ul></li><li><a href="#pull-latest-image">Pull latest image</a></li><li><a href="#run-container-mapping-containers-port-80-to-the-hosts-port-80">Run container mapping containers port 80 to the host\&#x27;s port 80</a></li><li><a href="#login-to-private-registry">Login to private registry</a></li><li><a href="#pull-tagged-image">Pull tagged image</a></li><li><a href="#run-container">Run container</a><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-undefined" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [**Resources**](#resources)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**docker_installation**](#docker_installation)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**docker_installation_tarball**](#docker_installation_tarball)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**docker_installation_script**](#docker_installation_script)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**docker_installation_package**](#docker_installation_package)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**docker_service_manager**](#docker_service_manager)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**docker_service_manager_execute**](#docker_service_manager_execute)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**docker_service_manager_sysvinit**](#docker_service_manager_sysvinit)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**docker_service_manager_upstart**](#docker_service_manager_upstart)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**docker_service_manager_systemd**](#docker_service_manager_systemd)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**docker_service**](#docker_service)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**docker_image**](#docker_image)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**docker_tag**](#docker_tag)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**docker_container**](#docker_container)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**docker_registry**](#docker_registry)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**docker_network**](#docker_network)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**docker_volume**](#docker_volume)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**docker_execute**](#docker_execute)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Maintainers**](#maintainers)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**License**](#license)</span></div></pre></div><ul><li><a href="#security">Security</a><ul><li><a href="#docker-security">Docker security</a><ul><li><a href="#kernel-namespaces"><strong>Kernel namespaces</strong></a></li><li><a href="#control-groups-2"><strong>Control groups</strong></a></li><li><a href="#docker-daemon-attack-surface"><strong>Docker daemon attack surface</strong></a></li><li><a href="#linux-kernel-capabilities"><strong>Linux kernel capabilities</strong></a></li><li><a href="#other-kernel-security-features"><strong>Other kernel security features</strong></a></li><li><a href="#conclusions"><strong>Conclusions</strong></a></li><li><a href="#related-information-6"><strong>Related information</strong></a></li></ul></li><li><a href="#docker-security-non-events">Docker security non-events</a></li><li><a href="#protect-the-docker-daemon-socket">Protect the Docker daemon socket</a><ul><li><a href="#create-a-ca-server-and-client-keys-with-openssl"><strong>Create a CA, server and client keys with OpenSSL</strong></a></li><li><a href="#secure-by-default"><strong>Secure by default</strong></a></li><li><a href="#other-modes"><strong>Other modes</strong></a><ul><li><a href="#daemon-modes"><strong>Daemon modes</strong></a></li><li><a href="#client-modes"><strong>Client modes</strong></a></li><li><a href="#connecting-to-the-secure-docker-port-usingcurl"><strong>Connecting to the secure Docker port using curl</strong></a></li></ul></li><li><a href="#related-information-7"><strong>Related information</strong></a></li></ul></li><li><a href="#verify-repository-client-with-certificates">Verify repository client with certificates</a><ul><li><a href="#understanding-the-configuration"><strong>Understanding the configuration</strong></a></li><li><a href="#creating-the-client-certificates"><strong>Creating the client certificates</strong></a></li><li><a href="#troubleshooting-tips"><strong>Troubleshooting tips</strong></a></li><li><a href="#related-information-8"><strong>Related Information</strong></a></li></ul></li><li><a href="#use-trusted-images">Use Trusted Images</a><ul><li><a href="#content-trust-in-docker"><strong>Content trust in Docker</strong></a><ul><li><a href="#about-trust-in-docker"><strong>About trust in Docker</strong></a></li><li><a href="#survey-of-typical-content-trust-operations"><strong>Survey of typical content trust operations</strong></a></li><li><a href="#related-information-9"><strong>Related information</strong></a></li></ul></li><li><a href="#automation-with-content-trust"><strong>Automation with content trust</strong></a><ul><li><a href="#bypass-requests-for-passphrases"><strong>Bypass requests for passphrases</strong></a></li><li><a href="#building-with-content-trust"><strong>Building with content trust</strong></a></li><li><a href="#related-information-10"><strong>Related information</strong></a></li></ul></li><li><a href="#delegations-for-content-trust"><strong>Delegations for content trust</strong></a><ul><li><a href="#generating-delegation-keys"><strong>Generating delegation keys</strong></a></li><li><a href="#adding-a-delegation-key-to-an-existing-repository"><strong>Adding a delegation key to an existing repository</strong></a></li><li><a href="#removing-a-delegation-key-from-an-existing-repository"><strong>Removing a delegation key from an existing repository</strong></a></li><li><a href="#removing-thetargetsreleasesdelegation-entirely-from-a-repository"><strong>Removing the targets/releases delegation entirely from a repository</strong></a></li><li><a href="#pushing-trusted-data-as-a-collaborator"><strong>Pushing trusted data as a collaborator</strong></a></li><li><a href="#docker-pushbehavior"><strong>docker push behavior</strong></a></li><li><a href="#docker-pullanddocker-buildbehavior"><strong>docker pull and docker build behavior</strong></a></li><li><a href="#related-information-11"><strong>Related information</strong></a></li></ul></li><li><a href="#deploy-notary-server-with-compose"><strong>Deploy Notary Server with Compose</strong></a><ul><li><a href="#if-you-want-to-use-notary-in-production"><strong>If you want to use Notary in production</strong></a></li></ul></li><li><a href="#manage-keys-for-content-trust"><strong>Manage keys for content trust</strong></a><ul><li><a href="#choosing-a-passphrase"><strong>Choosing a passphrase</strong></a></li><li><a href="#back-up-your-keys"><strong>Back up your keys</strong></a></li><li><a href="#hardware-storage-and-signing"><strong>Hardware storage and signing</strong></a></li><li><a href="#lost-keys"><strong>Lost keys</strong></a></li><li><a href="#related-information-12"><strong>Related information</strong></a></li></ul></li><li><a href="#play-in-a-content-trust-sandbox"><strong>Play in a content trust sandbox</strong></a><ul><li><a href="#what-is-in-the-sandbox"><strong>What is in the sandbox?</strong></a></li><li><a href="#build-the-sandbox"><strong>Build the sandbox</strong></a></li><li><a href="#playing-in-the-sandbox"><strong>Playing in the sandbox</strong></a></li><li><a href="#more-play-in-the-sandbox"><strong>More play in the sandbox</strong></a></li><li><a href="#cleaning-up-your-sandbox"><strong>Cleaning up your sandbox</strong></a></li></ul></li></ul></li><li><a href="#antivirus-software-and-docker">Antivirus software and Docker</a></li><li><a href="#apparmor-security-profiles-for-docker">AppArmor security profiles for Docker</a><ul><li><a href="#understand-the-policies"><strong>Understand the policies</strong></a></li><li><a href="#load-and-unload-profiles"><strong>Load and unload profiles</strong></a></li></ul></li></ul></li></ul></li><li><a href="#stop-apparmor">stop apparmor</a></li><li><a href="#unload-the-profile">unload the profile</a></li><li><a href="#start-apparmor">start apparmor</a><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-undefined" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [**Resources for writing profiles**](#resources-for-writing-profiles)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Nginx example profile**](#nginx-example-profile)</span></div></pre></div></li><li><a href="#deny-write-to-files-not-in-procnumber-or-procsys">deny write to files not in /proc/<code>&lt;number&gt;</code>/<strong> or /proc/sys/</strong></a><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-undefined" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [**Debug AppArmor**](#debug-apparmor)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Use dmesg**](#use-dmesg)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Use aa-status**](#use-aa-status)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Contribute Docker&#x27;s AppArmor code**](#contribute-dockers-apparmor-code)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [Seccomp security profiles for Docker](#seccomp-security-profiles-for-docker)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Pass a profile for a container**](#pass-a-profile-for-a-container)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Significant syscalls blocked by the default profile**](#significant-syscalls-blocked-by-the-default-profile)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Run without the default seccomp profile**](#run-without-the-default-seccomp-profile)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [Isolate containers with a user namespace](#isolate-containers-with-a-user-namespace)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**About remapping and subordinate user and group IDs**](#about-remapping-and-subordinate-user-and-group-ids)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Prerequisites**](#prerequisites-14)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Enable userns-remap on the daemon**](#enable-userns-remap-on-the-daemon)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Disable namespace remapping for a container**](#disable-namespace-remapping-for-a-container)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**User namespace known limitations**](#user-namespace-known-limitations)</span></div></pre></div><ul><li><a href="#scale-your-app">Scale Your App</a><ul><li><a href="#swarm-mode-overview">Swarm mode overview</a><ul><li><a href="#feature-highlights"><strong>Feature highlights</strong></a></li><li><a href="#whats-next"><strong>What&#x27;s next?</strong></a><ul><li><a href="#swarm-mode-key-concepts-and-tutorial"><strong>Swarm mode key concepts and tutorial</strong></a></li><li><a href="#swarm-mode-cli-commands"><strong>Swarm mode CLI commands</strong></a></li></ul></li></ul></li><li><a href="#swarm-mode-key-concepts">Swarm mode key concepts</a><ul><li><a href="#what-is-a-swarm"><strong>What is a swarm?</strong></a></li><li><a href="#nodes"><strong>Nodes</strong></a></li><li><a href="#services-and-tasks"><strong>Services and tasks</strong></a></li><li><a href="#load-balancing"><strong>Load balancing</strong></a></li><li><a href="#whats-next-1"><strong>What&#x27;s next?</strong></a></li></ul></li><li><a href="#getting-started-with-swarm-mode">Getting started with swarm mode</a><ul><li><a href="#set-up"><strong>Set up</strong></a><ul><li><a href="#three-networked-host-machines"><strong>Three networked host machines</strong></a></li><li><a href="#docker-engine-112-or-newer"><strong>Docker Engine 1.12 or newer</strong></a></li><li><a href="#the-ip-address-of-the-manager-machine"><strong>The IP address of the manager machine</strong></a></li><li><a href="#open-protocols-and-ports-between-the-hosts"><strong>Open protocols and ports between the hosts</strong></a></li></ul></li><li><a href="#whats-next-2"><strong>What&#x27;s next?</strong></a></li></ul></li><li><a href="#create-a-swarm">Create a swarm</a><ul><li><a href="#whats-next-3"><strong>What&#x27;s next?</strong></a></li></ul></li><li><a href="#add-nodes-to-the-swarm">Add nodes to the swarm</a><ul><li><a href="#whats-next-4"><strong>What&#x27;s next?</strong></a></li></ul></li><li><a href="#deploy-a-service-to-the-swarm">Deploy a service to the swarm</a><ul><li><a href="#whats-next-5"><strong>What&#x27;s next?</strong></a></li></ul></li><li><a href="#inspect-a-service-on-the-swarm">Inspect a service on the swarm</a><ul><li><a href="#whats-next-6"><strong>What&#x27;s next?</strong></a></li></ul></li><li><a href="#scale-the-service-in-the-swarm">Scale the service in the swarm</a><ul><li><a href="#whats-next-7"><strong>What&#x27;s next?</strong></a></li></ul></li><li><a href="#delete-the-service-running-on-the-swarm">Delete the service running on the swarm</a><ul><li><a href="#whats-next-8"><strong>What&#x27;s next?</strong></a></li></ul></li><li><a href="#apply-rolling-updates-to-a-service">Apply rolling updates to a service</a><ul><li><a href="#whats-next-9"><strong>What&#x27;s next?</strong></a></li></ul></li><li><a href="#drain-a-node-on-the-swarm">Drain a node on the swarm</a><ul><li><a href="#whats-next-10"><strong>What&#x27;s next?</strong></a></li></ul></li><li><a href="#use-swarm-mode-routing-mesh">Use swarm mode routing mesh</a><ul><li><a href="#publish-a-port-for-a-service"><strong>Publish a port for a service</strong></a><ul><li><a href="#publish-a-port-for-tcp-only-or-udp-only"><strong>Publish a port for TCP only or UDP only</strong></a></li></ul></li><li><a href="#bypass-the-routing-mesh"><strong>Bypass the routing mesh</strong></a></li><li><a href="#configure-an-external-load-balancer"><strong>Configure an external load balancer</strong></a><ul><li><a href="#using-the-routing-mesh"><strong>Using the routing mesh</strong></a></li></ul></li></ul></li></ul></li></ul></li><li><a href="#configure-haproxy-to-listen-on-port-80">Configure HAProxy to listen on port 80</a></li><li><a href="#configure-haproxy-to-route-requests-to-swarm-nodes-on-port-8080">Configure HAProxy to route requests to swarm nodes on port 8080</a><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-undefined" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [**Without the routing mesh**](#without-the-routing-mesh)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Learn more**](#learn-more)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [How Swarm Mode Works](#how-swarm-mode-works)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**How nodes work**](#how-nodes-work)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Manager nodes**](#manager-nodes)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Worker nodes**](#worker-nodes)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Change roles**](#change-roles)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Learn more**](#learn-more-1)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**How services work**](#how-services-work)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Services, tasks, and containers**](#services-tasks-and-containers)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Tasks and scheduling**](#tasks-and-scheduling)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Replicated and global services**](#replicated-and-global-services)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Learn more**](#learn-more-2)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Manage swarm security with public key infrastructure (PKI)**](#manage-swarm-security-with-public-key-infrastructure-pki)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Rotating the CA certificate**](#rotating-the-ca-certificate)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Learn More**](#learn-more-3)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Swarm task states**](#swarm-task-states)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**View task state**](#view-task-state)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Where to go next**](#where-to-go-next)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [Run Docker Engine in swarm mode](#run-docker-engine-in-swarm-mode)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Create a swarm**](#create-a-swarm-1)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Configure the advertise address**](#configure-the-advertise-address)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**View the join command or update a swarm join token**](#view-the-join-command-or-update-a-swarm-join-token)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Learn more**](#learn-more-4)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [Join nodes to a swarm](#join-nodes-to-a-swarm)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Join as a worker node**](#join-as-a-worker-node)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Join as a manager node**](#join-as-a-manager-node)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Learn More**](#learn-more-5)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [Manage nodes in a swarm](#manage-nodes-in-a-swarm)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**List nodes**](#list-nodes)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Inspect an individual node**](#inspect-an-individual-node)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Update a node**](#update-a-node)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Change node availability**](#change-node-availability)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Add or remove label metadata**](#add-or-remove-label-metadata)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Promote or demote a node**](#promote-or-demote-a-node)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Install plugins on swarm nodes**](#install-plugins-on-swarm-nodes)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Leave the swarm**](#leave-the-swarm)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Learn more**](#learn-more-6)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [Deploy services to a swarm](#deploy-services-to-a-swarm)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Create a service**](#create-a-service)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Create a service using an image on a private registry**](#create-a-service-using-an-image-on-a-private-registry)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Update a service**](#update-a-service)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Remove a service**](#remove-a-service)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Service configuration details**](#service-configuration-details)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Configure the runtime environment**](#configure-the-runtime-environment)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Update the command an existing service runs**](#update-the-command-an-existing-service-runs)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Specify the image version a service should use**](#specify-the-image-version-a-service-should-use)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Update a service&#x27;s image after creation**](#update-a-services-image-after-creation)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Publish ports**](#publish-ports-1)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Connect the service to an overlay network**](#connect-the-service-to-an-overlay-network)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Grant a service access to secrets**](#grant-a-service-access-to-secrets)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Customize a service&#x27;s isolation mode**](#customize-a-services-isolation-mode)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Control service placement**](#control-service-placement)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Configure a service&#x27;s update behavior**](#configure-a-services-update-behavior)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Roll back to the previous version of a service**](#roll-back-to-the-previous-version-of-a-service)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Automatically roll back if an update fails**](#automatically-roll-back-if-an-update-fails)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Give a service access to volumes or bind mounts**](#give-a-service-access-to-volumes-or-bind-mounts)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Create services using templates**](#create-services-using-templates)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Learn More**](#learn-more-7)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [Store configuration data using Docker Configs](#store-configuration-data-using-docker-configs)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**About configs**](#about-configs)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Windows support**](#windows-support)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**How Docker manages configs**](#how-docker-manages-configs)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Read more about docker config commands**](#read-more-aboutdocker-configcommands)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Examples**](#examples-2)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Defining and using configs in compose files**](#defining-and-using-configs-in-compose-files)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Simple example: Get started with configs**](#simple-example-get-started-with-configs)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Simple example: Use configs in a Windows service**](#simple-example-use-configs-in-a-windows-service)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Advanced example: Use configs with a Nginx service**](#advanced-example-use-configs-with-a-nginx-service)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Example: Rotate a config**](#example-rotate-a-config)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [Manage sensitive data with Docker secrets](#manage-sensitive-data-with-docker-secrets)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**About secrets**](#about-secrets)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Windows support**](#windows-support-1)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**How Docker manages secrets**](#how-docker-manages-secrets)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Read more about docker secret commands**](#read-more-aboutdocker-secretcommands)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Examples**](#examples-3)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Defining and using secrets in compose files**](#defining-and-using-secrets-in-compose-files)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Simple example: Get started with secrets**](#simple-example-get-started-with-secrets)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Simple example: Use secrets in a Windows service**](#simple-example-use-secrets-in-a-windows-service)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Intermediate example: Use secrets with a Nginx service**](#intermediate-example-use-secrets-with-a-nginx-service)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Advanced example: Use secrets with a WordPress service**](#advanced-example-use-secrets-with-a-wordpress-service)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Example: Rotate a secret**](#example-rotate-a-secret)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Build support for Docker Secrets into your images**](#build-support-for-docker-secrets-into-your-images)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Use Secrets in Compose**](#use-secrets-in-compose)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [Lock your swarm to protect its encryption key](#lock-your-swarm-to-protect-its-encryption-key)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Initialize a swarm with autolocking enabled**](#initialize-a-swarm-with-autolocking-enabled)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Enable or disable autolock on an existing swarm**](#enable-or-disable-autolock-on-an-existing-swarm)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Unlock a swarm**](#unlock-a-swarm)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**View the current unlock key for a running swarm**](#view-the-current-unlock-key-for-a-running-swarm)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Rotate the unlock key**](#rotate-the-unlock-key)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [Administer and maintain a swarm of Docker Engines](#administer-and-maintain-a-swarm-of-docker-engines)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Operate manager nodes in a swarm**](#operate-manager-nodes-in-a-swarm)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Maintain the quorum of managers**](#maintain-the-quorum-of-managers)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Configure the manager to advertise on a static IP address**](#configure-the-manager-to-advertise-on-a-static-ip-address)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Add manager nodes for fault tolerance**](#add-manager-nodes-for-fault-tolerance)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Distribute manager nodes**](#distribute-manager-nodes)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Run manager-only nodes**](#run-manager-only-nodes)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Add worker nodes for load balancing**](#add-worker-nodes-for-load-balancing)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Monitor swarm health**](#monitor-swarm-health)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Troubleshoot a manager node**](#troubleshoot-a-manager-node)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Forcibly remove a node**](#forcibly-remove-a-node)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Back up the swarm**](#back-up-the-swarm)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">  - [**Recover from disaster**](#recover-from-disaster)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Restore from a backup**](#restore-from-a-backup)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">    - [**Recover from losing the quorum**](#recover-from-losing-the-quorum)</span></div></pre></div></li><li><a href="#from-the-node-to-recover">From the node to recover</a><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-undefined" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [**Force the swarm to rebalance**](#force-the-swarm-to-rebalance)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">- [Raft consensus in swarm mode](#raft-consensus-in-swarm-mode)</span></div></pre></div><ul><li><a href="#extended-docker">Extended Docker</a><ul><li><a href="#docker-engine-managed-plugin-system">Docker Engine managed plugin system</a><ul><li><a href="#installing-and-using-a-plugin"><strong>Installing and using a plugin</strong></a></li><li><a href="#developing-a-plugin"><strong>Developing a plugin</strong></a></li><li><a href="#debugging-plugins"><strong>Debugging plugins</strong></a></li></ul></li><li><a href="#access-authorization-plugin">Access authorization plugin</a><ul><li><a href="#basic-principles"><strong>Basic principles</strong></a></li><li><a href="#default-user-authorization-mechanism"><strong>Default user authorization mechanism</strong></a></li><li><a href="#basic-architecture"><strong>Basic architecture</strong></a></li><li><a href="#docker-client-flows"><strong>Docker client flows</strong></a><ul><li><a href="#setting-up-docker-daemon"><strong>Setting up Docker daemon</strong></a></li><li><a href="#calling-authorized-command-allow"><strong>Calling authorized command (allow)</strong></a></li><li><a href="#calling-unauthorized-command-deny"><strong>Calling unauthorized command (deny)</strong></a></li><li><a href="#error-from-plugins"><strong>Error from plugins</strong></a></li></ul></li><li><a href="#api-schema-and-implementation"><strong>API schema and implementation</strong></a><ul><li><a href="#request-authorization"><strong>Request authorization</strong></a></li><li><a href="#response-authorization"><strong>Response authorization</strong></a></li></ul></li></ul></li><li><a href="#use-docker-engine-plugins">Use Docker Engine plugins</a><ul><li><a href="#types-of-plugins"><strong>Types of plugins</strong></a></li><li><a href="#installing-a-plugin"><strong>Installing a plugin</strong></a></li><li><a href="#finding-a-plugin"><strong>Finding a plugin</strong></a><ul><li><a href="#network-plugins"><strong>Network plugins</strong></a></li><li><a href="#volume-plugins"><strong>Volume plugins</strong></a></li><li><a href="#authorization-plugins"><strong>Authorization plugins</strong></a></li></ul></li><li><a href="#troubleshooting-a-plugin"><strong>Troubleshooting a plugin</strong></a></li><li><a href="#writing-a-plugin"><strong>Writing a plugin</strong></a></li></ul></li><li><a href="#docker-network-driver-plugins">Docker network driver plugins</a><ul><li><a href="#network-plugins-and-swarm-mode"><strong>Network plugins and swarm mode</strong></a></li><li><a href="#use-network-driver-plugins"><strong>Use network driver plugins</strong></a></li><li><a href="#find-network-plugins"><strong>Find network plugins</strong></a></li><li><a href="#write-a-network-plugin"><strong>Write a network plugin</strong></a></li><li><a href="#network-plugin-protocol"><strong>Network plugin protocol</strong></a></li><li><a href="#related-information-13"><strong>Related Information</strong></a></li></ul></li><li><a href="#docker-volume-plugins">Docker volume plugins</a><ul><li><a href="#changelog"><strong>Changelog</strong></a><ul><li><a href="#1130"><strong>1.13.0</strong></a></li><li><a href="#1120"><strong>1.12.0</strong></a></li><li><a href="#1100"><strong>1.10.0</strong></a></li><li><a href="#180"><strong>1.8.0</strong></a></li></ul></li><li><a href="#command-line-changes"><strong>Command-line changes</strong></a><ul><li><a href="#--volume"><strong>--volume</strong></a></li><li><a href="#volumedriver"><strong>volumedriver</strong></a></li></ul></li><li><a href="#create-a-volumedriver"><strong>Create a VolumeDriver</strong></a></li><li><a href="#volume-plugin-protocol"><strong>Volume plugin protocol</strong></a><ul><li><a href="#volumedrivercreate"><strong>/VolumeDriver.Create</strong></a></li><li><a href="#volumedriverremove"><strong>/VolumeDriver.Remove</strong></a></li><li><a href="#volumedrivermount"><strong>/VolumeDriver.Mount</strong></a></li><li><a href="#volumedriverpath"><strong>/VolumeDriver.Path</strong></a></li><li><a href="#volumedriverunmount"><strong>/VolumeDriver.Unmount</strong></a></li><li><a href="#volumedriverget"><strong>/VolumeDriver.Get</strong></a></li><li><a href="#volumedriverlist"><strong>/VolumeDriver.List</strong></a></li><li><a href="#volumedrivercapabilities"><strong>/VolumeDriver.Capabilities</strong></a></li></ul></li></ul></li><li><a href="#plugin-config-version-1-of-plugin-v2">Plugin Config Version 1 of Plugin V2</a><ul><li><a href="#configfield-descriptions"><strong>Config Field Descriptions</strong></a></li><li><a href="#example-config"><strong>Example Config</strong></a></li></ul></li><li><a href="#docker-plugin-api">Docker Plugin API</a><ul><li><a href="#what-plugins-are"><strong>What plugins are</strong></a></li><li><a href="#plugin-discovery"><strong>Plugin discovery</strong></a><ul><li><a href="#json-specification"><strong>JSON specification</strong></a></li></ul></li><li><a href="#plugin-lifecycle"><strong>Plugin lifecycle</strong></a></li><li><a href="#plugin-activation"><strong>Plugin activation</strong></a></li><li><a href="#systemd-socket-activation"><strong>Systemd socket activation</strong></a></li><li><a href="#api-design"><strong>API design</strong></a></li><li><a href="#handshake-api"><strong>Handshake API</strong></a><ul><li><a href="#pluginactivate"><strong>/Plugin.Activate</strong></a></li></ul></li><li><a href="#plugin-retries"><strong>Plugin retries</strong></a></li><li><a href="#plugins-helpers"><strong>Plugins helpers</strong></a></li></ul></li></ul></li></ul></li></ul><h1>Important Links</h1><p><a href="https://docs.docker.com/get-started/">https://docs.docker.com/get-started/</a></p><ul><li><a href="https://docs.docker.com/samples/">Samples</a>: Our samples include multiple examples of popular software running in containers, and some good labs that teach best practices.</li><li><a href="https://docs.docker.com/engine/userguide/">User Guide</a>: The user guide has several examples that explain networking and storage in greater depth than was covered here.</li><li><a href="https://docs.docker.com/engine/admin/">Admin Guide</a>: Covers how to manage a Dockerized production environment.</li><li><a href="https://training.docker.com/">Training</a>: Official Docker courses that offer in-person instruction and virtual classroom environments.</li><li><a href="https://blog.docker.com/">Blog</a>: Covers what&#x27;s going on with Docker lately.</li></ul><h1>Code Links</h1><p><a href="https://github.com/docker/labs">https://github.com/docker/labs</a></p><h1>Get Started with Docker</h1><h2><a href="https://docs.docker.com/install/">Get Docker</a></h2><p>Docker is available in two editions: Community Edition (CE) and Enterprise Edition (EE).</p><p><strong>Docker Community Edition (CE)</strong> is ideal for developers and small teams looking to get started with Docker and experimenting with container-based apps. Docker CE has two update channels, stable and edge:</p><ul><li>Stable gives you reliable updates every quarter</li><li>Edge gives you new features every month</li></ul><p><strong>Docker Enterprise Edition (EE)</strong> is designed for enterprise development and IT teams who build, ship, and run business critical applications in production at scale.</p><p>Table ‑ Capabilities of different Docker editions</p><hr/><p>  Capabilities                                                        Community Edition   Enterprise Edition Basic   Enterprise Edition Standard   Enterprise Edition Advanced
Container engine and built in orchestration, networking, security   yup                 yup                        yup                           yup
Certified infrastructure, plugins and ISV containers                                    yup                        yup                           yup
Image management                                                                                                   yup                           yup
Container app management                                                                                           yup                           yup
Image security scanning                                                                                                                          yup</p><hr/><h3>Supported platforms</h3><p>Docker CE and EE are available on multiple platforms, on cloud and on-premises. Use the following tables to choose the best installation path for you.</p><p>Table ‑ Desktop Installations</p><hr/><p>  Platform                                                                                           Docker CE x86_64   Docker CE ARM   Docker EE
<a href="https://docs.docker.com/docker-for-mac/install/">Docker for Mac (macOS)</a>                          Yup<br/>
<a href="https://docs.docker.com/docker-for-windows/install/">Docker for Windows (Microsoft Windows 10)</a>   yup                                </p><hr/><p>Table ‑ Cloud Installations</p><hr/><p>  Platform                                                            Docker CE x86_64   Docker CE ARM   Docker EE
<a href="https://docs.docker.com/docker-for-aws/">Amazon Web Services</a>      Yup                                Yup
<a href="https://docs.docker.com/docker-for-azure/">Microsoft Azure</a>        yup                                Yup
<a href="https://docs.docker.com/docker-for-ibm-cloud/">IBM Cloud (Beta)</a>                                      yup</p><hr/><h3>Time-based release schedule</h3><p>Starting with Docker 17.03, Docker uses a time-based release schedule.</p><ul><li>Docker CE Edge releases generally happen monthly.</li><li>Docker CE Stable releases generally happen quarterly, with patch releases as needed.</li><li>Docker EE releases generally happen twice per year, with patch releases as needed.</li></ul><h3>Updates, and patches</h3><p>A given Docker EE release receives patches and updates for at least <strong>one year</strong> after it is released.</p><p>A given Docker CE Stable release receives patches and updates for <strong>one month after the next Docker CE Stable release</strong>.</p><p>A given Docker CE Edge release does not receive any patches or updates after a subsequent Docker CE Edge or Stable release.</p><h3>Prior releases</h3><p>Instructions for installing prior releases of Docker can be found in the <a href="https://docs.docker.com/docsarchive/">Docker archives</a>.</p><h3>Install</h3><h4>Manage Docker as a non-root user</h4><p>The docker daemon binds to a Unix socket instead of a TCP port. By default that Unix socket is owned by the user root and other users can only access it using sudo. The docker daemon always runs as the root user.</p><p>If you don&#x27;t want to use sudo when you use the docker command, create a Unix group called docker and add users to it. When the docker daemon starts, it makes the ownership of the Unix socket read/writable by the docker group.</p><p><strong>Warning</strong>: The docker group grants privileges equivalent to the root user. For details on how this impacts security in your system, see <a href="https://docs.docker.com/engine/security/security/#docker-daemon-attack-surface"><em>Docker Daemon Attack Surface</em></a>.</p><p>To create the docker group and add your user:</p><ol><li>Create the docker group.</li></ol><p>$ sudo groupadd docker</p><ol><li>Add your user to the docker group.</li></ol><p>$ sudo usermod -aG docker $USER</p><ol><li>Log out and log back in so that your group membership is re-evaluated. If testing on a virtual machine, it may be necessary to restart the virtual machine for changes to take effect.</li><li>On a desktop Linux environment such as X Windows, log out of your session completely and then log back in. Verify that you can run docker commands without sudo.</li></ol><p>$ docker run hello-world</p><p>This command downloads a test image and runs it in a container. When the container runs, it prints an informational message and exits.</p><p>If you initially ran Docker CLI commands using sudo before adding your user to the docker group, you may see the following error, which indicates that your <!-- -->~<!-- -->/.docker/ directory was created with incorrect permissions due to the sudo commands.</p><p>WARNING: Error loading config file: /home/user/.docker/config.json -</p><p>stat /home/user/.docker/config.json: permission denied</p><p>To fix this problem, either remove the <!-- -->~<!-- -->/.docker/ directory (it is recreated automatically, but any custom settings are lost), or change its ownership and permissions using the following commands:</p><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-bash" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">$ </span><span class="token function" style="color:rgb(220, 220, 170)">sudo</span><span class="token plain"> </span><span class="token function" style="color:rgb(220, 220, 170)">chown</span><span class="token plain"> </span><span class="token string" style="color:rgb(206, 145, 120)">&quot;</span><span class="token string environment constant" style="color:rgb(100, 102, 149)">$USER</span><span class="token string" style="color:rgb(206, 145, 120)">&quot;</span><span class="token builtin class-name" style="color:rgb(78, 201, 176)">:</span><span class="token string" style="color:rgb(206, 145, 120)">&quot;</span><span class="token string environment constant" style="color:rgb(100, 102, 149)">$USER</span><span class="token string" style="color:rgb(206, 145, 120)">&quot;</span><span class="token plain"> /home/</span><span class="token string" style="color:rgb(206, 145, 120)">&quot;</span><span class="token string environment constant" style="color:rgb(100, 102, 149)">$USER</span><span class="token string" style="color:rgb(206, 145, 120)">&quot;</span><span class="token plain">/.docker -R</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">$ </span><span class="token function" style="color:rgb(220, 220, 170)">sudo</span><span class="token plain"> </span><span class="token function" style="color:rgb(220, 220, 170)">chmod</span><span class="token plain"> g+rwx </span><span class="token string" style="color:rgb(206, 145, 120)">&quot;/home/</span><span class="token string environment constant" style="color:rgb(100, 102, 149)">$USER</span><span class="token string" style="color:rgb(206, 145, 120)">/.docker&quot;</span><span class="token plain"> -R</span></div></pre></div><h4>Configure Docker to start on boot</h4><p>Most current Linux distributions (RHEL, CentOS, Fedora, Ubuntu 16.04 and higher) use <a href="https://docs.docker.com/install/linux/linux-postinstall/#systemd">systemd</a> to manage which services start when the system boots. Ubuntu 14.10 and below use <a href="https://docs.docker.com/install/linux/linux-postinstall/#upstart">upstart</a>.</p><p><strong>systemd</strong></p><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-bash" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">$ </span><span class="token function" style="color:rgb(220, 220, 170)">sudo</span><span class="token plain"> systemctl </span><span class="token builtin class-name" style="color:rgb(78, 201, 176)">enable</span><span class="token plain"> docker</span></div></pre></div><p>To disable this behavior, use disable instead.</p><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-bash" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">$ </span><span class="token function" style="color:rgb(220, 220, 170)">sudo</span><span class="token plain"> systemctl disable docker</span></div></pre></div><p>If you need to add an HTTP Proxy, set a different directory or partition for the Docker runtime files, or make other customizations, see <a href="https://docs.docker.com/engine/admin/systemd/">customize your systemd Docker daemon options</a>.</p><p><strong>upstart</strong></p><p>Docker is automatically configured to start on boot using upstart. To disable this behavior, use the following command:</p><p>$ echo manual | sudo tee /etc/init/docker.override</p><p><strong>chkconfig</strong></p><p>$ sudo chkconfig docker on</p><h4>Use a different storage engine</h4><h4>Configure where the Docker daemon listens for connections</h4><h4>Enable IPv6 on the Docker daemon</h4><h4>Troubleshooting</h4><h5>Kernel compatibility</h5><h5>IP forwarding problems</h5><h4>Specify DNS servers for Docker</h4><h4>Allow access to the remote API through a firewall</h4><h2>Docker CE Edge documentation</h2><p>The current Docker CE Edge release is <a href="https://docs.docker.com/release-notes/docker-ce/#edge-releases"><strong>here</strong></a>.</p><p>The Docker CE Edge channel provides monthly releases which allow you to try new features of Docker and verify bug fixes quickly. Each edge release is only supported for one month and does not receive updates after a new Edge release is available.</p><p>Stable releases are not published to the Edge channel, so Linux repository users should subscribe to both Edge and Stable channels.</p><p>Commercial support is not available for Docker CE. For information about all Docker release channels and expectations about support, see <a href="https://docs.docker.com/install/#docker-channels">Docker channels</a>.</p><p>Documentation for API and CLI references is updated with each Edge release as appropriate. However, full documentation for features may not be available until a Docker CE Stable release incorporates the feature.</p><h4>Docker CE Edge resources</h4><p>The <a href="https://docs.docker.com/edge/engine/reference/commandline/docker/">Docker CE Edge CLI reference</a> includes commands, options, and flags which have not yet been integrated into a Docker CE Stable release.</p><p>The <a href="https://docs.docker.com/edge/engine/reference/commandline/dockerd/">Docker CE Edge dockerd reference</a> includes commands, options, and flags for the Docker daemon which have not yet been integrated into a Docker CE Stable release.</p><h2><a href="https://docs.docker.com/compose/install/"></a>Get Docker-Compose</h2><h3>Prerequisites</h3><p>Docker Compose relies on Docker Engine for any meaningful work, so make sure you have Docker Engine installed either locally or remote, depending on your setup.</p><ul><li>On desktop systems like Docker for Mac and Windows, Docker Compose is included as part of those desktop installs.</li><li>On Linux systems, first install the <a href="https://docs.docker.com/install/#server">Docker</a> for your OS as described on the Get Docker page, then come back here for instructions on installing Compose on Linux systems.</li><li>To run Compose as a non-root user, see <a href="https://docs.docker.com/install/linux/linux-postinstall/">Manage Docker as a non-root user</a>.</li></ul><h3>Install Compose</h3><p>Follow the instructions below to install Compose on Mac, Windows, Windows Server 2016, or Linux systems, or find out about alternatives like using the pip Python package manager or installing Compose as a container.</p><ul><li>Mac</li><li>Windows</li><li>Linux</li><li>Alternative Install Options</li></ul><h4>Install Compose on Linux systems</h4><p>On <strong>Linux</strong>, you can download the Docker Compose binary from the <a href="https://github.com/docker/compose/releases">Compose repository release page on GitHub</a>. Follow the instructions from the link, which involve running the curl command in your terminal to download the binaries. These step by step instructions are also included below.</p><ol><li>Run this command to download the latest version of Docker Compose:</li></ol><p>sudo curl -L <a href="https://github.com/docker/compose/releases/download/1.19.0/docker-compose-%60uname">https://github.com/docker/compose/releases/download/1.19.0/docker-compose-`uname</a> -s<code style="background-color:lightgray">-</code>uname -m` -o /usr/local/bin/docker-compose</p><p>Use the latest Compose release number in the download command.</p><p>The above command is an example, and it may become out-of-date. To ensure you have the latest version, check the <a href="https://github.com/docker/compose/releases">Compose repository release page on GitHub</a>.</p><ol><li>Apply executable permissions to the binary:</li></ol><p>sudo chmod +x /usr/local/bin/docker-compose</p><ol><li>Optionally, install <a href="https://docs.docker.com/compose/completion/">command completion</a> for the bash and zsh shell.</li><li>Test the installation.</li></ol><p>$ docker-compose --version</p><p>docker-compose version 1.19.0, build 1719ceb</p><h3>Master builds</h3><p>If you&#x27;re interested in trying out a pre-release build, you can download a binary from<code style="background-color:lightgray">&lt;https://dl.bintray.com/docker-compose/master/&gt;</code>. Pre-release builds allow you to try out new features before they are released, but may be less stable.</p><h3>Upgrading</h3><p>If you&#x27;re upgrading from Compose 1.2 or earlier, remove or migrate your existing containers after upgrading Compose. This is because, as of version 1.3, Compose uses Docker labels to keep track of containers, and your containers need to be recreated to add the labels.</p><p>If Compose detects containers that were created without labels, it refuses to run so that you don&#x27;t end up with two sets of them. If you want to keep using your existing containers (for example, because they have data volumes you want to preserve), you can use Compose 1.5.x to migrate them with the following command:</p><p>docker-compose migrate-to-labels</p><p>Alternatively, if you&#x27;re not worried about keeping them, you can remove them. Compose just creates new ones.</p><p>docker container rm -f -v myapp_web_1 myapp_db_1 ...</p><h3>Uninstallation</h3><p>To uninstall Docker Compose if you installed using curl:</p><p>sudo rm /usr/local/bin/docker-compose</p><p>To uninstall Docker Compose if you installed using pip:</p><p>pip uninstall docker-compose</p><p>Got a &quot;Permission denied&quot; error?</p><p>If you get a &quot;Permission denied&quot; error using either of the above methods, you probably do not have the proper permissions to remove docker-compose. To force the removal, prepend sudoto either of the above commands and run again.</p><h2>Docker -- Get Started</h2><p>Docker is a platform for developers and sysadmins to develop, deploy, and run applications with containers. The use of Linux containers to deploy applications is called containerization. Containers are not new, but their use for easily deploying applications.</p><p>Containerization is increasingly popular because containers are:</p><ul><li>Flexible: Even the most complex applications can be containerized.</li><li>Lightweight: Containers leverage and share the host kernel.</li><li>Interchangeable: You can deploy updates and upgrades on-the-fly.</li><li>Portable: You can build locally, deploy to the cloud, and run anywhere.</li><li>Scalable: You can increase and automatically distribute container replicas.</li><li>Stackable: You can stack services vertically and on-the-fly.</li></ul><h3>Images and containers</h3><p>A container is launched by running an image. An image is an executable package that includes everything needed to run an application--the code, a runtime, libraries, environment variables, and configuration files.</p><p>A container is a runtime instance of an image--what the image becomes in memory when executed (that is, an image with state, or a user process). You can see a list of your running containers with the command, docker ps, just as you would in Linux.</p><h3>Containers and virtual machines</h3><p>A container runs natively on Linux and shares the kernel of the host machine with other containers. It runs a discrete process, taking no more memory than any other executable, making it lightweight.</p><p>By contrast, a virtual machine (VM) runs a full-blown &quot;guest&quot; operating system with virtual access to host resources through a hypervisor. In general, VMs provide an environment with more resources than most applications need.</p><h3>Orientation and Setup</h3><h4>Test Docker version</h4><p>Ensure that you have a supported version of Docker:</p><p>$ docker --version</p><p>Docker version 17.12.0-ce, build c97c6d6</p><p>Run docker version (without --) or docker info to view even more details about your docker installation:</p><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-bash" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">$ docker info</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">Containers: </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">Running: </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">Paused: </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">Stopped: </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">Images: </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">Server Version: </span><span class="token number" style="color:rgb(181, 206, 168)">17.12</span><span class="token plain">.0-ce</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">Storage Driver: overlay2</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">`</span><span class="token variable" style="color:rgb(156, 220, 254)">`</span><span class="token variable" style="color:rgb(156, 220, 254)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="display:inline-block;color:rgb(156, 220, 254)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="color:rgb(156, 220, 254)">**Note**: To avoid permission errors </span><span class="token variable punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token variable" style="color:rgb(156, 220, 254)">and the use of </span><span class="token variable function" style="color:rgb(220, 220, 170)">sudo</span><span class="token variable punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token variable" style="color:rgb(156, 220, 254)">, </span><span class="token variable function" style="color:rgb(220, 220, 170)">add</span><span class="token variable" style="color:rgb(156, 220, 254)"> your user to the docker group. </span><span class="token variable punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token variable" style="color:rgb(156, 220, 254)">Read more</span><span class="token variable punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token variable punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token variable" style="color:rgb(156, 220, 254)">https://docs.docker.com/engine/installation/linux/linux-postinstall/</span><span class="token variable punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token variable" style="color:rgb(156, 220, 254)">.</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="display:inline-block;color:rgb(156, 220, 254)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="color:rgb(156, 220, 254)"></span><span class="token variable comment" style="color:rgb(106, 153, 85)">#### Test Docker installation</span><span class="token variable" style="color:rgb(156, 220, 254)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="display:inline-block;color:rgb(156, 220, 254)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="color:rgb(156, 220, 254)">Test that your installation works by running the simple Docker image, </span><span class="token variable punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token variable" style="color:rgb(156, 220, 254)">hello-world</span><span class="token variable punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token variable punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token variable" style="color:rgb(156, 220, 254)">https://hub.docker.com/_/hello-world/</span><span class="token variable punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token variable" style="color:rgb(156, 220, 254)">:</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="display:inline-block;color:rgb(156, 220, 254)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="color:rgb(156, 220, 254)">$ docker run hello-world</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="display:inline-block;color:rgb(156, 220, 254)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="color:rgb(156, 220, 254)">Unable to </span><span class="token variable function" style="color:rgb(220, 220, 170)">find</span><span class="token variable" style="color:rgb(156, 220, 254)"> image </span><span class="token variable punctuation" style="color:rgb(212, 212, 212)">\</span><span class="token variable string" style="color:rgb(206, 145, 120)">&#x27;hello-world:latest\&#x27; locally</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">latest: Pulling from library/hello-world</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">ca4f61b1923c: Pull complete</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">Digest: sha256:ca0eeb6fb05351dfc8759c20733c91def84cb8007aa89a5bf606bc8b315b9fc7</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">Status: Downloaded newer image for hello-world:latest</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">Hello from Docker!</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">This message shows that your installation appears to be working correctly.</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">...</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">List the hello-world image that was downloaded to your machine:</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">$ docker image ls</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">List the hello-world container (spawned by the image), which exits after displaying its message. If it were still running, you would not need the --all option:</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">$ docker container ls --all</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">CONTAINER ID IMAGE COMMAND CREATED STATUS</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">54f4984ed6a8 hello-world &quot;/hello&quot; 20 seconds ago Exited (0) 19 seconds ago</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">#### Recap and cheat sheet</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">## List Docker CLI commands</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">docker</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">docker container --help</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">## Display Docker version and info</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">docker --version</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">docker version</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">docker info</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">## Excecute Docker image</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">docker run hello-world</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">## List Docker images</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">docker image ls</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">## List Docker containers (running, all, all in quiet mode)</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">docker container ls</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">docker container ls --all</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">docker container ls -a -q</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">Containerization makes [CI/CD](https://www.docker.com/use-cases/cicd) seamless. For example:</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">-   applications have no system dependencies</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">-   updates can be pushed to any part of a distributed application</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">-   resource density can be optimized.</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">With Docker, scaling your application is a matter of spinning up new executables, not running heavy VM hosts.</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">### Containers</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">#### Your new development environment</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">In the past, if you were to start writing a Python app, your first order of business was to install a Python runtime onto your machine. But, that creates a situation where the environment on your machine needs to be perfect for your app to run as expected, and needs to match your production environment.</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">With Docker, you can just grab a portable Python runtime as an image, no installation necessary. Then, your build can include the base Python image right alongside your app code, ensuring that your app, its dependencies, and the runtime, all travel together.</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">These portable images are defined by something called a Dockerfile.</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">#### Define a container with Dockerfile</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">Dockerfile defines what goes on in the environment inside your container. Access to resources like networking interfaces and disk drives is virtualized inside this environment, which is isolated from the rest of your system, so you need to map ports to the outside world, and be specific about what files you want to &quot;copy in&quot; to that environment. However, after doing that, you can expect that the build of your app defined in this Dockerfile behaves the same wherever it runs.</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">#### Dockerfile</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">Create an empty directory. Change directories (cd) into the new directory, create a file called Dockerfile, copy-and-paste the following content into that file, and save it. Take note of the comments that explain each statement in your new Dockerfile.</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)"># Use an official Python runtime as a parent image</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">FROM python:2.7-slim</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)"># Set the working directory to /app</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">WORKDIR /app</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)"># Copy the current directory contents into the container at /app</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">ADD . /app</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)"># Install any needed packages specified in requirements.txt</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">RUN pip install --trusted-host pypi.python.org -r requirements.txt</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)"># Make port 80 available to the world outside this container</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">EXPOSE 80</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)"># Define environment variable</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">ENV NAME World</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)"># Run app.py when the container launches</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">CMD [&quot;python&quot;, &quot;app.py&quot;]</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">**Are you behind a proxy server?**</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">Proxy servers can block connections to your web app once it&#x27;</span><span class="token variable" style="color:rgb(156, 220, 254)">s up and running. If you are behind a proxy server, </span><span class="token variable function" style="color:rgb(220, 220, 170)">add</span><span class="token variable" style="color:rgb(156, 220, 254)"> the following lines to your Dockerfile, using the ENV </span><span class="token variable builtin class-name" style="color:rgb(78, 201, 176)">command</span><span class="token variable" style="color:rgb(156, 220, 254)"> to specify the </span><span class="token variable function" style="color:rgb(220, 220, 170)">host</span><span class="token variable" style="color:rgb(156, 220, 254)"> and port </span><span class="token variable keyword" style="color:rgb(86, 156, 214)">for</span><span class="token variable" style="color:rgb(156, 220, 254)"> your proxy servers:</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="display:inline-block;color:rgb(156, 220, 254)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="color:rgb(156, 220, 254)"></span><span class="token variable comment" style="color:rgb(106, 153, 85)"># Set proxy server, replace host:port with values for your servers</span><span class="token variable" style="color:rgb(156, 220, 254)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="display:inline-block;color:rgb(156, 220, 254)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="color:rgb(156, 220, 254)">ENV http_proxy host:port</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="display:inline-block;color:rgb(156, 220, 254)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="color:rgb(156, 220, 254)">ENV https_proxy host:port</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="display:inline-block;color:rgb(156, 220, 254)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="color:rgb(156, 220, 254)">Add these lines before the call to pip so that the installation succeeds.</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="display:inline-block;color:rgb(156, 220, 254)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="color:rgb(156, 220, 254)">This Dockerfile refers to a couple of files we haven</span><span class="token variable string" style="color:rgb(206, 145, 120)">&#x27;t created yet, namely app.py and requirements.txt. Let&#x27;</span><span class="token variable" style="color:rgb(156, 220, 254)">s create those next.</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="display:inline-block;color:rgb(156, 220, 254)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="color:rgb(156, 220, 254)"></span><span class="token variable comment" style="color:rgb(106, 153, 85)">#### The app itself</span><span class="token variable" style="color:rgb(156, 220, 254)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="display:inline-block;color:rgb(156, 220, 254)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="color:rgb(156, 220, 254)">Create two </span><span class="token variable function" style="color:rgb(220, 220, 170)">more</span><span class="token variable" style="color:rgb(156, 220, 254)"> files, requirements.txt and app.py, and put them </span><span class="token variable keyword" style="color:rgb(86, 156, 214)">in</span><span class="token variable" style="color:rgb(156, 220, 254)"> the same folder with the Dockerfile. This completes our app, </span><span class="token variable function" style="color:rgb(220, 220, 170)">which</span><span class="token variable" style="color:rgb(156, 220, 254)"> as you can see is quite simple. When the above Dockerfile is built into an image, app.py and requirements.txt is present because of that Dockerfile&#x27;s ADD command, and the output from app.py is accessible over HTTP thanks to the EXPOSE command.</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="display:inline-block;color:rgb(156, 220, 254)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="color:rgb(156, 220, 254)">**requirements.txt**</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="display:inline-block;color:rgb(156, 220, 254)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="color:rgb(156, 220, 254)">Flask</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="display:inline-block;color:rgb(156, 220, 254)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="color:rgb(156, 220, 254)">Redis</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="display:inline-block;color:rgb(156, 220, 254)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="color:rgb(156, 220, 254)">**app.py**</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="display:inline-block;color:rgb(156, 220, 254)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="color:rgb(156, 220, 254)">from flask </span><span class="token variable function" style="color:rgb(220, 220, 170)">import</span><span class="token variable" style="color:rgb(156, 220, 254)"> Flask</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="display:inline-block;color:rgb(156, 220, 254)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="color:rgb(156, 220, 254)">from redis </span><span class="token variable function" style="color:rgb(220, 220, 170)">import</span><span class="token variable" style="color:rgb(156, 220, 254)"> Redis, RedisError</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="color:rgb(156, 220, 254)"></span><span class="token variable" style="color:rgb(156, 220, 254)">`</span><span class="token plain">`</span><span class="token variable" style="color:rgb(156, 220, 254)">`</span><span class="token variable" style="color:rgb(156, 220, 254)">python</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="color:rgb(156, 220, 254)"></span><span class="token variable function" style="color:rgb(220, 220, 170)">import</span><span class="token variable" style="color:rgb(156, 220, 254)"> os</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="display:inline-block;color:rgb(156, 220, 254)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="color:rgb(156, 220, 254)"></span><span class="token variable function" style="color:rgb(220, 220, 170)">import</span><span class="token variable" style="color:rgb(156, 220, 254)"> socket</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="display:inline-block;color:rgb(156, 220, 254)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="color:rgb(156, 220, 254)"></span><span class="token variable comment" style="color:rgb(106, 153, 85)"># Connect to Redis</span><span class="token variable" style="color:rgb(156, 220, 254)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="display:inline-block;color:rgb(156, 220, 254)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="color:rgb(156, 220, 254)">redis </span><span class="token variable operator" style="color:rgb(212, 212, 212)">=</span><span class="token variable" style="color:rgb(156, 220, 254)"> Redis</span><span class="token variable punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token variable" style="color:rgb(156, 220, 254)">host</span><span class="token variable operator" style="color:rgb(212, 212, 212)">=</span><span class="token variable string" style="color:rgb(206, 145, 120)">&quot;redis&quot;</span><span class="token variable" style="color:rgb(156, 220, 254)">, </span><span class="token variable assign-left variable" style="color:rgb(156, 220, 254)">db</span><span class="token variable operator" style="color:rgb(212, 212, 212)">=</span><span class="token variable number" style="color:rgb(181, 206, 168)">0</span><span class="token variable" style="color:rgb(156, 220, 254)">, </span><span class="token variable assign-left variable" style="color:rgb(156, 220, 254)">socket_connect_timeout</span><span class="token variable operator" style="color:rgb(212, 212, 212)">=</span><span class="token variable number" style="color:rgb(181, 206, 168)">2</span><span class="token variable" style="color:rgb(156, 220, 254)">, </span><span class="token variable assign-left variable" style="color:rgb(156, 220, 254)">socket_timeout</span><span class="token variable operator" style="color:rgb(212, 212, 212)">=</span><span class="token variable number" style="color:rgb(181, 206, 168)">2</span><span class="token variable punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token variable" style="color:rgb(156, 220, 254)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="display:inline-block;color:rgb(156, 220, 254)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="color:rgb(156, 220, 254)">app </span><span class="token variable operator" style="color:rgb(212, 212, 212)">=</span><span class="token variable" style="color:rgb(156, 220, 254)"> Flask</span><span class="token variable punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token variable" style="color:rgb(156, 220, 254)">__name__</span><span class="token variable punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token variable" style="color:rgb(156, 220, 254)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="display:inline-block;color:rgb(156, 220, 254)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="color:rgb(156, 220, 254)"></span><span class="token variable punctuation" style="color:rgb(212, 212, 212)">\</span><span class="token variable" style="color:rgb(156, 220, 254)">@app.route</span><span class="token variable punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token variable string" style="color:rgb(206, 145, 120)">&quot;/&quot;</span><span class="token variable punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token variable" style="color:rgb(156, 220, 254)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="display:inline-block;color:rgb(156, 220, 254)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="color:rgb(156, 220, 254)">def hello</span><span class="token variable punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token variable punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token variable" style="color:rgb(156, 220, 254)">:</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="display:inline-block;color:rgb(156, 220, 254)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="color:rgb(156, 220, 254)">try:</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="display:inline-block;color:rgb(156, 220, 254)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="color:rgb(156, 220, 254)">visits </span><span class="token variable operator" style="color:rgb(212, 212, 212)">=</span><span class="token variable" style="color:rgb(156, 220, 254)"> redis.incr</span><span class="token variable punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token variable string" style="color:rgb(206, 145, 120)">&quot;counter&quot;</span><span class="token variable punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token variable" style="color:rgb(156, 220, 254)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="display:inline-block;color:rgb(156, 220, 254)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="color:rgb(156, 220, 254)">except RedisError:</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="display:inline-block;color:rgb(156, 220, 254)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable" style="color:rgb(156, 220, 254)">visits </span><span class="token variable operator" style="color:rgb(212, 212, 212)">=</span><span class="token variable" style="color:rgb(156, 220, 254)"> &quot;</span><span class="token variable" style="color:rgb(156, 220, 254)">`</span><span class="token operator" style="color:rgb(212, 212, 212)">&lt;</span><span class="token plain">i</span><span class="token operator" style="color:rgb(212, 212, 212)">&gt;</span><span class="token plain">cannot connect to Redis, counter disabled</span><span class="token operator" style="color:rgb(212, 212, 212)">&lt;</span><span class="token plain">/i</span><span class="token operator" style="color:rgb(212, 212, 212)">&gt;</span><span class="token variable" style="color:rgb(156, 220, 254)">`</span><span class="token variable string" style="color:rgb(206, 145, 120)">&quot;</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">html = &quot;</span><span class="token variable" style="color:rgb(156, 220, 254)">`</span><span class="token operator" style="color:rgb(212, 212, 212)">&lt;</span><span class="token plain">h</span><span class="token operator file-descriptor important" style="color:rgb(212, 212, 212)">3</span><span class="token operator" style="color:rgb(212, 212, 212)">&gt;</span><span class="token plain">Hello </span><span class="token punctuation" style="color:rgb(212, 212, 212)">{</span><span class="token plain">name</span><span class="token punctuation" style="color:rgb(212, 212, 212)">}</span><span class="token operator" style="color:rgb(212, 212, 212)">!</span><span class="token operator" style="color:rgb(212, 212, 212)">&lt;</span><span class="token plain">/h</span><span class="token operator file-descriptor important" style="color:rgb(212, 212, 212)">3</span><span class="token operator" style="color:rgb(212, 212, 212)">&gt;</span><span class="token variable" style="color:rgb(156, 220, 254)">`</span><span class="token variable string" style="color:rgb(206, 145, 120)">&quot; \</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">&quot;</span><span class="token variable" style="color:rgb(156, 220, 254)">`</span><span class="token operator" style="color:rgb(212, 212, 212)">&lt;</span><span class="token plain">b</span><span class="token operator" style="color:rgb(212, 212, 212)">&gt;</span><span class="token plain">Hostname:</span><span class="token operator" style="color:rgb(212, 212, 212)">&lt;</span><span class="token plain">/b</span><span class="token operator" style="color:rgb(212, 212, 212)">&gt;</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(212, 212, 212)">{</span><span class="token plain">hostname</span><span class="token punctuation" style="color:rgb(212, 212, 212)">}</span><span class="token operator" style="color:rgb(212, 212, 212)">&lt;</span><span class="token plain">br/</span><span class="token operator" style="color:rgb(212, 212, 212)">&gt;</span><span class="token variable" style="color:rgb(156, 220, 254)">`</span><span class="token variable string" style="color:rgb(206, 145, 120)">&quot; \</span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token variable string" style="color:rgb(206, 145, 120)">&quot;</span><span class="token variable" style="color:rgb(156, 220, 254)">`</span><span class="token operator" style="color:rgb(212, 212, 212)">&lt;</span><span class="token plain">b</span><span class="token operator" style="color:rgb(212, 212, 212)">&gt;</span><span class="token plain">Visits:</span><span class="token operator" style="color:rgb(212, 212, 212)">&lt;</span><span class="token plain">/b</span><span class="token operator" style="color:rgb(212, 212, 212)">&gt;</span><span class="token plain">` </span><span class="token punctuation" style="color:rgb(212, 212, 212)">{</span><span class="token plain">visits</span><span class="token punctuation" style="color:rgb(212, 212, 212)">}</span><span class="token string" style="color:rgb(206, 145, 120)">&quot;</span></div><div class="token-line" style="color:#9CDCFE"><span class="token string" style="display:inline-block;color:rgb(206, 145, 120)"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token string" style="color:rgb(206, 145, 120)">return html.format(name=os.getenv(&quot;</span><span class="token plain">NAME&quot;</span><span class="token plain">, </span><span class="token string" style="color:rgb(206, 145, 120)">&quot;world&quot;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">, </span><span class="token assign-left variable" style="color:rgb(156, 220, 254)">hostname</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain">socket.gethostname</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">, </span><span class="token assign-left variable" style="color:rgb(156, 220, 254)">visits</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain">visits</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token keyword" style="color:rgb(86, 156, 214)">if</span><span class="token plain"> __name__ </span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token plain"> </span><span class="token string" style="color:rgb(206, 145, 120)">&quot;__main__&quot;</span><span class="token builtin class-name" style="color:rgb(78, 201, 176)">:</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">app.run</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">host</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token punctuation" style="color:rgb(212, 212, 212)">\</span><span class="token plain">&#x27;0.0.0.0</span><span class="token punctuation" style="color:rgb(212, 212, 212)">\</span><span class="token plain">&#x27;, </span><span class="token assign-left variable" style="color:rgb(156, 220, 254)">port</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token number" style="color:rgb(181, 206, 168)">80</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span></div></pre></div><p>Now we see that pip install -r requirements.txt installs the Flask and Redis libraries for Python, and the app prints the environment variable NAME, as well as the output of a call to socket.gethostname(). Finally, because Redis isn&#x27;t running (as we&#x27;ve only installed the Python library, and not Redis itself), we should expect that the attempt to use it here fails and produces the error message.</p><p><strong>Note</strong>: Accessing the name of the host when inside a container retrieves the container ID, which is like the process ID for a running executable.</p><p>That&#x27;s it! You don&#x27;t need Python or anything in requirements.txt on your system, nor does building or running this image install them on your system. It doesn&#x27;t seem like you&#x27;ve really set up an environment with Python and Flask, but you have.</p><h4>Build the app</h4><p>We are ready to build the app. Make sure you are still at the top level of your new directory. Here&#x27;s what ls should show:</p><p>$ ls</p><p>Dockerfile app.py requirements.txt</p><p>Now run the build command. This creates a Docker image, which we&#x27;re going to tag using -t so it has a friendly name.</p><p>docker build -t friendlyhello .</p><p>Where is your built image? It&#x27;s in your machine&#x27;s local Docker image registry:</p><p>$ docker image ls</p><p>REPOSITORY TAG IMAGE ID</p><p>friendlyhello latest 326387cea398</p><h4>Run the app</h4><p>Run the app, mapping your machine&#x27;s port 4000 to the container&#x27;s published port 80 using -p:</p><p>docker run -p 4000:80 friendlyhello</p><p>You should see a message that Python is serving your app at <a href="http://0.0.0.0:80">http://0.0.0.0:80</a>. But that message is coming from inside the container, which doesn&#x27;t know you mapped port 80 of that container to 4000, making the correct URL http://localhost:4000.</p><p>Go to that URL in a web browser to see the display content served up on a web page.</p><p><strong>Note</strong>: If you are using Docker Toolbox on Windows 7, use the Docker Machine IP instead of localhost. For example, <a href="http://192.168.99.100:4000/">http://192.168.99.100:4000/</a>. To find the IP address, use the command docker-machine ip.</p><p>You can also use the curl command in a shell to view the same content.</p><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-bash" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">$ </span><span class="token function" style="color:rgb(220, 220, 170)">curl</span><span class="token plain"> http://localhost:4000</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token variable" style="color:rgb(156, 220, 254)">`</span><span class="token variable operator" style="color:rgb(212, 212, 212)">&lt;</span><span class="token variable" style="color:rgb(156, 220, 254)">h</span><span class="token variable operator file-descriptor important" style="color:rgb(212, 212, 212)">3</span><span class="token variable operator" style="color:rgb(212, 212, 212)">&gt;</span><span class="token variable" style="color:rgb(156, 220, 254)">Hello World</span><span class="token variable operator" style="color:rgb(212, 212, 212)">!</span><span class="token variable operator" style="color:rgb(212, 212, 212)">&lt;</span><span class="token variable" style="color:rgb(156, 220, 254)">/h</span><span class="token variable operator file-descriptor important" style="color:rgb(212, 212, 212)">3</span><span class="token variable operator" style="color:rgb(212, 212, 212)">&gt;</span><span class="token variable operator" style="color:rgb(212, 212, 212)">&lt;</span><span class="token variable" style="color:rgb(156, 220, 254)">b</span><span class="token variable operator" style="color:rgb(212, 212, 212)">&gt;</span><span class="token variable" style="color:rgb(156, 220, 254)">Hostname:</span><span class="token variable operator" style="color:rgb(212, 212, 212)">&lt;</span><span class="token variable" style="color:rgb(156, 220, 254)">/b</span><span class="token variable operator" style="color:rgb(212, 212, 212)">&gt;</span><span class="token variable" style="color:rgb(156, 220, 254)"> 8fc990912a1</span><span class="token variable operator file-descriptor important" style="color:rgb(212, 212, 212)">4</span><span class="token variable operator" style="color:rgb(212, 212, 212)">&lt;</span><span class="token variable" style="color:rgb(156, 220, 254)">br/</span><span class="token variable operator" style="color:rgb(212, 212, 212)">&gt;</span><span class="token variable operator" style="color:rgb(212, 212, 212)">&lt;</span><span class="token variable" style="color:rgb(156, 220, 254)">b</span><span class="token variable operator" style="color:rgb(212, 212, 212)">&gt;</span><span class="token variable" style="color:rgb(156, 220, 254)">Visits:</span><span class="token variable operator" style="color:rgb(212, 212, 212)">&lt;</span><span class="token variable" style="color:rgb(156, 220, 254)">/b</span><span class="token variable operator" style="color:rgb(212, 212, 212)">&gt;</span><span class="token variable" style="color:rgb(156, 220, 254)"> </span><span class="token variable operator" style="color:rgb(212, 212, 212)">&lt;</span><span class="token variable" style="color:rgb(156, 220, 254)">i</span><span class="token variable operator" style="color:rgb(212, 212, 212)">&gt;</span><span class="token variable" style="color:rgb(156, 220, 254)">cannot connect to Redis, counter disabled</span><span class="token variable operator" style="color:rgb(212, 212, 212)">&lt;</span><span class="token variable" style="color:rgb(156, 220, 254)">/i</span><span class="token variable operator" style="color:rgb(212, 212, 212)">&gt;</span><span class="token variable" style="color:rgb(156, 220, 254)">`</span></div></pre></div><p>This port remapping of 4000:80 is to demonstrate the difference between what you EXPOSE within the Dockerfile, and what you publish using docker run -p. In later steps, we just map port 80 on the host to port 80 in the container and use http://localhost.</p><p>Hit CTRL+C in your terminal to quit.</p><p>On Windows, explicitly stop the container</p><p>On Windows systems, CTRL+C does not stop the container. So, first type CTRL+C to get the prompt back (or open another shell), then type docker container ls to list the running containers, followed by docker container stop <code style="background-color:lightgray">&lt;Container NAME or ID&gt;</code> to stop the container. Otherwise, you get an error response from the daemon when you try to re-run the container in the next step.</p><p>Now let&#x27;s run the app in the background, in detached mode:</p><p>docker run -d -p 4000:80 friendlyhello</p><p>You get the long container ID for your app and then are kicked back to your terminal. Your container is running in the background. You can also see the abbreviated container ID with docker container ls(and both work interchangeably when running commands):</p><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-bash" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">$ docker container </span><span class="token function" style="color:rgb(220, 220, 170)">ls</span></div></pre></div><p>CONTAINER ID IMAGE COMMAND CREATED</p><p>1fa4ab2cf395 friendlyhello &quot;python app.py&quot; 28 seconds ago</p><p>Notice that CONTAINER ID matches what&#x27;s on <code style="background-color:lightgray">&lt;http://localhost:4000&gt;</code>. Now use docker container stop to end the process, using the CONTAINER ID, like so:</p><p>docker container stop 1fa4ab2cf395</p><h4>Share your image</h4><p>To demonstrate the portability of what we just created, let&#x27;s upload our built image and run it somewhere else. After all, you need to know how to push to registries when you want to deploy containers to production.</p><p>A registry is a collection of repositories, and a repository is a collection of images---sort of like a GitHub repository, except the code is already built. An account on a registry can create many repositories. The docker CLI uses Docker&#x27;s public registry by default.</p><p><strong>Note</strong>: We use Docker&#x27;s public registry here just because it&#x27;s free and pre-configured, but there are many public ones to choose from, and you can even set up your own private registry using <a href="https://docs.docker.com/datacenter/dtr/2.2/guides/">Docker Trusted Registry</a>.</p><h4>Log in with your Docker ID</h4><p>If you don&#x27;t have a Docker account, sign up for one at <a href="https://cloud.docker.com/">cloud.docker.com</a>. Make note of your username. Log in to the Docker public registry on your local machine.</p><p>$ docker login</p><h4>Tag the image</h4><p>The notation for associating a local image with a repository on a registry is username/repository:tag. The tag is optional, but recommended, since it is the mechanism that registries use to give Docker images a version. Give the repository and tag meaningful names for the context, such as get-started:part2. This puts the image in the get-started repository and tag it as part2.</p><p>Now, put it all together to tag the image. Run docker tag image with your username, repository, and tag names so that the image uploads to your desired destination. The syntax of the command is:</p><p>docker tag image username/repository:tag</p><p>For example:</p><p>docker tag friendlyhello john/get-started:part2</p><p>Run <a href="https://docs.docker.com/engine/reference/commandline/image_ls/">docker image ls</a> to see your newly tagged image.</p><p>$ docker image ls</p><p>REPOSITORY TAG IMAGE ID CREATED SIZE</p><p>friendlyhello latest d9e555c53008 3 minutes ago 195MB</p><p>john/get-started part2 d9e555c53008 3 minutes ago 195MB</p><p>python 2.7-slim 1c7128a655f6 5 days ago 183MB</p><p>...</p><h4>Publish the image</h4><p>Upload your tagged image to the repository:</p><p>docker push username/repository:tag</p><p>Once complete, the results of this upload are publicly available. If you log in to <a href="https://hub.docker.com/">Docker Hub</a>, you see the new image there, with its pull command.</p><h4>Pull and run the image from the remote repository</h4><p>From now on, you can use docker run and run your app on any machine with this command:</p><p>docker run -p 4000:80 username/repository:tag</p><p>If the image isn&#x27;t available locally on the machine, Docker pulls it from the repository.</p><p>$ docker run -p 4000:80 john/get-started:part2</p><p>Unable to find image \&#x27;john/get-started:part2\&#x27; locally</p><p>part2: Pulling from john/get-started</p><p>10a267c67f42: Already exists</p><p>f68a39a6a5e4: Already exists</p><p>9beaffc0cf19: Already exists</p><p>3c1fe835fb6b: Already exists</p><p>4c9f1fa8fcb8: Already exists</p><p>ee7d8f576a14: Already exists</p><p>fbccdcced46e: Already exists</p><p>Digest: sha256:0601c866aab2adcc6498200efd0f754037e909e5fd42069adeff72d1e2439068</p><p>Status: Downloaded newer image for john/get-started:part2</p><ul><li>Running on <a href="http://0.0.0.0:80/">http://0.0.0.0:80/</a> (Press CTRL+C to quit)</li></ul><p>No matter where docker run executes, it pulls your image, along with Python and all the dependencies from requirements.txt, and runs your code. It all travels together in a neat little package, and you don&#x27;t need to install anything on the host machine for Docker to run it.</p><p>Here is a list of the basic Docker commands from this page, and some related ones if you&#x27;d like to explore a bit before moving on.</p><p>docker build -t friendlyhello . # Create image using this directory\&#x27;s Dockerfile</p><p>docker run -p 4000:80 friendlyhello # Run &quot;friendlyname&quot; mapping port 4000 to 80</p><p>docker run -d -p 4000:80 friendlyhello # Same thing, but in detached mode</p><p>docker container ls # List all running containers</p><p>docker container ls -a # List all containers, even those not running</p><p>docker container stop <code style="background-color:lightgray">&lt;hash&gt;</code> # Gracefully stop the specified container</p><p>docker container kill <code style="background-color:lightgray">&lt;hash&gt;</code> # Force shutdown of the specified container</p><p>docker container rm <code style="background-color:lightgray">&lt;hash&gt;</code> # Remove specified container from this machine</p><p>docker container rm $(docker container ls -a -q) # Remove all containers</p><p>docker image ls -a # List all images on this machine</p><p>docker image rm <code style="background-color:lightgray">&lt;image id&gt;</code> # Remove specified image from this machine</p><p>docker image rm $(docker image ls -a -q) # Remove all images from this machine</p><p>docker login # Log in this CLI session using your Docker credentials</p><p>docker tag <code style="background-color:lightgray">&lt;image&gt; username/repository:tag # Tag &lt;image&gt;</code> for upload to registry</p><p>docker push username/repository:tag # Upload tagged image to registry</p><p>docker run username/repository:tag # Run image from a registry</p><h2><a href="https://docs.docker.com/compose/overview/"></a>Docker Compose</h2><p>In a distributed application, different pieces of the app are called &quot;services.&quot; For example, if you imagine a video sharing site, it probably includes a service for storing application data in a database, a service for video transcoding in the background after a user uploads something, a service for the front-end, and so on.</p><p>Services are just &quot;containers in production.&quot; A service only runs one image, but it codifies the way that image runs---what ports it should use, how many replicas of the container should run so the service has the capacity it needs, and so on. Scaling a service changes the number of container instances running that piece of software, assigning more computing resources to the service in the process.</p><p>Luckily, it&#x27;s very easy to define, run, and scale services with the Docker platform -- just write a docker-compose.yml file.</p><h3>Your first docker-compose.yml file</h3><p>A docker-compose.yml file is a YAML file that defines how Docker containers should behave in production.</p><p><strong>docker-compose.yml</strong></p><p>Save this file as docker-compose.yml wherever you want and update this .yml by replacing username/repo:tag with your image details.</p><p>version: &quot;3&quot;</p><p>services:</p><p>web:</p><h1>replace username/repo:tag with your name and image details</h1><p>image: username/repo:tag</p><p>deploy:</p><p>replicas: 5</p><p>resources:</p><p>limits:</p><p>cpus: &quot;0.1&quot;</p><p>memory: 50M</p><p>restart_policy:</p><p>condition: on-failure</p><p>ports:</p><ul><li>&quot;80:80&quot;</li></ul><p>networks:</p><ul><li>webnet</li></ul><p>networks:</p><p>webnet:</p><p>This docker-compose.yml file tells Docker to do the following:</p><ul><li>Pull <a href="https://docs.docker.com/get-started/part2/">the image</a> from the registry.</li><li>Run 5 instances of that image as a service called web, limiting each one to use, at most, 10% of the CPU (across all cores), and 50MB of RAM.</li><li>Immediately restart containers if one fails.</li><li>Map port 80 on the host to web&#x27;s port 80.</li><li>Instruct web&#x27;s containers to share port 80 via a load-balanced network called webnet. (Internally, the containers themselves publish to web&#x27;s port 80 at an ephemeral port.)</li><li>Define the webnet network with the default settings (which is a load-balanced overlay network).</li></ul><h3>Run your new load-balanced app</h3><p>Before we can use the docker stack deploy command we first run:</p><p>docker swarm init</p><p>Now let&#x27;s run it. You need to give your app a name. Here, it is set to getstartedlab:</p><p>docker stack deploy -c docker-compose.yml getstartedlab</p><p>Our single service stack is running 5 container instances of our deployed image on one host. Let&#x27;s investigate.</p><p>Get the service ID for the one service in our application:</p><p>docker service ls</p><p>Look for output for the web service, prepended with your app name. If you named it the same as shown in this example, the name is getstartedlab_web. The service ID is listed as well, along with the number of replicas, image name, and exposed ports.</p><p>A single container running in a service is called a <strong>task</strong>. Tasks are given unique IDs that numerically increment, up to the number of replicas you defined in docker-compose.yml. List the tasks for your service:</p><p>docker service ps getstartedlab_web</p><p>Tasks also show up if you just list all the containers on your system, though that is not filtered by service:</p><p>docker container ls -q</p><p>You can run curl -4 http://localhost several times in a row, or go to that URL in your browser and hit refresh a few times.</p><p>Either way, the container ID changes, demonstrating the load-balancing; with each request, one of the 5 tasks is chosen, in a round-robin fashion, to respond. The container IDs match your output from the previous command (docker container ls -q).</p><h3>Scale the app</h3><p>You can scale the app by changing the replicas value in docker-compose.yml, saving the change, and re-running the docker stack deploy command:</p><p>docker stack deploy -c docker-compose.yml getstartedlab</p><p>Docker performs an in-place update, no need to tear the stack down first or kill any containers.</p><p>Now, re-run docker container ls -q to see the deployed instances reconfigured. If you scaled up the replicas, more tasks, and hence, more containers, are started.</p><h4>Take down the app and the swarm</h4><p>Take the app down with docker stack rm:</p><p>docker stack rm getstartedlab</p><p>Take down the swarm.</p><p>docker swarm leave --force</p><p>It&#x27;s as easy as that to stand up and scale your app with Docker.</p><p><strong>Note</strong>: Compose files like this are used to define applications with Docker, and can be uploaded to cloud providers using <a href="https://docs.docker.com/docker-cloud/">Docker Cloud</a>, or on any hardware or cloud provider you choose with<a href="https://www.docker.com/enterprise-edition">Docker Enterprise Edition</a>.</p><h3>Recap and cheat sheet</h3><p>Here&#x27;s <a href="https://asciinema.org/a/b5gai4rnflh7r0kie01fx6lip">a terminal recording of what was covered on this section</a>:</p><p>To recap, while typing docker run is simple enough, the true implementation of a container in production is running it as a service. Services codify a container&#x27;s behavior in a Compose file, and this file can be used to scale, limit, and redeploy our app. Changes to the service can be applied in place, as it runs, using the same command that launched the service: docker stack deploy.</p><p>Some commands to explore at this stage:</p><p>docker stack ls # List stacks or apps</p><p>docker stack deploy -c <code style="background-color:lightgray">&lt;composefile&gt; &lt;appname&gt;</code> # Run the specified Compose file</p><p>docker service ls # List running services associated with an app</p><p>docker service ps <code style="background-color:lightgray">&lt;service&gt;</code> # List tasks associated with an app</p><p>docker inspect <code style="background-color:lightgray">&lt;task or container&gt;</code> # Inspect task or container</p><p>docker container ls -q # List container IDs</p><p>docker stack rm <code style="background-color:lightgray">&lt;appname&gt;</code> # Tear down an application</p><p>docker swarm leave --force # Take down a single node swarm from the manager</p><h2><a href="https://docs.docker.com/get-started/part4/#introduction"></a>Docker Swarm</h2><p><a href="https://wiki.centos.org/HowTos/Virtualization/VirtualBox">Installing Virtual box on centos</a></p><h3>Understanding Swarm clusters</h3><p>A swarm is a group of machines that are running Docker and joined into a cluster. After that has happened, you continue to run the Docker commands you&#x27;re used to, but now they are executed on a cluster by a <strong>swarm manager</strong>. The machines in a swarm can be physical or virtual. After joining a swarm, they are referred to as <strong>nodes</strong>.</p><p>Swarm managers can use several strategies to run containers, such as &quot;emptiest node&quot; -- which fills the least utilized machines with containers. Or &quot;global&quot;, which ensures that each machine gets exactly one instance of the specified container. You instruct the swarm manager to use these strategies in the Compose file, just like the one you have already been using.</p><p>Swarm managers are the only machines in a swarm that can execute your commands or authorize other machines to join the swarm as <strong>workers</strong>. Workers are just there to provide capacity and do not have the authority to tell any other machine what it can and cannot do.</p><p>Up until now, you have been using Docker in a single-host mode on your local machine. But Docker also can be switched into <strong>swarm mode</strong>, and that&#x27;s what enables the use of swarms. Enabling swarm mode instantly makes the current machine a swarm manager. From then on, Docker runs the commands you execute on the swarm you&#x27;re managing, rather than just on the current machine.</p><h3>Set up your swarm</h3><p>A swarm is made up of multiple nodes, which can be either physical or virtual machines. The basic concept is simple enough: run docker swarm init to enable swarm mode and make your current machine a swarm manager, then run docker swarm join on other machines to have them join the swarm as workers.</p><h4>Create a cluster</h4><h5>VMS ON YOUR LOCAL MACHINE (MAC, LINUX, WINDOWS 7 AND 8)</h5><p>You need a hypervisor that can create virtual machines (VMs), so <a href="https://www.virtualbox.org/wiki/Downloads">install Oracle VirtualBox</a> for your machine&#x27;s OS.</p><p><strong>Note</strong>: If you are on a Windows system that has Hyper-V installed, such as Windows 10, there is no need to install VirtualBox and you should use Hyper-V instead. View the instructions for Hyper-V systems by clicking the Hyper-V tab above. If you are using <a href="https://docs.docker.com/toolbox/overview/">Docker Toolbox</a>, you should already have VirtualBox installed as part of it, so you are good to go.</p><p>Now, create a couple of VMs using docker-machine, using the VirtualBox driver:</p><p>docker-machine create --driver virtualbox myvm1</p><p>docker-machine create --driver virtualbox myvm2</p><h5>LIST THE VMS AND GET THEIR IP ADDRESSES</h5><p>You now have two VMs created, named myvm1 and myvm2.</p><p>Use this command to list the machines and get their IP addresses.</p><p>docker-machine ls</p><p>Here is example output from this command.</p><p>$ docker-machine ls</p><p>NAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORS</p><p>myvm1 - virtualbox Running tcp://192.168.99.100:2376 v17.06.2-ce</p><p>myvm2 - virtualbox Running tcp://192.168.99.101:2376 v17.06.2-ce</p><h5>INITIALIZE THE SWARM AND ADD NODES</h5><p>The first machine acts as the manager, which executes management commands and authenticates workers to join the swarm, and the second is a worker.</p><p>You can send commands to your VMs using docker-machine ssh. Instruct myvm1 to become a swarm manager with docker swarm init and look for output like this:</p><p>$ docker-machine ssh myvm1 &quot;docker swarm init --advertise-addr <code style="background-color:lightgray">&lt;myvm1 ip&gt;</code>&quot;</p><p>Swarm initialized: current node <code style="background-color:lightgray">&lt;node ID&gt;</code> is now a manager.</p><p>To add a worker to this swarm, run the following command:</p><p>docker swarm join \</p><p>--token <code style="background-color:lightgray">&lt;token&gt;</code> \</p><p><code style="background-color:lightgray">&lt;myvm ip&gt;:&lt;port&gt;</code></p><p>To add a manager to this swarm, run \&#x27;docker swarm join-token manager\&#x27; and follow the instructions.</p><p><strong>Ports 2377 and 2376</strong></p><p>Always run docker swarm init and docker swarm join with port 2377 (the swarm management port), or no port at all and let it take the default.</p><p>The machine IP addresses returned by docker-machine ls include port 2376, which is the Docker daemon port. Do not use this port or <a href="https://forums.docker.com/t/docker-swarm-join-with-virtualbox-connection-error-13-bad-certificate/31392/2">you may experience errors</a>.</p><p><strong>Having trouble using SSH? Try the --native-ssh flag</strong></p><p>Docker Machine has <a href="https://docs.docker.com/machine/reference/ssh/#different-types-of-ssh">the option to let you use your own system&#x27;s SSH</a>, if for some reason you&#x27;re having trouble sending commands to your Swarm manager. Just specify the --native-ssh flag when invoking the ssh command:</p><p>docker-machine --native-ssh ssh myvm1 ...</p><p>As you can see, the response to docker swarm init contains a pre-configured docker swarm join command for you to run on any nodes you want to add. Copy this command, and send it to myvm2 via docker-machine ssh to have myvm2 join your new swarm as a worker:</p><p>$ docker-machine ssh myvm2 &quot;docker swarm join \</p><p>--token <code style="background-color:lightgray">&lt;token&gt;</code> \</p><p><code style="background-color:lightgray">&lt;ip&gt;</code>:2377&quot;</p><p>This node joined a swarm as a worker.</p><p>Congratulations, you have created your first swarm!</p><p>Run docker node ls on the manager to view the nodes in this swarm:</p><p>$ docker-machine ssh myvm1 &quot;docker node ls&quot;</p><p>ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS</p><p>brtu9urxwfd5j0zrmkubhpkbd myvm2 Ready Active</p><p>rihwohkh3ph38fhillhhb84sk * myvm1 Ready Active Leader</p><p><strong>Leaving a swarm</strong></p><p>If you want to start over, you can run docker swarm leave from each node.</p><h3>Deploy your app on the swarm cluster</h3><p><strong>Configure a docker-machine shell to the swarm manager</strong></p><p>So far, you&#x27;ve been wrapping Docker commands in docker-machine ssh to talk to the VMs. Another option is to run docker-machine env <code style="background-color:lightgray">&lt;machine&gt;</code> to get and run a command that configures your current shell to talk to the Docker daemon on the VM. This method works better for the next step because it allows you to use your local docker-compose.yml file to deploy the app &quot;remotely&quot; without having to copy it anywhere.</p><p>Type docker-machine env myvm1, then copy-paste and run the command provided as the last line of the output to configure your shell to talk to myvm1, the swarm manager.</p><p>The commands to configure your shell differ depending on whether you are Mac, Linux, or Windows, so examples of each are shown on the tabs below.</p><h4>DOCKER MACHINE SHELL ENVIRONMENT ON MAC OR LINUX</h4><p>Run docker-machine env myvm1 to get the command to configure your shell to talk to myvm1.</p><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-bash" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">$ docker-machine </span><span class="token function" style="color:rgb(220, 220, 170)">env</span><span class="token plain"> myvm1</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token builtin class-name" style="color:rgb(78, 201, 176)">export</span><span class="token plain"> </span><span class="token assign-left variable" style="color:rgb(156, 220, 254)">DOCKER_TLS_VERIFY</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token string" style="color:rgb(206, 145, 120)">&quot;1&quot;</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token builtin class-name" style="color:rgb(78, 201, 176)">export</span><span class="token plain"> </span><span class="token assign-left variable" style="color:rgb(156, 220, 254)">DOCKER_HOST</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token string" style="color:rgb(206, 145, 120)">&quot;tcp://192.168.99.100:2376&quot;</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token builtin class-name" style="color:rgb(78, 201, 176)">export</span><span class="token plain"> </span><span class="token assign-left variable" style="color:rgb(156, 220, 254)">DOCKER_CERT_PATH</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token string" style="color:rgb(206, 145, 120)">&quot;/Users/sam/.docker/machine/machines/myvm1&quot;</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token builtin class-name" style="color:rgb(78, 201, 176)">export</span><span class="token plain"> </span><span class="token assign-left variable" style="color:rgb(156, 220, 254)">DOCKER_MACHINE_NAME</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token string" style="color:rgb(206, 145, 120)">&quot;myvm1&quot;</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token comment" style="color:rgb(106, 153, 85)"># Run this command to configure your shell:</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token comment" style="color:rgb(106, 153, 85)"># eval $(docker-machine env myvm1)</span></div></pre></div><p>Run the given command to configure your shell to talk to myvm1.</p><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-bash" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token builtin class-name" style="color:rgb(78, 201, 176)">eval</span><span class="token plain"> </span><span class="token variable" style="color:rgb(156, 220, 254)">$(</span><span class="token variable" style="color:rgb(156, 220, 254)">docker-machine </span><span class="token variable function" style="color:rgb(220, 220, 170)">env</span><span class="token variable" style="color:rgb(156, 220, 254)"> myvm1</span><span class="token variable" style="color:rgb(156, 220, 254)">)</span></div></pre></div><p>Run docker-machine ls to verify that myvm1 is now the active machine, as indicated by the asterisk next to it.</p><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-bash" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">$ docker-machine </span><span class="token function" style="color:rgb(220, 220, 170)">ls</span></div></pre></div><p>NAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORS</p><p>myvm1 * virtualbox Running tcp://192.168.99.100:2376 v17.06.2-ce</p><p>myvm2 - virtualbox Running tcp://192.168.99.101:2376 v17.06.2-ce</p><h4>Deploy the app on the swarm manager</h4><p>Now that you have myvm1, you can use its powers as a swarm manager to deploy your app by using the same docker stack deploy command you used in part 3 to myvm1, and your local copy of docker-compose.yml. This command may take a few seconds to complete and the deployment takes some time to be available. Use the docker service ps <code style="background-color:lightgray">&lt;service_name&gt;</code> command on a swarm manager to verify that all services have been redeployed.</p><p>You are connected to myvm1 by means of the docker-machine shell configuration, and you still have access to the files on your local host. Make sure you are in the same directory as before, which includes the <a href="https://docs.docker.com/get-started/part3/#docker-composeyml">docker-compose.yml </a></p><p>Just like before, run the following command to deploy the app on myvm1.</p><p>docker stack deploy -c docker-compose.yml getstartedlab</p><p>And that&#x27;s it, the app is deployed on a swarm cluster!</p><p><strong>Note</strong>: If your image is stored on a private registry instead of Docker Hub, you need to be logged in using <strong>docker login <code>&lt;your-registry&gt;</code></strong> and then you need to add the <strong>--with-registry-auth</strong> flag to the above command. For example:</p><p>docker login registry.example.com</p><p>docker stack deploy --with-registry-auth -c docker-compose.yml getstartedlab</p><p>This passes the login token from your local client to the swarm nodes where the service is deployed, using the encrypted WAL logs. With this information, the nodes can log into the registry and pull the image.</p><p>$ docker stack ps getstartedlab</p><p>ID NAME IMAGE NODE DESIRED STATE</p><p>jq2g3qp8nzwx getstartedlab_web.1 john/get-started:part2 myvm1 Running</p><p>88wgshobzoxl getstartedlab_web.2 john/get-started:part2 myvm2 Running</p><p>vbb1qbkb0o2z getstartedlab_web.3 john/get-started:part2 myvm2 Running</p><p>ghii74p9budx getstartedlab_web.4 john/get-started:part2 myvm1 Running</p><p>0prmarhavs87 getstartedlab_web.5 john/get-started:part2 myvm2 Running</p><p><strong>Connecting to VMs with docker-machine env and docker-machine ssh</strong></p><ul><li>To set your shell to talk to a different machine like myvm2, simply re-rundocker-machine env in the same or a different shell, then run the given command to point to myvm2. This is always specific to the current shell. If you change to an unconfigured shell or open a new one, you need to re-run the commands. Use docker-machine ls to list machines, see what state they are in, get IP addresses, and find out which one, if any, you are connected to. To learn more, see the <a href="https://docs.docker.com/machine/get-started/#create-a-machine">Docker Machine getting started topics</a>.</li><li>Alternatively, you can wrap Docker commands in the form ofdocker-machine ssh <code>&lt;machine&gt; &quot;&lt;command&gt;</code>&quot;, which logs directly into the VM but doesn&#x27;t give you immediate access to files on your local host.</li><li>On Mac and Linux, you can use docker-machine scp <code>&lt;file&gt; &lt;machine&gt;</code>:<!-- -->~<!-- --> to copy files across machines, but Windows users need a Linux terminal emulator like <a href="https://git-for-windows.github.io/">Git Bash</a> for this to work.</li><li>This tutorial demos both docker-machine ssh and docker-machine env, since these are available on all platforms via the docker-machine CLI.</li></ul><h4>Accessing your cluster</h4><p>You can access your app from the IP address of <strong>either</strong> myvm1 or myvm2.</p><p>The network you created is shared between them and load-balancing. Run docker-machine ls to get your VMs&#x27; IP addresses and visit either of them on a browser, hitting refresh (or just curl them).</p><p>The reason both IP addresses work is that nodes in a swarm participate in an ingress <strong>routing mesh</strong>. This ensures that a service deployed at a certain port within your swarm always has that port reserved to itself, no matter what node is running the container. Here&#x27;s a diagram of how a routing mesh for a service called my-web published at port 8080 on a three-node swarm would look:</p><p>Having connectivity trouble?</p><p>Keep in mind that to use the ingress network in the swarm, you need to have the following ports open between the swarm nodes before you enable swarm mode:</p><p>Port 7946 TCP/UDP for container network discovery.</p><p>Port 4789 UDP for the container ingress network.</p><h3>Iterating and scaling your app</h3><p>Scale the app by changing the docker-compose.yml file.</p><p>Change the app behavior by editing code, then rebuild, and push the new image.</p><p>In either case, simply run docker stack deploy again to deploy these changes.</p><p>You can join any machine, physical or virtual, to this swarm, using the same docker swarm join command you used on myvm2, and capacity is added to your cluster. Just run docker stack deploy afterwards, and your app can take advantage of the new resources.</p><h3>Cleanup and reboot</h3><h4>Stacks and swarms</h4><p>You can tear down the stack with docker stack rm. For example:</p><p>docker stack rm getstartedlab</p><p>Keep the swarm or remove it? At some point later, you can remove this swarm if you want to withdocker-machine ssh myvm2 &quot;docker swarm leave&quot; on the worker and docker-machine ssh myvm1 &quot;docker swarm leave --force&quot; on the manager,</p><h4>Unsetting docker-machine shell variable settings</h4><p>You can unset the docker-machine environment variables in your current shell with the following command:</p><p>eval $(docker-machine env -u)</p><p>This disconnects the shell from docker-machine created virtual machines, and allows you to continue working in the same shell, now using native docker commands (for example, on Docker for Mac or Docker for Windows). To learn more, see the <a href="https://docs.docker.com/machine/get-started/#unset-environment-variables-in-the-current-shell">Machine topic on unsetting environment variables</a>.</p><h4>Restarting Docker machines</h4><p>If you shut down your local host, Docker machines stops running. You can check the status of machines by running docker-machine ls.</p><p>$ docker-machine ls</p><p>NAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORS</p><p>myvm1 - virtualbox Stopped Unknown</p><p>myvm2 - virtualbox Stopped Unknown</p><p>To restart a machine that&#x27;s stopped, run:</p><p>docker-machine start <code style="background-color:lightgray">&lt;machine-name&gt;</code></p><p>For example:</p><p>$ docker-machine start myvm1</p><p>Starting &quot;myvm1&quot;...</p><p>(myvm1) Check network to re-create if needed...</p><p>(myvm1) Waiting for an IP...</p><p>Machine &quot;myvm1&quot; was started.</p><p>Waiting for SSH to be available...</p><p>Detecting the provisioner...</p><p>Started machines may have new IP addresses. You may need to re-run the <code style="background-color:lightgray">docker-machine env</code> command.</p><p>$ docker-machine start myvm2</p><p>Starting &quot;myvm2&quot;...</p><p>(myvm2) Check network to re-create if needed...</p><p>(myvm2) Waiting for an IP...</p><p>Machine &quot;myvm2&quot; was started.</p><p>Waiting for SSH to be available...</p><p>Detecting the provisioner...</p><p>Started machines may have new IP addresses. You may need to re-run the <code style="background-color:lightgray">docker-machine env</code> command.</p><h3>Recap and cheat sheet (optional)</h3><p>Here&#x27;s <a href="https://asciinema.org/a/113837">a terminal recording of what was covered on this section</a>:</p><p>You learned what a swarm is, how nodes in swarms can be managers or workers, created a swarm, and deployed an application on it. You saw that the core Docker commands didn&#x27;t change from part 3, they just had to be targeted to run on a swarm master. You also saw the power of Docker&#x27;s networking in action, which kept load-balancing requests across containers, even though they were running on different machines. Finally, you learned how to iterate and scale your app on a cluster.</p><p>Here are some commands you might like to run to interact with your swarm and your VMs a bit:</p><p>docker-machine create --driver virtualbox myvm1 # Create a VM (Mac, Win7, Linux)</p><p>docker-machine create -d hyperv --hyperv-virtual-switch &quot;myswitch&quot; myvm1 # Win10</p><p>docker-machine env myvm1 # View basic information about your node</p><p>docker-machine ssh myvm1 &quot;docker node ls&quot; # List the nodes in your swarm</p><p>docker-machine ssh myvm1 &quot;docker node inspect <code style="background-color:lightgray">&lt;node ID&gt;</code>&quot; # Inspect a node</p><p>docker-machine ssh myvm1 &quot;docker swarm join-token -q worker&quot; # View join token</p><p>docker-machine ssh myvm1 # Open an SSH session with the VM; type &quot;exit&quot; to end</p><p>docker node ls # View nodes in swarm (while logged on to manager)</p><p>docker-machine ssh myvm2 &quot;docker swarm leave&quot; # Make the worker leave the swarm</p><p>docker-machine ssh myvm1 &quot;docker swarm leave -f&quot; # Make master leave, kill swarm</p><p>docker-machine ls # list VMs, asterisk shows which VM this shell is talking to</p><p>docker-machine start myvm1 # Start a VM that is currently not running</p><p>docker-machine env myvm1 # show environment variables and command for myvm1</p><p>eval $(docker-machine env myvm1) # Mac command to connect shell to myvm1</p><p>&amp; &quot;C:\Program Files\Docker\Docker\Resources\bin\docker-machine.exe&quot; env myvm1 | Invoke-Expression # Windows command to connect shell to myvm1</p><p>docker stack deploy -c <code style="background-color:lightgray">&lt;file&gt; &lt;app&gt;</code> # Deploy an app; command shell must be set to talk to manager (myvm1), uses local Compose file</p><p>docker-machine scp docker-compose.yml myvm1:<!-- -->~<!-- --> # Copy file to node\&#x27;s home dir (only required if you use ssh to connect to manager and deploy the app)</p><p>docker-machine ssh myvm1 &quot;docker stack deploy -c <code style="background-color:lightgray">&lt;file&gt; &lt;app&gt;</code>&quot; # Deploy an app using ssh (you must have first copied the Compose file to myvm1)</p><p>eval $(docker-machine env -u) # Disconnect shell from VMs, use native docker</p><p>docker-machine stop $(docker-machine ls -q) # Stop all running VMs</p><p>docker-machine rm $(docker-machine ls -q) # Delete all VMs and their disk images</p><h2><a href="https://docs.docker.com/get-started/part5/"></a>Stacks</h2><h3>Introduction</h3><p>You learned how to set up a swarm, which is a cluster of machines running Docker, and deployed an application to it, with containers running in concert on multiple machines.</p><p>You reach the top of the hierarchy of distributed applications: the <strong>stack</strong>. A stack is a group of interrelated services that share dependencies and can be orchestrated and scaled together. A single stack can define and coordinating the functionality of an entire application (though very complex applications may want to use multiple stacks).</p><h3>Add a new service and redeploy</h3><p>It&#x27;s easy to add services to our docker-compose.yml file. First, let&#x27;s add a free visualizer service that lets us look at how our swarm is scheduling containers.</p><ol><li>Open docker-compose.yml in an editor and replace its contents with the following. Be sure to replace username/repo:tag with your image details.</li></ol><p>version: &quot;3&quot;</p><p>services:</p><p>web:</p><h1>replace username/repo:tag with your name and image details</h1><p>image: username/repo:tag</p><p>deploy:</p><p>replicas: 5</p><p>restart_policy:</p><p>condition: on-failure</p><p>resources:</p><p>limits:</p><p>cpus: &quot;0.1&quot;</p><p>memory: 50M</p><p>ports:</p><ul><li>&quot;80:80&quot;</li></ul><p>networks:</p><ul><li>webnet</li></ul><p>visualizer:</p><p>image: dockersamples/visualizer:stable</p><p>ports:</p><ul><li>&quot;8080:8080&quot;</li></ul><p>volumes:</p><ul><li>&quot;/var/run/docker.sock:/var/run/docker.sock&quot;</li></ul><p>deploy:</p><p>placement:</p><p>constraints: <!-- -->[node.role == manager]</p><p>networks:</p><ul><li>webnet</li></ul><p>networks:</p><p>webnet:</p><ol><li>Make sure your shell is configured to talk to myvm1 (full examples are <a href="https://docs.docker.com/get-started/part4/#configure-a-docker-machine-shell-to-the-swarm-manager">here</a>).</li></ol><p>Run docker-machine ls to list machines and make sure you are connected to myvm1, as indicated by an asterisk next it.</p><p>If needed, re-run docker-machine env myvm1, then run the given command to configure the shell.</p><ul><li>On <strong>Mac or Linux</strong> the command is:</li></ul><p>eval $(docker-machine env myvm1)</p><ul><li>On <strong>Windows</strong> the command is:</li></ul><p>&amp; &quot;C:\Program Files\Docker\Docker\Resources\bin\docker-machine.exe&quot; env myvm1 | Invoke-Expression</p><ol><li>Re-run the docker stack deploy command on the manager, and whatever services need updating are updated:</li></ol><p>$ docker stack deploy -c docker-compose.yml getstartedlab</p><p>Updating service getstartedlab_web (id: angi1bf5e4to03qu9f93trnxm)</p><p>Creating service getstartedlab_visualizer (id: l9mnwkeq2jiononb5ihz9u7a4)</p><ol><li>Look at the visualizer.</li></ol><p>You saw in the Compose file that visualizer runs on port 8080. Get the IP address of one of your nodes by running docker-machine ls. Go to either IP address at port 8080 and you can see the visualizer running:</p><p>The single copy of visualizer is running on the manager as you expect, and the 5 instances of web are spread out across the swarm. You can corroborate this visualization by running docker stack ps <code style="background-color:lightgray">&lt;stack&gt;</code>:</p><p>docker stack ps getstartedlab</p><p>The visualizer is a standalone service that can run in any app that includes it in the stack. It doesn&#x27;t depend on anything else. Now let&#x27;s create a service that does have a dependency: the Redis service that provides a visitor counter.</p><h3>Persist the data</h3><p>Let&#x27;s go through the same workflow once more to add a Redis database for storing app data.</p><ol><li>Save this new docker-compose.yml file, which finally adds a Redis service. Be sure to replace username/repo:tag with your image details.</li></ol><p>version: &quot;3&quot;</p><p>services:</p><p>web:</p><h1>replace username/repo:tag with your name and image details</h1><p>image: username/repo:tag</p><p>deploy:</p><p>replicas: 5</p><p>restart_policy:</p><p>condition: on-failure</p><p>resources:</p><p>limits:</p><p>cpus: &quot;0.1&quot;</p><p>memory: 50M</p><p>ports:</p><ul><li>&quot;80:80&quot;</li></ul><p>networks:</p><ul><li>webnet</li></ul><p>visualizer:</p><p>image: dockersamples/visualizer:stable</p><p>ports:</p><ul><li>&quot;8080:8080&quot;</li></ul><p>volumes:</p><ul><li>&quot;/var/run/docker.sock:/var/run/docker.sock&quot;</li></ul><p>deploy:</p><p>placement:</p><p>constraints: <!-- -->[node.role == manager]</p><p>networks:</p><ul><li>webnet</li></ul><p>redis:</p><p>image: redis</p><p>ports:</p><ul><li>&quot;6379:6379&quot;</li></ul><p>volumes:</p><ul><li>&quot;/home/docker/data:/data&quot;</li></ul><p>deploy:</p><p>placement:</p><p>constraints: <!-- -->[node.role == manager]</p><p>command: redis-server --appendonly yes</p><p>networks:</p><ul><li>webnet</li></ul><p>networks:</p><p>webnet:</p><p>Redis has an official image in the Docker library and has been granted the short image name of just redis, so no username/repo notation here. The Redis port, 6379, has been pre-configured by Redis to be exposed from the container to the host, and here in our Compose file we expose it from the host to the world, so you can enter the IP for any of your nodes into Redis Desktop Manager and manage this Redis instance, if you so choose.</p><p>Most importantly, there are a couple of things in the redis specification that make data persist between deployments of this stack:</p><ul><li>redis always runs on the manager, so it&#x27;s always using the same filesystem.</li><li>redis accesses an arbitrary directory in the host&#x27;s file system as /data inside the container, which is where Redis stores data.</li></ul><p>Together, this is creating a &quot;source of truth&quot; in your host&#x27;s physical filesystem for the Redis data. Without this, Redis would store its data in /data inside the container&#x27;s filesystem, which would get wiped out if that container were ever redeployed.</p><p>This source of truth has two components:</p><ul><li>The placement constraint you put on the Redis service, ensuring that it always uses the same host.</li><li>The volume you created that lets the container access ./data (on the host) as /data(inside the Redis container). While containers come and go, the files stored on ./data on the specified host persists, enabling continuity.</li></ul><p>You are ready to deploy your new Redis-using stack.</p><ol><li>Create a ./data directory on the manager:</li></ol><p>docker-machine ssh myvm1 &quot;mkdir ./data&quot;</p><ol><li>Make sure your shell is configured to talk to myvm1 (full examples are <a href="https://docs.docker.com/get-started/part4/#configure-a-docker-machine-shell-to-the-swarm-manager">here</a>).</li></ol><ul><li>Run docker-machine ls to list machines and make sure you are connected to myvm1, as indicated by an asterisk next it.</li><li>If needed, re-run docker-machine env myvm1, then run the given command to configure the shell.<ul><li>On <strong>Mac or Linux</strong> the command is:</li></ul></li></ul><p>eval $(docker-machine env myvm1)</p><ul><li>On <strong>Windows</strong> the command is:</li></ul><p>&amp; &quot;C:\Program Files\Docker\Docker\Resources\bin\docker-machine.exe&quot; env myvm1 | Invoke-Expression</p><ol><li>Run docker stack deploy one more time.</li></ol><p>$ docker stack deploy -c docker-compose.yml getstartedlab</p><ol><li>Run docker service ls to verify that the three services are running as expected.</li></ol><p>ID NAME MODE REPLICAS IMAGE PORTS</p><p>x7uij6xb4foj getstartedlab_redis replicated 1/1 redis:latest *:6379-&gt;6379/tcp</p><p>n5rvhm52ykq7 getstartedlab_visualizer replicated 1/1 dockersamples/visualizer:stable *:8080-&gt;8080/tcp</p><p>mifd433bti1d getstartedlab_web replicated 5/5 orangesnap/getstarted:latest *:80-&gt;80/tcp</p><ol><li>Check the web page at one of your nodes, such as <a href="http://192.168.99.101">http://192.168.99.101</a>, and look at the results of the visitor counter, which is now live and storing information on Redis.</li></ol><p>Also, check the visualizer at port 8080 on either node&#x27;s IP address, and notice see the redis service running along with the web and visualizer services.</p><h2><a href="https://docs.docker.com/engine/docker-overview/"></a>Docker overview</h2><p>Docker is an open platform for developing, shipping, and running applications. Docker enables you to separate your applications from your infrastructure, so you can deliver software quickly. With Docker, you can manage your infrastructure in the same ways you manage your applications. By taking advantage of Docker&#x27;s methodologies for shipping, testing, and deploying code quickly, you can significantly reduce the delay between writing code and running it in production.</p><h3>The Docker platform</h3><p>Docker provides the ability to package and run an application in a loosely isolated environment called a container. The isolation and security allow you to run many containers simultaneously on a given host. Containers are lightweight because they don&#x27;t need the extra load of a hypervisor but run directly within the host machine&#x27;s kernel. This means you can run more containers on a given hardware combination than if you were using virtual machines. You can even run Docker containers within host machines that are virtual machines!</p><p>Docker provides tooling and a platform to manage the lifecycle of your containers:</p><ul><li>Develop your application and its supporting components using containers.</li><li>The container becomes the unit for distributing and testing your application.</li><li>When you&#x27;re ready, deploy your application into your production environment, as a container or an orchestrated service. This works the same whether your production environment is a local data center, a cloud provider, or a hybrid of the two.</li></ul><h3>Docker Engine</h3><p>Docker Engine is a client-server application with these major components:</p><ul><li>A server which is a type of long-running program called a daemon process (the dockerd command).</li><li>A REST API which specifies interfaces that programs can use to talk to the daemon and instruct it what to do.</li><li></li></ul><p>The CLI uses the Docker REST API to control or interact with the Docker daemon through scripting or direct CLI commands. Many other Docker applications use the underlying API and CLI.</p><p>The daemon creates and manages Docker objects, such as images, containers, networks, and volumes.</p><p><strong>Note</strong>: Docker is licensed under the open source Apache 2.0 license.</p><p>For more details, see <a href="https://docs.docker.com/engine/docker-overview/#docker-architecture">Docker Architecture</a>.</p><h3>What can I use Docker for?</h3><p><strong>Fast, consistent delivery of your applications</strong></p><p>Docker streamlines the development lifecycle by allowing developers to work in standardized environments using local containers which provide your applications and services. Containers are great for continuous integration and continuous delivery (CI/CD) workflows.</p><p>Consider the following example scenario:</p><ul><li>Your developers write code locally and share their work with their colleagues using Docker containers.</li><li>They use Docker to push their applications into a test environment and execute automated and manual tests.</li><li>When developers find bugs, they can fix them in the development environment and redeploy them to the test environment for testing and validation.</li><li>When testing is complete, getting the fix to the customer is as simple as pushing the updated image to the production environment.</li></ul><p><strong>Responsive deployment and scaling</strong></p><p>Docker&#x27;s container-based platform allows for highly portable workloads. Docker containers can run on a developer&#x27;s local laptop, on physical or virtual machines in a data center, on cloud providers, or in a mixture of environments.</p><p>Docker&#x27;s portability and lightweight nature also make it easy to dynamically manage workloads, scaling up or tearing down applications and services as business needs dictate, in near real time.</p><p><strong>Running more workloads on the same hardware</strong></p><p>Docker is lightweight and fast. It provides a viable, cost-effective alternative to hypervisor-based virtual machines, so you can use more of your compute capacity to achieve your business goals. Docker is perfect for high density environments and for small and medium deployments where you need to do more with fewer resources.</p><h3>Docker architecture</h3><h4>The Docker daemon</h4><p>The Docker daemon (dockerd) listens for Docker API requests and manages Docker objects such as images, containers, networks, and volumes. A daemon can also communicate with other daemons to manage Docker services.</p><h4>The Docker client</h4><p>The Docker client (docker) is the primary way that many Docker users interact with Docker. When you use commands such as docker run, the client sends these commands to dockerd, which carries them out. The docker command uses the Docker API. The Docker client can communicate with more than one daemon.</p><h4>Docker registries</h4><p>A Docker registry stores Docker images. Docker Hub and Docker Cloud are public registries that anyone can use, and Docker is configured to look for images on Docker Hub by default. You can even run your own private registry. If you use Docker Datacenter (DDC), it includes Docker Trusted Registry (DTR).</p><p>When you use the docker pull or docker run commands, the required images are pulled from your configured registry. When you use the docker push command, your image is pushed to your configured registry.</p><p><a href="http://store.docker.com/">Docker store</a> allows you to buy and sell Docker images or distribute them for free. For instance, you can buy a Docker image containing an application or service from a software vendor and use the image to deploy the application into your testing, staging, and production environments. You can upgrade the application by pulling the new version of the image and redeploying the containers.</p><h4>Docker objects</h4><p>When you use Docker, you are creating and using images, containers, networks, volumes, plugins, and other objects. This section is a brief overview of some of those objects.</p><h5>IMAGES</h5><p>An image is a read-only template with instructions for creating a Docker container. Often, an image is based on another image, with some additional customization. For example, you may build an image which is based on the ubuntu image, but installs the Apache web server and your application, as well as the configuration details needed to make your application run.</p><p>You might create your own images, or you might only use those created by others and published in a registry. To build your own image, you create a Dockerfile with a simple syntax for defining the steps needed to create the image and run it. Each instruction in a Dockerfile creates a layer in the image. When you change the Dockerfile and rebuild the image, only those layers which have changed are rebuilt. This is part of what makes images so lightweight, small, and fast, when compared to other virtualization technologies.</p><h5>CONTAINERS</h5><p>A container is a runnable instance of an image. You can create, start, stop, move, or delete a container using the Docker API or CLI. You can connect a container to one or more networks, attach storage to it, or even create a new image based on its current state.</p><p>By default, a container is relatively well isolated from other containers and its host machine. You can control how isolated a container&#x27;s network, storage, or other underlying subsystems are from other containers or from the host machine.</p><p>A container is defined by its image as well as any configuration options you provide to it when you create or start it. When a container is removed, any changes to its state that are not stored in persistent storage disappear.</p><h6>Example <strong>docker run</strong> command</h6><p>The following command runs an ubuntu container, attaches interactively to your local command-line session, and runs /bin/bash.</p><p>$ docker run -i -t ubuntu /bin/bash</p><p>When you run this command, the following happens (assuming you are using the default registry configuration):</p><p>If you do not have the ubuntu image locally, Docker pulls it from your configured registry, as though you had run docker pull ubuntu manually.</p><ol><li>Docker creates a new container, as though you had run a docker container create command manually.</li><li>Docker allocates a read-write filesystem to the container, as its final layer. This allows a running container to create or modify files and directories in its local filesystem.</li><li>Docker creates a network interface to connect the container to the default network, since you did not specify any networking options. This includes assigning an IP address to the container. By default, containers can connect to external networks using the host machine&#x27;s network connection.</li><li>Docker starts the container and executes /bin/bash. Because the container is run interactively and attached to your terminal (due to the -i and -t) flags, you can provide input using your keyboard and output is logged to your terminal.</li><li>When you type exit to terminate the /bin/bash command, the container stops but is not removed. You can start it again or remove it.</li></ol><h5>Services</h5><p>Services allow you to scale containers across multiple Docker daemons, which all work together as a swarm with multiple managers and workers. Each member of a swarm is a Docker daemon, and the daemons all communicate using the Docker API. A service allows you to define the desired state, such as the number of replicas of the service that must be available at any given time. By default, the service is load-balanced across all worker nodes. To the consumer, the Docker service appears to be a single application. Docker Engine supports swarm mode in Docker 1.12 and higher.</p><h3>The underlying technology</h3><p>Docker is written in <a href="https://golang.org/">Go</a> and takes advantage of several features of the Linux kernel to deliver its functionality.</p><h4>Namespaces</h4><p>Docker uses a technology called namespaces to provide the isolated workspace called the container. When you run a container, Docker creates a set of namespaces for that container.</p><p>These namespaces provide a layer of isolation. Each aspect of a container runs in a separate namespace and its access is limited to that namespace.</p><p>Docker Engine uses namespaces such as the following on Linux:</p><ul><li><strong>The pid namespace:</strong> Process isolation (PID: Process ID).</li><li><strong>The net namespace:</strong> Managing network interfaces (NET: Networking).</li><li><strong>The ipc namespace:</strong> Managing access to IPC resources (IPC: InterProcess Communication).</li><li><strong>The mnt namespace:</strong> Managing filesystem mount points (MNT: Mount).</li><li><strong>The uts namespace:</strong> Isolating kernel and version identifiers. (UTS: Unix Timesharing System).</li></ul><h4>Control groups</h4><p>Docker Engine on Linux also relies on another technology called control groups (cgroups). A cgroup limits an application to a specific set of resources. Control groups allow Docker Engine to share available hardware resources to containers and optionally enforce limits and constraints. For example, you can limit the memory available to a specific container.</p><h4>Union file systems</h4><p>Union file systems, or UnionFS, are file systems that operate by creating layers, making them very lightweight and fast. Docker Engine uses UnionFS to provide the building blocks for containers. Docker Engine can use multiple UnionFS variants, including AUFS, btrfs, vfs, and DeviceMapper.</p><h4>Container format</h4><p>Docker Engine combines the namespaces, control groups, and UnionFS into a wrapper called a container format. The default container format is libcontainer. In the future, Docker may support other container formats by integrating with technologies such as BSD Jails or Solaris Zones.</p><h1><a href="https://docs.docker.com/develop/"></a>Develop with Docker</h1><p>This page lists resources for application developers using Docker.</p><h2>Develop new apps on Docker</h2><p>If you&#x27;re just getting started developing a brand-new app on Docker, check out these resources to understand some of the most common patterns for getting the most benefits from Docker.</p><ul><li>Learn to <a href="https://docs.docker.com/get-started/part2/">build an image from a Dockerfile</a></li><li>Use <a href="https://docs.docker.com/engine/userguide/eng-image/multistage-build/">multistage builds</a> to keep your images lean</li><li>Manage application data using <a href="https://docs.docker.com/engine/admin/volumes/volumes/">volumes</a> and <a href="https://docs.docker.com/engine/admin/volumes/bind-mounts/">bind mounts</a></li><li><a href="https://docs.docker.com/get-started/part3/">Scale your app</a> as a swarm service</li><li><a href="https://docs.docker.com/get-started/part5/">Define your app stack</a> using a compose file</li><li>General application development best practices</li></ul><h2>Learn about language-specific app development with Docker</h2><ul><li><a href="https://github.com/docker/labs/tree/master/developer-tools/java/">Docker for Java developers</a> lab</li><li><a href="https://github.com/docker/labs/tree/master/developer-tools/nodejs/porting">Port a node.js app to Docker</a></li><li><a href="https://github.com/docker/labs/tree/master/developer-tools/ruby">Ruby on Rails app on Docker</a> lab</li><li><a href="https://docs.docker.com/engine/examples/dotnetcore/">Dockerize a .Net Core application</a></li><li><a href="https://docs.docker.com/compose/aspnet-mssql-compose/">Dockerize an ASP.NET Core application with SQL Server on Linux</a> using Docker Compose</li></ul><h2>Advanced development with the SDK or API</h2><p>When you&#x27;re comfortable developing apps by writing Dockerfiles or compose files and using the Docker CLI, you can take it to the next level by using the Docker Engine SDK for Go or Python or using the HTTP API directly.</p><h2><a href="https://docs.docker.com/develop/dev-best-practices/"></a>Docker development best practices</h2><h3>How to keep your images small</h3><p>Small images are faster to pull over the network and faster to load into memory when starting containers or services. There are a few rules of thumb to keep image size small:</p><ul><li>Start with an appropriate base image. For instance, if you need a JDK, consider basing your image on the official openjdk image, rather than starting with a generic ubuntu image and installing openjdk as part of the Dockerfile.</li><li><a href="https://docs.docker.com/engine/userguide/eng-image/multistage-build/">Use multistage builds</a>. For instance, you can use the maven image to build your Java application, then reset to the tomcat image and copy the Java artifacts into the correct location to deploy your app, all in the same Dockerfile. This means that your final image doesn&#x27;t include all the libraries and dependencies pulled in by the build, but only the artifacts and the environment needed to run them.</li><li>If you need to use a version of Docker that does not include multistage builds, try to reduce the number of layers in your image by <strong>minimizing the number of separate RUN commands</strong> in your Dockerfile. You can do this by consolidating multiple commands into a single RUN line and using your shell&#x27;s mechanisms to combine them together. Consider the following two fragments. The first creates two layers in the image, while the second only creates one.</li></ul><p>RUN apt-get -y update</p><p>RUN apt-get install -y python</p><p>RUN apt-get -y update &amp;&amp; apt-get install -y python</p><ul><li>If you have <strong>multiple images with a lot in common, consider creating your own </strong><a href="https://docs.docker.com/engine/userguide/eng-image/baseimages/"><strong>base image</strong></a> with the shared components, and basing your unique images on that. Docker only needs to load the common layers once, and they are cached. This means that your derivative images use memory on the Docker host more efficiently and load more quickly.</li><li>To keep your production image lean but allow for debugging, consider using the production image as the base image for the debug image. Additional testing or debugging tooling can be added on top of the production image.</li><li>When building images, always tag them with useful tags which codify version information, intended destination (prod or test, for instance), stability, or other information that is useful when deploying the application in different environments. Do not rely on the automatically-created latest tag.</li></ul><h3>Where and how to persist application data</h3><ul><li><strong>Avoid</strong> storing application data in your container&#x27;s writable layer using <a href="https://docs.docker.com/engine/userguide/storagedriver/">storage drivers</a>. This increases the size of your container and is less efficient from an I/O perspective than using volumes or bind mounts.</li><li>Instead, store data using <a href="https://docs.docker.com/engine/admin/volumes/volumes/">volumes</a>.</li><li>One case where it is appropriate to use <a href="https://docs.docker.com/engine/admin/volumes/bind-mounts/">bind mounts</a> is during development, when you may want to mount your source directory or a binary you just built into your container. For production, use a volume instead, mounting it into the same location as you mounted a bind mount during development.</li><li>For production, use <a href="https://docs.docker.com/engine/swarm/secrets/">secrets</a> to store sensitive application data used by services, and use <a href="https://docs.docker.com/engine/swarm/configs/">configs</a> for non-sensitive data such as configuration files. If you currently use standalone containers, consider migrating to use single-replica services, so that you can take advantage of these service-only features.</li></ul><h3>Use swarm services when possible</h3><ul><li>When possible, design your application with the ability to scale using swarm services.</li><li>Even if you only need to run a single instance of your application, swarm services provide several advantages over standalone containers. A service&#x27;s configuration is declarative, and Docker is always working to keep the desired and actual state in sync.</li><li>Networks and volumes can be connected and disconnected from swarm services, and Docker handles redeploying the individual service containers in a non-disruptive way. Standalone containers need to be manually stopped, removed, and recreated to accommodate configuration changes.</li><li>Several features, such as the ability to store <a href="https://docs.docker.com/engine/swarm/secrets/">secrets</a> and <a href="https://docs.docker.com/engine/swarm/configs/">configs</a>, are only available to services rather than standalone containers. These features allow you to keep your images as generic as possible and to avoid storing sensitive data within the Docker images or containers themselves.</li><li>Let docker stack deploy handle any image pulls for you, instead of using docker pull. This way, your deployment doesn&#x27;t try to pull from nodes that are down. Also, when new nodes are added to the swarm, images are pulled automatically.</li></ul><p>There are limitations around sharing data amongst nodes of a swarm service. If you use <a href="https://docs.docker.com/docker-for-aws/persistent-data-volumes/">Docker for AWS</a> or <a href="https://docs.docker.com/develop/docker-for-azure/persistent-data-volumes/">Docker for Azure</a>, you can use the Cloudstor plugin to share data amongst your swarm service nodes. You can also write your application data into a separate database which supports simultaneous updates.</p><h3>Use CI/CD for testing and deployment</h3><ul><li>When you check a change into source control or create a pull request, use <a href="https://docs.docker.com/docker-cloud/builds/automated-build/">Docker Cloud</a> or another CI/CD pipeline to automatically build and tag a Docker image and test it. Docker Cloud can also deploy tested apps straight into production.</li><li>Take this even further with <a href="https://docs.docker.com/enterprise/">Docker EE</a> by requiring your development, testing, and security teams to sign images before they can be deployed into production. This way, you can be sure that before an image is deployed into production, it has been tested and signed off by, for instance, development, quality, and security teams.</li></ul><h3>Differences in development and production environments</h3><hr/><p>  Development                                                          Production
Use bind mounts to give your container access to your source code.   Use volumes to store container data.
Use Docker for Mac or Docker for Windows.                            Use Docker EE if possible, with <a href="https://docs.docker.com/engine/security/userns-remap/">userns mapping</a> for greater isolation of Docker processes from host processes.
Don&#x27;t worry about time drift.                                        Always run an NTP client on the Docker host and within each container process and sync them all to the same NTP server. If you use swarm services, also ensure that each Docker node syncs its clocks to the same time source as the containers.</p><hr/><h2>Develop Images</h2><h3><a href="https://docs.docker.com/develop/develop-images/dockerfile_best-practices/"></a>Best practices for writing Dockerfiles</h3><p>Docker can build images automatically by reading the instructions from a Dockerfile, a text file that contains all the commands, in order, needed to build a given image. Dockerfiles adhere to a specific format and use a specific set of instructions.</p><p>This covers the best practices and methods recommended by Docker, Inc. and the Docker community for building efficient images. To see many of these practices and recommendations in action, check out the Dockerfile for <a href="https://github.com/docker-library/buildpack-deps/blob/master/jessie/Dockerfile">buildpack-deps</a>.</p><p><strong>Note</strong>: for more detailed explanations of any of the Dockerfile commands mentioned here, visit the <a href="https://docs.docker.com/engine/reference/builder/">Dockerfile Reference</a> page.</p><h4>General guidelines and recommendations</h4><h5>Containers should be ephemeral</h5><p>The container produced by the image your Dockerfile defines should be as ephemeral as possible. By &quot;ephemeral,&quot; we mean that it can be stopped and destroyed and a new one built and put in place with an absolute minimum of set-up and configuration. You may want to take a look at the <a href="https://12factor.net/processes">Processes</a> section of the 12 Factor app methodology to get a feel for the motivations of running containers in such a stateless fashion.</p><h6>Use a .dockerignore file</h6><p>The current working you directory where are located when you issue a docker build command is called the build context, and the Dockerfile must be somewhere within this build context. By default, it is assumed to be in the current directory, but you can specify a different location by using the -fflag. Regardless of where the Dockerfile lives, all the recursive contents of files and directories in the current directory are sent to the Docker daemon as the build context. Inadvertently including files that are not necessary for building the image results in a larger build context and larger image size. These in turn can increase build time, time to pull and push the image, and the runtime size of containers. To see how big your build context is, look for a message like the following, when you build your Dockerfile.</p><p>Sending build context to Docker daemon 187.8MB</p><p>To exclude files which are not relevant to the build, without restructuring your source repository, use a .dockerignore file. This file supports exclusion patterns similar to .gitignore files. For information on creating one, see the <a href="https://docs.docker.com/engine/reference/builder/#dockerignore-file">.dockerignore file</a>. In addition to using a .dockerignore file, check out the information below on <a href="https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#use-multi-stage-builds">multi-stage builds</a>.</p><h5>Use multi-stage builds</h5><p>If you use Docker 17.05 or higher, you can use <a href="https://docs.docker.com/develop/develop-images/multistage-build/">multi-stage builds</a> to drastically reduce the size of your final image, without the need to jump through hoops to reduce the number of intermediate layers or remove intermediate files during the build.</p><p>Images being built by the final stage only, you can most of the time benefit both the build cache and minimize images layers.</p><p>Your build stage may contain several layers, ordered from the less frequently changed to the more frequently changed for example:</p><ul><li>Install tools you need to build your application</li><li>Install or update library dependencies</li><li>Generate your application</li></ul><p>A Dockerfile for a go application could look like:</p><p>FROM golang:1.9.2-alpine3.6 AS build</p><h1>Install tools required to build the project</h1><h1>We need to run <code>docker build --no-cache .</code> to update those dependencies</h1><p>RUN apk add --no-cache git</p><p>RUN go get github.com/golang/dep/cmd/dep</p><h1>Gopkg.toml and Gopkg.lock lists project dependencies</h1><h1>These layers are only re-built when Gopkg files are updated</h1><p>COPY Gopkg.lock Gopkg.toml /go/src/project/</p><p>WORKDIR /go/src/project/</p><h1>Install library dependencies</h1><p>RUN dep ensure -vendor-only</p><h1>Copy all project and build it</h1><h1>This layer is rebuilt when ever a file has changed in the project directory</h1><p>COPY . /go/src/project/</p><p>RUN go build -o /bin/project</p><h1>This results in a single layer image</h1><p>FROM scratch</p><p>COPY --from=build /bin/project /bin/project</p><p>ENTRYPOINT <!-- -->[&quot;/bin/project&quot;]</p><p>CMD <!-- -->[&quot;--help&quot;]</p><h5>Avoid installing unnecessary packages</h5><p>To reduce complexity, dependencies, file sizes, and build times, you should avoid installing extra or unnecessary packages just because they might be &quot;nice to have.&quot; For example, you don&#x27;t need to include a text editor in a database image.</p><h5>Each container should have only one concern</h5><p>Decoupling applications into multiple containers makes it much easier to scale horizontally and reuse containers. For instance, a web application stack might consist of three separate containers, each with its own unique image, to manage the web application, database, and an in-memory cache in a decoupled manner.</p><p>You may have heard that there should be &quot;one process per container&quot;. While this mantra has good intentions, it is not necessarily true that there should be only one operating system process per container. In addition to the fact that containers can now be <a href="https://docs.docker.com/engine/reference/run/#specifying-an-init-process">spawned with an init process</a>, some programs might spawn additional processes of their own accord. For instance, <a href="http://www.celeryproject.org/">Celery</a> can spawn multiple worker processes, or <a href="https://httpd.apache.org/">Apache</a> might create a process per request. While &quot;one process per container&quot; is frequently a good rule of thumb, it is not a hard and fast rule. Use your best judgment to keep containers as clean and modular as possible.</p><p>If containers depend on each other, you can use <a href="https://docs.docker.com/engine/userguide/networking/">Docker container networks</a> to ensure that these containers can communicate.</p><h5>Minimize the number of layers</h5><p>Prior to Docker 17.05, and even more, prior to Docker 1.10, it was important to minimize the number of layers in your image. The following improvements have mitigated this need:</p><ul><li>In Docker 1.10 and higher, only RUN, COPY, and ADD instructions create layers. Other instructions create temporary intermediate images, and no longer directly increase the size of the build.</li><li>Docker 17.05 and higher add support for <a href="https://docs.docker.com/develop/develop-images/multistage-build/">multi-stage builds</a>, which allow you to copy only the artifacts you need into the final image. This allows you to include tools and debug information in your intermediate build stages without increasing the size of the final image.</li></ul><h5>Sort multi-line arguments</h5><p>Whenever possible, ease later changes by sorting multi-line arguments alphanumerically. This helps you avoid duplication of packages and make the list much easier to update. This also makes PRs a lot easier to read and review. Adding a space before a backslash (<!-- -->)<!-- --> helps as well.</p><p>Here&#x27;s an example from the <a href="https://github.com/docker-library/buildpack-deps">buildpack-deps image</a>:</p><p>RUN apt-get update &amp;&amp; apt-get install -y \</p><p>bzr \</p><p>cvs \</p><p>git \</p><p>mercurial \</p><p>subversion</p><h5>Build cache</h5><p>During the process of building an image Docker steps through the instructions in your Dockerfile executing each in the order specified. As each instruction is examined Docker looks for an existing image in its cache that it can reuse, rather than creating a new (duplicate) image. If you do not want to use the cache at all you can use the --no-cache=true option on the docker build command.</p><p>However, if you do let Docker use its cache then it is very important to understand when it can, and cannot, find a matching image. The basic rules that Docker follows are outlined below:</p><ul><li>Starting with a parent image that is already in the cache, the next instruction is compared against all child images derived from that base image to see if one of them was built using the exact same instruction. If not, the cache is invalidated.</li><li>In most cases simply comparing the instruction in the Dockerfile with one of the child images is sufficient. However, certain instructions require a little more examination and explanation.</li><li>For the ADD and COPY instructions, the contents of the file(s) in the image are examined and a checksum is calculated for each file. The last-modified and last-accessed times of the file(s) are not considered in these checksums. During the cache lookup, the checksum is compared against the checksum in the existing images. If anything has changed in the file(s), such as the contents and metadata, then the cache is invalidated.</li><li>Aside from the ADD and COPY commands, cache checking does not look at the files in the container to determine a cache match. For example, when processing a RUN apt-get -y update command the files updated in the container are not examined to determine if a cache hit exists. In that case just the command string itself is used to find a match.</li></ul><p>Once the cache is invalidated, all subsequent Dockerfile commands generate new images and the cache is not used.</p><h4>The Dockerfile instructions</h4><p>These recommendations help you to write an efficient and maintainable Dockerfile.</p><h5>FROM</h5><ul><li><a href="https://docs.docker.com/engine/reference/builder/#from">Dockerfile reference for the FROM instruction</a></li></ul><p>Whenever possible, use current Official Repositories as the basis for your image. We recommend the <a href="https://hub.docker.com/_/alpine/">Alpine image</a> since it&#x27;s very tightly controlled and kept minimal (currently under 5 mb), while still being a full distribution.</p><h5>LABEL</h5><ul><li><a href="https://docs.docker.com/config/labels-custom-metadata/">Understanding object labels</a></li></ul><p>You can add labels to your image to help organize images by project, record licensing information, to aid in automation, or for other reasons. For each label, add a line beginning with LABEL and with one or more key-value pairs. The following examples show the different acceptable formats. Explanatory comments are included inline.</p><p><strong>Note</strong>: If your string contains spaces, it must be quoted, <strong>or</strong> the spaces must be escaped. If your string contains inner quote characters (&quot;), escape them as well.</p><h1>Set one or more individual labels</h1><p>LABEL com.example.version=&quot;0.0.1-beta&quot;</p><p>LABEL vendor=&quot;ACME Incorporated&quot;</p><p>LABEL com.example.release-date=&quot;2015-02-12&quot;</p><p>LABEL com.example.version.is-production=&quot;&quot;</p><p>An image can have more than one label. Prior to Docker 1.10, it was recommended to combine all labels into a single LABEL instruction, to prevent extra layers from being created. This is no longer necessary, but combining labels is still supported.</p><h1>Set multiple labels on one line</h1><p>LABEL com.example.version=&quot;0.0.1-beta&quot; com.example.release-date=&quot;2015-02-12&quot;</p><p>The above can also be written as:</p><h1>Set multiple labels at once, using line-continuation characters to break long lines</h1><p>LABEL vendor=ACME\ Incorporated \</p><p>com.example.is-beta= \</p><p>com.example.is-production=&quot;&quot; \</p><p>com.example.version=&quot;0.0.1-beta&quot; \</p><p>com.example.release-date=&quot;2015-02-12&quot;</p><p>See <a href="https://docs.docker.com/config/labels-custom-metadata/">Understanding object labels</a> for guidelines about acceptable label keys and values. For information about querying labels, refer to the items related to filtering in <a href="https://docs.docker.com/config/labels-custom-metadata/#managing-labels-on-objects">Managing labels on objects</a>. See also <a href="https://docs.docker.com/engine/reference/builder/#label">LABEL</a> in the Dockerfile reference.</p><h5>RUN</h5><ul><li><a href="https://docs.docker.com/engine/reference/builder/#run">Dockerfile reference for the RUN instruction</a></li></ul><p>As always, to make your Dockerfile more readable, understandable, and maintainable, split long or complex RUN statements on multiple lines separated with backslashes.</p><h6>APT-GET</h6><p>Probably the most common use-case for RUN is an application of apt-get. The RUN apt-get command, because it installs packages, has several gotchas to look out for.</p><p>You should avoid RUN apt-get upgrade or dist-upgrade, as many of the &quot;essential&quot; packages from the parent images can&#x27;t upgrade inside an <a href="https://docs.docker.com/engine/reference/run/#security-configuration">unprivileged container</a>. If a package contained in the parent image is out-of-date, you should contact its maintainers. If you know there&#x27;s a package, foo, that needs to be updated, use apt-get install -y foo to update automatically.</p><p>Always combine RUN apt-get update with apt-get install in the same RUN statement. For example:</p><p>RUN apt-get update &amp;&amp; apt-get install -y \</p><p>package-bar \</p><p>package-baz \</p><p>package-foo</p><p>Using apt-get update alone in a RUN statement causes caching issues and subsequent apt-get install instructions fail. For example, say you have a Dockerfile:</p><p>FROM ubuntu:14.04</p><p>RUN apt-get update</p><p>RUN apt-get install -y curl</p><p>After building the image, all layers are in the Docker cache. Suppose you later modify apt-get installby adding extra package:</p><p>FROM ubuntu:14.04</p><p>RUN apt-get update</p><p>RUN apt-get install -y curl nginx</p><p>Docker sees the initial and modified instructions as identical and reuses the cache from previous steps. As a result the apt-get update is NOT executed because the build uses the cached version. Because the apt-get update is not run, your build can potentially get an outdated version of the curl and nginx packages.</p><p>Using RUN apt-get update &amp;&amp; apt-get install -y ensures your Dockerfile installs the latest package versions with no further coding or manual intervention. This technique is known as &quot;cache busting&quot;. You can also achieve cache-busting by specifying a package version. This is known as version pinning, for example:</p><p>RUN apt-get update &amp;&amp; apt-get install -y \</p><p>package-bar \</p><p>package-baz \</p><p>package-foo=1.3.*</p><p>Version pinning forces the build to retrieve a version regardless of what&#x27;s in the cache. This technique can also reduce failures due to unanticipated changes in required packages.</p><p>Below is a well-formed RUN instruction that demonstrates all the apt-get recommendations.</p><p>RUN apt-get update &amp;&amp; apt-get install -y \</p><p>aufs-tools \</p><p>automake \</p><p>build-essential \</p><p>curl \</p><p>dpkg-sig \</p><p>libcap-dev \</p><p>libsqlite3-dev \</p><p>mercurial \</p><p>reprepro \</p><p>ruby1.9.1 \</p><p>ruby1.9.1-dev \</p><p>s3cmd=1.1.* \</p><p>&amp;&amp; rm -rf /var/lib/apt/lists/*</p><p>The s3cmd instructions specifies a version 1.1.*. If the image previously used an older version, specifying the new one causes a cache bust of apt-get update and ensure the installation of the new version. Listing packages on each line can also prevent mistakes in package duplication.</p><p>In addition, when you clean up the apt cache by removing /var/lib/apt/lists reduces the image size, since the apt cache is not stored in a layer. Since the RUN statement starts with apt-get update, the package cache is always refreshed prior to apt-get install.</p><p><strong>Note</strong>: The official Debian and Ubuntu images <a href="https://github.com/moby/moby/blob/03e2923e42446dbb830c654d0eec323a0b4ef02a/contrib/mkimage/debootstrap#L82-L105">automatically run apt-get clean</a>, so explicit invocation is not required.</p><h6>USING PIPES</h6><p>Some RUN commands depend on the ability to pipe the output of one command into another, using the pipe character (|), as in the following example:</p><p>RUN wget -O - <a href="https://some.site">https://some.site</a> | wc -l &gt; /number</p><p>Docker executes these commands using the /bin/sh -c interpreter, which only evaluates the exit code of the last operation in the pipe to determine success. In the example above this build step succeeds and produces a new image so long as the wc -l command succeeds, even if the wget command fails.</p><p>If you want the command to fail due to an error at any stage in the pipe, prepend set -o pipefail &amp;&amp;to ensure that an unexpected error prevents the build from inadvertently succeeding. For example:</p><p>RUN set -o pipefail &amp;&amp; wget -O - <a href="https://some.site">https://some.site</a> | wc -l &gt; /number</p><p><strong>Note</strong>: Not all shells support the -o pipefail option. In such cases (such as the dash shell, which is the default shell on Debian-based images), consider using the exec form of RUN to explicitly choose a shell that does support the pipefail option. For example:</p><p>RUN <!-- -->[&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;set -o pipefail &amp;&amp; wget -O - https://some.site | wc -l &gt; /number&quot;]</p><h5>CMD</h5><ul><li><a href="https://docs.docker.com/engine/reference/builder/#cmd">Dockerfile reference for the CMD instruction</a></li></ul><p>The CMD instruction should be used to run the software contained by your image, along with any arguments. CMD should almost always be used in the form of CMD <!-- -->[&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot; ...]<!-- -->. Thus, if the image is for a service, such as Apache and Rails, you would run something like CMD <!-- -->[&quot;apache2&quot;,&quot;-DFOREGROUND&quot;]<!-- -->. Indeed, this form of the instruction is recommended for any service-based image.</p><p>In most other cases, CMD should be given an interactive shell, such as bash, python and perl. For example, CMD <!-- -->[&quot;perl&quot;, &quot;-de0&quot;]<!-- -->, CMD <!-- -->[&quot;python&quot;]<!-- -->, or CMD <!-- -->[&quot;php&quot;, &quot;-a&quot;]<!-- -->. Using this form means that when you execute something like docker run -it python, you&#x27;ll get dropped into a usable shell, ready to go. CMD should rarely be used in the manner of CMD <!-- -->[&quot;param&quot;, &quot;param&quot;]<!-- --> in conjunction with <a href="https://docs.docker.com/engine/reference/builder/#entrypoint">ENTRYPOINT</a>, unless you and your expected users are already quite familiar with how ENTRYPOINT works.</p><h5>EXPOSE</h5><ul><li><a href="https://docs.docker.com/engine/reference/builder/#expose">Dockerfile reference for the EXPOSE instruction</a></li></ul><p>The EXPOSE instruction indicates the ports on which a container listens for connections. Consequently, you should use the common, traditional port for your application. For example, an image containing the Apache web server would use EXPOSE 80, while an image containing MongoDB would use EXPOSE 27017 and so on.</p><p>For external access, your users can execute docker run with a flag indicating how to map the specified port to the port of their choice. For container linking, Docker provides environment variables for the path from the recipient container back to the source (ie, MYSQL_PORT_3306_TCP).</p><h5>ENV</h5><ul><li><a href="https://docs.docker.com/engine/reference/builder/#env">Dockerfile reference for the ENV instruction</a></li></ul><p>To make new software easier to run, you can use ENV to update the PATH environment variable for the software your container installs. For example, ENV PATH /usr/local/nginx/bin:$PATH ensures that CMD <!-- -->[&quot;nginx&quot;]<!-- --> just works.</p><p>The ENV instruction is also useful for providing required environment variables specific to services you wish to containerize, such as Postgres&#x27;s PGDATA.</p><p>Lastly, ENV can also be used to set commonly used version numbers so that version bumps are easier to maintain, as seen in the following example:</p><p>ENV PG_MAJOR 9.3</p><p>ENV PG_VERSION 9.3.4</p><p>RUN curl -SL <a href="http://example.com/postgres-$PG_VERSION.tar.xz">http://example.com/postgres-$PG_VERSION.tar.xz</a> | tar -xJC /usr/src/postgress &amp;&amp; ...</p><p>ENV PATH /usr/local/postgres-$PG_MAJOR/bin:$PATH</p><p>Like having constant variables in a program (as opposed to hard-coding values), this approach lets you change a single ENV instruction to auto-magically bump the version of the software in your container.</p><p>Each ENV line creates a new intermediate layer, just like RUN commands. This means that even if you unset the environment variable in a future layer, it persists in this layer and its value can be dumped. You can test this by creating a Dockerfile like the following, and then building it.</p><p>FROM alpine</p><p>ENV ADMIN_USER=&quot;mark&quot;</p><p>RUN echo $ADMIN_USER &gt; ./mark</p><p>RUN unset ADMIN_USER</p><p>CMD sh</p><p>$ docker run --rm -it test sh echo $ADMIN_USER</p><p>mark</p><p>To prevent this, and really unset the environment variable, use a RUN command with shell commands, to set, use, and unset the variable all in a single layer. You can separate your commands with; or &amp;&amp;. If you use the second method, and one of the commands fails, the docker build also fails. This is usually a good idea. Using \ as a line continuation character for Linux Dockerfiles improves readability. You could also put all the commands into a shell script and have the RUN command just run that shell script.</p><p>FROM alpine</p><p>RUN export ADMIN_USER=&quot;mark&quot; \</p><p>&amp;&amp; echo $ADMIN_USER &gt; ./mark \</p><p>&amp;&amp; unset ADMIN_USER</p><p>CMD sh</p><p>$ docker run --rm -it test sh echo $ADMIN_USER</p><h5>ADD or COPY</h5><ul><li><a href="https://docs.docker.com/engine/reference/builder/#add">Dockerfile reference for the ADD instruction</a></li><li><a href="https://docs.docker.com/engine/reference/builder/#copy">Dockerfile reference for the COPY instruction</a></li></ul><p>Although ADD and COPY are functionally similar, generally speaking, COPY is preferred. That&#x27;s because it&#x27;s more transparent than ADD. COPY only supports the basic copying of local files into the container, while ADD has some features (like local-only tar extraction and remote URL support) that are not immediately obvious. Consequently, the best use for ADD is local tar file auto-extraction into the image, as in ADD rootfs.tar.xz /.</p><p>If you have multiple Dockerfile steps that use different files from your context, COPY them individually, rather than all at once. This ensures that each step&#x27;s build cache is only invalidated (forcing the step to be re-run) if the specifically required files change.</p><p>For example:</p><p>COPY requirements.txt /tmp/</p><p>RUN pip install --requirement /tmp/requirements.txt</p><p>COPY . /tmp/</p><p>Results in fewer cache invalidations for the RUN step, than if you put the COPY . /tmp/ before it.</p><p>Because image size matters, using ADD to fetch packages from remote URLs is strongly discouraged; you should use curl or wget instead. That way you can delete the files you no longer need after they&#x27;ve been extracted, and you don&#x27;t have to add another layer in your image. For example, you should avoid doing things like:</p><p>ADD <a href="http://example.com/big.tar.xz">http://example.com/big.tar.xz</a> /usr/src/things/</p><p>RUN tar -xJf /usr/src/things/big.tar.xz -C /usr/src/things</p><p>RUN make -C /usr/src/things all</p><p>And instead, do something like:</p><p>RUN mkdir -p /usr/src/things \</p><p>&amp;&amp; curl -SL <a href="http://example.com/big.tar.xz">http://example.com/big.tar.xz</a> \</p><p>| tar -xJC /usr/src/things \</p><p>&amp;&amp; make -C /usr/src/things all</p><p>For other items (files, directories) that do not require ADD&#x27;s tar auto-extraction capability, you should always use COPY.</p><h5>ENTRYPOINT</h5><ul><li><a href="https://docs.docker.com/engine/reference/builder/#entrypoint">Dockerfile reference for the ENTRYPOINT instruction</a></li></ul><p>The best use for ENTRYPOINT is to set the image&#x27;s main command, allowing that image to be run as though it was that command (and then use CMD as the default flags).</p><p>Let&#x27;s start with an example of an image for the command line tool s3cmd:</p><p>ENTRYPOINT <!-- -->[&quot;s3cmd&quot;]</p><p>CMD <!-- -->[&quot;--help&quot;]</p><p>Now the image can be run like this to show the command&#x27;s help:</p><p>$ docker run s3cmd</p><p>Or using the right parameters to execute a command:</p><p>$ docker run s3cmd ls s3://mybucket</p><p>This is useful because the image name can double as a reference to the binary as shown in the command above.</p><p>The ENTRYPOINT instruction can also be used in combination with a helper script, allowing it to function in a similar way to the command above, even when starting the tool may require more than one step.</p><p>For example, the <a href="https://hub.docker.com/_/postgres/">Postgres Official Image</a> uses the following script as its ENTRYPOINT:</p><p>#!/bin/bash</p><p>set -e</p><p>if <!-- -->[ &quot;$1&quot; = \&#x27;postgres\&#x27; ]<!-- -->; then</p><p>chown -R postgres &quot;$PGDATA&quot;</p><p>if <!-- -->[ -z &quot;$(ls -A &quot;$PGDATA&quot;)&quot; ]<!-- -->; then</p><p>gosu postgres initdb</p><p>fi</p><p>exec gosu postgres &quot;$@&quot;</p><p>fi</p><p>exec &quot;$@&quot;</p><p><strong>Note</strong>: This script uses <a href="http://wiki.bash-hackers.org/commands/builtin/exec">the exec Bash command</a> so that the final running application becomes the container&#x27;s PID 1. This allows the application to receive any Unix signals sent to the container. See the <a href="https://docs.docker.com/engine/reference/builder/#entrypoint">ENTRYPOINT</a> help for more details.</p><p>The helper script is copied into the container and run via ENTRYPOINT on container start:</p><p>COPY ./docker-entrypoint.sh /</p><p>ENTRYPOINT <!-- -->[&quot;/docker-entrypoint.sh&quot;]</p><p>CMD <!-- -->[&quot;postgres&quot;]</p><p>This script allows the user to interact with Postgres in several ways.</p><p>It can simply start Postgres:</p><p>$ docker run postgres</p><p>Or, it can be used to run Postgres and pass parameters to the server:</p><p>$ docker run postgres postgres --help</p><p>Lastly, it could also be used to start a totally different tool, such as Bash:</p><p>$ docker run --rm -it postgres bash</p><h5>VOLUME</h5><ul><li><a href="https://docs.docker.com/engine/reference/builder/#volume">Dockerfile reference for the VOLUME instruction</a></li></ul><p>The VOLUME instruction should be used to expose any database storage area, configuration storage, or files/folders created by your docker container. You are strongly encouraged to use VOLUME for any mutable and/or user-serviceable parts of your image.</p><h5>USER</h5><ul><li><a href="https://docs.docker.com/engine/reference/builder/#user">Dockerfile reference for the USER instruction</a></li></ul><p>If a service can run without privileges, use USER to change to a non-root user. Start by creating the user and group in the Dockerfile with something like RUN groupadd -r postgres &amp;&amp; useradd --no-log-init -r -g postgres postgres.</p><p><strong>Note</strong>: Users and groups in an image get a non-deterministic UID/GID in that the &quot;next&quot; UID/GID gets assigned regardless of image rebuilds. So, if it&#x27;s critical, you should assign an explicit UID/GID.</p><p><strong>Note</strong>: Due to an <a href="https://github.com/golang/go/issues/13548">unresolved bug</a> in the Go archive/tar package&#x27;s handling of sparse files, attempting to create a user with a sufficiently large UID inside a Docker container can lead to disk exhaustion as /var/log/faillog in the container layer is filled with NUL (\0) characters. Passing the --no-log-init flag to useradd works around this issue. The Debian/Ubuntu adduser wrapper does not support the --no-log-init flag and should be avoided.</p><p>Avoid installing or using sudo since it has unpredictable TTY and signal-forwarding behavior that can cause problems. If you absolutely need functionality similar to sudo, such as initializing the daemon as root but running it as non-root), consider using <a href="https://github.com/tianon/gosu">&quot;gosu&quot;</a>.</p><p>Lastly, to reduce layers and complexity, avoid switching USER back and forth frequently.</p><h5>WORKDIR</h5><ul><li><a href="https://docs.docker.com/engine/reference/builder/#workdir">Dockerfile reference for the WORKDIR instruction</a></li></ul><p>For clarity and reliability, you should always use absolute paths for your WORKDIR. Also, you should use WORKDIR instead of proliferating instructions like RUN cd ... &amp;&amp; do-something, which are hard to read, troubleshoot, and maintain.</p><h5>ONBUILD</h5><ul><li><a href="https://docs.docker.com/engine/reference/builder/#onbuild">Dockerfile reference for the ONBUILD instruction</a></li></ul><p>An ONBUILD command executes after the current Dockerfile build completes. ONBUILD executes in any child image derived FROM the current image. Think of the ONBUILD command as an instruction the parent Dockerfile gives to the child Dockerfile.</p><p>A Docker build executes ONBUILD commands before any command in a child Dockerfile.</p><p>ONBUILD is useful for images that are going to be built FROM a given image. For example, you would use ONBUILD for a language stack image that builds arbitrary user software written in that language within the Dockerfile, as you can see in <a href="https://github.com/docker-library/ruby/blob/master/2.4/jessie/onbuild/Dockerfile">Ruby&#x27;s ONBUILD variants</a>.</p><p>Images built from ONBUILD should get a separate tag, for example: ruby:1.9-onbuild or ruby:2.0-onbuild.</p><p>Be careful when putting ADD or COPY in ONBUILD. The &quot;onbuild&quot; image fails catastrophically if the new build&#x27;s context is missing the resource being added. Adding a separate tag, as recommended above, helps mitigate this by allowing the Dockerfile author to make a choice.</p><h4>Examples for Official Repositories</h4><p>These Official Repositories have exemplary Dockerfiles:</p><ul><li><a href="https://hub.docker.com/_/golang/">Go</a></li><li><a href="https://hub.docker.com/_/perl/">Perl</a></li><li><a href="https://hub.docker.com/_/hylang/">Hy</a></li><li><a href="https://hub.docker.com/_/ruby/">Ruby</a></li></ul><h4>Additional resources</h4><ul><li><a href="https://docs.docker.com/engine/reference/builder/">Dockerfile Reference</a></li><li><a href="https://docs.docker.com/develop/develop-images/baseimages/">More about Base Images</a></li><li><a href="https://docs.docker.com/docker-hub/builds/">More about Automated Builds</a></li><li><a href="https://docs.docker.com/docker-hub/official_repos/">Guidelines for Creating Official Repositories</a></li></ul><h3><a href="https://docs.docker.com/develop/develop-images/baseimages"></a>Create a base image</h3><p>Most Dockerfiles start from a parent image. If you need to completely control the contents of your image, you might need to create a base image instead. Here&#x27;s the difference:</p><p>A <a href="https://docs.docker.com/glossary/?term=parent%20image">parent image</a> is the image that your image is based on. It refers to the contents of the FROMdirective in the Dockerfile. Each subsequent declaration in the Dockerfile modifies this parent image. Most Dockerfiles start from a parent image, rather than a base image. However, the terms are sometimes used interchangeably.</p><p>A <a href="https://docs.docker.com/glossary/?term=base%20image">base image</a> either has no FROM line in its Dockerfile, or has FROM scratch.</p><p>This topic shows you several ways to create a base image. The specific process will depend heavily on the Linux distribution you want to package. We have some examples below, and you are encouraged to submit pull requests to contribute new ones.</p><h4>Create a full image using tar</h4><p>In general, start with a working machine that is running the distribution you&#x27;d like to package as a parent image, though that is not required for some tools like Debian&#x27;s <a href="https://wiki.debian.org/Debootstrap">Debootstrap</a>, which you can also use to build Ubuntu images.</p><p>It can be as simple as this to create an Ubuntu parent image:</p><p>$ sudo debootstrap xenial xenial &gt; /dev/null</p><p>$ sudo tar -C xenial -c . | docker import - xenial</p><p>a29c15f1bf7a</p><p>$ docker run xenial cat /etc/lsb-release</p><p>DISTRIB_ID=Ubuntu</p><p>DISTRIB_RELEASE=16.04</p><p>DISTRIB_CODENAME=xenial</p><p>DISTRIB_DESCRIPTION=&quot;Ubuntu 16.04 LTS&quot;</p><p>There are more example scripts for creating parent images in the Docker GitHub Repo:</p><ul><li><a href="https://github.com/moby/moby/blob/master/contrib/mkimage/busybox-static">BusyBox</a></li><li>CentOS / Scientific Linux CERN (SLC) <a href="https://github.com/moby/moby/blob/master/contrib/mkimage/rinse">on Debian/Ubuntu</a> or <a href="https://github.com/moby/moby/blob/master/contrib/mkimage-yum.sh">on CentOS/RHEL/SLC/etc.</a></li><li><a href="https://github.com/moby/moby/blob/master/contrib/mkimage/debootstrap">Debian / Ubuntu</a></li></ul><h4>Create a simple parent image using scratch</h4><p>You can use Docker&#x27;s reserved, minimal image, scratch, as a starting point for building containers. Using the scratch &quot;image&quot; signals to the build process that you want the next command in the Dockerfile to be the first filesystem layer in your image.</p><p>While scratch appears in Docker&#x27;s repository on the hub, you can&#x27;t pull it, run it, or tag any image with the name scratch. Instead, you can refer to it in your Dockerfile. For example, to create a minimal container using scratch:</p><p>FROM scratch</p><p>ADD hello /</p><p>CMD <!-- -->[&quot;/hello&quot;]</p><p>Assuming you built the &quot;hello&quot; executable example by following the instructions at <code style="background-color:lightgray">&lt;https://github.com/docker-library/hello-world/&gt;</code>, and you compiled it with the -static flag, you can build this Docker image using this docker build command:</p><p>docker build --tag hello .</p><p>Don&#x27;t forget the . character at the end, which sets the build context to the current directory.</p><p><strong>Note</strong>: Because Docker for Mac and Docker for Windows use a Linux VM, you need a Linux binary, rather than a Mac or Windows binary. You can use a Docker container to build it:</p><p>$ docker run --rm -it -v $PWD:/build ubuntu:16.04</p><p>container# apt-get update &amp;&amp; apt-get install build-essential</p><p>container# cd /build</p><p>container# gcc -o hello -static -nostartfiles hello.c</p><p>To run your new image, use the docker run command:</p><p>docker run --rm hello</p><p>This example creates the hello-world image used in the tutorials. If you want to test it out, you can clone <a href="https://github.com/docker-library/hello-world">the image repo</a>.</p><h4>More resources</h4><p>There are lots more resources available to help you write your Dockerfile.</p><ul><li>There&#x27;s a <a href="https://docs.docker.com/engine/reference/builder/">complete guide to all the instructions</a> available for use in a Dockerfile in the reference section.</li><li>To help you write a clear, readable, maintainable Dockerfile, we&#x27;ve also written a <a href="https://docs.docker.com/develop/develop-images/dockerfile_best-practices/">Dockerfile best practices guide</a>.</li><li>If your goal is to create a new Official Repository, be sure to read up on Docker&#x27;s <a href="https://docs.docker.com/docker-hub/official_repos/">Official Repositories</a>.</li></ul><h3><a href="https://docs.docker.com/develop/develop-images/multistage-build/4"></a>Use multi-stage builds</h3><p>Multi-stage builds are a new feature requiring Docker 17.05 or higher on the daemon and client. Multistage builds are useful to anyone who has struggled to optimize Dockerfiles while keeping them easy to read and maintain.</p><p><strong>Acknowledgment</strong>: Special thanks to <a href="https://twitter.com/alexellisuk">Alex Ellis</a> for granting permission to use his blog post <a href="http://blog.alexellis.io/mutli-stage-docker-builds/">Builder pattern vs. Multi-stage builds in Docker</a> as the basis of the examples below.</p><h4>Before multi-stage builds</h4><p>One of the most challenging things about building images is keeping the image size down. Each instruction in the Dockerfile adds a layer to the image, and you need to remember to clean up any artifacts you don&#x27;t need before moving on to the next layer. To write a efficient Dockerfile, you have traditionally needed to employ shell tricks and other logic to keep the layers as small as possible and to ensure that each layer has the artifacts it needs from the previous layer and nothing else.</p><p>It was actually very common to have one Dockerfile to use for development (which contained everything needed to build your application), and a slimmed-down one to use for production, which only contained your application and exactly what was needed to run it. This has been referred to as the &quot;builder pattern&quot;. Maintaining two Dockerfiles is not ideal.</p><p>Here&#x27;s an example of a Dockerfile.build and Dockerfile which adhere to the builder pattern above:</p><p><strong>Dockerfile.build</strong>:</p><p>FROM golang:1.7.3</p><p>WORKDIR /go/src/github.com/alexellis/href-counter/</p><p>COPY app.go .</p><p>RUN go get -d -v golang.org/x/net/html \</p><p>&amp;&amp; CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .</p><p>Notice that this example also artificially compresses two RUN commands together using the Bash &amp;&amp;operator, to avoid creating an additional layer in the image. This is failure-prone and hard to maintain. It&#x27;s easy to insert another command and forget to continue the line using the \ character, for example.</p><p><strong>Dockerfile</strong>:</p><p>FROM alpine:latest</p><p>RUN apk --no-cache add ca-certificates</p><p>WORKDIR /root/</p><p>COPY app .</p><p>CMD <!-- -->[&quot;./app&quot;]</p><p><strong>build.sh</strong>:</p><p>#!/bin/sh</p><p>echo Building alexellis2/href-counter:build</p><p>docker build --build-arg https_proxy=$https_proxy --build-arg http_proxy=$http_proxy \</p><p>-t alexellis2/href-counter:build . -f Dockerfile.build</p><p>docker container create --name extract alexellis2/href-counter:build</p><p>docker container cp extract:/go/src/github.com/alexellis/href-counter/app ./app</p><p>docker container rm -f extract</p><p>echo Building alexellis2/href-counter:latest</p><p>docker build --no-cache -t alexellis2/href-counter:latest .</p><p>rm ./app</p><p>When you run the build.sh script, it needs to build the first image, create a container from it to copy the artifact out, then build the second image. Both images take up room on your system and you still have the app artifact on your local disk as well.</p><p>Multi-stage builds vastly simplify this situation!</p><h4>Use multi-stage builds</h4><p>With multi-stage builds, you use multiple FROM statements in your Dockerfile. Each FROM instruction can use a different base, and each of them begins a new stage of the build. You can selectively copy artifacts from one stage to another, leaving behind everything you don&#x27;t want in the final image. To show how this works, Let&#x27;s adapt the Dockerfile from the previous section to use multi-stage builds.</p><p><strong>Dockerfile</strong>:</p><p>FROM golang:1.7.3</p><p>WORKDIR /go/src/github.com/alexellis/href-counter/</p><p>RUN go get -d -v golang.org/x/net/html</p><p>COPY app.go .</p><p>RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .</p><p>FROM alpine:latest</p><p>RUN apk --no-cache add ca-certificates</p><p>WORKDIR /root/</p><p>COPY --from=0 /go/src/github.com/alexellis/href-counter/app .</p><p>CMD <!-- -->[&quot;./app&quot;]</p><p>You only need the single Dockerfile. You don&#x27;t need a separate build script, either. Just run docker build.</p><p>$ docker build -t alexellis2/href-counter:latest .</p><p>The result is the same tiny production image as before, with a significant reduction in complexity. You don&#x27;t need to create any intermediate images and you don&#x27;t need to extract any artifacts to your local system at all.</p><p>How does it work? The second FROM instruction starts a new build stage with the alpine:latest image as its base. The COPY --from=0 line copies just the built artifact from the previous stage into this new stage. The Go SDK and any intermediate artifacts are left behind, and not saved in the final image.</p><h4>Name your build stages</h4><p>By default, the stages are not named, and you refer to them by their integer number, starting with 0 for the first FROM instruction. However, you can name your stages, by adding an as <code style="background-color:lightgray">&lt;NAME&gt;</code> to the FROMinstruction. This example improves the previous one by naming the stages and using the name in the COPY instruction. This means that even if the instructions in your Dockerfile are re-ordered later, the COPY doesn&#x27;t break.</p><p>FROM golang:1.7.3 as builder</p><p>WORKDIR /go/src/github.com/alexellis/href-counter/</p><p>RUN go get -d -v golang.org/x/net/html</p><p>COPY app.go .</p><p>RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .</p><p>FROM alpine:latest</p><p>RUN apk --no-cache add ca-certificates</p><p>WORKDIR /root/</p><p>COPY --from=builder /go/src/github.com/alexellis/href-counter/app .</p><p>CMD <!-- -->[&quot;./app&quot;]</p><h4>Stop at a specific build stage</h4><p>When you build your image, you don&#x27;t necessarily need to build the entire Dockerfile including every stage. You can specify a target build stage. The following command assumes you are using the previous Dockerfile but stops at the stage named builder:</p><p>$ docker build --target builder -t alexellis2/href-counter:latest .</p><p>A few scenarios where this might be very powerful are:</p><ul><li>Debugging a specific build stage</li><li>Using a debug stage with all debugging symbols or tools enabled, and a lean production stage</li><li>Using a testing stage in which your app gets populated with test data, but building for production using a different stage which uses real data</li></ul><h4>Use an external image as a &quot;stage&quot;</h4><p>When using multi-stage builds, you are not limited to copying from stages you created earlier in your Dockerfile. You can use the COPY --from instruction to copy from a separate image, either using the local image name, a tag available locally or on a Docker registry, or a tag ID. The Docker client pulls the image if necessary and copies the artifact from there. The syntax is:</p><p>COPY --from=nginx:latest /etc/nginx/nginx.conf /nginx.conf</p><h3>Dockerfile reference (Unread) (REF)</h3><p>Docker can build images automatically by reading the instructions from a Dockerfile. A Dockerfile is a text document that contains all the commands a user could call on the command line to assemble an image. Using docker build users can create an automated build that executes several command-line instructions in succession.</p><p>This page describes the commands you can use in a Dockerfile. When you are done reading this page, refer to the <a href="https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices/">Dockerfile Best Practices</a> for a tip-oriented guide.</p><h4>Usage</h4><p>The <a href="https://docs.docker.com/engine/reference/commandline/build/">docker build</a> command builds an image from a Dockerfile and a context. The build&#x27;s context is the set of files at a specified location PATH or URL. The PATH is a directory on your local filesystem. The URL is a Git repository location.</p><p>A context is processed recursively. So, a PATH includes any subdirectories and the URL includes the repository and its submodules. This example shows a build command that uses the current directory as context:</p><p>$ docker build .</p><p>Sending build context to Docker daemon 6.51 MB</p><p>...</p><p>The build is run by the Docker daemon, not by the CLI. The first thing a build process does is send the entire context (recursively) to the daemon. In most cases, it&#x27;s best to start with an empty directory as context and keep your Dockerfile in that directory. Add only the files needed for building the Dockerfile.</p><p><strong>Warning</strong>: Do not use your root directory, /, as the PATH as it causes the build to transfer the entire contents of your hard drive to the Docker daemon.</p><p>To use a file in the build context, the Dockerfile refers to the file specified in an instruction, for example, a COPY instruction. To increase the build&#x27;s performance, exclude files and directories by adding a .dockerignore file to the context directory. For information about how to <a href="https://docs.docker.com/engine/reference/builder/#dockerignore-file">create a .dockerignore file</a> see the documentation on this page.</p><p>Traditionally, the Dockerfile is called Dockerfile and located in the root of the context. You use the -f flag with docker build to point to a Dockerfile anywhere in your file system.</p><p>$ docker build -f /path/to/a/Dockerfile .</p><p>You can specify a repository and tag at which to save the new image if the build succeeds:</p><p>$ docker build -t shykes/myapp .</p><p>To tag the image into multiple repositories after the build, add multiple -t parameters when you run the build command:</p><p>$ docker build -t shykes/myapp:1.0.2 -t shykes/myapp:latest .</p><p>Before the Docker daemon runs the instructions in the Dockerfile, it performs a preliminary validation of the Dockerfile and returns an error if the syntax is incorrect:</p><p>$ docker build -t test/myapp .</p><p>Sending build context to Docker daemon 2.048 kB</p><p>Error response from daemon: Unknown instruction: RUNCMD</p><p>The Docker daemon runs the instructions in the Dockerfile one-by-one, committing the result of each instruction to a new image if necessary, before finally outputting the ID of your new image. The Docker daemon will automatically clean up the context you sent.</p><p>Note that each instruction is run independently and causes a new image to be created - so RUN cd /tmp will not have any effect on the next instructions.</p><p>Whenever possible, Docker will re-use the intermediate images (cache), to accelerate the docker build process significantly. This is indicated by the Using cache message in the console output. (For more information, see the <a href="https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices/#build-cache">Build cache section</a> in the Dockerfile best practices guide):</p><p>$ docker build -t svendowideit/ambassador .</p><p>Sending build context to Docker daemon 15.36 kB</p><p>Step 1/4 : FROM alpine:3.2</p><p>---&gt; 31f630c65071</p><p>Step 2/4 : MAINTAINER SvenDowideit\@home.org.au</p><p>---&gt; Using cache</p><p>---&gt; 2a1c91448f5f</p><p>Step 3/4 : RUN apk update &amp;&amp; apk add socat &amp;&amp; rm -r /var/cache/</p><p>---&gt; Using cache</p><p>---&gt; 21ed6e7fbb73</p><p>Step 4/4 : CMD env | grep <em>TCP= | (sed \&#x27;s/.*_PORT</em>(<!-- -->[0-9]<em>)<!-- -->_TCP=tcp:\/\/<!-- -->(<!-- -->.</em>)<!-- -->:<!-- -->(<!-- -->.*<!-- -->)<!-- -->/socat -t 100000000 TCP4-LISTEN:\1,fork,reuseaddr TCP4:\2:\3 \&amp;/\&#x27; &amp;&amp; echo wait) | sh</p><p>---&gt; Using cache</p><p>---&gt; 7ea8aef582cc</p><p>Successfully built 7ea8aef582cc</p><p>Build cache is only used from images that have a local parent chain. This means that these images were created by previous builds or the whole chain of images was loaded with docker load. If you wish to use build cache of a specific image you can specify it with --cache-from option. Images specified with--cache-from do not need to have a parent chain and may be pulled from other registries.</p><p>When you&#x27;re done with your build, you&#x27;re ready to look into <a href="https://docs.docker.com/engine/tutorials/dockerrepos/#/contributing-to-docker-hub">Pushing a repository to its registry</a>.</p><h4>Format</h4><p>Here is the format of the Dockerfile:</p><h1>Comment</h1><p>INSTRUCTION arguments</p><p>The instruction is not case-sensitive. However, convention is for them to be UPPERCASE to distinguish them from arguments more easily.</p><p>Docker runs instructions in a Dockerfile in order. A Dockerfile <strong>must start with a <code>FROM</code> instruction</strong>. The FROM instruction specifies the <a href="https://docs.docker.com/engine/reference/glossary/#base-image">Base Image</a> from which you are building. FROM may only be preceded by one or more ARG instructions, which declare arguments that are used in FROMlines in the Dockerfile.</p><p>Docker treats lines that begin with # as a comment, unless the line is a valid <a href="https://docs.docker.com/engine/reference/builder/#parser-directives">parser directive</a>. A #marker anywhere else in a line is treated as an argument. This allows statements like:</p><h1>Comment</h1><p>RUN echo \&#x27;we are running some # of cool things\&#x27;</p><p>Line continuation characters are not supported in comments.</p><h4>Parser directives</h4><p>Parser directives are optional, and affect the way in which subsequent lines in a Dockerfile are handled. Parser directives do not add layers to the build, and will not be shown as a build step. Parser directives are written as a special type of comment in the form # directive=value. A single directive may only be used once.</p><p>Once a comment, empty line or builder instruction has been processed, Docker no longer looks for parser directives. Instead it treats anything formatted as a parser directive as a comment and does not attempt to validate if it might be a parser directive. Therefore, all parser directives must be at the very top of a Dockerfile.</p><p>Parser directives are not case-sensitive. However, convention is for them to be lowercase. Convention is also to include a blank line following any parser directives. Line continuation characters are not supported in parser directives.</p><p>Due to these rules, the following examples are all invalid:</p><p>Invalid due to line continuation:</p><h1>direc \</h1><p>tive=value</p><p>Invalid due to appearing twice:</p><h1>directive=value1</h1><h1>directive=value2</h1><p>FROM ImageName</p><p>Treated as a comment due to appearing after a builder instruction:</p><p>FROM ImageName</p><h1>directive=value</h1><p>Treated as a comment due to appearing after a comment which is not a parser directive:</p><h1>About my dockerfile</h1><h1>directive=value</h1><p>FROM ImageName</p><p>The unknown directive is treated as a comment due to not being recognized. In addition, the known directive is treated as a comment due to appearing after a comment which is not a parser directive.</p><h1>unknowndirective=value</h1><h1>knowndirective=value</h1><p>Non-line-breaking whitespace is permitted in a parser directive. Hence, the following lines are all treated identically:</p><p>#directive=value</p><h1>directive =value</h1><h1>directive= value</h1><h1>directive = value</h1><h1>dIrEcTiVe=value</h1><p>The following parser directive is supported:</p><ul><li>escape</li></ul><h4>escape</h4><h1>escape=\ (backslash)</h1><p>Or</p><h1>escape=` (backtick)</h1><p>The escape directive sets the character used to escape characters in a Dockerfile. If not specified, the default escape character is .</p><p>The escape character is used both to escape characters in a line, and to escape a newline. This allows a Dockerfile instruction to span multiple lines. Note that regardless of whether the escape parser directive is included in a Dockerfile, <em>escaping is not performed in a </em>RUN<em> command, except at the end of a line.</em></p><p>Setting the escape character to <code style="background-color:lightgray"> is especially useful on Windows, where \ is the directory path separator. </code> is consistent with <a href="https://technet.microsoft.com/en-us/library/hh847755.aspx">Windows PowerShell</a>.</p><p>Consider the following example which would fail in a non-obvious way on Windows. The second \ at the end of the second line would be interpreted as an escape for the newline, instead of a target of the escape from the first . Similarly, the \ at the end of the third line would, assuming it was actually handled as an instruction, cause it be treated as a line continuation. The result of this dockerfile is that second and third lines are considered a single instruction:</p><p>FROM microsoft/nanoserver</p><p>COPY testfile.txt c:<!-- -->\</p><p>RUN dir c:\</p><p>Results in:</p><p>PS C:\John&gt; docker build -t cmd .</p><p>Sending build context to Docker daemon 3.072 kB</p><p>Step 1/2 : FROM microsoft/nanoserver</p><p>---&gt; 22738ff49c6d</p><p>Step 2/2 : COPY testfile.txt c:\RUN dir c:</p><p>GetFileAttributesEx c:RUN: The system cannot find the file specified.</p><p>PS C:\John&gt;</p><p>One solution to the above would be to use / as the target of both the COPY instruction, and dir. However, this syntax is, at best, confusing as it is not natural for paths on Windows, and at worst, error prone as not all commands on Windows support / as the path separator.</p><p>By adding the escape parser directive, the following Dockerfile succeeds as expected with the use of natural platform semantics for file paths on Windows:</p><h1>escape=`</h1><p>FROM microsoft/nanoserver</p><p>COPY testfile.txt c:\</p><p>RUN dir c:\</p><p>Results in:</p><p>PS C:\John&gt; docker build -t succeeds --no-cache=true .</p><p>Sending build context to Docker daemon 3.072 kB</p><p>Step 1/3 : FROM microsoft/nanoserver</p><p>---&gt; 22738ff49c6d</p><p>Step 2/3 : COPY testfile.txt c:\</p><p>---&gt; 96655de338de</p><p>Removing intermediate container 4db9acbb1682</p><p>Step 3/3 : RUN dir c:\</p><p>---&gt; Running in a2c157f842f5</p><p>Volume in drive C has no label.</p><p>Volume Serial Number is 7E6D-E0F7</p><p>Directory of c:\</p><p>10/05/2016 05:04 PM 1,894 License.txt</p><p>10/05/2016 02:22 PM <code style="background-color:lightgray">&lt;DIR&gt;</code> Program Files</p><p>10/05/2016 02:14 PM <code style="background-color:lightgray">&lt;DIR&gt;</code> Program Files (x86)</p><p>10/28/2016 11:18 AM 62 testfile.txt</p><p>10/28/2016 11:20 AM <code style="background-color:lightgray">&lt;DIR&gt;</code> Users</p><p>10/28/2016 11:20 AM <code style="background-color:lightgray">&lt;DIR&gt;</code> Windows</p><p>2 File(s) 1,956 bytes</p><p>4 Dir(s) 21,259,096,064 bytes free</p><p>---&gt; 01c7f3bef04f</p><p>Removing intermediate container a2c157f842f5</p><p>Successfully built 01c7f3bef04f</p><p>PS C:\John&gt;</p><h4>Environment replacement</h4><p>Environment variables (declared with <a href="https://docs.docker.com/engine/reference/builder/#env">the ENV statement</a>) can also be used in certain instructions as variables to be interpreted by the Dockerfile. Escapes are also handled for including variable-like syntax into a statement literally.</p><p>Environment variables are notated in the Dockerfile either with $variable_name or ${variable_name}. They are treated equivalently and the brace syntax is typically used to address issues with variable names with no whitespace, like ${foo}_bar.</p><p>The ${variable_name} syntax also supports a few of the standard bash modifiers as specified below:</p><ul><li>${variable:-word} indicates that if variable is set then the result will be that value. If variable is not set then word will be the result.</li><li>${variable:+word} indicates that if variable is set then word will be the result, otherwise the result is the empty string.</li></ul><p>In all cases, word can be any string, including additional environment variables.</p><p>Escaping is possible by adding a \ before the variable: \$foo or \${foo}, for example, will translate to $foo and ${foo} literals respectively.</p><p>Example (parsed representation is displayed after the #):</p><p>FROM busybox</p><p>ENV foo /bar</p><p>WORKDIR ${foo} # WORKDIR /bar</p><p>ADD . $foo # ADD . /bar</p><p>COPY \$foo /quux # COPY $foo /quux</p><p>Environment variables are supported by the following list of instructions in the Dockerfile:</p><ul><li>ADD</li><li>COPY</li><li>ENV</li><li>EXPOSE</li><li>FROM</li><li>LABEL</li><li>STOPSIGNAL</li><li>USER</li><li>VOLUME</li><li>WORKDIR</li><li>ONBUILD (when combined with one of the supported instructions above)</li></ul><p>Environment variable substitution will use the same value for each variable throughout the entire instruction. In other words, in this example:</p><p>ENV abc=hello</p><p>ENV abc=bye def=$abc</p><p>ENV ghi=$abc</p><p>will result in def having a value of hello, not bye. However, ghi will have a value of byebecause it is not part of the same instruction that set abc to bye.</p><h4>.dockerignore file</h4><p>Before the docker CLI sends the context to the docker daemon, it looks for a file named .dockerignorein the root directory of the context. If this file exists, the CLI modifies the context to exclude files and directories that match patterns in it. This helps to avoid unnecessarily sending large or sensitive files and directories to the daemon and potentially adding them to images using ADD or COPY.</p><p>The CLI interprets the .dockerignore file as a newline-separated list of patterns similar to the file globs of Unix shells. For the purposes of matching, the root of the context is considered to be both the working and the root directory. For example, the patterns /foo/bar and foo/bar both exclude a file or directory named bar in the foo subdirectory of PATH or in the root of the git repository located at URL. Neither excludes anything else.</p><p>If a line in .dockerignore file starts with # in column 1, then this line is considered as a comment and is ignored before interpreted by the CLI.</p><p>Here is an example .dockerignore file:</p><h1>comment</h1><p><em>/temp</em></p><p><em>/</em>/temp*</p><p>temp?</p><p>This file causes the following build behavior:</p><hr/><p>  Rule           Behavior</p><h1>comment     Ignored.</h1><p>  <em>/temp</em>      Exclude files and directories whose names start with temp in any immediate subdirectory of the root. For example, the plain file /somedir/temporary.txt is excluded, as is the directory /somedir/temp.
<em>/</em>/temp*   Exclude files and directories starting with temp from any subdirectory that is two levels below the root. For example, /somedir/subdir/temporary.txt is excluded.
temp?          Exclude files and directories in the root directory whose names are a one-character extension of temp. For example, /tempa and /tempb are excluded.</p><hr/><p>Matching is done using Go&#x27;s <a href="http://golang.org/pkg/path/filepath#Match">filepath.Match</a> rules. A preprocessing step removes leading and trailing whitespace and eliminates. and .. elements using Go&#x27;s <a href="http://golang.org/pkg/path/filepath/#Clean">filepath.Clean</a>. Lines that are blank after preprocessing are ignored.</p><p>Beyond Go&#x27;s filepath. Match rules, Docker also supports a special wildcard string <strong> that matches any number of directories (including zero). For example, </strong>/*.go will exclude all files that end with .gothat are found in all directories, including the root of the build context.</p><p>Lines starting with ! (exclamation mark) can be used to make exceptions to exclusions. The following is an example .dockerignore file that uses this mechanism:</p><p>*.md</p><p>!README.md</p><p>All markdown files except README.md are excluded from the context.</p><p>The placement of! exception rules influences the behavior: the last line of the .dockerignore that matches a particular file determines whether it is included or excluded. Consider the following example:</p><p>*.md</p><p>!README*.md</p><p>README-secret.md</p><p>No markdown files are included in the context except README files other than README-secret.md.</p><p>Now consider this example:</p><p>*.md</p><p>README-secret.md</p><p>!README*.md</p><p>All of the README files are included. The middle line has no effect because !README*.md matches README-secret.md and comes last.</p><p>You can even use the .dockerignore file to exclude the Dockerfile and .dockerignore files. These files are still sent to the daemon because it needs them to do its job. But the ADD and COPY instructions do not copy them to the image.</p><p>Finally, you may want to specify which files to include in the context, rather than which to exclude. To achieve this, specify * as the first pattern, followed by one or more ! exception patterns.</p><p><strong>Note</strong>: For historical reasons, the pattern . is ignored.</p><h4>FROM</h4><p>FROM <code style="background-color:lightgray">&lt;image&gt; [AS &lt;name&gt;</code>]</p><p>Or</p><p>FROM <code style="background-color:lightgray">&lt;image&gt;[:&lt;tag&gt;] [AS &lt;name&gt;</code>]</p><p>Or</p><p>FROM <code style="background-color:lightgray">&lt;image&gt;[@&lt;digest&gt;] [AS &lt;name&gt;</code>]</p><p>The FROM instruction initializes a new build stage and sets the <a href="https://docs.docker.com/engine/reference/glossary/#base-image">Base Image</a> for subsequent instructions. As such, a valid Dockerfile must start with a FROM instruction. The image can be any valid image -- it is especially easy to start by <strong>pulling an image</strong> from the <a href="https://docs.docker.com/engine/tutorials/dockerrepos/">Public Repositories</a>.</p><ul><li>ARG is the only instruction that may precede FROM in the Dockerfile. See <a href="https://docs.docker.com/engine/reference/builder/#understand-how-arg-and-from-interact">Understand how ARG and FROM interact</a>.</li><li>FROM can appear multiple times within a single Dockerfile to create multiple images or use one build stage as a dependency for another. Simply make a note of the last image ID output by the commit before each new FROM instruction. Each FROM instruction clears any state created by previous instructions.</li><li>Optionally a name can be given to a new build stage by adding AS name to the FROMinstruction. The name can be used in subsequent FROM and COPY --from=<code>&lt;name|index&gt;</code>instructions to refer to the image built in this stage.</li><li>The tag or digest values are optional. If you omit either of them, the builder assumes a latest tag by default. The builder returns an error if it cannot find the tag value.</li></ul><h5>Understand how ARG and FROM interact</h5><p>FROM instructions support variables that are declared by any ARG instructions that occur before the first FROM.</p><p>ARG CODE_VERSION=latest</p><p>FROM base:${CODE_VERSION}</p><p>CMD /code/run-app</p><p>FROM extras:${CODE_VERSION}</p><p>CMD /code/run-extras</p><p>An ARG declared before a FROM is outside of a build stage, so it can&#x27;t be used in any instruction after a FROM. To use the default value of an ARG declared before the first FROM use an ARG instruction without a value inside of a build stage:</p><p>ARG VERSION=latest</p><p>FROM busybox:$VERSION</p><p>ARG VERSION</p><p>RUN echo $VERSION &gt; image_version</p><h4>RUN</h4><p>RUN has 2 forms:</p><ul><li>RUN <code>&lt;command&gt;</code> (shell form, the command is run in a shell, which by default is /bin/sh -c on Linux or cmd /S /C on Windows)</li><li>RUN <!-- -->[&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;]<!-- --> (exec form)</li></ul><p>The RUN instruction will execute any commands in a new layer on top of the current image and commit the results. The resulting committed image will be used for the next step in the Dockerfile.</p><p>Layering RUN instructions and generating commits conforms to the core concepts of Docker where commits are cheap and containers can be created from any point in an image&#x27;s history, much like source control.</p><p>The exec form makes it possible to avoid shell string munging, and to RUN commands using a base image that does not contain the specified shell executable.</p><p>The default shell for the shell form can be changed using the SHELL command.</p><p>In the shell form you can use a \ (backslash) to continue a single RUN instruction onto the next line. For example, consider these two lines:</p><p>RUN /bin/bash -c \&#x27;source $HOME/.bashrc; \</p><p>echo $HOME\&#x27;</p><p>Together they are equivalent to this single line:</p><p>RUN /bin/bash -c \&#x27;source $HOME/.bashrc; echo $HOME\&#x27;</p><p><strong>Note</strong>: To use a different shell, other than &#x27;/bin/sh&#x27;, use the exec form passing in the desired shell. For example, RUN <!-- -->[&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;echo hello&quot;]</p><p><strong>Note</strong>: The exec form is parsed as a JSON array, which means that you must use double-quotes (&quot;) around words not single-quotes (&#x27;).</p><p><strong>Note: Unlike the shell form, the exec form does not invoke a command shell. This means that normal shell processing does not happen. For example, RUN <!-- -->[ &quot;echo&quot;, &quot;$HOME&quot; ]<!-- --> will not do variable substitution on $HOME. If you want shell processing then either use the shell form or execute a shell directly, for example: RUN <!-- -->[ &quot;sh&quot;, &quot;-c&quot;, &quot;echo $HOME&quot; ]<!-- -->. When using the exec form and executing a shell directly, as in the case for the shell form, it is the shell that is doing the environment variable expansion, not docker.</strong></p><p><strong>Note</strong>: In the JSON form, it is necessary to escape backslashes. This is particularly relevant on Windows where the backslash is the path separator. The following line would otherwise be treated as shell form due to not being valid JSON, and fail in an unexpected way:RUN <!-- -->[&quot;c:\windows\system32\tasklist.exe&quot;]<!-- --> The correct syntax for this example is:RUN <!-- -->[&quot;c:<!-- -->\<!-- -->windows<!-- -->\<!-- -->system32<!-- -->\<!-- -->tasklist.exe&quot;]</p><p>The cache for RUN instructions isn&#x27;t invalidated automatically during the next build. The cache for an instruction like RUN apt-get dist-upgrade -y will be reused during the next build. The cache for RUNinstructions can be invalidated by using the --no-cache flag, for example docker build --no-cache.</p><p>See the <a href="https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices/#/build-cache">Dockerfile Best Practices guide</a> for more information.</p><p>The cache for RUN instructions can be invalidated by ADD instructions. See <a href="https://docs.docker.com/engine/reference/builder/#add">below</a> for details.</p><h5>Known issues (RUN)</h5><ul><li><a href="https://github.com/docker/docker/issues/783">Issue 783</a> is about file permissions problems that can occur when using the AUFS file system. You might notice it during an attempt to rm a file, for example.</li><li>For systems that have recent aufs version (i.e., dirperm1 mount option can be set), docker will attempt to fix the issue automatically by mounting the layers with dirperm1 option. More details on dirperm1 option can be found at <a href="https://github.com/sfjro/aufs3-linux/tree/aufs3.18/Documentation/filesystems/aufs">aufs man page</a></li></ul><p>If your system doesn&#x27;t have support for dirperm1, the issue describes a workaround.</p><h4>CMD</h4><p>The CMD instruction has three forms:</p><ul><li>CMD <!-- -->[&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;]<!-- --> (exec form, this is the preferred form)</li><li>CMD <!-- -->[&quot;param1&quot;,&quot;param2&quot;]<!-- --> (as default parameters to ENTRYPOINT)</li><li>CMD command param1 param2 (shell form)</li></ul><p>There can only be one CMD instruction in a Dockerfile. If you list more than one CMD then only the last CMD will take effect.</p><p><strong>The main purpose of a </strong>CMD<strong> is to provide defaults for an executing container.</strong> These defaults can include an executable, or they can omit the executable, in which case you must specify an ENTRYPOINT instruction as well.</p><p><strong>Note</strong>: If CMD is used to provide default arguments for the ENTRYPOINT instruction, both the CMD and ENTRYPOINT instructions should be specified with the JSON array format.</p><p><strong>Note</strong>: The exec form is parsed as a JSON array, which means that you must use double-quotes (&quot;) around words not single-quotes (&#x27;).</p><p><strong>Note</strong>: Unlike the shell form, the exec form does not invoke a command shell. This means that normal shell processing does not happen. For example, CMD <!-- -->[ &quot;echo&quot;, &quot;$HOME&quot; ]<!-- --> will not do variable substitution on $HOME. If you want shell processing then either use the shell form or execute a shell directly, for example: CMD <!-- -->[ &quot;sh&quot;, &quot;-c&quot;, &quot;echo $HOME&quot; ]<!-- -->. When using the exec form and executing a shell directly, as in the case for the shell form, it is the shell that is doing the environment variable expansion, not docker.</p><p>When used in the shell or exec formats, the CMD instruction sets the command to be executed when running the image.</p><p>If you use the shell form of the CMD, then the <code style="background-color:lightgray">&lt;command&gt;</code> will execute in /bin/sh -c:</p><p>FROM ubuntu</p><p>CMD echo &quot;This is a test.&quot; | wc -</p><p>If you want to <strong>run your</strong> <code style="background-color:lightgray">&lt;command&gt;</code> <strong>without a shell</strong> then you must express the command as a JSON array and give the full path to the executable. <strong>This array form is the preferred format of </strong>CMD<strong>.</strong> Any additional parameters must be individually expressed as strings in the array:</p><p>FROM ubuntu</p><p>CMD <!-- -->[&quot;/usr/bin/wc&quot;,&quot;--help&quot;]</p><p>If you would like your container to run the same executable every time, then you should consider using ENTRYPOINT in combination with CMD. See <a href="https://docs.docker.com/engine/reference/builder/#entrypoint">ENTRYPOINT</a>.</p><p>If the user specifies arguments to docker run then they will override the default specified in CMD.</p><p><strong>Note</strong>: Don&#x27;t confuse RUN with CMD. RUN actually runs a command and commits the result; CMD does not execute anything at build time but specifies the intended command for the image.</p><h4>LABEL</h4><p>LABEL <code style="background-color:lightgray">&lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt;</code> ...</p><p>The LABEL instruction adds metadata to an image. A LABEL is a key-value pair. To include spaces within a LABEL value, use quotes and backslashes as you would in command-line parsing. A few usage examples:</p><p>LABEL &quot;com.example.vendor&quot;=&quot;ACME Incorporated&quot;</p><p>LABEL com.example.label-with-value=&quot;foo&quot;</p><p>LABEL version=&quot;1.0&quot;</p><p>LABEL description=&quot;This text illustrates \</p><p>that label-values can span multiple lines.&quot;</p><p>An image can have more than one label. You can specify multiple labels on a single line. Prior to Docker 1.10, this decreased the size of the final image, but this is no longer the case. You may still choose to specify multiple labels in a single instruction, in one of the following two ways:</p><p>LABEL multi.label1=&quot;value1&quot; multi.label2=&quot;value2&quot; other=&quot;value3&quot;</p><p>LABEL multi.label1=&quot;value1&quot; \</p><p>multi.label2=&quot;value2&quot; \</p><p>other=&quot;value3&quot;</p><p>Labels included in base or parent images (images in the FROM line) are inherited by your image. If a label already exists but with a different value, the most-recently-applied value overrides any previously-set value.</p><p>To view an image&#x27;s labels, use the docker inspect command.</p><p>&quot;Labels&quot;: {</p><p>&quot;com.example.vendor&quot;: &quot;ACME Incorporated&quot;</p><p>&quot;com.example.label-with-value&quot;: &quot;foo&quot;,</p><p>&quot;version&quot;: &quot;1.0&quot;,</p><p>&quot;description&quot;: &quot;This text illustrates that label-values can span multiple lines.&quot;,</p><p>&quot;multi.label1&quot;: &quot;value1&quot;,</p><p>&quot;multi.label2&quot;: &quot;value2&quot;,</p><p>&quot;other&quot;: &quot;value3&quot;</p><p>},</p><h4>MAINTAINER (deprecated)</h4><p>MAINTAINER <code style="background-color:lightgray">&lt;name&gt;</code></p><p>The MAINTAINER instruction sets the Author field of the generated images. The LABEL instruction is a much more flexible version of this and you should use it instead, as it enables setting any metadata you require, and can be viewed easily, for example with docker inspect. To set a label corresponding to the MAINTAINER field you could use:</p><p>LABEL maintainer=&quot;SvenDowideit\@home.org.au&quot;</p><p>This will then be visible from docker inspect with the other labels.</p><h4>EXPOSE</h4><p>EXPOSE <code style="background-color:lightgray">&lt;port&gt; [&lt;port&gt;/&lt;protocol&gt;</code>...]</p><p>The EXPOSE instruction informs Docker that the container listens on the specified network ports at runtime. You can specify whether the port listens on TCP or UDP, and the default is TCP if the protocol is not specified.</p><p>The EXPOSE instruction does not actually publish the port. It functions as a type of documentation between the person who builds the image and the person who runs the container, about which ports are intended to be published. To publish the port when running the container, use the -p flag on docker run to publish and map one or more ports, or the -P flag to publish all exposed ports and map them to high-order ports.</p><p>To set up port redirection on the host system, see <a href="https://docs.docker.com/engine/reference/run/#expose-incoming-ports">using the -P flag</a>. The docker network command supports creating networks for communication among containers without the need to expose or publish specific ports, because the containers connected to the network can communicate with each other over any port. For detailed information, see the <a href="https://docs.docker.com/engine/userguide/networking/">overview of this feature</a>).</p><h4>ENV</h4><p>ENV <code style="background-color:lightgray">&lt;key&gt; &lt;value&gt;</code></p><p>ENV <code style="background-color:lightgray">&lt;key&gt;=&lt;value&gt;</code> ...</p><p>The ENV instruction sets the environment variable <code style="background-color:lightgray">&lt;key&gt; to the value &lt;value&gt;</code>. This value will be in the environment of all &quot;descendant&quot; Dockerfile commands and can be <a href="https://docs.docker.com/engine/reference/builder/#environment-replacement">replaced inline</a> in many as well.</p><p>The ENV instruction has two forms. The first form, ENV <code style="background-color:lightgray">&lt;key&gt; &lt;value&gt;, will set a single variable to a value. The entire string after the first space will be treated as the &lt;value&gt;</code> - including characters such as spaces and quotes.</p><p>The second form, ENV <code style="background-color:lightgray">&lt;key&gt;=&lt;value&gt;</code> ..., allows for multiple variables to be set at one time. Notice that the second form uses the equals sign (=) in the syntax, while the first form does not. Like command line parsing, quotes and backslashes can be used to include spaces within values.</p><p>For example:</p><p>ENV myName=&quot;John Doe&quot; myDog=Rex\ The\ Dog \</p><p>myCat=fluffy</p><p>and</p><p>ENV myName John Doe</p><p>ENV myDog Rex The Dog</p><p>ENV myCat fluffy</p><p>will yield the same net results in the final image, but the first form is preferred because it produces a single cache layer.</p><p>The environment variables set using ENV will persist when a container is run from the resulting image. You can view the values using docker inspect, and change them using docker run --env <code style="background-color:lightgray">&lt;key&gt;=&lt;value&gt;</code>.</p><p><strong>Note</strong>: Environment persistence can cause unexpected side effects. For example, setting ENV DEBIAN_FRONTEND noninteractive may confuse apt-get users on a Debian-based image. To set a value for a single command, use RUN <code style="background-color:lightgray">&lt;key&gt;=&lt;value&gt; &lt;command&gt;</code>.</p><h4>ADD</h4><p><code style="background-color:lightgray">ADD [--chown=&lt;user&gt;:&lt;group&gt;] [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;]</code> (this form is required for paths containing whitespace)</p><p><strong>Note</strong>: The --chown feature is only supported on Dockerfiles used to build Linux containers, and will not work on Windows containers. Since user and group ownership concepts do not translate between Linux and Windows, the use of /etc/passwd and /etc/group for translating user and group names to IDs restricts this feature to only be viable for for Linux OS-based containers.</p><p>The ADD instruction copies new files, directories or remote file URLs from <code style="background-color:lightgray">&lt;src&gt;</code> and adds them to the filesystem of the image at the path <code style="background-color:lightgray">&lt;dest&gt;</code>.</p><p>Multiple <code style="background-color:lightgray">&lt;src&gt;</code> resources may be specified but if they are files or directories, their paths are interpreted as relative to the source of the context of the build.</p><p>Each <code style="background-color:lightgray">&lt;src&gt;</code> may contain wildcards and matching will be done using Go&#x27;s <a href="http://golang.org/pkg/path/filepath#Match">filepath.Match</a> rules. For example:</p><p>ADD hom* /mydir/ # adds all files starting with &quot;hom&quot;</p><p>ADD hom?.txt /mydir/ # ? is replaced with any single character, e.g., &quot;home.txt&quot;</p><p>The <code style="background-color:lightgray">&lt;dest&gt;</code> is an absolute path, or a path relative to WORKDIR, into which the source will be copied inside the destination container.</p><p>ADD test relativeDir/ # adds &quot;test&quot; to <code style="background-color:lightgray">WORKDIR</code>/relativeDir/</p><p>ADD test /absoluteDir/ # adds &quot;test&quot; to /absoluteDir/</p><p>When adding files or directories that contain special characters (such as <!-- -->[ and ]<!-- -->), you need to escape those paths following the Golang rules to prevent them from being treated as a matching pattern. For example, to add a file named arr<!-- -->[0]<!-- -->.txt, use the following;</p><p>ADD arr[[]0].txt /mydir/ # copy a file named &quot;arr<!-- -->[0]<!-- -->.txt&quot; to /mydir/</p><p>All new files and directories are created with a UID and GID of 0, unless the optional --chown flag specifies a given username, groupname, or UID/GID combination to request specific ownership of the content added. The format of the --chown flag allows for either username and groupname strings or direct integer UID and GID in any combination. Providing a username without groupname or a UID without GID will use the same numeric UID as the GID. If a username or groupname is provided, the container&#x27;s root filesystem /etc/passwd and /etc/group files will be used to perform the translation from name to integer UID or GID respectively. The following examples show valid definitions for the --chown flag:</p><p>ADD --chown=55:mygroup files* /somedir/</p><p>ADD --chown=bin files* /somedir/</p><p>ADD --chown=1 files* /somedir/</p><p>ADD --chown=10:11 files* /somedir/</p><p>If the container root filesystem does not contain either /etc/passwd or /etc/group files and either user or group names are used in the --chown flag, the build will fail on the ADD operation. Using numeric IDs requires no lookup and will not depend on container root filesystem content.</p><p>In the case where <code style="background-color:lightgray">&lt;src&gt;</code> is a remote file URL, the destination will have permissions of 600. If the remote file being retrieved has an HTTP Last-Modified header, the timestamp from that header will be used to set the mtime on the destination file. However, like any other file processed during an ADD, mtime will not be included in the determination of whether or not the file has changed and the cache should be updated.</p><p><strong>Note</strong>: If you build by passing a Dockerfile through STDIN (docker build - &lt; somefile), there is no build context, so the Dockerfile can only contain a URL based ADD instruction. You can also pass a compressed archive through STDIN: (docker build - &lt; archive.tar.gz), the Dockerfile at the root of the archive and the rest of the archive will be used as the context of the build.</p><p><strong>Note</strong>: If your URL files are protected using authentication, you will need to use RUN wget, RUN curl or use another tool from within the container as the ADD instruction does not support authentication.</p><p><strong>Note</strong>: The first encountered ADD instruction will invalidate the cache for all following instructions from the Dockerfile if the contents of <code style="background-color:lightgray">&lt;src&gt;</code> have changed. This includes invalidating the cache for RUN instructions. See the <a href="https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices/#/build-cache">Dockerfile Best Practices guide</a> for more information.</p><p>ADD obeys the following rules:</p><ul><li>The <code>&lt;src&gt;</code> path must be inside the context of the build; you cannot ADD ../something /something, because the first step of a docker build is to send the context directory (and subdirectories) to the docker daemon.</li><li>If <code>&lt;src&gt;</code> is a URL and <code>&lt;dest&gt;</code> does not end with a trailing slash, then a file is downloaded from the URL and copied to <code>&lt;dest&gt;</code>.</li><li>If <code>&lt;src&gt;</code> is a URL and <code>&lt;dest&gt;</code> does end with a trailing slash, then the filename is inferred from the URL and the file is downloaded to <code>&lt;dest&gt;/&lt;filename&gt;</code>. For instance, ADD <a href="http://example.com/foobar">http://example.com/foobar</a> / would create the file /foobar. The URL must have a nontrivial path so that an appropriate filename can be discovered in this case (<a href="http://example.com">http://example.com</a> will not work).</li><li>If <code>&lt;src&gt;</code> is a directory, the entire contents of the directory are copied, including filesystem metadata.</li></ul><p><strong>Note</strong>: The directory itself is not copied, just its contents.</p><ul><li>If <code>&lt;src&gt;</code> is a local tar archive in a recognized compression format (identity, gzip, bzip2 or xz) then it is unpacked as a directory. Resources from remote URLs are <strong>not</strong> decompressed. When a directory is copied or unpacked, it has the same behavior as tar -x, the result is the union of:</li></ul><ol><li>Whatever existed at the destination path and</li><li>The contents of the source tree, with conflicts resolved in favor of &quot;2.&quot; on a file-by-file basis.</li></ol><ul><li><strong>Note</strong>: Whether a file is identified as a recognized compression format or not is done solely based on the contents of the file, not the name of the file. For example, if an empty file happens to end with .tar.gz this will not be recognized as a compressed file and <strong>will not</strong>generate any kind of decompression error message, rather the file will simply be copied to the destination.</li><li>If <code>&lt;src&gt;</code> is any other kind of file, it is copied individually along with its metadata. In this case, if <code>&lt;dest&gt;</code> ends with a trailing slash /, it will be considered a directory and the contents of <code>&lt;src&gt;</code> will be written at <code>&lt;dest&gt;/base(&lt;src&gt;</code>).</li><li>If multiple <code>&lt;src&gt;</code> resources are specified, either directly or due to the use of a wildcard, then <code>&lt;dest&gt;</code> must be a directory, and it must end with a slash /.</li><li>If <code>&lt;dest&gt;</code> does not end with a trailing slash, it will be considered a regular file and the contents of <code>&lt;src&gt;</code> will be written at <code>&lt;dest&gt;</code>.</li><li>If <code>&lt;dest&gt;</code> doesn&#x27;t exist, it is created along with all missing directories in its path.</li></ul><h4>COPY</h4><p>COPY has two forms:</p><p><code style="background-color:lightgray">COPY [--chown=&lt;user&gt;:&lt;group&gt;] [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;]</code> (this form is required for paths containing whitespace)</p><p><strong>Note</strong>: The --chown feature is only supported on Dockerfiles used to build Linux containers, and will not work on Windows containers. Since user and group ownership concepts do not translate between Linux and Windows, the use of /etc/passwd and /etc/group for translating user and group names to IDs restricts this feature to only be viable for for Linux OS-based containers.</p><p>The COPY instruction copies new files or directories from <code style="background-color:lightgray">&lt;src&gt;</code> and adds them to the filesystem of the container at the path <code style="background-color:lightgray">&lt;dest&gt;</code>.</p><p>Multiple <code style="background-color:lightgray">&lt;src&gt;</code> resources may be specified but the paths of files and directories will be interpreted as relative to the source of the context of the build.</p><p>Each <code style="background-color:lightgray">&lt;src&gt;</code> may contain wildcards and matching will be done using Go&#x27;s <a href="http://golang.org/pkg/path/filepath#Match">filepath.Match</a> rules. For example:</p><p>COPY hom* /mydir/ # adds all files starting with &quot;hom&quot;</p><p>COPY hom?.txt /mydir/ # ? is replaced with any single character, e.g., &quot;home.txt&quot;</p><p>The <code style="background-color:lightgray">&lt;dest&gt;</code> is an absolute path, or a path relative to WORKDIR, into which the source will be copied inside the destination container.</p><p>COPY test relativeDir/ # adds &quot;test&quot; to <code style="background-color:lightgray">WORKDIR</code>/relativeDir/</p><p>COPY test /absoluteDir/ # adds &quot;test&quot; to /absoluteDir/</p><p>When copying files or directories that contain special characters (such as <!-- -->[ and ]<!-- -->), you need to escape those paths following the Golang rules to prevent them from being treated as a matching pattern. For example, to copy a file named <code style="background-color:lightgray">arr[0].txt</code>, use the following;</p><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-bash" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">COPY arr</span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain">.txt /mydir/ </span><span class="token comment" style="color:rgb(106, 153, 85)"># copy a file named &quot;arr[0].txt&quot; to /mydir/</span></div></pre></div><p>All new files and directories are created with a UID and GID of 0, unless the optional --chown flag specifies a given username, groupname, or UID/GID combination to request specific ownership of the copied content. The format of the --chown flag allows for either username and groupname strings or direct integer UID and GID in any combination. Providing a username without groupname or a UID without GID will use the same numeric UID as the GID. If a username or groupname is provided, the container&#x27;s root filesystem /etc/passwd and /etc/group files will be used to perform the translation from name to integer UID or GID respectively. The following examples show valid definitions for the --chown flag:</p><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-bash" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">COPY --chown</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token number" style="color:rgb(181, 206, 168)">55</span><span class="token plain">:mygroup files* /somedir/</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">COPY --chown</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain">bin files* /somedir/</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">COPY --chown</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token number" style="color:rgb(181, 206, 168)">1</span><span class="token plain"> files* /somedir/</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">COPY --chown</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token number" style="color:rgb(181, 206, 168)">10</span><span class="token plain">:11 files* /somedir/</span></div></pre></div><p>If the container root filesystem does not contain either /etc/passwd or /etc/group files and either user or group names are used in the --chown flag, the build will fail on the COPY operation. Using numeric IDs requires no lookup and will not depend on container root filesystem content.</p><p><strong>Note</strong>: If you build using STDIN (docker build - &lt; somefile), there is no build context, so COPYcan&#x27;t be used.</p><p>Optionally COPY accepts a flag --from=<code style="background-color:lightgray">&lt;name|index&gt;</code> that can be used to set the source location to a previous build stage (created with FROM .. AS <code style="background-color:lightgray">&lt;name&gt;</code>) that will be used instead of a build context sent by the user. The flag also accepts a numeric index assigned for all previous build stages started withFROM instruction. In case a build stage with a specified name can&#x27;t be found an image with the same name is attempted to be used instead.</p><p>COPY obeys the following rules:</p><ul><li>The <code>&lt;src&gt;</code> path must be inside the context of the build; you cannot COPY ../something /something, because the first step of a docker build is to send the context directory (and subdirectories) to the docker daemon.</li><li>If <code>&lt;src&gt;</code> is a directory, the entire contents of the directory are copied, including filesystem metadata.</li></ul><p><strong>Note</strong>: The directory itself is not copied, just its contents.</p><ul><li>If <code>&lt;src&gt;</code> is any other kind of file, it is copied individually along with its metadata. In this case, if <code>&lt;dest&gt;</code> ends with a trailing slash /, it will be considered a directory and the contents of <code>&lt;src&gt;</code> will be written at <code>&lt;dest&gt;/base(&lt;src&gt;</code>).</li><li>If multiple <code>&lt;src&gt;</code> resources are specified, either directly or due to the use of a wildcard, then <code>&lt;dest&gt;</code> must be a directory, and it must end with a slash /.</li><li>If <code>&lt;dest&gt;</code> does not end with a trailing slash, it will be considered a regular file and the contents of <code>&lt;src&gt;</code> will be written at <code>&lt;dest&gt;</code>.</li><li>If <code>&lt;dest&gt;</code> doesn&#x27;t exist, it is created along with all missing directories in its path.</li></ul><h4>ENTRYPOINT</h4><p>ENTRYPOINT has two forms:</p><ul><li>ENTRYPOINT <!-- -->[&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;]<!-- --> (exec form, preferred)</li><li>ENTRYPOINT command param1 param2 (shell form)</li></ul><p>An ENTRYPOINT allows you to configure a container that will run as an executable.</p><p>For example, the following will start nginx with its default content, listening on port 80:</p><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-bash" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">docker run -i -t --rm -p </span><span class="token number" style="color:rgb(181, 206, 168)">80</span><span class="token plain">:80 nginx</span></div></pre></div><p>Command line arguments to docker run <code style="background-color:lightgray">&lt;image&gt;</code> will be appended after all elements in an exec form ENTRYPOINT, and will override all elements specified using CMD. This allows arguments to be passed to the entry point, i.e., <code style="background-color:lightgray">docker run &lt;image&gt;</code> <code style="background-color:lightgray">-d</code> will pass the <code style="background-color:lightgray">-d</code> argument to the entry point. You can override the ENTRYPOINT instruction using the docker run <code style="background-color:lightgray">--entrypoint</code> flag.</p><p>The shell form prevents any CMD or run command line arguments from being used, but has the disadvantage that your ENTRYPOINT will be started as a subcommand of <code style="background-color:lightgray">/bin/sh -c</code>, which does not pass signals. This means that the executable will not be the container&#x27;s PID 1 - and will not receive Unix signals - so your executable will not receive a <code style="background-color:lightgray">SIGTERM</code> from docker stop <code style="background-color:lightgray">&lt;container&gt;</code>.</p><p>Only the last ENTRYPOINT instruction in the Dockerfile will have an effect.</p><h5>Exec form ENTRYPOINT example</h5><p>You can use the exec form of ENTRYPOINT to set fairly stable default commands and arguments and then use either form of CMD to set additional defaults that are more likely to be changed.</p><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-docker" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">FROM ubuntu</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">ENTRYPOINT [&quot;top&quot;, &quot;-b&quot;]</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">CMD [&quot;-c&quot;]</span></div></pre></div><p>When you run the container, you can see that top is the only process:</p><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-bash" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">$ docker run -it --rm --name </span><span class="token builtin class-name" style="color:rgb(78, 201, 176)">test</span><span class="token plain"> </span><span class="token function" style="color:rgb(220, 220, 170)">top</span><span class="token plain"> -H</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token function" style="color:rgb(220, 220, 170)">top</span><span class="token plain"> - 08:25:00 up </span><span class="token number" style="color:rgb(181, 206, 168)">7</span><span class="token plain">:27, </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain"> users, load average: </span><span class="token number" style="color:rgb(181, 206, 168)">0.00</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">0.01</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">0.05</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">Threads: </span><span class="token number" style="color:rgb(181, 206, 168)">1</span><span class="token plain"> total, </span><span class="token number" style="color:rgb(181, 206, 168)">1</span><span class="token plain"> running, </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain"> sleeping, </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain"> stopped, </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain"> zombie</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">%Cpu</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">s</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">: </span><span class="token number" style="color:rgb(181, 206, 168)">0.1</span><span class="token plain"> us, </span><span class="token number" style="color:rgb(181, 206, 168)">0.1</span><span class="token plain"> sy, </span><span class="token number" style="color:rgb(181, 206, 168)">0.0</span><span class="token plain"> ni, </span><span class="token number" style="color:rgb(181, 206, 168)">99.7</span><span class="token plain"> id, </span><span class="token number" style="color:rgb(181, 206, 168)">0.0</span><span class="token plain"> wa, </span><span class="token number" style="color:rgb(181, 206, 168)">0.0</span><span class="token plain"> hi, </span><span class="token number" style="color:rgb(181, 206, 168)">0.0</span><span class="token plain"> si, </span><span class="token number" style="color:rgb(181, 206, 168)">0.0</span><span class="token plain"> st</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">KiB Mem: </span><span class="token number" style="color:rgb(181, 206, 168)">2056668</span><span class="token plain"> total, </span><span class="token number" style="color:rgb(181, 206, 168)">1616832</span><span class="token plain"> used, </span><span class="token number" style="color:rgb(181, 206, 168)">439836</span><span class="token plain"> free, </span><span class="token number" style="color:rgb(181, 206, 168)">99352</span><span class="token plain"> buffers</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">KiB Swap: </span><span class="token number" style="color:rgb(181, 206, 168)">1441840</span><span class="token plain"> total, </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain"> used, </span><span class="token number" style="color:rgb(181, 206, 168)">1441840</span><span class="token plain"> free. </span><span class="token number" style="color:rgb(181, 206, 168)">1324440</span><span class="token plain"> cached Mem</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">PID </span><span class="token environment constant" style="color:rgb(100, 102, 149)">USER</span><span class="token plain"> PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token number" style="color:rgb(181, 206, 168)">1</span><span class="token plain"> root </span><span class="token number" style="color:rgb(181, 206, 168)">20</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">19744</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">2336</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">2080</span><span class="token plain"> R </span><span class="token number" style="color:rgb(181, 206, 168)">0.0</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">0.1</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">:00.04 </span><span class="token function" style="color:rgb(220, 220, 170)">top</span></div></pre></div><p>To examine the result further, you can use docker exec:</p><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-bash" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">$ docker </span><span class="token builtin class-name" style="color:rgb(78, 201, 176)">exec</span><span class="token plain"> -it </span><span class="token builtin class-name" style="color:rgb(78, 201, 176)">test</span><span class="token plain"> </span><span class="token function" style="color:rgb(220, 220, 170)">ps</span><span class="token plain"> aux</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token environment constant" style="color:rgb(100, 102, 149)">USER</span><span class="token plain"> PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">root </span><span class="token number" style="color:rgb(181, 206, 168)">1</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">2.6</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">0.1</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">19752</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">2352</span><span class="token plain"> ? Ss+ 08:24 </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">:00 </span><span class="token function" style="color:rgb(220, 220, 170)">top</span><span class="token plain"> -b -H</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">root </span><span class="token number" style="color:rgb(181, 206, 168)">7</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">0.0</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">0.1</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">15572</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">2164</span><span class="token plain"> ? R+ 08:25 </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">:00 </span><span class="token function" style="color:rgb(220, 220, 170)">ps</span><span class="token plain"> aux</span></div></pre></div><p>And you can gracefully request top to shut down using docker stop test.</p><p>The following Dockerfile shows using the ENTRYPOINT to run Apache in the foreground (i.e., as PID 1):</p><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-docker" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">FROM debian:stable</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">RUN apt-get update &amp;&amp; apt-get install -y --force-yes apache2</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">EXPOSE 80 443</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">VOLUME [&quot;/var/www&quot;, &quot;/var/log/apache2&quot;, &quot;/etc/apache2&quot;]</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">ENTRYPOINT [&quot;/usr/sbin/apache2ctl&quot;, &quot;-D&quot;, &quot;FOREGROUND&quot;]</span></div></pre></div><p>If you need to write a starter script for a single executable, you can ensure that the final executable receives the Unix signals by using exec and gosu commands:</p><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-bash" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token shebang important">#!/usr/bin/env bash</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token builtin class-name" style="color:rgb(78, 201, 176)">set</span><span class="token plain"> -e</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token keyword" style="color:rgb(86, 156, 214)">if</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token plain"> </span><span class="token string" style="color:rgb(206, 145, 120)">&quot;</span><span class="token string variable" style="color:rgb(156, 220, 254)">$1</span><span class="token string" style="color:rgb(206, 145, 120)">&quot;</span><span class="token plain"> </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(212, 212, 212)">\</span><span class="token plain">&#x27;postgres</span><span class="token punctuation" style="color:rgb(212, 212, 212)">\</span><span class="token plain">&#x27; </span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token punctuation" style="color:rgb(212, 212, 212)">;</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(86, 156, 214)">then</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token function" style="color:rgb(220, 220, 170)">chown</span><span class="token plain"> -R postgres </span><span class="token string" style="color:rgb(206, 145, 120)">&quot;</span><span class="token string variable" style="color:rgb(156, 220, 254)">$PGDATA</span><span class="token string" style="color:rgb(206, 145, 120)">&quot;</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token keyword" style="color:rgb(86, 156, 214)">if</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token plain"> -z </span><span class="token string" style="color:rgb(206, 145, 120)">&quot;</span><span class="token string variable" style="color:rgb(156, 220, 254)">$(</span><span class="token string variable function" style="color:rgb(220, 220, 170)">ls</span><span class="token string variable" style="color:rgb(156, 220, 254)"> -A </span><span class="token string variable string" style="color:rgb(206, 145, 120)">&quot;</span><span class="token string variable string variable" style="color:rgb(156, 220, 254)">$PGDATA</span><span class="token string variable string" style="color:rgb(206, 145, 120)">&quot;</span><span class="token string variable" style="color:rgb(156, 220, 254)">)</span><span class="token string" style="color:rgb(206, 145, 120)">&quot;</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token punctuation" style="color:rgb(212, 212, 212)">;</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(86, 156, 214)">then</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">gosu postgres initdb</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token keyword" style="color:rgb(86, 156, 214)">fi</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token builtin class-name" style="color:rgb(78, 201, 176)">exec</span><span class="token plain"> gosu postgres </span><span class="token string" style="color:rgb(206, 145, 120)">&quot;</span><span class="token string variable" style="color:rgb(156, 220, 254)">$@</span><span class="token string" style="color:rgb(206, 145, 120)">&quot;</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token keyword" style="color:rgb(86, 156, 214)">fi</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token builtin class-name" style="color:rgb(78, 201, 176)">exec</span><span class="token plain"> </span><span class="token string" style="color:rgb(206, 145, 120)">&quot;</span><span class="token string variable" style="color:rgb(156, 220, 254)">$@</span><span class="token string" style="color:rgb(206, 145, 120)">&quot;</span></div></pre></div><p>Lastly, if you need to do some extra cleanup (or communicate with other containers) on shutdown, or are co-ordinating more than one executable, you may need to ensure that the ENTRYPOINT script receives the Unix signals, passes them on, and then does some more work:</p><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-bash" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token shebang important">#!/bin/sh</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token comment" style="color:rgb(106, 153, 85)"># Note: I\&#x27;ve written this using sh so it works in the busybox container too</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token comment" style="color:rgb(106, 153, 85)"># USE the trap if you need to also do manual cleanup after the service is stopped,</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token comment" style="color:rgb(106, 153, 85)"># or need to start multiple services in the one container</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token builtin class-name" style="color:rgb(78, 201, 176)">trap</span><span class="token plain"> </span><span class="token string" style="color:rgb(206, 145, 120)">&quot;echo TRAPed signal&quot;</span><span class="token plain"> HUP INT QUIT </span><span class="token environment constant" style="color:rgb(100, 102, 149)">TERM</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token comment" style="color:rgb(106, 153, 85)"># start service in background here</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">/usr/sbin/apachectl start</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token builtin class-name" style="color:rgb(78, 201, 176)">echo</span><span class="token plain"> </span><span class="token string" style="color:rgb(206, 145, 120)">&quot;[hit enter key to exit] or run \&#x27;docker stop </span><span class="token string variable" style="color:rgb(156, 220, 254)">`</span><span class="token string variable operator" style="color:rgb(212, 212, 212)">&lt;</span><span class="token string variable" style="color:rgb(156, 220, 254)">container</span><span class="token string variable operator" style="color:rgb(212, 212, 212)">&gt;</span><span class="token string variable" style="color:rgb(156, 220, 254)">`</span><span class="token string" style="color:rgb(206, 145, 120)">\&#x27;&quot;</span><span class="token plain"> </span><span class="token builtin class-name" style="color:rgb(78, 201, 176)">read</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token comment" style="color:rgb(106, 153, 85)"># stop service and clean up here</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token builtin class-name" style="color:rgb(78, 201, 176)">echo</span><span class="token plain"> </span><span class="token string" style="color:rgb(206, 145, 120)">&quot;stopping apache&quot;</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">/usr/sbin/apachectl stop</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token builtin class-name" style="color:rgb(78, 201, 176)">echo</span><span class="token plain"> </span><span class="token string" style="color:rgb(206, 145, 120)">&quot;exited </span><span class="token string variable" style="color:rgb(156, 220, 254)">$0</span><span class="token string" style="color:rgb(206, 145, 120)">&quot;</span></div></pre></div><p>If you run this image with docker run -it --rm -p 80:80 --name test apache, you can then examine the container&#x27;s processes with docker exec, or docker top, and then ask the script to stop Apache:</p><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-bash" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">$ docker </span><span class="token builtin class-name" style="color:rgb(78, 201, 176)">exec</span><span class="token plain"> -it </span><span class="token builtin class-name" style="color:rgb(78, 201, 176)">test</span><span class="token plain"> </span><span class="token function" style="color:rgb(220, 220, 170)">ps</span><span class="token plain"> aux</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token environment constant" style="color:rgb(100, 102, 149)">USER</span><span class="token plain"> PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">root </span><span class="token number" style="color:rgb(181, 206, 168)">1</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">0.1</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">0.0</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">4448</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">692</span><span class="token plain"> ? Ss+ 00:42 </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">:00 /bin/sh /run.sh </span><span class="token number" style="color:rgb(181, 206, 168)">123</span><span class="token plain"> cmd cmd2</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">root </span><span class="token number" style="color:rgb(181, 206, 168)">19</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">0.0</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">0.2</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">71304</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">4440</span><span class="token plain"> ? Ss 00:42 </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">:00 /usr/sbin/apache2 -k start</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">www-data </span><span class="token number" style="color:rgb(181, 206, 168)">20</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">0.2</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">0.2</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">360468</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">6004</span><span class="token plain"> ? Sl 00:42 </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">:00 /usr/sbin/apache2 -k start</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">www-data </span><span class="token number" style="color:rgb(181, 206, 168)">21</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">0.2</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">0.2</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">360468</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">6000</span><span class="token plain"> ? Sl 00:42 </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">:00 /usr/sbin/apache2 -k start</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">root </span><span class="token number" style="color:rgb(181, 206, 168)">81</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">0.0</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">0.1</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">15572</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">2140</span><span class="token plain"> ? R+ 00:44 </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">:00 </span><span class="token function" style="color:rgb(220, 220, 170)">ps</span><span class="token plain"> aux</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">$ docker </span><span class="token function" style="color:rgb(220, 220, 170)">top</span><span class="token plain"> </span><span class="token builtin class-name" style="color:rgb(78, 201, 176)">test</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">PID </span><span class="token environment constant" style="color:rgb(100, 102, 149)">USER</span><span class="token plain"> COMMAND</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token number" style="color:rgb(181, 206, 168)">10035</span><span class="token plain"> root </span><span class="token punctuation" style="color:rgb(212, 212, 212)">{</span><span class="token plain">run.sh</span><span class="token punctuation" style="color:rgb(212, 212, 212)">}</span><span class="token plain"> /bin/sh /run.sh </span><span class="token number" style="color:rgb(181, 206, 168)">123</span><span class="token plain"> cmd cmd2</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token number" style="color:rgb(181, 206, 168)">10054</span><span class="token plain"> root /usr/sbin/apache2 -k start</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token number" style="color:rgb(181, 206, 168)">10055</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">33</span><span class="token plain"> /usr/sbin/apache2 -k start</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token number" style="color:rgb(181, 206, 168)">10056</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">33</span><span class="token plain"> /usr/sbin/apache2 -k start</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">$ /usr/bin/time docker stop </span><span class="token builtin class-name" style="color:rgb(78, 201, 176)">test</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token builtin class-name" style="color:rgb(78, 201, 176)">test</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">real 0m </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">.27s</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">user 0m </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">.03s</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">sys 0m </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">.03s</span></div></pre></div><p><strong>Note:</strong> you can override the ENTRYPOINT setting using --entrypoint, but this can only set the binary to exec (no sh -c will be used).</p><p><strong>Note</strong>: The exec form is parsed as a JSON array, which means that you must use double-quotes (&quot;) around words not single-quotes (&#x27;).</p><p><strong>Note</strong>: Unlike the shell form, the exec form does not invoke a command shell. This means that normal shell processing does not happen. For example, ENTRYPOINT <!-- -->[ &quot;echo&quot;, &quot;$HOME&quot; ]<!-- --> will not do variable substitution on $HOME. If you want shell processing then either use the shellform or execute a shell directly, for example: ENTRYPOINT <!-- -->[ &quot;sh&quot;, &quot;-c&quot;, &quot;echo $HOME&quot; ]<!-- -->. When using the exec form and executing a shell directly, as in the case for the shell form, it is the shell that is doing the environment variable expansion, not docker.</p><h5>Shell form ENTRYPOINT example</h5><p>You can specify a plain string for the ENTRYPOINT and it will execute in /bin/sh -c. This form will use shell processing to substitute shell environment variables, and will ignore any CMD or docker runcommand line arguments. To ensure that docker stop will signal any long running ENTRYPOINTexecutable correctly, you need to remember to start it with exec:</p><p>FROM ubuntu</p><p>ENTRYPOINT exec top -b</p><p>When you run this image, you&#x27;ll see the single PID 1 process:</p><p>$ docker run -it --rm --name test top</p><p>Mem: 1704520K used, 352148K free, 0K shrd, 0K buff, 140368121167873K cached</p><p>CPU: 5% usr 0% sys 0% nic 94% idle 0% io 0% irq 0% sirq</p><p>Load average: 0.08 0.03 0.05 2/98 6</p><p>PID PPID USER STAT VSZ %VSZ %CPU COMMAND</p><p>1 0 root R 3164 0% 0% top -b</p><p>Which will exit cleanly on docker stop:</p><p>$ /usr/bin/time docker stop test</p><p>test</p><p>real 0m 0.20s</p><p>user 0m 0.02s</p><p>sys 0m 0.04s</p><p>If you forget to add exec to the beginning of your ENTRYPOINT:</p><p>FROM ubuntu</p><p>ENTRYPOINT top -b</p><p>CMD --ignored-param1</p><p>You can then run it (giving it a name for the next step):</p><p>$ docker run -it --name test top --ignored-param2</p><p>Mem: 1704184K used, 352484K free, 0K shrd, 0K buff, 140621524238337K cached</p><p>CPU: 9% usr 2% sys 0% nic 88% idle 0% io 0% irq 0% sirq</p><p>Load average: 0.01 0.02 0.05 2/101 7</p><p>PID PPID USER STAT VSZ %VSZ %CPU COMMAND</p><p>1 0 root S 3168 0% 0% /bin/sh -c top -b cmd cmd2</p><p>7 1 root R 3164 0% 0% top -b</p><p>You can see from the output of top that the specified ENTRYPOINT is not PID 1.</p><p>If you then run docker stop test, the container will not exit cleanly - the stop command will be forced to send a SIGKILL after the timeout:</p><p>$ docker exec -it test ps aux</p><p>PID USER COMMAND</p><p>1 root /bin/sh -c top -b cmd cmd2</p><p>7 root top -b</p><p>8 root ps aux</p><p>$ /usr/bin/time docker stop test</p><p>test</p><p>real 0m 10.19s</p><p>user 0m 0.04s</p><p>sys 0m 0.03s</p><h5>Understand how CMD and ENTRYPOINT interact</h5><p>Both CMD and ENTRYPOINT instructions define what command gets executed when running a container. There are few rules that describe their co-operation.</p><ol><li>Dockerfile should specify at least one of CMD or ENTRYPOINT commands.</li><li>ENTRYPOINT should be defined when using the container as an executable.</li><li>CMD should be used as a way of defining default arguments for an ENTRYPOINT command or for executing an ad-hoc command in a container.</li><li>CMD will be overridden when running the container with alternative arguments.</li></ol><p>The table below shows what command is executed for different ENTRYPOINT / CMD combinations:</p><hr/><p>                                     No ENTRYPOINT                ENTRYPOINT exec_entry p1_entry   ENTRYPOINT <!-- -->[&quot;exec_entry&quot;, &quot;p1_entry&quot;]<!-- -->
<strong>No CMD</strong>                         error, not allowed           /bin/sh -c exec_entry p1_entry   exec_entry p1_entry
<strong>CMD <!-- -->[&quot;exec_cmd&quot;, &quot;p1_cmd&quot;]</strong>   exec_cmd p1_cmd              /bin/sh -c exec_entry p1_entry   exec_entry p1_entry exec_cmd p1_cmd
<strong>CMD <!-- -->[&quot;p1_cmd&quot;, &quot;p2_cmd&quot;]</strong>     p1_cmd p2_cmd                /bin/sh -c exec_entry p1_entry   exec_entry p1_entry p1_cmd p2_cmd
<strong>CMD exec_cmd p1_cmd</strong>            /bin/sh -c exec_cmd p1_cmd   /bin/sh -c exec_entry p1_entry   exec_entry p1_entry /bin/sh -c exec_cmd p1_cmd</p><hr/><h4>VOLUME</h4><p>VOLUME <!-- -->[&quot;/data&quot;]</p><p>The VOLUME instruction creates a mount point with the specified name and marks it as holding externally mounted volumes from native host or other containers. The value can be a JSON array, VOLUME <!-- -->[&quot;/var/log/&quot;]<!-- -->, or a plain string with multiple arguments, such as VOLUME /var/log or VOLUME /var/log /var/db. For more information/examples and mounting instructions via the Docker client, refer to <a href="https://docs.docker.com/engine/tutorials/dockervolumes/#/mount-a-host-directory-as-a-data-volume">Share Directories via Volumes</a> documentation.</p><p>The docker run command initializes the newly created volume with any data that exists at the specified location within the base image. For example, consider the following Dockerfile snippet:</p><p>FROM ubuntu</p><p>RUN mkdir /myvol</p><p>RUN echo &quot;hello world&quot; &gt; /myvol/greeting</p><p>VOLUME /myvol</p><p>This Dockerfile results in an image that causes docker run to create a new mount point at /myvoland copy the greeting file into the newly created volume.</p><h5>Notes about specifying volumes</h5><p>Keep the following things in mind about volumes in the Dockerfile.</p><ul><li><strong>Volumes on Windows-based containers</strong>: When using Windows-based containers, the destination of a volume inside the container must be one of:<ul><li>a non-existing or empty directory</li><li>a drive other than C:</li></ul></li><li><strong>Changing the volume from within the Dockerfile</strong>: If any build steps change the data within the volume after it has been declared, those changes will be discarded.</li><li><strong>JSON formatting</strong>: The list is parsed as a JSON array. You must enclose words with double quotes (&quot;)rather than single quotes (\&#x27;).</li><li><strong>The host directory is declared at container run-time</strong>: The host directory (the mountpoint) is, by its nature, host-dependent. This is to preserve image portability, since a given host directory can&#x27;t be guaranteed to be available on all hosts. For this reason, you can&#x27;t mount a host directory from within the Dockerfile. The VOLUME instruction does not support specifying a host-dirparameter. You must specify the mountpoint when you create or run the container.</li></ul><h4>USER</h4><p>USER <code style="background-color:lightgray">&lt;user&gt;[:&lt;group&gt;</code>] or</p><p>USER <code style="background-color:lightgray">&lt;UID&gt;[:&lt;GID&gt;</code>]</p><p>The USER instruction sets the user name (or UID) and optionally the user group (or GID) to use when running the image and for any RUN, CMD and ENTRYPOINT instructions that follow it in the Dockerfile.</p><p><strong>Warning</strong>: When the user doesn&#x27;t have a primary group then the image (or the next instructions) will be run with the root group.</p><p>On Windows, the user must be created first if it&#x27;s not a built-in account. This can be done with the net user command called as part of a Dockerfile.</p><p>FROM microsoft/windowsservercore</p><h1>Create Windows user in the container</h1><p>RUN net user /add patrick</p><h1>Set it for subsequent commands</h1><p>USER patrick</p><h4>WORKDIR</h4><p>WORKDIR /path/to/workdir</p><p>The WORKDIR instruction sets the working directory for any RUN, CMD, ENTRYPOINT, COPY and ADDinstructions that follow it in the Dockerfile. If the WORKDIR doesn&#x27;t exist, it will be created even if it&#x27;s not used in any subsequent Dockerfile instruction.</p><p>The WORKDIR instruction can be used multiple times in a Dockerfile. If a relative path is provided, it will be relative to the path of the previous WORKDIR instruction. For example:</p><p>WORKDIR /a</p><p>WORKDIR b</p><p>WORKDIR c</p><p>RUN pwd</p><p>The output of the final pwd command in this Dockerfile would be /a/b/c.</p><p>The WORKDIR instruction can resolve environment variables previously set using ENV. You can only use environment variables explicitly set in the Dockerfile. For example:</p><p>ENV DIRPATH /path</p><p>WORKDIR $DIRPATH/$DIRNAME</p><p>RUN pwd</p><p>The output of the final pwd command in this Dockerfile would be /path/$DIRNAME</p><h4>ARG</h4><p>ARG <code style="background-color:lightgray">&lt;name&gt;[=&lt;default value&gt;</code>]</p><p>The ARG instruction defines a variable that users can pass at build-time to the builder with the docker build command using the --build-arg <code style="background-color:lightgray">&lt;varname&gt;=&lt;value&gt;</code> flag. If a user specifies a build argument that was not defined in the Dockerfile, the build outputs a warning.</p><p>[Warning]<!-- --> One or more build-args <!-- -->[foo]<!-- --> were not consumed.</p><p>A Dockerfile may include one or more ARG instructions. For example, the following is a valid Dockerfile:</p><p>FROM busybox</p><p>ARG user1</p><p>ARG buildno</p><p>...</p><p><strong>Warning:</strong> It is not recommended to use build-time variables for passing secrets like github keys, user credentials etc. Build-time variable values are visible to any user of the image with the docker history command.</p><h5>Default values</h5><p>An ARG instruction can optionally include a default value:</p><p>FROM busybox</p><p>ARG user1=someuser</p><p>ARG buildno=1</p><p>...</p><p>If an ARG instruction has a default value and if there is no value passed at build-time, the builder uses the default.</p><h5>Scope</h5><p>An ARG variable definition comes into effect from the line on which it is defined in the Dockerfile not from the argument&#x27;s use on the command-line or elsewhere. For example, consider this Dockerfile:</p><p>1 FROM busybox</p><p>2 USER ${user:-some_user}</p><p>3 ARG user</p><p>4 USER $user</p><p>...</p><p>A user builds this file by calling:</p><p>$ docker build --build-arg user=what_user .</p><p>The USER at line 2 evaluates to some_user as the user variable is defined on the subsequent line 3. The USER at line 4 evaluates to what_user as user is defined and the what_user value was passed on the command line. Prior to its definition by an ARG instruction, any use of a variable results in an empty string.</p><p>An ARG instruction goes out of scope at the end of the build stage where it was defined. To use an arg in multiple stages, each stage must include the ARG instruction.</p><p>FROM busybox</p><p>ARG SETTINGS</p><p>RUN ./run/setup $SETTINGS</p><p>FROM busybox</p><p>ARG SETTINGS</p><p>RUN ./run/other $SETTINGS</p><h5>Using ARG variables</h5><p>You can use an ARG or an ENV instruction to specify variables that are available to the RUNinstruction. Environment variables defined using the ENV instruction always override an ARGinstruction of the same name. Consider this Dockerfile with an ENV and ARG instruction.</p><p>1 FROM ubuntu</p><p>2 ARG CONT_IMG_VER</p><p>3 ENV CONT_IMG_VER v1.0.0</p><p>4 RUN echo $CONT_IMG_VER</p><p>Then, assume this image is built with this command:</p><p>$ docker build --build-arg CONT_IMG_VER=v2.0.1 .</p><p>In this case, the RUN instruction uses v1.0.0 instead of the ARG setting passed by the user:v2.0.1This behavior is similar to a shell script where a locally scoped variable overrides the variables passed as arguments or inherited from environment, from its point of definition.</p><p>Using the example above but a different ENV specification you can create more useful interactions between ARG and ENV instructions:</p><p>1 FROM ubuntu</p><p>2 ARG CONT_IMG_VER</p><p>3 ENV CONT_IMG_VER ${CONT_IMG_VER:-v1.0.0}</p><p>4 RUN echo $CONT_IMG_VER</p><p>Unlike an ARG instruction, ENV values are always persisted in the built image. Consider a docker build without the --build-arg flag:</p><p>$ docker build .</p><p>Using this Dockerfile example, CONT_IMG_VER is persisted in the image but its value would be v1.0.0 as it is the default set in line 3 by the ENV instruction.</p><p>The variable expansion technique in this example allows you to pass arguments from the command line and persist them in the final image by leveraging the ENV instruction. Variable expansion is only supported for <a href="https://docs.docker.com/engine/reference/builder/#environment-replacement">a limited set of Dockerfile instructions.</a></p><h5>Predefined ARGs</h5><p>Docker has a set of predefined ARG variables that you can use without a corresponding ARGinstruction in the Dockerfile.</p><ul><li>HTTP_PROXY</li><li>http_proxy</li><li>HTTPS_PROXY</li><li>https_proxy</li><li>FTP_PROXY</li><li>ftp_proxy</li><li>NO_PROXY</li><li>no_proxy</li></ul><p>To use these, simply pass them on the command line using the flag:</p><p>--build-arg <code style="background-color:lightgray">&lt;varname&gt;=&lt;value&gt;</code></p><p>By default, these pre-defined variables are excluded from the output of docker history. Excluding them reduces the risk of accidentally leaking sensitive authentication information in an HTTP_PROXYvariable.</p><p>For example, consider building the following Dockerfile using--build-arg HTTP_PROXY=http://user:pass\@proxy.lon.example.com</p><p>FROM ubuntu</p><p>RUN echo &quot;Hello World&quot;</p><p>In this case, the value of the HTTP_PROXY variable is not available in the docker history and is not cached. If you were to change location, and your proxy server changed to http://user:pass\@proxy.sfo.example.com, a subsequent build does not result in a cache miss.</p><p>If you need to override this behaviour then you may do so by adding an ARG statement in the Dockerfile as follows:</p><p>FROM ubuntu</p><p>ARG HTTP_PROXY</p><p>RUN echo &quot;Hello World&quot;</p><p>When building this Dockerfile, the HTTP_PROXY is preserved in the docker history, and changing its value invalidates the build cache.</p><h5>Impact on build caching</h5><p>ARG variables are not persisted into the built image as ENV variables are. However, ARG variables do impact the build cache in similar ways. If a Dockerfile defines an ARG variable whose value is different from a previous build, then a &quot;cache miss&quot; occurs upon its first usage, not its definition. In particular, all RUN instructions following an ARG instruction use the ARG variable implicitly (as an environment variable), thus can cause a cache miss. All predefined ARG variables are exempt from caching unless there is a matching ARG statement in the Dockerfile.</p><p>For example, consider these two Dockerfile:</p><p>1 FROM ubuntu</p><p>2 ARG CONT_IMG_VER</p><p>3 RUN echo $CONT_IMG_VER</p><p>1 FROM ubuntu</p><p>2 ARG CONT_IMG_VER</p><p>3 RUN echo hello</p><p>If you specify --build-arg CONT_IMG_VER=<code style="background-color:lightgray">&lt;value&gt; on the command line, in both cases, the specification on line 2 does not cause a cache miss; line 3 does cause a cache miss.ARG CONT_IMG_VER causes the RUN line to be identified as the same as running CONT_IMG_VER=&lt;value&gt; echo hello, so if the &lt;value&gt;</code>changes, we get a cache miss.</p><p>Consider another example under the same command line:</p><p>1 FROM ubuntu</p><p>2 ARG CONT_IMG_VER</p><p>3 ENV CONT_IMG_VER $CONT_IMG_VER</p><p>4 RUN echo $CONT_IMG_VER</p><p>In this example, the cache miss occurs on line 3. The miss happens because the variable&#x27;s value in the ENV references the ARG variable and that variable is changed through the command line. In this example, the ENV command causes the image to include the value.</p><p>If an ENV instruction overrides an ARG instruction of the same name, like this Dockerfile:</p><p>1 FROM ubuntu</p><p>2 ARG CONT_IMG_VER</p><p>3 ENV CONT_IMG_VER hello</p><p>4 RUN echo $CONT_IMG_VER</p><p>Line 3 does not cause a cache miss because the value of CONT_IMG_VER is a constant (hello). As a result, the environment variables and values used on the RUN (line 4) doesn&#x27;t change between builds.</p><h4>ONBUILD</h4><p>ONBUILD <!-- -->[INSTRUCTION]</p><p>The ONBUILD instruction adds to the image a trigger instruction to be executed at a later time, when the image is used as the base for another build. The trigger will be executed in the context of the downstream build, as if it had been inserted immediately after the FROM instruction in the downstream Dockerfile.</p><p>Any build instruction can be registered as a trigger.</p><p>This is useful if you are building an image which will be used as a base to build other images, for example an application build environment or a daemon which may be customized with user-specific configuration.</p><p>For example, if your image is a reusable Python application builder, it will require application source code to be added in a particular directory, and it might require a build script to be called after that. You can&#x27;t just call ADD and RUN now, because you don&#x27;t yet have access to the application source code, and it will be different for each application build. You could simply provide application developers with a boilerplate Dockerfile to copy-paste into their application, but that is inefficient, error-prone and difficult to update because it mixes with application-specific code.</p><p>The solution is to use ONBUILD to register advance instructions to run later, during the next build stage.</p><p>Here&#x27;s how it works:</p><ul><li>When it encounters an ONBUILD instruction, the builder adds a trigger to the metadata of the image being built. The instruction does not otherwise affect the current build.</li><li>At the end of the build, a list of all triggers is stored in the image manifest, under the key OnBuild. They can be inspected with the docker inspect command.</li><li>Later the image may be used as a base for a new build, using the FROM instruction. As part of processing the FROM instruction, the downstream builder looks for ONBUILD triggers, and executes them in the same order they were registered. If any of the triggers fail, the FROMinstruction is aborted which in turn causes the build to fail. If all triggers succeed, the FROMinstruction completes and the build continues as usual.</li><li>Triggers are cleared from the final image after being executed. In other words they are not inherited by &quot;grand-children&quot; builds.</li></ul><p>For example, you might add something like this:</p><p>[...]</p><p>ONBUILD ADD . /app/src</p><p>ONBUILD RUN /usr/local/bin/python-build --dir /app/src</p><p>[...]</p><p><strong>Warning</strong>: Chaining ONBUILD instructions using ONBUILD ONBUILD isn&#x27;t allowed.</p><p><strong>Warning</strong>: The ONBUILD instruction may not trigger FROM or MAINTAINER instructions.</p><h4>STOPSIGNAL</h4><p>STOPSIGNAL signal</p><p>The STOPSIGNAL instruction sets the system call signal that will be sent to the container to exit. This signal can be a valid unsigned number that matches a position in the kernel&#x27;s syscall table, for instance 9, or a signal name in the format SIGNAME, for instance SIGKILL.</p><h4>HEALTHCHECK</h4><p>The HEALTHCHECK instruction has two forms:</p><ul><li>HEALTHCHECK <!-- -->[OPTIONS]<!-- --> CMD command (check container health by running a command inside the container)</li><li>HEALTHCHECK NONE (disable any healthcheck inherited from the base image)</li></ul><p>The HEALTHCHECK instruction tells Docker how to test a container to check that it is still working. This can detect cases such as a web server that is stuck in an infinite loop and unable to handle new connections, even though the server process is still running.</p><p>When a container has a healthcheck specified, it has a health status in addition to its normal status. This status is initially starting. Whenever a health check passes, it becomes healthy (whatever state it was previously in). After a certain number of consecutive failures, it becomes unhealthy.</p><p>The options that can appear before CMD are:</p><ul><li>--interval=DURATION (default: 30s)</li><li>--timeout=DURATION (default: 30s)</li><li>--start-period=DURATION (default: 0s)</li><li>--retries=N (default: 3)</li></ul><p>The health check will first run <strong>interval</strong> seconds after the container is started, and then again <strong>interval</strong>seconds after each previous check completes.</p><p>If a single run of the check takes longer than <strong>timeout</strong> seconds then the check is considered to have failed.</p><p>It takes <strong>retries</strong> consecutive failures of the health check for the container to be considered unhealthy.</p><p><strong>start period</strong> provides initialization time for containers that need time to bootstrap. Probe failure during that period will not be counted towards the maximum number of retries. However, if a health check succeeds during the start period, the container is considered started and all consecutive failures will be counted towards the maximum number of retries.</p><p>There can only be one HEALTHCHECK instruction in a Dockerfile. If you list more than one then only the last HEALTHCHECK will take effect.</p><p>The command after the CMD keyword can be either a shell command (e.g. HEALTHCHECK CMD /bin/check-running) or an exec array (as with other Dockerfile commands; see e.g. ENTRYPOINT for details).</p><p>The command&#x27;s exit status indicates the health status of the container. The possible values are:</p><ul><li>0: success - the container is healthy and ready for use</li><li>1: unhealthy - the container is not working correctly</li><li>2: reserved - do not use this exit code</li></ul><p>For example, to check every five minutes or so that a web-server is able to serve the site&#x27;s main page within three seconds:</p><p>HEALTHCHECK --interval=5m --timeout=3s \</p><p>CMD curl -f http://localhost/ || exit 1</p><p>To help debug failing probes, any output text (UTF-8 encoded) that the command writes on stdout or stderr will be stored in the health status and can be queried with docker inspect. Such output should be kept short (only the first 4096 bytes are stored currently).</p><p>When the health status of a container changes, a health_status event is generated with the new status.</p><p>The HEALTHCHECK feature was added in Docker 1.12.</p><h4>SHELL</h4><p>SHELL <!-- -->[&quot;executable&quot;, &quot;parameters&quot;]</p><p>The SHELL instruction allows the default shell used for the shell form of commands to be overridden. The default shell on Linux is <!-- -->[&quot;/bin/sh&quot;, &quot;-c&quot;]<!-- -->, and on Windows is <!-- -->[&quot;cmd&quot;, &quot;/S&quot;, &quot;/C&quot;]<!-- -->. The SHELL instruction must be written in JSON form in a Dockerfile.</p><p>The SHELL instruction is particularly useful on Windows where there are two commonly used and quite different native shells: cmd and powershell, as well as alternate shells available including sh.</p><p>The SHELL instruction can appear multiple times. Each SHELL instruction overrides all previous SHELL instructions, and affects all subsequent instructions. For example:</p><p>FROM microsoft/windowsservercore</p><h1>Executed as cmd /S /C echo default</h1><p>RUN echo default</p><h1>Executed as cmd /S /C powershell -command Write-Host default</h1><p>RUN powershell -command Write-Host default</p><h1>Executed as powershell -command Write-Host hello</h1><p>SHELL <!-- -->[&quot;powershell&quot;, &quot;-command&quot;]</p><p>RUN Write-Host hello</p><h1>Executed as cmd /S /C echo hello</h1><p>SHELL <!-- -->[&quot;cmd&quot;, &quot;/S&quot;&quot;, &quot;/C&quot;]</p><p>RUN echo hello</p><p>The following instructions can be affected by the SHELL instruction when the shell form of them is used in a Dockerfile: RUN, CMD and ENTRYPOINT.</p><p>The following example is a common pattern found on Windows which can be streamlined by using the SHELL instruction:</p><p>...</p><p>RUN powershell -command Execute-MyCmdlet -param1 &quot;c:\foo.txt&quot;</p><p>...</p><p>The command invoked by docker will be:</p><p>cmd /S /C powershell -command Execute-MyCmdlet -param1 &quot;c:\foo.txt&quot;</p><p>This is inefficient for two reasons. First, there is an un-necessary cmd.exe command processor (aka shell) being invoked. Second, each RUN instruction in the shell form requires an extra powershell -command prefixing the command.</p><p>To make this more efficient, one of two mechanisms can be employed. One is to use the JSON form of the RUN command such as:</p><p>...</p><p>RUN <!-- -->[&quot;powershell&quot;, &quot;-command&quot;, &quot;Execute-MyCmdlet&quot;, &quot;-param1 \&quot;c:<!-- -->\<!-- -->foo.txt\&quot;&quot;]</p><p>...</p><p>While the JSON form is unambiguous and does not use the un-necessary cmd.exe, it does require more verbosity through double-quoting and escaping. The alternate mechanism is to use the SHELLinstruction and the shell form, making a more natural syntax for Windows users, especially when combined with the escape parser directive:</p><h1>escape=`</h1><p>FROM microsoft/nanoserver</p><p>SHELL <!-- -->[&quot;powershell&quot;,&quot;-command&quot;]</p><p>RUN New-Item -ItemType Directory C:\Example</p><p>ADD Execute-MyCmdlet.ps1 c:\example\</p><p>RUN c:\example\Execute-MyCmdlet -sample \&#x27;hello world\&#x27;</p><p>Resulting in:</p><p>PS E:\docker\build\shell&gt; docker build -t shell .</p><p>Sending build context to Docker daemon 4.096 kB</p><p>Step 1/5 : FROM microsoft/nanoserver</p><p>---&gt; 22738ff49c6d</p><p>Step 2/5 : SHELL powershell -command</p><p>---&gt; Running in 6fcdb6855ae2</p><p>---&gt; 6331462d4300</p><p>Removing intermediate container 6fcdb6855ae2</p><p>Step 3/5 : RUN New-Item -ItemType Directory C:\Example</p><p>---&gt; Running in d0eef8386e97</p><p>Directory: C:\</p><p>Mode LastWriteTime Length Name</p><hr/><p>d----- 10/28/2016 11:26 AM Example</p><p>---&gt; 3f2fbf1395d9</p><p>Removing intermediate container d0eef8386e97</p><p>Step 4/5 : ADD Execute-MyCmdlet.ps1 c:\example\</p><p>---&gt; a955b2621c31</p><p>Removing intermediate container b825593d39fc</p><p>Step 5/5 : RUN c:\example\Execute-MyCmdlet \&#x27;hello world\&#x27;</p><p>---&gt; Running in be6d8e63fe75</p><p>hello world</p><p>---&gt; 8e559e9bf424</p><p>Removing intermediate container be6d8e63fe75</p><p>Successfully built 8e559e9bf424</p><p>PS E:\docker\build\shell&gt;</p><p>The SHELL instruction could also be used to modify the way in which a shell operates. For example, using SHELL cmd /S /C /V:ON|OFF on Windows, delayed environment variable expansion semantics could be modified.</p><p>The SHELL instruction can also be used on Linux should an alternate shell be required such as zsh, csh, tcsh and others.</p><p>The SHELL feature was added in Docker 1.12.</p><h4>Dockerfile examples</h4><p>Below you can see some examples of Dockerfile syntax. If you&#x27;re interested in something more realistic, look at the list of <a href="https://docs.docker.com/engine/examples/">Dockerization examples</a>.</p><h1>Nginx</h1><h1></h1><h1>VERSION 0.0.1</h1><p>FROM ubuntu</p><p>LABEL Description=&quot;This image is used to start the foobar executable&quot; Vendor=&quot;ACME Products&quot; Version=&quot;1.0&quot;</p><p>RUN apt-get update &amp;&amp; apt-get install -y inotify-tools nginx apache2 openssh-server</p><h1>Firefox over VNC</h1><h1></h1><h1>VERSION 0.3</h1><p>FROM ubuntu</p><h1>Install vnc, xvfb in order to create a \&#x27;fake\&#x27; display and firefox</h1><p>RUN apt-get update &amp;&amp; apt-get install -y x11vnc xvfb firefox</p><p>RUN mkdir <!-- -->~<!-- -->/.vnc</p><h1>Setup a password</h1><p>RUN x11vnc -storepasswd 1234 <!-- -->~<!-- -->/.vnc/passwd</p><h1>Autostart firefox (might not be the best way, but it does the trick)</h1><p>RUN bash -c \&#x27;echo &quot;firefox&quot; &gt;&gt; /.bashrc\&#x27;</p><p>EXPOSE 5900</p><p>CMD <!-- -->[&quot;x11vnc&quot;, &quot;-forever&quot;, &quot;-usepw&quot;, &quot;-create&quot;]</p><h1>Multiple images example</h1><h1></h1><h1>VERSION 0.1</h1><p>FROM ubuntu</p><p>RUN echo foo &gt; bar</p><h1>Will output something like ===&gt; 907ad6c2736f</h1><p>FROM ubuntu</p><p>RUN echo moo &gt; oink</p><h1>Will output something like ===&gt; 695d7793cbe4</h1><h1>You\&#x27;ll now have two images, 907ad6c2736f with /bar, and 695d7793cbe4 with</h1><h1>/oink.</h1><h3>Manage images</h3><p>The easiest way to make your images available for use by others inside or outside your organization is to use a Docker registry, such as <a href="https://docs.docker.com/develop/develop-images/image_management/#docker-hub">Docker Hub</a>, <a href="https://docs.docker.com/develop/develop-images/image_management/#docker-trusted-registry">Docker Trusted Registry</a>, or by running your own <a href="https://docs.docker.com/develop/develop-images/image_management/#docker-registry">private registry</a>.</p><h4>Docker Hub</h4><p><a href="https://docs.docker.com/docker-hub/">Docker Hub</a> is a public registry managed by Docker, Inc. It centralizes information about organizations, user accounts, and images. It includes a web UI, authentication and authorization using organizations, CLI and API access using commands such as docker login, docker pull, and docker push, comments, stars, search, and more. Docker Hub is also integrated into <a href="https://docs.docker.com/docker-store/">Docker Store</a>, which is a marketplace that allows you to buy and sell entitlements to non-free images.</p><h4>Docker Registry</h4><p>The Docker Registry is a component of Docker&#x27;s ecosystem. A registry is a storage and content delivery system, holding named Docker images, available in different tagged versions. For example, the image distribution/registry, with tags 2.0 and latest. Users interact with a registry by using docker push and pull commands such as docker pull myregistry.com/stevvooe/batman:voice.</p><p>Docker Hub is an instance of a Docker Registry.</p><h4>Docker Trusted Registry</h4><p><a href="https://docs.docker.com/datacenter/dtr/2.1/guides/">Docker Trusted Registry</a> is part of Docker Enterprise Edition, and is a private, secure Docker registry which includes features such as image signing and content trust, role-based access controls, and other Enterprise-grade features.</p><h4>Content Trust</h4><p>When transferring data among networked systems, trust is a central concern. When communicating over an untrusted medium such as the internet, it is critical to ensure the integrity and publisher of all the data a system operates on. You use Docker to push and pull images (data) to a registry. Content trust gives you the ability to both verify the integrity and the publisher of all the data received from a registry over any channel.</p><p>See <a href="https://docs.docker.com/engine/security/trust/">Content trust</a> for information about configuring and using this feature on Docker clients.</p><h3>Samples (To Be Done)</h3><h4>Tutorial labs</h4><p>Learn how to develop and ship containerized applications, by walking through a sample that exhibits canonical practices. These labs are from the <a href="https://github.com/docker/labs/tree/master">Docker Labs repository</a>.</p><hr/><p>  Sample                                                                                                                          Description
<a href="https://github.com/docker/labs/tree/master/beginner/">Docker for Beginners</a>                                                    A good &quot;Docker 101&quot; course.
<a href="https://github.com/docker/labs/tree/master/swarm-mode">Docker Swarm mode</a>                                                      Use Docker for natively managing a cluster of Docker Engines called a swarm.
<a href="https://github.com/docker/labs/tree/master/developer-tools/README.md">Configuring developer tools and programming languages</a>   How to set-up and use common developer tools and programming languages with Docker.
<a href="https://github.com/docker/labs/tree/master/developer-tools/java-debugging">Live Debugging Java with Docker</a>                    Java developers can use Docker to build a development environment where they can run, test, and live debug code running within a container.
<a href="https://github.com/docker/labs/tree/master/developer-tools/java/">Docker for Java Developers</a>                                  Offers Java developers an intro-level and self-paced hands-on workshop with Docker.
<a href="https://github.com/docker/labs/tree/master/developer-tools/nodejs-debugging">Live Debugging a Node.js application in Docker</a>   Node developers can use Docker to build a development environment where they can run, test, and live debug code running within a container.
<a href="https://github.com/docker/labs/tree/master/developer-tools/nodejs/porting/">Dockerizing a Node.js application</a>                 This tutorial starts with a simple Node.js application and details the steps needed to Dockerize it and ensure its scalability.
<a href="https://github.com/docker/labs/tree/master/windows/readme.md">Docker for ASP.NET and Windows containers</a>                       Docker supports Windows containers, too! Learn how to run ASP.NET, SQL Server, and more in these tutorials.
<a href="https://github.com/docker/labs/tree/master/security/README.md">Docker Security</a>                                                How to take advantage of Docker security features.
<a href="https://github.com/docker/labs/tree/master/12factor">Building a 12-factor application with Docker</a>                             Use Docker to create an app that conforms to Heroku&#x27;s &quot;12 factors for cloud-native applications.&quot;</p><hr/><h4>Library references</h4><p>These docs are imported from <a href="https://github.com/docker-library/docs/">the official Docker Library docs</a>, and help you use some of the most popular software that has been &quot;Dockerized&quot; into Docker images.</p><hr/><p>  Image name                                                                        Description
<a href="https://docs.docker.com/samples/library/adminer/">adminer</a>                       Database management in a single PHP file.
<a href="https://docs.docker.com/samples/library/aerospike/">aerospike</a>                   Aerospike -- the reliable, high performance, distributed database optimized for flash and RAM.
<a href="https://docs.docker.com/samples/library/alpine/">alpine</a>                         A minimal Docker image based on Alpine Linux with a complete package index and only 5 MB in size!
<a href="https://docs.docker.com/samples/library/amazonlinux/">amazonlinux</a>               Amazon Linux provides a stable, secure, and high-performance execution environment for applications.
<a href="https://docs.docker.com/samples/library/arangodb/">arangodb</a>                     ArangoDB - a distributed database with a flexible data model for documents, graphs, and key-values.
<a href="https://docs.docker.com/samples/library/backdrop/">backdrop</a>                     The comprehensive CMS for small to medium sized businesses and non-profits.
<a href="https://docs.docker.com/samples/library/bash/">bash</a>                             Bash is the GNU Project&#x27;s Bourne Again SHell
<a href="https://docs.docker.com/samples/library/bonita/">bonita</a>                         Bonita is an open-source business process management and workflow suite
<a href="https://docs.docker.com/samples/library/buildpack-deps/">buildpack-deps</a>         A collection of common build dependencies used for installing various modules, e.g., gems.
<a href="https://docs.docker.com/samples/library/busybox/">busybox</a>                       Busybox base image.
<a href="https://docs.docker.com/samples/library/cassandra/">cassandra</a>                   Apache Cassandra is an open-source distributed storage system.
<a href="https://docs.docker.com/samples/library/centos/">centos</a>                         The official build of CentOS.
<a href="https://docs.docker.com/samples/library/chronograf/">chronograf</a>                 Chronograf is a visualization tool for time series data in InfluxDB.
<a href="https://docs.docker.com/samples/library/cirros/">cirros</a>                         CirrOS is a Tiny OS that specializes in running on a cloud.
<a href="https://docs.docker.com/samples/library/clearlinux/">clearlinux</a>                 Official docker build of Clear Linux OS for Intel Architecture
<a href="https://docs.docker.com/samples/library/clefos/">clefos</a>                         The official build of ClefOS.
<a href="https://docs.docker.com/samples/library/clojure/">clojure</a>                       Clojure is a dialect of Lisp that runs on the JVM.
<a href="https://docs.docker.com/samples/library/composer/">composer</a>                     Composer is a dependency manager written in and for PHP.
<a href="https://docs.docker.com/samples/library/consul/">consul</a>                         Consul is a datacenter runtime that provides service discovery, configuration, and orchestration.
<a href="https://docs.docker.com/samples/library/convertigo/">convertigo</a>                 Convertigo is an open source MBaaS/MADP platform for mobile application development and back-end.
<a href="https://docs.docker.com/samples/library/couchbase/">couchbase</a>                   Couchbase Server is a NoSQL document database with a distributed architecture.
<a href="https://docs.docker.com/samples/library/couchdb/">couchdb</a>                       CouchDB is a database that uses JSON for documents, an HTTP API, &amp; JavaScript/declarative indexing.
<a href="https://docs.docker.com/samples/library/crate/">crate</a>                           CrateDB is a distributed SQL database handles massive amounts of machine data in real-time.
<a href="https://docs.docker.com/samples/library/crux/">crux</a>                             CRUX is a lightweight Linux distribution targeted at experienced Linux users
<a href="https://docs.docker.com/samples/library/debian/">debian</a>                         Debian is a Linux distribution that&#x27;s composed entirely of free and open-source software.
<a href="https://docs.docker.com/samples/library/docker/">docker</a>                         Docker in Docker!
<a href="https://docs.docker.com/samples/library/drupal/">drupal</a>                         Drupal is an open source content management platform powering millions of websites and applications.
<a href="https://docs.docker.com/samples/library/eclipse-mosquitto/">eclipse-mosquitto</a>   Eclipse Mosquitto is an open source message broker which implements MQTT version 3.1 and 3.1.1
<a href="https://docs.docker.com/samples/library/eggdrop/">eggdrop</a>                       The official Docker image of Eggdrop- IRC&#x27;s oldest actively-developed bot!
<a href="https://docs.docker.com/samples/library/elasticsearch/">elasticsearch</a>           Elasticsearch is a powerful open source search and analytics engine that makes data easy to explore.
<a href="https://docs.docker.com/samples/library/elixir/">elixir</a>                         Elixir is a dynamic, functional language for building scalable and maintainable applications.
<a href="https://docs.docker.com/samples/library/erlang/">erlang</a>                         Erlang is a programming language used to build massively scalable systems with high availability.
<a href="https://docs.docker.com/samples/library/euleros/">euleros</a>                       The official release of EulerOS.
<a href="https://docs.docker.com/samples/library/fedora/">fedora</a>                         Official Docker builds of Fedora
<a href="https://docs.docker.com/samples/library/flink/">flink</a>                           Apache Flink® is a powerful open-source distributed stream and batch processing framework.
<a href="https://docs.docker.com/samples/library/fsharp/">fsharp</a>                         F# is a multi-paradigm language encompassing functional, imperative, and object-oriented styles
<a href="https://docs.docker.com/samples/library/gazebo/">gazebo</a>                         Gazebo is an open source project for simulating robots, offering robust physics and rendering.
<a href="https://docs.docker.com/samples/library/gcc/">gcc</a>                               The GNU Compiler Collection is a compiling system that supports several languages.
<a href="https://docs.docker.com/samples/library/geonetwork/">geonetwork</a>                 GeoNetwork is a FOSS catalog for spatially referenced resources.
<a href="https://docs.docker.com/samples/library/ghost/">ghost</a>                           Ghost is a free and open source blogging platform written in JavaScript
<a href="https://docs.docker.com/samples/library/golang/">golang</a>                         Go (golang) is a general purpose, higher-level, imperative programming language.
<a href="https://docs.docker.com/samples/library/gradle/">gradle</a>                         Gradle is a build tool with a focus on build automation and support for multi-language development.
<a href="https://docs.docker.com/samples/library/groovy/">groovy</a>                         Apache Groovy is a multi-faceted language for the Java platform.
<a href="https://docs.docker.com/samples/library/haproxy/">haproxy</a>                       HAProxy - The Reliable, High Performance TCP/HTTP Load Balancer
<a href="https://docs.docker.com/samples/library/haskell/">haskell</a>                       Haskell is an advanced purely-functional programming language.
<a href="https://docs.docker.com/samples/library/haxe/">haxe</a>                             Haxe is a modern, high level, static typed programming language with multiple compilation targets.
<a href="https://docs.docker.com/samples/library/hello-seattle/">hello-seattle</a>           Hello from DockerCon 2016 (Seattle)!
<a href="https://docs.docker.com/samples/library/hello-world/">hello-world</a>               Hello World! (an example of minimal Dockerization)
<a href="https://docs.docker.com/samples/library/hola-mundo/">hola-mundo</a>                 ¡Hola de DockerCon EU 2015 (Barcelona)!
<a href="https://docs.docker.com/samples/library/httpd/">httpd</a>                           The Apache HTTP Server Project
<a href="https://docs.docker.com/samples/library/hylang/">hylang</a>                         Hy is a Lisp dialect that translates expressions into Python&#x27;s abstract syntax tree.
<a href="https://docs.docker.com/samples/library/ibmjava/">ibmjava</a>                       Official IBM® SDK, Java™ Technology Edition Docker Image.
<a href="https://docs.docker.com/samples/library/influxdb/">influxdb</a>                     InfluxDB is an open source time series database for recording metrics, events, and analytics.
<a href="https://docs.docker.com/samples/library/irssi/">irssi</a>                           irssi - The IRC client of the future
<a href="https://docs.docker.com/samples/library/jenkins/">jenkins</a>                       Official Jenkins Docker image
<a href="https://docs.docker.com/samples/library/jetty/">jetty</a>                           Jetty provides a Web server and javax.servlet container.
<a href="https://docs.docker.com/samples/library/joomla/">joomla</a>                         Joomla! is an open source content management system.
<a href="https://docs.docker.com/samples/library/jruby/">jruby</a>                           JRuby (<a href="http://www.jruby.org">http://www.jruby.org</a>) is an implementation of Ruby (<a href="http://www.ruby-lang.org">http://www.ruby-lang.org</a>) on the JVM.
<a href="https://docs.docker.com/samples/library/julia/">julia</a>                           Julia is a high-level, high-performance dynamic programming language for technical computing.
<a href="https://docs.docker.com/samples/library/kaazing-gateway/">kaazing-gateway</a>       Official build of Kaazing Gateway.
<a href="https://docs.docker.com/samples/library/kapacitor/">kapacitor</a>                   Kapacitor is an open source framework for processing, monitoring, and alerting on time series data.
<a href="https://docs.docker.com/samples/library/kibana/">kibana</a>                         Kibana gives shape to any kind of data --- structured and unstructured --- indexed in Elasticsearch.
<a href="https://docs.docker.com/samples/library/known/">known</a>                           Blogging, meet social. Known is a social publishing platform.
<a href="https://docs.docker.com/samples/library/kong/">kong</a>                             Open-source Microservice &amp; API Management layer built on top of NGINX.
<a href="https://docs.docker.com/samples/library/lightstreamer/">lightstreamer</a>           Lightstreamer is a real-time messaging server optimized for the Internet.
<a href="https://docs.docker.com/samples/library/logstash/">logstash</a>                     Logstash is a tool for managing events and logs.
<a href="https://docs.docker.com/samples/library/mageia/">mageia</a>                         Official Mageia base image
<a href="https://docs.docker.com/samples/library/mariadb/">mariadb</a>                       MariaDB is a community-developed fork of MySQL intended to remain free under the GNU GPL.
<a href="https://docs.docker.com/samples/library/maven/">maven</a>                           Apache Maven is a software project management and comprehension tool.
<a href="https://docs.docker.com/samples/library/mediawiki/">mediawiki</a>                   MediaWiki is a free software open source wiki package written in PHP.
<a href="https://docs.docker.com/samples/library/memcached/">memcached</a>                   Free &amp; open source, high-performance, distributed memory object caching system.
<a href="https://docs.docker.com/samples/library/mongo-express/">mongo-express</a>           Web-based MongoDB admin interface, written with Node.js and express
<a href="https://docs.docker.com/samples/library/mongo/">mongo</a>                           MongoDB document databases provide high availability and easy scalability.
<a href="https://docs.docker.com/samples/library/mono/">mono</a>                             Mono is an open source implementation of Microsoft&#x27;s .NET Framework
<a href="https://docs.docker.com/samples/library/mysql/">mysql</a>                           MySQL is a widely used, open-source relational database management system (RDBMS).
<a href="https://docs.docker.com/samples/library/nats-streaming/">nats-streaming</a>         NATS Streaming is an open-source, high-performance, cloud native messaging streaming system.
<a href="https://docs.docker.com/samples/library/nats/">nats</a>                             NATS is an open-source, high-performance, cloud native messaging system.
<a href="https://docs.docker.com/samples/library/neo4j/">neo4j</a>                           Neo4j is a highly scalable, robust native graph database.
<a href="https://docs.docker.com/samples/library/neurodebian/">neurodebian</a>               NeuroDebian provides neuroscience research software for Debian, Ubuntu, and other derivatives.
<a href="https://docs.docker.com/samples/library/nextcloud/">nextcloud</a>                   A safe home for all your data
<a href="https://docs.docker.com/samples/library/nginx/">nginx</a>                           Official build of Nginx.
<a href="https://docs.docker.com/samples/library/node/">node</a>                             Node.js is a JavaScript-based platform for server-side and networking applications.
<a href="https://docs.docker.com/samples/library/notary/">notary</a>                         Notary server and signer cooperatively handle signing and distribution of notary repositories.
<a href="https://docs.docker.com/samples/library/nuxeo/">nuxeo</a>                           Nuxeo is an open source Content Management Platform that is completely customizable.
<a href="https://docs.docker.com/samples/library/odoo/">odoo</a>                             Odoo (formerly known as OpenERP) is a suite of open-source business apps.
<a href="https://docs.docker.com/samples/library/open-liberty/">open-liberty</a>             Official Open Liberty image.
<a href="https://docs.docker.com/samples/library/openjdk/">openjdk</a>                       OpenJDK is an open-source implementation of the Java Platform, Standard Edition
<a href="https://docs.docker.com/samples/library/opensuse/">opensuse</a>                     This project contains the stable releases of the openSUSE distribution.
<a href="https://docs.docker.com/samples/library/oraclelinux/">oraclelinux</a>               Oracle Linux is an open-source operating system suitable for general purpose or Oracle workloads.
<a href="https://docs.docker.com/samples/library/orientdb/">orientdb</a>                     OrientDB a Multi-Model Open Source NoSQL DBMS that combines graphs and documents.
<a href="https://docs.docker.com/samples/library/owncloud/">owncloud</a>                     ownCloud is a self-hosted file sync and share server.
<a href="https://docs.docker.com/samples/library/percona/">percona</a>                       Percona Server is a fork of the MySQL relational database management system created by Percona.
<a href="https://docs.docker.com/samples/library/perl/">perl</a>                             Perl is a high-level, general-purpose, interpreted, dynamic programming language.
<a href="https://docs.docker.com/samples/library/photon/">photon</a>                         Photon OS is a technology preview of a minimal Linux container host.
<a href="https://docs.docker.com/samples/library/php-zendserver/">php-zendserver</a>         Zend Server - the integrated PHP application platform for mobile and web apps.
<a href="https://docs.docker.com/samples/library/php/">php</a>                               While designed for web development, the PHP scripting language also provides general-purpose use.
<a href="https://docs.docker.com/samples/library/piwik/">piwik</a>                           Piwik is the leading open-source analytics platform that gives you more than powerful analytics.
<a href="https://docs.docker.com/samples/library/plone/">plone</a>                           Plone is a free and open source content management system built on top of Zope.
<a href="https://docs.docker.com/samples/library/postgres/">postgres</a>                     The PostgreSQL object-relational database system provides reliability and data integrity.
<a href="https://docs.docker.com/samples/library/pypy/">pypy</a>                             PyPy is a fast, compliant alternative implementation of the Python language.
<a href="https://docs.docker.com/samples/library/python/">python</a>                         Python is an interpreted, interactive, object-oriented, open-source programming language.
<a href="https://docs.docker.com/samples/library/r-base/">r-base</a>                         R is a system for statistical computation and graphics.
<a href="https://docs.docker.com/samples/library/rabbitmq/">rabbitmq</a>                     RabbitMQ is an open source multi-protocol messaging broker.
<a href="https://docs.docker.com/samples/library/rakudo-star/">rakudo-star</a>               Rakudo Perl 6, or simply Rakudo, is a compiler for the Perl 6 programming language.
<a href="https://docs.docker.com/samples/library/rapidoid/">rapidoid</a>                     Rapidoid is a high-performance HTTP server and modern Java web framework / application container.
<a href="https://docs.docker.com/samples/library/redis/">redis</a>                           Redis is an open source key-value store that functions as a data structure server.
<a href="https://docs.docker.com/samples/library/redmine/">redmine</a>                       Redmine is a flexible project management web application written using Ruby on Rails framework
<a href="https://docs.docker.com/samples/library/registry/">registry</a>                     The Docker Registry 2.0 implementation for storing and distributing Docker images
<a href="https://docs.docker.com/samples/library/rethinkdb/">rethinkdb</a>                   RethinkDB is an open-source, document database that makes it easy to build and scale realtime apps.
<a href="https://docs.docker.com/samples/library/rocket.chat/">rocket.chat</a>               The Complete Open Source Chat Solution
<a href="https://docs.docker.com/samples/library/ros/">ros</a>                               The Robot Operating System (ROS) is an open source project for building robot applications.
<a href="https://docs.docker.com/samples/library/ruby/">ruby</a>                             Ruby is a dynamic, reflective, object-oriented, general-purpose, open-source programming language.
<a href="https://docs.docker.com/samples/library/rust/">rust</a>                             Rust is a systems programming language focused on safety, speed, and concurrency.
<a href="https://docs.docker.com/samples/library/scratch/">scratch</a>                       an explicitly empty image, especially for building images &quot;FROM scratch&quot;
<a href="https://docs.docker.com/samples/library/sentry/">sentry</a>                         Sentry is a realtime, platform-agnostic error logging and aggregation platform
<a href="https://docs.docker.com/samples/library/silverpeas/">silverpeas</a>                 Silverpeas is a turnkey and open-source Collaborative and Social-Networking Portal.
<a href="https://docs.docker.com/samples/library/sl/">sl</a>                                 Official containers for Scientific Linux(SL)
<a href="https://docs.docker.com/samples/library/solr/">solr</a>                             Solr is the popular, blazing-fast, open source enterprise search platform built on Apache Lucene™.
<a href="https://docs.docker.com/samples/library/sonarqube/">sonarqube</a>                   SonarQube is an open source platform for continuous inspection of code quality.
<a href="https://docs.docker.com/samples/library/sourcemage/">sourcemage</a>                 Source Mage is a source-based GNU/Linux distribution with maximum flexibility in customization.
<a href="https://docs.docker.com/samples/library/spiped/">spiped</a>                         Spiped is a utility for creating symmetrically encrypted and authenticated pipes between sockets.
<a href="https://docs.docker.com/samples/library/storm/">storm</a>                           Apache Storm is a free and open source distributed realtime computation system.
<a href="https://docs.docker.com/samples/library/swarm/">swarm</a>                           Swarm: a Docker-native clustering system.
<a href="https://docs.docker.com/samples/library/swift/">swift</a>                           Swift is a general-purpose programming language using a modern approach to safety and performance.
<a href="https://docs.docker.com/samples/library/swipl/">swipl</a>                           SWI-Prolog offers a comprehensive free Prolog environment.
<a href="https://docs.docker.com/samples/library/teamspeak/">teamspeak</a>                   TeamSpeak is software for quality voice communication via the Internet.
<a href="https://docs.docker.com/samples/library/telegraf/">telegraf</a>                     Telegraf is an agent for collecting metrics and writing them to InfluxDB or other outputs.
<a href="https://docs.docker.com/samples/library/thrift/">thrift</a>                         Thrift is a framework for generating client and services from an IDL.
<a href="https://docs.docker.com/samples/library/tomcat/">tomcat</a>                         Apache Tomcat is an open source implementation of the Java Servlet and JavaServer Pages technologies
<a href="https://docs.docker.com/samples/library/tomee/">tomee</a>                           Apache TomEE is an all-Apache Java EE certified stack where Apache Tomcat is top dog.
<a href="https://docs.docker.com/samples/library/traefik/">traefik</a>                       Træfɪk, a modern reverse proxy
<a href="https://docs.docker.com/samples/library/ubuntu/">ubuntu</a>                         Ubuntu is a Debian-based Linux operating system based on free software.
<a href="https://docs.docker.com/samples/library/vault/">vault</a>                           Vault is a tool for securely accessing secrets via a unified interface and tight access control.
<a href="https://docs.docker.com/samples/library/websphere-liberty/">websphere-liberty</a>   Official IBM WebSphere Application Server for Developers Liberty image.
<a href="https://docs.docker.com/samples/library/wordpress/">wordpress</a>                   The WordPress rich content management system can utilize plugins, widgets, and themes.
<a href="https://docs.docker.com/samples/library/xwiki/">xwiki</a>                           XWiki: The Advanced Open Source Enterprise Wiki.
<a href="https://docs.docker.com/samples/library/znc/">znc</a>                               ZNC - An advanced IRC bouncer
<a href="https://docs.docker.com/samples/library/zookeeper/">zookeeper</a>                   Apache ZooKeeper is an open-source server which enables highly reliable distributed coordination.</p><hr/><h4>Sample applications</h4><p>Run popular software using Docker.</p><hr/><p>  Sample                                                                                       Description
<a href="https://docs.docker.com/engine/examples/apt-cacher-ng">apt-cacher-ng</a>                       Run a Dockerized apt-cacher-ng instance.
<a href="https://docs.docker.com/compose/aspnet-mssql-compose">ASP.NET Core + SQL Server on Linux</a>   Run a Dockerized ASP.NET Core + SQL Server environment.
<a href="https://docs.docker.com/engine/examples/couchdb_data_volumes">CouchDB</a>                      Run a Dockerized CouchDB instance.
<a href="https://docs.docker.com/compose/django/">Django + PostgreSQL</a>                               Run a Dockerized Django + PostgreSQL environment.
<a href="https://docs.docker.com/engine/examples/postgresql_service">PostgreSQL</a>                     Run a Dockerized PosgreSQL instance.
<a href="https://docs.docker.com/compose/rails/">Rails + PostgreSQL</a>                                 Run a Dockerized Rails + PostgreSQL environment.
<a href="https://docs.docker.com/engine/examples/running_riak_service">Riak</a>                         Run a Dockerized Riak instance.
<a href="https://docs.docker.com/engine/examples/running_ssh_service">SSHd</a>                          Run a Dockerized SSHd instance.</p><hr/><h2>Develop with Docker Engine SDKs and API</h2><p>Docker provides an API for interacting with the Docker daemon (called the Docker Engine API), as well as SDKs for Go and Python. The SDKs allow you to build and scale Docker apps and solutions quickly and easily. If Go or Python don&#x27;t work for you, you can use the Docker Engine API directly.</p><p>The Docker Engine API is a RESTful API accessed by an HTTP client such as wget or curl, or the HTTP library which is part of most modern programming languages.</p><h3>Install the SDKs</h3><p>Use the following commands to install the Go or Python SDK. Both SDKs can be installed and coexist together.</p><h4>Go SDK</h4><p>go get github.com/docker/docker/client</p><p><a href="https://godoc.org/github.com/docker/docker/client">Read the full Docker Engine Go SDK reference</a>.</p><h4>Python SDK</h4><ul><li><strong>Recommended</strong>: Run pip install docker.</li><li><strong>If you can&#x27;t use pip</strong>:<ol><li><a href="https://pypi.python.org/pypi/docker/">Download the package directly</a>.</li><li>Extract it and change to the extracted directory,</li><li>Run python setup.py install.</li></ol></li></ul><p><a href="https://docker-py.readthedocs.io/">Read the full Docker Engine Python SDK reference</a>.</p><h3>View the API reference</h3><p>You can <a href="https://docs.docker.com/engine/api/latest/">view the reference for the latest version of the API</a> or <a href="https://docs.docker.com/engine/api/version-history/">choose a specific version</a>.</p><h3>Versioned API and SDK</h3><p>The version of the Docker Engine API you should use depends upon the version of your Docker daemon and Docker client.</p><p>A given version of the Docker Engine SDK supports a specific version of the Docker Engine API, as well as all earlier versions. If breaking changes occur, they are documented prominently.</p><p><strong>Daemon and client API mismatches</strong></p><p>The Docker daemon and client do not necessarily need to be the same version at all times. However, keep the following in mind.</p><ul><li>If the daemon is newer than the client, the client does not know about new features or deprecated API endpoints in the daemon.</li><li>If the client is newer than the daemon, the client can request API endpoints that the daemon does not know about.</li></ul><p>A new version of the API is released when new features are added. The Docker API is backward-compatible, so you do not need to update code that uses the API unless you need to take advantage of new features.</p><p>To see the highest version of the API your Docker daemon and client support, use docker version:</p><p>$ docker version</p><p>Client:</p><p>Version: 17.04.0-ce</p><p>API version: 1.28</p><p>Go version: go1.7.5</p><p>Git commit: 4845c56</p><p>Built: Wed Apr 5 06:06:36 2017</p><p>OS/Arch: darwin/amd64</p><p>Server:</p><p>Version: 17.04.0-ce</p><p>API version: 1.28 (minimum version 1.12)</p><p>Go version: go1.7.5</p><p>Git commit: 4845c56</p><p>Built: Tue Apr 4 00:37:25 2017</p><p>OS/Arch: linux/amd64</p><p>Experimental: true</p><p>You can specify the API version to use, in one of the following ways:</p><ul><li>When using the SDK, use the latest version you can, but at least the version that incorporates the API version with the features you need.</li><li>When using curl directly, specify the version as the first part of the URL. For instance, if the endpoint is /containers/, you can use /v1.27/containers/.</li><li>To force the Docker CLI or the Docker Engine SDKs to use an old version version of the API than the version reported by docker version, set the environment variable DOCKER_API_VERSION to the correct version. This works on Linux, Windows, or macOS clients.</li><li>DOCKER_API_VERSION=\&#x27;1.27\&#x27;</li></ul><p>While the environment variable is set, that version of the API is used, even if the Docker daemon supports a newer version.</p><ul><li>For the SDKs, you can also specify the API version programmatically, as a parameter to the client object. See the <a href="https://github.com/moby/moby/blob/master/client/client.go#L136">Go constructor</a> or the <a href="https://docker-py.readthedocs.io/en/stable/client.html">Python SDK documentation for client</a>.</li></ul><h4>Docker EE and CE API mismatch</h4><p>If you use Docker EE in production, we recommend using Docker EE in development too. If you can&#x27;t, such as when your developers use Docker for Mac or Docker for Windows and manually build and push images, then your developers need to configure their Docker clients to use the same version of the API reported by their Docker daemon. This prevents the developer from using a feature that is not yet supported on the daemon where the workload runs in production. You can do this one of two ways:</p><ul><li>Configure the Docker client to connect to an external daemon running Docker EE. You can use the -H flag on the docker command or set the DOCKER_HOST environment variable. The client uses the daemon&#x27;s latest supported API version.</li><li>Configure the Docker client to use a specific API by setting the DOCKER_API_VERSION environment variable to the API version to use, such as 1.30.</li></ul><h4>API version matrix</h4><p>Docker does not recommend running versions prior to 1.12, which means you are encouraged to use an API version of 1.24 or higher.</p><p>  <strong>Docker version</strong>   <strong>Maximum API version</strong>                             <strong>Change log</strong></p><hr/><p>  18.02                <a href="https://docs.docker.com/engine/api/v1.36/">1.36</a>   <a href="https://docs.docker.com/engine/api/version-history/#v136-api-changes">changes</a>
17.12                <a href="https://docs.docker.com/engine/api/v1.35/">1.35</a>   <a href="https://docs.docker.com/engine/api/version-history/#v135-api-changes">changes</a>
17.11                <a href="https://docs.docker.com/engine/api/v1.34/">1.34</a>   <a href="https://docs.docker.com/engine/api/version-history/#v134-api-changes">changes</a>
17.10                <a href="https://docs.docker.com/engine/api/v1.33/">1.33</a>   <a href="https://docs.docker.com/engine/api/version-history/#v133-api-changes">changes</a>
17.09                <a href="https://docs.docker.com/engine/api/v1.32/">1.32</a>   <a href="https://docs.docker.com/engine/api/version-history/#v132-api-changes">changes</a>
17.07                <a href="https://docs.docker.com/engine/api/v1.31/">1.31</a>   <a href="https://docs.docker.com/engine/api/version-history/#v131-api-changes">changes</a>
17.06                <a href="https://docs.docker.com/engine/api/v1.30/">1.30</a>   <a href="https://docs.docker.com/engine/api/version-history/#v130-api-changes">changes</a>
17.05                <a href="https://docs.docker.com/engine/api/v1.29/">1.29</a>   <a href="https://docs.docker.com/engine/api/version-history/#v129-api-changes">changes</a>
17.04                <a href="https://docs.docker.com/engine/api/v1.28/">1.28</a>   <a href="https://docs.docker.com/engine/api/version-history/#v128-api-changes">changes</a>
17.03.1              <a href="https://docs.docker.com/engine/api/v1.27/">1.27</a>   <a href="https://docs.docker.com/engine/api/version-history/#v127-api-changes">changes</a>
17.03                <a href="https://docs.docker.com/engine/api/v1.27/">1.26</a>   <a href="https://docs.docker.com/engine/api/version-history/#v126-api-changes">changes</a>
1.13.1               <a href="https://docs.docker.com/engine/api/v1.26/">1.26</a>   <a href="https://docs.docker.com/engine/api/version-history/#v126-api-changes">changes</a>
1.13                 <a href="https://docs.docker.com/engine/api/v1.26/">1.25</a>   <a href="https://docs.docker.com/engine/api/version-history/#v125-api-changes">changes</a>
1.12                 <a href="https://docs.docker.com/engine/api/v1.24/">1.24</a>   <a href="https://docs.docker.com/engine/api/version-history/#v124-api-changes">changes</a>
1.11                 <a href="https://docs.docker.com/engine/api/v1.23/">1.23</a>   <a href="https://docs.docker.com/engine/api/version-history/#v123-api-changes">changes</a>
1.10                 <a href="https://docs.docker.com/engine/api/v1.22/">1.22</a>   <a href="https://docs.docker.com/engine/api/version-history/#v122-api-changes">changes</a>
1.9                  <a href="https://docs.docker.com/engine/api/v1.21/">1.21</a>   <a href="https://docs.docker.com/engine/api/version-history/#v121-api-changes">changes</a>
1.8                  <a href="https://docs.docker.com/engine/api/v1.20/">1.20</a>   <a href="https://docs.docker.com/engine/api/version-history/#v120-api-changes">changes</a>
1.7                  <a href="https://docs.docker.com/engine/api/v1.19/">1.19</a>   <a href="https://docs.docker.com/engine/api/version-history/#v119-api-changes">changes</a>
1.6                  <a href="https://docs.docker.com/engine/api/v1.18/">1.18</a>   <a href="https://docs.docker.com/engine/api/version-history/#v118-api-changes">changes</a></p><h4>Choose the SDK or API version to use</h4><p>Use the following guidelines to choose the SDK or API version to use in your code:</p><ul><li>If you&#x27;re starting a new project, use the <a href="https://docs.docker.com/engine/api/latest/">latest version</a>, but do specify the version you are using. This helps prevent surprises.</li><li>If you need a new feature, update your code to use at least the minimum version that supports the feature, and prefer the latest version you can use.</li><li>Otherwise, continue to use the version that your code is already using.</li></ul><h3>SDK and API quickstart</h3><p>As an example, the docker run command can be easily implemented using the Docker API directly, or using the Python or Go SDK.</p><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-python" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token keyword" style="color:rgb(86, 156, 214)">import</span><span class="token plain"> docker</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">client </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> docker</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">from_env</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token keyword" style="color:rgb(86, 156, 214)">print</span><span class="token plain"> client</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">containers</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">run</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token string" style="color:rgb(206, 145, 120)">&quot;alpine&quot;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&quot;echo&quot;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(206, 145, 120)">&quot;hello&quot;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(206, 145, 120)">&quot;world&quot;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">package main</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token keyword" style="color:rgb(86, 156, 214)">import</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token string" style="color:rgb(206, 145, 120)">&quot;io&quot;</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token string" style="color:rgb(206, 145, 120)">&quot;os&quot;</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token string" style="color:rgb(206, 145, 120)">&quot;github.com/docker/docker/client&quot;</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token string" style="color:rgb(206, 145, 120)">&quot;github.com/docker/docker/api/types&quot;</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token string" style="color:rgb(206, 145, 120)">&quot;github.com/docker/docker/api/types/container&quot;</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token string" style="color:rgb(206, 145, 120)">&quot;golang.org/x/net/context&quot;</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">func main</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(212, 212, 212)">{</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">ctx </span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> context</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">Background</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">cli</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> err </span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> client</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">NewEnvClient</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token keyword" style="color:rgb(86, 156, 214)">if</span><span class="token plain"> err </span><span class="token operator" style="color:rgb(212, 212, 212)">!=</span><span class="token plain"> nil </span><span class="token punctuation" style="color:rgb(212, 212, 212)">{</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">panic</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">err</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token punctuation" style="color:rgb(212, 212, 212)">}</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">_</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> err </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> cli</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">ImagePull</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">ctx</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(206, 145, 120)">&quot;docker.io/library/alpine&quot;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> types</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">ImagePullOptions</span><span class="token punctuation" style="color:rgb(212, 212, 212)">{</span><span class="token punctuation" style="color:rgb(212, 212, 212)">}</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token keyword" style="color:rgb(86, 156, 214)">if</span><span class="token plain"> err </span><span class="token operator" style="color:rgb(212, 212, 212)">!=</span><span class="token plain"> nil </span><span class="token punctuation" style="color:rgb(212, 212, 212)">{</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">panic</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">err</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token punctuation" style="color:rgb(212, 212, 212)">}</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">resp</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> err </span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> cli</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">ContainerCreate</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">ctx</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> </span><span class="token operator" style="color:rgb(212, 212, 212)">&amp;</span><span class="token plain">container</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">Config</span><span class="token punctuation" style="color:rgb(212, 212, 212)">{</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">Image</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(206, 145, 120)">&quot;alpine&quot;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">Cmd</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain">string</span><span class="token punctuation" style="color:rgb(212, 212, 212)">{</span><span class="token string" style="color:rgb(206, 145, 120)">&quot;echo&quot;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(206, 145, 120)">&quot;hello world&quot;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">}</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token punctuation" style="color:rgb(212, 212, 212)">}</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> nil</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> nil</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(206, 145, 120)">&quot;&quot;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token keyword" style="color:rgb(86, 156, 214)">if</span><span class="token plain"> err </span><span class="token operator" style="color:rgb(212, 212, 212)">!=</span><span class="token plain"> nil </span><span class="token punctuation" style="color:rgb(212, 212, 212)">{</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">panic</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">err</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token punctuation" style="color:rgb(212, 212, 212)">}</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token keyword" style="color:rgb(86, 156, 214)">if</span><span class="token plain"> err </span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> cli</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">ContainerStart</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">ctx</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> resp</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">ID</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> types</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">ContainerStartOptions</span><span class="token punctuation" style="color:rgb(212, 212, 212)">{</span><span class="token punctuation" style="color:rgb(212, 212, 212)">}</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token punctuation" style="color:rgb(212, 212, 212)">;</span><span class="token plain"> err </span><span class="token operator" style="color:rgb(212, 212, 212)">!=</span><span class="token plain"> nil </span><span class="token punctuation" style="color:rgb(212, 212, 212)">{</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">panic</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">err</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token punctuation" style="color:rgb(212, 212, 212)">}</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">statusCh</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> errCh </span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> cli</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">ContainerWait</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">ctx</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> resp</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">ID</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> container</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">WaitConditionNotRunning</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">select </span><span class="token punctuation" style="color:rgb(212, 212, 212)">{</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">case err </span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> </span><span class="token operator" style="color:rgb(212, 212, 212)">&lt;</span><span class="token operator" style="color:rgb(212, 212, 212)">-</span><span class="token plain">errCh</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token keyword" style="color:rgb(86, 156, 214)">if</span><span class="token plain"> err </span><span class="token operator" style="color:rgb(212, 212, 212)">!=</span><span class="token plain"> nil </span><span class="token punctuation" style="color:rgb(212, 212, 212)">{</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">panic</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">err</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token punctuation" style="color:rgb(212, 212, 212)">}</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">case </span><span class="token operator" style="color:rgb(212, 212, 212)">&lt;</span><span class="token operator" style="color:rgb(212, 212, 212)">-</span><span class="token plain">statusCh</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token punctuation" style="color:rgb(212, 212, 212)">}</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">out</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> err </span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> cli</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">ContainerLogs</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">ctx</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> resp</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">ID</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> types</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">ContainerLogsOptions</span><span class="token punctuation" style="color:rgb(212, 212, 212)">{</span><span class="token plain">ShowStdout</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> true</span><span class="token punctuation" style="color:rgb(212, 212, 212)">}</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token keyword" style="color:rgb(86, 156, 214)">if</span><span class="token plain"> err </span><span class="token operator" style="color:rgb(212, 212, 212)">!=</span><span class="token plain"> nil </span><span class="token punctuation" style="color:rgb(212, 212, 212)">{</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">panic</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">err</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token punctuation" style="color:rgb(212, 212, 212)">}</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">io</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">Copy</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">os</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">Stdout</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> out</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token punctuation" style="color:rgb(212, 212, 212)">}</span></div></pre></div><ul><li>HTTP</li></ul><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-bash" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">$ </span><span class="token function" style="color:rgb(220, 220, 170)">curl</span><span class="token plain"> --unix-socket /var/run/docker.sock -H </span><span class="token string" style="color:rgb(206, 145, 120)">&quot;Content-Type: application/json&quot;</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(212, 212, 212)">\</span><span class="token plain"> -d </span><span class="token punctuation" style="color:rgb(212, 212, 212)">\</span><span class="token plain">&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">{</span><span class="token string" style="color:rgb(206, 145, 120)">&quot;Image&quot;</span><span class="token builtin class-name" style="color:rgb(78, 201, 176)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(206, 145, 120)">&quot;alpine&quot;</span><span class="token plain">, </span><span class="token string" style="color:rgb(206, 145, 120)">&quot;Cmd&quot;</span><span class="token builtin class-name" style="color:rgb(78, 201, 176)">:</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&quot;echo&quot;</span><span class="token plain">, </span><span class="token string" style="color:rgb(206, 145, 120)">&quot;hello world&quot;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token punctuation" style="color:rgb(212, 212, 212)">}</span><span class="token punctuation" style="color:rgb(212, 212, 212)">\</span><span class="token plain">&#x27; </span><span class="token punctuation" style="color:rgb(212, 212, 212)">\</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">-X POST http:/v1.24/containers/create </span><span class="token punctuation" style="color:rgb(212, 212, 212)">{</span><span class="token string" style="color:rgb(206, 145, 120)">&quot;Id&quot;</span><span class="token builtin class-name" style="color:rgb(78, 201, 176)">:</span><span class="token string" style="color:rgb(206, 145, 120)">&quot;1c6594faf5&quot;</span><span class="token plain">,</span><span class="token string" style="color:rgb(206, 145, 120)">&quot;Warnings&quot;</span><span class="token plain">:null</span><span class="token punctuation" style="color:rgb(212, 212, 212)">}</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">$ </span><span class="token function" style="color:rgb(220, 220, 170)">curl</span><span class="token plain"> --unix-socket /var/run/docker.sock -X POST http:/v1.24/containers/1c6594faf5/start</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">$ </span><span class="token function" style="color:rgb(220, 220, 170)">curl</span><span class="token plain"> --unix-socket /var/run/docker.sock -X POST http:/v1.24/containers/1c6594faf5/wait</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token punctuation" style="color:rgb(212, 212, 212)">{</span><span class="token string" style="color:rgb(206, 145, 120)">&quot;StatusCode&quot;</span><span class="token plain">:0</span><span class="token punctuation" style="color:rgb(212, 212, 212)">}</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">$ </span><span class="token function" style="color:rgb(220, 220, 170)">curl</span><span class="token plain"> --unix-socket /var/run/docker.sock </span><span class="token string" style="color:rgb(206, 145, 120)">&quot;http:/v1.24/containers/1c6594faf5/logs?stdout=1&quot;</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">hello world</span></div></pre></div><h3>Unofficial libraries</h3><p>There are a number of community supported libraries available for other languages. They have not been tested by Docker, so if you run into any issues, file them with the library maintainers.</p><p>  <strong>Language</strong>            <strong>Library</strong></p><hr/><p>  C                       <a href="https://github.com/danielsuo/libdocker">libdocker</a>
C#                     <a href="https://github.com/ahmetalpbalkan/Docker.DotNet">Docker.DotNet</a>
C++                     <a href="https://github.com/lasote/docker_client">lasote/docker_client</a>
Dart                    <a href="https://github.com/bwu-dart/bwu_docker">bwu_docker</a>
Erlang                  <a href="https://github.com/proger/erldocker">erldocker</a>
Gradle                  <a href="https://github.com/gesellix/gradle-docker-plugin">gradle-docker-plugin</a>
Groovy                  <a href="https://github.com/gesellix/docker-client">docker-client</a>
Haskell                 <a href="https://github.com/denibertovic/docker-hs">docker-hs</a>
HTML (Web Components)   <a href="https://github.com/kapalhq/docker-elements">docker-elements</a>
Java                    <a href="https://github.com/spotify/docker-client">docker-client</a>
Java                    <a href="https://github.com/docker-java/docker-java">docker-java</a>
NodeJS                  <a href="https://github.com/apocas/dockerode">dockerode</a>
NodeJS                  <a href="https://github.com/arhea/harbor-master">harbor-master</a>
Perl                    <a href="https://github.com/alambike/eixo-docker">Eixo::Docker</a>
PHP                     <a href="https://github.com/docker-php/docker-php">Docker-PHP</a>
Ruby                    <a href="https://github.com/swipely/docker-api">docker-api</a>
Rust                    <a href="https://github.com/abh1nav/docker-rust">docker-rust</a>
Rust                    <a href="https://github.com/softprops/shiplift">shiplift</a>
Scala                   <a href="https://github.com/softprops/tugboat">tugboat</a>
Scala                   <a href="https://github.com/almoehi/reactive-docker">reactive-docker</a>
Swift                   <a href="https://github.com/valeriomazzeo/docker-client-swift">docker-client-swift</a></p><h2><a href="https://docs.docker.com/develop/sdk/examples/"></a>Examples using the Docker Engine SDKs and Docker API</h2><h1>Configuring Networks</h1><h2>Network Overview</h2><p>One of the reasons Docker containers and services are so powerful is that you can connect them together, or connect them to non-Docker workloads. Docker containers and services do not even need to be aware that they are deployed on Docker, or whether their peers are also Docker workloads or not. Whether your Docker hosts run Linux, Windows, or a mix of the two, you can use Docker to manage them in a platform-agnostic way.</p><p>This topic defines some basic Docker networking concepts and prepares you to design and deploy your applications to take full advantage of these capabilities.</p><p>Most of this content applies to all Docker installations. However, <a href="https://docs.docker.com/network/#docker-ee-networking-features">a few advanced features</a> are only available to Docker EE customers.</p><h3>Scope of this topic</h3><p>This topic does <strong>not</strong> go into OS-specific details about how Docker networks work, so you will not find information about how Docker manipulates iptables rules on Linux or how it manipulates routing rules on Windows servers, and you will not find detailed information about how Docker forms and encapsulates packets or handles encryption. See <a href="https://docs.docker.com/network/iptables/">Docker and iptables</a> and <a href="https://success.docker.com/Architecture/Docker_Reference_Architecture%3A_Designing_Scalable%2C_Portable_Docker_Container_Networks">Docker Reference Architecture: Designing Scalable, Portable Docker Container Networks</a> for a much greater depth of technical detail.</p><p>In addition, this topic does not provide any tutorials for how to create, manage, and use Docker networks. Each section includes links to relevant tutorials and command references.</p><h3>Network drivers</h3><p>Docker&#x27;s networking subsystem is pluggable, using drivers. Several drivers exist by default, and provide core networking functionality:</p><ul><li>bridge: The default network driver. If you don&#x27;t specify a driver, this is the type of network you are creating. <strong>Bridge networks are usually used when your applications run in standalone containers that need to communicate.</strong> See <a href="https://docs.docker.com/network/bridge/">bridge networks</a>.</li><li>host: For standalone containers, remove network isolation between the container and the Docker host, and use the host&#x27;s networking directly. host is only available for swarm services on Docker 17.06 and higher. See <a href="https://docs.docker.com/network/host/">use the host network</a>.</li><li>overlay: Overlay networks connect multiple Docker daemons together and enable swarm services to communicate with each other. You can also use overlay networks to facilitate communication between a swarm service and a standalone container, or between two standalone containers on different Docker daemons. This strategy removes the need to do OS-level routing between these containers. See <a href="https://docs.docker.com/network/overlay/">overlay networks</a>.</li><li>macvlan: Macvlan networks allow you to assign a MAC address to a container, making it appear as a physical device on your network. The Docker daemon routes traffic to containers by their MAC addresses. Using the macvlan driver is sometimes the best choice when dealing with legacy applications that expect to be directly connected to the physical network, rather than routed through the Docker host&#x27;s network stack. See <a href="https://docs.docker.com/network/macvlan/">Macvlan networks</a>.</li><li>none: For this container, disable all networking. Usually used in conjunction with a custom network driver. none is not available for swarm services. See <a href="https://docs.docker.com/network/none/">disable container networking</a>.</li><li><a href="https://docs.docker.com/engine/extend/plugins_services/">Network plugins</a>: You can install and use third-party network plugins with Docker. These plugins are available from <a href="https://store.docker.com/search?category=network&amp;q=&amp;type=plugin">Docker Store</a> or from third-party vendors. See the vendor&#x27;s documentation for installing and using a given network plugin.</li></ul><h4>Network driver summary</h4><ul><li><strong>User-defined bridge networks</strong> are best when you need multiple containers to communicate on the same Docker host.</li><li><strong>Host networks</strong> are best when the network stack should not be isolated from the Docker host, but you want other aspects of the container to be isolated.</li><li><strong>Overlay networks</strong> are best when you need containers running on different Docker hosts to communicate, or when multiple applications work together using swarm services.</li><li><strong>Macvlan networks</strong> are best when you are migrating from a VM setup or need your containers to look like physical hosts on your network, each with a unique MAC address.</li><li><strong>Third-party network plugins</strong> allow you to integrate Docker with specialized network stacks.</li></ul><h3>Docker EE networking features</h3><p>The following two features are only possible when using Docker EE and managing your Docker services using Universal Control Plane (UCP):</p><ul><li>The <a href="https://docs.docker.com/datacenter/ucp/2.2/guides/admin/configure/use-domain-names-to-access-services/">HTTP routing mesh</a> allows you to share the same network IP address and port among multiple services. UCP routes the traffic to the appropriate service using the combination of hostname and port, as requested from the client.</li><li><a href="https://docs.docker.com/datacenter/ucp/2.2/guides/user/services/use-domain-names-to-access-services/#sticky-sessions">Session stickiness</a> allows you to specify information in the HTTP header which UCP uses to route subsequent requests to the same service task, for applications which require stateful sessions.</li></ul><h3>Networking tutorials</h3><p>Now that you understand the basics about Docker networks, deepen your understanding using the following tutorials:</p><ul><li><a href="https://docs.docker.com/network/network-tutorial-standalone/">Standalone networking tutorial</a></li><li><a href="https://docs.docker.com/network/network-tutorial-host/">Host networking tutorial</a></li><li><a href="https://docs.docker.com/network/network-tutorial-overlay/">Overlay networking tutorial</a></li><li><a href="https://docs.docker.com/network/network-tutorial-macvlan/">Macvlan networking tutorial</a></li></ul><h2>Use bridge networks</h2><p><em>Estimated reading time: 9 minutes</em></p><p>In terms of networking, a bridge network is a Link Layer device which forwards traffic between network segments. A bridge can be a hardware device or a software device running within a host machine&#x27;s kernel.</p><p>In terms of Docker, a bridge network uses a software bridge which allows containers connected to the same bridge network to communicate, while providing isolation from containers which are not connected to that bridge network. The Docker bridge driver automatically installs rules in the host machine so that containers on different bridge networks cannot communicate directly with each other.</p><p>Bridge networks apply to containers running on the <strong>same</strong> Docker daemon host. For communication among containers running on different Docker daemon hosts, you can either manage routing at the OS level, or you can use an <a href="https://docs.docker.com/network/overlay/">overlay network</a>.</p><p>When you start Docker, a <a href="https://docs.docker.com/network/bridge/#use-the-default-bridge-network">default bridge network</a> (also called bridge) is created automatically, and newly-started containers connect to it unless otherwise specified. You can also create user-defined custom bridge networks. <strong>User-defined bridge networks are superior to the default bridge network.</strong></p><h3>Differences between user-defined bridges and the default bridge</h3><ul><li><strong>User-defined bridges provide better isolation and interoperability between containerized applications</strong>.</li></ul><p>Containers connected to the same user-defined bridge network automatically expose <strong>all ports</strong> to each other, and <strong>no ports</strong> to the outside world. This allows containerized applications to communicate with each other easily, without accidentally opening access to the outside world.</p><p>Imagine an application with a web front-end and a database back-end. The outside world needs access to the web front-end (perhaps on port 80), but only the front-end itself needs access to the database host and port. Using a user-defined bridge, only the web port needs to be opened, and the database application doesn&#x27;t need any ports open, since the web front-end can reach it over the user-defined bridge.</p><p>If you run the same application stack on the default bridge network, you need to open both the web port and the database port, using the -p or --publish flag for each. This means the Docker host needs to block access to the database port by other means.</p><ul><li><strong>User-defined bridges provide automatic DNS resolution between containers</strong>.</li></ul><p>Containers on the default bridge network can only access each other by IP addresses, unless you use the <a href="https://docs.docker.com/network/links/">--link option</a>, which is considered legacy. On a user-defined bridge network, containers can resolve each other by name or alias.</p><p>Imagine the same application as in the previous point, with a web front-end and a database back-end. If you call your containers web and db, the web container can connect to the db container at db, no matter which Docker host the application stack is running on.</p><p>If you run the same application stack on the default bridge network, you need to manually create links between the containers (using the legacy --link flag). These links need to be created in both directions, so you can see this gets complex with more than two containers which need to communicate. Alternatively, you can manipulate the /etc/hosts files within the containers, but this creates problems that are difficult to debug.</p><ul><li><strong>Containers can be attached and detached from user-defined networks on the fly</strong>.</li></ul><p>During a container&#x27;s lifetime, you can connect or disconnect it from user-defined networks on the fly. To remove a container from the default bridge network, you need to stop the container and recreate it with different network options.</p><ul><li><strong>Each user-defined network creates a configurable bridge</strong>.</li></ul><p>If your containers use the default bridge network, you can configure it, but all the containers use the same settings, such as MTU and iptables rules. In addition, configuring the default bridge network happens outside of Docker itself, and requires a restart of Docker.</p><p>User-defined bridge networks are created and configured using docker network create. If different groups of applications have different network requirements, you can configure each user-defined bridge separately, as you create it.</p><ul><li><strong>Linked containers on the default bridge network share environment variables</strong>.</li></ul><p>Originally, the only way to share environment variables between two containers was to link them using the <a href="https://docs.docker.com/network/links/">--link flag</a>. This type of variable sharing is not possible with user-defined networks. However, there are superior ways to share environment variables. A few ideas:</p><ul><li><ul><li>Multiple containers can mount a file or directory containing the shared information, using a Docker volume.</li><li>Multiple containers can be started together using docker-compose and the compose file can define the shared variables.</li><li>You can use swarm services instead of standalone containers, and take advantage of shared <a href="https://docs.docker.com/engine/swarm/secrets/">secrets</a> and <a href="https://docs.docker.com/engine/swarm/configs/">configs</a>.</li></ul></li></ul><p>Containers connected to the same user-defined bridge network effectively expose all ports to each other. For a port to be accessible to containers or non-Docker hosts on different networks, that port must be published using the -p or --publish flag.</p><h3>Manage a user-defined bridge</h3><p>Use the docker network create command to create a user-defined bridge network.</p><p>$ docker network create my-net</p><p>You can specify the subnet, the IP address range, the gateway, and other options. See the <a href="https://docs.docker.com/engine/reference/commandline/network_create/#specify-advanced-options">docker network create</a> reference or the output of docker network create --help for details.</p><p>Use the docker network rm command to remove a user-defined bridge network. If containers are currently connected to the network, <a href="https://docs.docker.com/network/bridge/#disconnect-a-container-from-a-user-defined-bridge">disconnect them</a> first.</p><p>$ docker network rm my-net</p><p><strong>What&#x27;s really happening?</strong></p><p>When you create or remove a user-defined bridge or connect or disconnect a container from a user-defined bridge, Docker uses tools specific to the operating system to manage the underlying network infrastructure (such as adding or removing bridge devices or configuring iptables rules on Linux). These details should be considered implementation details. Let Docker manage your user-defined networks for you.</p><h3>Connect a container to a user-defined bridge</h3><p>When you create a new container, you can specify one or more --network flags. This example connects a Nginx container to the my-net network. It also publishes port 80 in the container to port 8080 on the Docker host, so external clients can access that port. Any other container connected to the my-net network has access to all ports on the my-nginx container, and vice versa.</p><p>$ docker create --name my-nginx \</p><p>--network my-net \</p><p>--publish 8080:80 \</p><p>nginx:latest</p><p>To connect a <strong>running</strong> container to an existing user-defined bridge, use the docker network connectcommand. The following command connects an already-running my-nginx container to an already-existing my-net network:</p><p>$ docker network connect my-net my-nginx</p><h3>Disconnect a container from a user-defined bridge</h3><p>To disconnect a running container from a user-defined bridge, use the docker network disconnectcommand. The following command disconnects the my-nginx container from the my-net network.</p><p>$ docker network disconnect my-net my-nginx</p><h3>Use IPv6</h3><p>If you need IPv6 support for Docker containers, you need to <a href="https://docs.docker.com/config/daemon/ipv6/">enable the option</a> on the Docker daemon and reload its configuration, before creating any IPv6 networks or assigning containers IPv6 addresses.</p><p>When you create your network, you can specify the --ipv6 flag to enable IPv6. You can&#x27;t selectively disable IPv6 support on the default bridge network.</p><h3>Enable forwarding from Docker containers to the outside world</h3><p>By default, traffic from containers connected to the default bridge network is <strong>not</strong> forwarded to the outside world. To enable forwarding, you need to change two settings. These are not Docker commands and they affect the Docker host&#x27;s kernel.</p><ol><li>Configure the Linux kernel to allow IP forwarding.</li><li>$ sysctl net.ipv4.conf.all.forwarding=1</li><li>Change the policy for the iptables FORWARD policy from DROP to ACCEPT.</li><li>$ sudo iptables -P FORWARD ACCEPT</li></ol><p>These settings do not persist across a reboot, so you may need to add them to a start-up script.</p><h3>Use the default bridge network</h3><p>The default bridge network is considered a legacy detail of Docker and is not recommended for production use. Configuring it is a manual operation, and it has <a href="https://docs.docker.com/network/bridge/#differences-between-user-defined-bridges-and-the-default-bridge">technical shortcomings</a>.</p><h4>Connect a container to the default bridge network</h4><p>If you do not specify a network using the --network flag, and you do specify a network driver, your container is connected to the default bridge network by default. Containers connected to the default bridge network can communicate, but only by IP address, unless they are linked using the <a href="https://docs.docker.com/network/links/">legacy --link flag</a>.</p><h4>Configure the default bridge network</h4><p>To configure the default bridge network, you specify options in daemon.json. Here is an example daemon.json with several options specified. Only specify the settings you need to customize.</p><p>{</p><p>&quot;bip&quot;: &quot;192.168.1.5/24&quot;,</p><p>&quot;fixed-cidr&quot;: &quot;192.168.1.5/25&quot;,</p><p>&quot;fixed-cidr-v6&quot;: &quot;2001:db8::/64&quot;,</p><p>&quot;mtu&quot;: 1500,</p><p>&quot;default-gateway&quot;: &quot;10.20.1.1&quot;,</p><p>&quot;default-gateway-v6&quot;: &quot;2001:db8:abcd::89&quot;,</p><p>&quot;dns&quot;: <!-- -->[&quot;10.20.1.2&quot;,&quot;10.20.1.3&quot;]</p><p>}</p><p>Restart Docker for the changes to take effect.</p><h4>Use IPv6 with the default bridge network</h4><p>If you configure Docker for IPv6 support (see <a href="https://docs.docker.com/network/bridge/#use-ipv6">Use IPv6</a>), the default bridge network is also configured for IPv6 automatically. Unlike user-defined bridges, you can&#x27;t selectively disable IPv6 on the default bridge.</p><h3>Next steps</h3><ul><li>Go through the <a href="https://docs.docker.com/network/network-tutorial-standalone/">standalone networking tutorial</a></li><li>Learn about <a href="https://docs.docker.com/config/container/container-networking/">networking from the container&#x27;s point of view</a></li><li>Learn about <a href="https://docs.docker.com/network/overlay/">overlay networks</a></li><li>Learn about <a href="https://docs.docker.com/network/macvlan/">Macvlan networks</a></li></ul><h2>Use overlay networks</h2><p><em>Estimated reading time: 10 minutes</em></p><p>The overlay network driver creates a distributed network among multiple Docker daemon hosts. This network sits on top of (overlays) the host-specific networks allows containers connected to it (including swarm service containers) to communicate securely. Docker transparently handles routing of each packet to and from the correct Docker daemon host and the correct destination container.</p><p>When you initialize a swarm or join a Docker host to an existing swarm, two new networks are created on that Docker host:</p><ul><li>an overlay network called ingress, which handles control and data traffic related to swarm services. When you create a swarm service and do not connect it to a user-defined overlay network, it connects to the ingress network by default.</li><li>a bridge network called docker_gwbridge, which connects the individual Docker daemon to the other daemons participating in the swarm.</li></ul><p>You can create user-defined overlay networks using docker network create, in the same way that you can create user-defined bridge networks. Services or containers can be connected to more than one network at a time. Services or containers can only communicate across networks they are each connected to.</p><p>Although you can connect both swarm services and standalone containers to an overlay network, the default behaviors and configuration concerns are different. For that reason, the rest of this topic is divided into operations that apply to all overlay networks, those that apply to swarm service networks, and those that apply to overlay networks used by standalone containers.</p><h3>Operations for all overlay networks</h3><h4>Create an overlay network</h4><p><strong>Prerequisites:</strong></p><ul><li>Firewall rules for Docker daemons using overlay networks</li></ul><p>You need the following ports open to traffic to and from each Docker host participating on an overlay network:</p><ul><li><ul><li>TCP port 2377 for cluster management communications</li><li>TCP and UDP port 7946 for communication among nodes</li><li>UDP port 4789 for overlay network traffic</li></ul></li><li><p>Before you can create an overlay network, you need to either initialize your Docker daemon as a swarm manager using docker swarm init or join it to an existing swarm using docker swarm join. Either of these creates the default ingress overlay network which is used by swarm services by default. You need to do this even if you never plan to use swarm services. Afterward, you can create additional user-defined overlay networks.</p></li></ul><p>To create an overlay network for use with swarm services, use a command like the following:</p><p>$ docker network create -d overlay my-overlay</p><p>To create an overlay network which can be used by swarm services <strong>or</strong> standalone containers to communicate with other standalone containers running on other Docker daemons, add the --attachable flag:</p><p>$ docker network create -d overlay --attachable my-attachable-overlay</p><p>You can specify the IP address range, subnet, gateway, and other options. Seedocker network create --help for details.</p><h4>Encrypt traffic on an overlay network</h4><p>All swarm service management traffic is encrypted by default, using the <a href="https://en.wikipedia.org/wiki/Galois/Counter_Mode">AES algorithm</a> in GCM mode. Manager nodes in the swarm rotate the key used to encrypt gossip data every 12 hours.</p><p>To encrypt application data as well, add --opt encrypted when creating the overlay network. This enables IPSEC encryption at the level of the vxlan. This encryption imposes a non-negligible performance penalty, so you should test this option before using it in production.</p><p>When you enable overlay encryption, Docker creates IPSEC tunnels between all the nodes where tasks are scheduled for services attached to the overlay network. These tunnels also use the AES algorithm in GCM mode and manager nodes automatically rotate the keys every 12 hours.</p><p><strong>Do not attach Windows nodes to encrypted overlay networks.</strong></p><p>Overlay network encryption is not supported on Windows. If a Windows node attempts to connect to an encrypted overlay network, no error is detected but the node cannot communicate.</p><h5><strong>SWARM MODE OVERLAY NETWORKS AND STANDALONE CONTAINERS</strong></h5><p>You can use the overlay network feature with both --opt encrypted --attachable and attach unmanaged containers to that network:</p><p>$ docker network create --opt encrypted --driver overlay --attachable my-attachable-multi-host-network</p><h4>Customize the default ingress network</h4><p>Most users never need to configure the ingress network, but Docker 17.05 and higher allow you to do so. This can be useful if the automatically-chosen subnet conflicts with one that already exists on your network, or you need to customize other low-level network settings such as the MTU.</p><p>Customizing the ingress network involves removing and recreating it. This is usually done before you create any services in the swarm. If you have existing services which publish ports, those services need to be removed before you can remove the ingress network.</p><p>During the time that no ingress network exists, existing services which do not publish ports continue to function but are not load-balanced. This affects services which publish ports, such as a WordPress service which publishes port 80.</p><ol><li>Inspect the ingress network using docker network inspect ingress, and remove any services whose containers are connected to it. These are services that publish ports, such as a WordPress service which publishes port 80. If all such services are not stopped, the next step fails.</li><li>Remove the existing ingress network:</li><li>$ docker network rm ingress</li><li>WARNING! Before removing the routing-mesh network, make sure all the nodes</li><li>in your swarm run the same docker engine version. Otherwise, removal may not</li><li>be effective and functionality of newly created ingress networks will be</li><li>impaired.</li><li>Are you sure you want to continue? <!-- -->[y/N]</li><li>Create a new overlay network using the --ingress flag, along with the custom options you want to set. This example sets the MTU to 1200, sets the subnet to 10.11.0.0/16, and sets the gateway to 10.11.0.2.</li><li>$ docker network create \</li><li>--driver overlay \</li><li>--ingress \</li><li>--subnet=10.11.0.0/16 \</li><li>--gateway=10.11.0.2 \</li><li>--opt com.docker.network.mtu=1200 \</li><li>my-ingress</li></ol><p><strong>Note</strong>: You can name your ingress network something other than ingress, but you can only have one. An attempt to create a second one fails.</p><ol><li>Restart the services that you stopped in the first step.</li></ol><h4>Customize the docker_gwbridge interface</h4><p>The docker_gwbridge is a virtual bridge that connects the overlay networks (including the ingressnetwork) to an individual Docker daemon&#x27;s physical network. Docker creates it automatically when you initialize a swarm or join a Docker host to a swarm, but it is not a Docker device. It exists in the kernel of the Docker host. If you need to customize its settings, you must do so before joining the Docker host to the swarm, or after temporarily removing the host from the swarm.</p><ol><li>Stop Docker.</li><li>Delete the existing docker_gwbridge interface.</li><li>$ sudo ip link set docker_gwbridge down</li><li>$ sudo ip link del name docker_gwbridge</li><li>Start Docker. Do not join or initialize the swarm.</li><li>Create or re-create the docker_gwbridge bridge manually with your custom settings, using the docker network create command. This example uses the subnet 10.11.0.0/16. For a full list of customizable options, see <a href="https://docs.docker.com/engine/reference/commandline/network_create/#bridge-driver-options">Bridge driver options</a>.</li><li>$ docker network create \</li><li>--subnet 10.11.0.0/16 \</li><li>--opt com.docker.network.bridge.name=docker_gwbridge \</li><li>--opt com.docker.network.bridge.enable_icc=false \</li><li>--opt com.docker.network.bridge.enable_ip_masquerade=true \</li><li>docker_gwbridge</li><li>Initialize or join the swarm. Since the bridge already exists, Docker does not create it with automatic settings.</li></ol><h3>Operations for swarm services</h3><h4>Publish ports on an overlay network</h4><p>Swarm services connected to the same overlay network effectively expose all ports to each other. For a port to be accessible outside of the service, that port must be published using the -p or --publishflag on docker service create or docker service update. Both the legacy colon-separated syntax and the newer comma-separated value syntax are supported. The longer syntax is preferred because it is somewhat self-documenting.</p><p>+-----------------------------------+-----------------------------------+
| <strong>Flag value</strong>                    | <strong>Description</strong>                   |
+===================================+===================================+
| -p 8080:80 or\                    | Map TCP port 80 on the service to |
| -p published=8080,target=80       | port 8080 on the routing mesh.    |
+-----------------------------------+-----------------------------------+
| -p 8080:80/udp or\                | Map UDP port 80 on the service to |
| -p                                | port 8080 on the routing mesh.    |
| publ                              |                                   |
| ished=8080,target=80,protocol=udp |                                   |
+-----------------------------------+-----------------------------------+
| -p 8080:80/tcp -p                 | Map TCP port 80 on the service to |
| 8080:80/udp or \                  | TCP port 8080 on the routing      |
| -p                                | mesh, and map UDP port 80 on the  |
| publ                              | service to UDP port 8080 on the   |
| ished=8080,target=80,protocol=tcp | routine mesh.                     |
| -p                                |                                   |
| publ                              |                                   |
| ished=8080,target=80,protocol=udp |                                   |
+-----------------------------------+-----------------------------------+</p><h4>Bypass the routing mesh for a swarm service</h4><p>By default, swarm services which publish ports do so using the routing mesh. When you connect to a published port on any swarm node (whether it is running a given service or not), you are redirected to a worker which is running that service, transparently. Effectively, Docker acts as a load balancer for your swarm services. Services using the routing mesh are running in virtual IP (VIP) mode. Even a service running on each node (by means of the --global flag) uses the routing mesh. When using the routing mesh, there is no guarantee about which Docker node services client requests.</p><p>To bypass the routing mesh, you can start a service using DNS Round Robin (DNSRR) mode, by setting the --endpoint-mode flag to dnsrr. You must run your own load balancer in front of the service. A DNS query for the service name on the Docker host returns a list of IP addresses for the nodes running the service. Configure your load balancer to consume this list and balance the traffic across the nodes.</p><h4>Separate control and data traffic</h4><p>By default, control traffic relating to swarm management and traffic to and from your applications runs over the same network, though the swarm control traffic is encrypted. You can configure Docker to use separate network interfaces for handling the two different types of traffic. When you initialize or join the swarm, specify --advertise-addr and --datapath-addr separately. You must do this for each node joining the swarm.</p><h3>Operations for standalone containers on overlay networks</h3><h4>Attach a standalone container to an overlay network</h4><p>The ingress network is create without the --attachable flag, which means that only swarm services can use it, and not standalone containers. You can connect standalone containers to user-defined overlay networks which are created with the --attachable flag. This gives standalone containers running on different Docker daemons the ability to communicate without the need to set up routing on the individual Docker daemon hosts.</p><h4>Publish ports</h4><p>  <strong>Flag value</strong>                  <strong>Description</strong></p><hr/><p>  -p 8080:80                      Map TCP port 80 in the container to port 8080 on the overlay network.
-p 8080:80/udp                  Map UDP port 80 in the container to port 8080 on the overlay network.
-p 8080:80/tcp -p 8080:80/udp   Map TCP port 80 in the container to TCP port 8080 on the overlay network, and map UDP port 80 in the container to UDP port 8080 on the overlay networkt.</p><h3>Next steps</h3><ul><li>Go through the <a href="https://docs.docker.com/network/network-tutorial-overlay/">overlay networking tutorial</a></li><li>Learn about <a href="https://docs.docker.com/config/containers/container-networking/">networking from the container&#x27;s point of view</a></li><li>Learn about <a href="https://docs.docker.com/network/bridge/">standalone bridge networks</a></li><li>Learn about <a href="https://docs.docker.com/network/macvlan/">Macvlan networks</a></li></ul><h2>Use host networking</h2><p><em>Estimated reading time: 1 minute</em></p><p>If you use the host network driver for a container, that container&#x27;s network stack is not isolated from the Docker host. For instance, if you run a container which binds to port 80 and you use hostnetworking, the container&#x27;s application will be available on port 80 on the host&#x27;s IP address.</p><p>In Docker 17.06 and higher, you can also use a host network for a swarm service, by passing --network host to the docker container create command. In this case, control traffic (traffic related to managing the swarm and the service) is still sent across an overlay network, but the individual swarm service containers send data using the Docker daemon&#x27;s host network and ports. This creates some extra limitations. For instance, if a service container binds to port 80, only one service container can run on a given swarm node.</p><p>If your container or service publishes no ports, host networking has no effect.</p><h3>Next steps</h3><ul><li>Go through the <a href="https://docs.docker.com/network/network-tutorial-host/">host networking tutorial</a></li><li>Learn about <a href="https://docs.docker.com/config/containers/container-networking/">networking from the container&#x27;s point of view</a></li><li>Learn about <a href="https://docs.docker.com/network/bridge/">bridge networks</a></li><li>Learn about <a href="https://docs.docker.com/network/overlay/">overlay networks</a></li><li>Learn about <a href="https://docs.docker.com/network/macvlan/">Macvlan networks</a></li></ul><h2>Use Macvlan networks</h2><p><em>Estimated reading time: 3 minutes</em></p><p>Some applications, especially legacy applications or applications which monitor network traffic, expect to be directly connected to the physical network. In this type of situation, you can use the macvlannetwork driver to assign a MAC address to each container&#x27;s virtual network interface, making it appear to be a physical network interface directly connected to the physical network. In this case, you need to designate a physical interface on your Docker host to use for the Macvlan, as well as the subnet and gateway of the Macvlan. You can even isolate your Macvlan networks using different physical network interfaces. Keep the following things in mind:</p><ul><li>It is very easy to unintentionally damage your network due IP address exhaustion or to &quot;VLAN spread&quot;, which is a situation in which you have an inappropriately large number of unique MAC addresses in your network.</li><li>Your networking equipment needs to be able to handle &quot;promiscuous mode&quot;, where one physical interface can be assigned multiple MAC addresses.</li><li>If your application can work using a bridge (on a single Docker host) or overlay (to communicate across multiple Docker hosts), these solutions may be better in the long term.</li></ul><h3>Create a macvlan network</h3><p>When you create a Macvlan network, it can either be in bridge mode or 802.1q trunk bridge mode.</p><ul><li>In bridge mode,Macvlan traffic goes through a physical device on the host.</li><li>In 802.1q trunk bridge mode, traffic goes through an 802.1q sub-interface which Docker creates on the fly. This allows you to control routing and filtering at a more granular level.</li></ul><h4>Bridge mode</h4><p>To create a Macvlan network which bridges with a given physical network interface, use --driver macvlan with the docker network create command. You also need to specify the parent, which is the interface the traffic will physically go through on the Docker host.</p><p>$ docker network create -d macvlan \</p><p>--subnet=172.16.86.0/24 \</p><p>--gateway=172.16.86.1 \</p><p>-o parent=eth0 pub_net</p><p>If you need to exclude IP addresses from being used in the Macvlan network, such as when a given IP address is already in use, use --aux-addresses:</p><p>$ docker network create -d macvlan \</p><p>--subnet=192.168.32.0/24 \</p><p>--ip-range=192.168.32.128/25 \</p><p>--gateway=192.168.32.254 \</p><p>-o parent=eth0 macnet32</p><h4>802.1q trunk bridge mode</h4><p>If you specify a parent interface name with a dot included, such as eth0.50, Docker interprets that as a sub-interface of eth0 and creates the sub-interface automatically.</p><p>$ docker network create -d macvlan \</p><p>--subnet=192.168.50.0/24 \</p><p>--gateway=192.168.50.1 \</p><p>-o parent=eth0.50 macvlan50</p><h4>Use an ipvlan instead of macvlan</h4><p>In the above example, you are still using a L3 bridge. You can use ipvlan instead, and get an L2 bridge. Specify -o ipvlan_mode=l2.</p><p>$ docker network create -d ipvlan \</p><p>--subnet=192.168.210.0/24 \</p><p>--subnet=192.168.212.0/24 \</p><p>--gateway=192.168.210.254 \</p><p>--gateway=192.168.212.254 \</p><p>-o ipvlan_mode=l2 ipvlan210</p><h3>Use IPv6</h3><p>If you have <a href="https://docs.docker.com/config/daemon/ipv6/">configured the Docker daemon to allow IPv6</a>, you can use dual-stack IPv4/IPv6 Macvlan networks.</p><p>$ docker network create -d macvlan \</p><p>--subnet=192.168.216.0/24 --subnet=192.168.218.0/24 \</p><p>--gateway=192.168.216.1 --gateway=192.168.218.1 \</p><p>--subnet=2001:db8:abc8::/64 --gateway=2001:db8:abc8::10 \</p><p>-o parent=eth0.218 \</p><p>-o macvlan_mode=bridge macvlan216</p><h3>Next steps</h3><ul><li>Go through the <a href="https://docs.docker.com/network/network-tutorial-macvlan/">macvlan networking tutorial</a></li><li>Learn about <a href="https://docs.docker.com/config/containers/container-networking/">networking from the container&#x27;s point of view</a></li><li>Learn about <a href="https://docs.docker.com/network/bridge/">bridge networks</a></li><li>Learn about <a href="https://docs.docker.com/network/overlay/">overlay networks</a></li><li>Learn about <a href="https://docs.docker.com/network/host/">host networking</a></li><li>Learn about <a href="https://docs.docker.com/network/macvlan/">Macvlan networks</a></li></ul><h2>Disable networking for a container</h2><p><em>Estimated reading time: 1 minute</em></p><p>If you want to completely disable the networking stack on a container, you can use the --network noneflag when starting the container. Within the container, only the loopback device is created. The following example illustrates this.</p><ol><li>Create the container.</li><li>$ docker run --rm -dit \</li><li>--network none \</li><li>--name no-net-alpine \</li><li>alpine:latest \</li><li>ash</li><li>Check the container&#x27;s network stack, by executing some common networking commands within the container. Notice that no eth0 was created.</li><li>$ docker exec no-net-alpine ip link show</li><li>1: lo: <code>&lt;LOOPBACK,UP,LOWER_UP&gt;</code> mtu 65536 qdisc noqueue state UNKNOWN qlen 1</li><li>link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</li><li>2: tunl0\@NONE: <code>&lt;NOARP&gt;</code> mtu 1480 qdisc noop state DOWN qlen 1</li><li>link/ipip 0.0.0.0 brd 0.0.0.0</li><li>3: ip6tnl0\@NONE: <code>&lt;NOARP&gt;</code> mtu 1452 qdisc noop state DOWN qlen 1</li><li>link/tunnel6 00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00 brd 00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00</li><li>$ docker exec no-net-alpine ip route</li></ol><p>The second command returns empty because there is no routing table.</p><ol><li>Stop the container. It is removed automatically because it was created with the --rm flag.</li><li>$ docker container rm no-net-alpine</li></ol><h3>Next steps</h3><ul><li>Go through the <a href="https://docs.docker.com/network/network-tutorial-host/">host networking tutorial</a></li><li>Learn about <a href="https://docs.docker.com/config/containers/container-networking/">networking from the container&#x27;s point of view</a></li><li>Learn about <a href="https://docs.docker.com/network/bridge/">bridge networks</a></li><li>Learn about <a href="https://docs.docker.com/network/overlay/">overlay networks</a></li><li>Learn about <a href="https://docs.docker.com/network/macvlan/">Macvlan networks</a></li></ul><h2>Networing Tutorials</h2><h3>Networking with standalone containers</h3><p><em>Estimated reading time: 18 minutes</em></p><p>This series of tutorials deals with networking for standalone Docker containers. For networking with swarm services, see <a href="https://docs.docker.com/network/network-tutorial-overlay/">Networking with swarm services</a>. If you need to learn more about Docker networking in general, see the <a href="https://docs.docker.com/network/">overview</a>.</p><p>This topic includes three different tutorials. You can run each of them on Linux, Windows, or a Mac, but for the last two, you need a second Docker host running elsewhere.</p><ul><li><a href="https://docs.docker.com/network/network-tutorial-standalone/#use-the-default-bridge-network">Use the default bridge network</a> demonstrates how to use the default bridge network that Docker sets up for you automatically. This network is not the best choice for production systems.</li><li><a href="https://docs.docker.com/network/network-tutorial-standalone/#use-user-defined-bridge-networks">Use user-defined bridge networks</a> shows how to create and use your own custom bridge networks, to connect containers running on the same Docker host. This is recommended for standalone containers running in production.</li></ul><p>Although <a href="https://docs.docker.com/network/overlay/">overlay networks</a> are generally used for swarm services, Docker 17.06 and higher allow you to use an overlay network for standalone containers. That&#x27;s covered as part of the <a href="https://docs.docker.com/network/network-tutorial-overlay/#use-an-overlay-network-for-standalone-containers">tutorial on using overlay networks</a>.</p><h4>Use the default bridge network</h4><p>In this example, you start two different alpine containers on the same Docker host and do some tests to understand how they communicate with each other. You need to have Docker installed and running.</p><ol><li>Open a terminal window. List current networks before you do anything else. Here&#x27;s what you should see if you&#x27;ve never added a network or initialized a swarm on this Docker daemon. You may see different networks, but you should at least see these (the network IDs will be different):</li><li>$ docker network ls</li><li>NETWORK ID NAME DRIVER SCOPE</li><li>17e324f45964 bridge bridge local</li><li>6ed54d316334 host host local</li><li>7092879f2cc8 none null local</li></ol><p>The default bridge network is listed, along with host and none. The latter two are not fully-fledged networks, but are used to start a container connected directly to the Docker daemon host&#x27;s networking stack, or to start a container with no network devices. <strong>This tutorial will connect two containers to the bridge network.</strong></p><ol><li>Start two alpine containers running ash, which is Alpine&#x27;s default shell rather than bash. The -dit flags mean to start the container detached (in the background), interactive (with the ability to type into it), and with a TTY (so you can see the input and output). Since you are starting it detached, you won&#x27;t be connected to the container right away. Instead, the container&#x27;s ID will be printed. Because you have not specified any --network flags, the containers connect to the default bridge network.</li><li>$ docker run -dit --name alpine1 alpine ash</li><li>$ docker run -dit --name alpine2 alpine ash</li></ol><p>Check that both containers are actually started:</p><p>$ docker container ls</p><p>CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES</p><p>602dbf1edc81 alpine &quot;ash&quot; 4 seconds ago Up 3 seconds alpine2</p><p>da33b7aa74b0 alpine &quot;ash&quot; 17 seconds ago Up 16 seconds alpine1</p><ol><li>Inspect the bridge network to see what containers are connected to it.</li><li>$ docker network inspect bridge</li><li>[</li><li>{</li><li>&quot;Name&quot;: &quot;bridge&quot;,</li><li>&quot;Id&quot;: &quot;17e324f459648a9baaea32b248d3884da102dde19396c25b30ec800068ce6b10&quot;,</li><li>&quot;Created&quot;: &quot;2017-06-22T20:27:43.826654485Z&quot;,</li><li>&quot;Scope&quot;: &quot;local&quot;,</li><li>&quot;Driver&quot;: &quot;bridge&quot;,</li><li>&quot;EnableIPv6&quot;: false,</li><li>&quot;IPAM&quot;: {</li><li>&quot;Driver&quot;: &quot;default&quot;,</li><li>&quot;Options&quot;: null,</li><li>&quot;Config&quot;: [</li><li>{</li><li>&quot;Subnet&quot;: &quot;172.17.0.0/16&quot;,</li><li>&quot;Gateway&quot;: &quot;172.17.0.1&quot;</li><li>}</li><li>]</li><li>},</li><li>&quot;Internal&quot;: false,</li><li>&quot;Attachable&quot;: false,</li><li>&quot;Containers&quot;: {</li><li>&quot;602dbf1edc81813304b6cf0a647e65333dc6fe6ee6ed572dc0f686a3307c6a2c&quot;: {</li><li>&quot;Name&quot;: &quot;alpine2&quot;,</li><li>&quot;EndpointID&quot;: &quot;03b6aafb7ca4d7e531e292901b43719c0e34cc7eef565b38a6bf84acf50f38cd&quot;,</li><li>&quot;MacAddress&quot;: &quot;02:42:ac:11:00:03&quot;,</li><li>&quot;IPv4Address&quot;: &quot;172.17.0.3/16&quot;,</li><li>&quot;IPv6Address&quot;: &quot;&quot;</li><li>},</li><li>&quot;da33b7aa74b0bf3bda3ebd502d404320ca112a268aafe05b4851d1e3312ed168&quot;: {</li><li>&quot;Name&quot;: &quot;alpine1&quot;,</li><li>&quot;EndpointID&quot;: &quot;46c044a645d6afc42ddd7857d19e9dcfb89ad790afb5c239a35ac0af5e8a5bc5&quot;,</li><li>&quot;MacAddress&quot;: &quot;02:42:ac:11:00:02&quot;,</li><li>&quot;IPv4Address&quot;: &quot;172.17.0.2/16&quot;,</li><li>&quot;IPv6Address&quot;: &quot;&quot;</li><li>}</li><li>},</li><li>&quot;Options&quot;: {</li><li>&quot;com.docker.network.bridge.default_bridge&quot;: &quot;true&quot;,</li><li>&quot;com.docker.network.bridge.enable_icc&quot;: &quot;true&quot;,</li><li>&quot;com.docker.network.bridge.enable_ip_masquerade&quot;: &quot;true&quot;,</li><li>&quot;com.docker.network.bridge.host_binding_ipv4&quot;: &quot;0.0.0.0&quot;,</li><li>&quot;com.docker.network.bridge.name&quot;: &quot;docker0&quot;,</li><li>&quot;com.docker.network.driver.mtu&quot;: &quot;1500&quot;</li><li>},</li><li>&quot;Labels&quot;: {}</li><li>}</li><li>]</li></ol><p>Near the top, information about the bridge network is listed, including the IP address of the gateway between the Docker host and the bridge network (172.17.0.1). Under the Containers key, each connected container is listed, along with information about its IP address (172.17.0.2 for alpine1 and 172.17.0.3 for alpine2).</p><ol><li>The containers are running in the background. Use the docker attach command to connect to alpine1.</li><li>$ docker attach alpine1</li><li>/ #</li></ol><p>The prompt changes to # to indicate that you are the root user within the container. Use the ip addr show command to show the network interfaces for alpine1 as they look from within the container:</p><h1>ip addr show</h1><p>1: lo: <code style="background-color:lightgray">&lt;LOOPBACK,UP,LOWER_UP&gt;</code> mtu 65536 qdisc noqueue state UNKNOWN qlen 1</p><p>link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</p><p>inet 127.0.0.1/8 scope host lo</p><p>valid_lft forever preferred_lft forever</p><p>inet6 ::1/128 scope host</p><p>valid_lft forever preferred_lft forever</p><p>27: eth0\@if28: <code style="background-color:lightgray">&lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt;</code> mtu 1500 qdisc noqueue state UP</p><p>link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff</p><p>inet 172.17.0.2/16 scope global eth0</p><p>valid_lft forever preferred_lft forever</p><p>inet6 fe80::42:acff:fe11:2/64 scope link</p><p>valid_lft forever preferred_lft forever</p><p>The first interface is the loopback device. Ignore it for now. Notice that the second interface has the IP address 172.17.0.2, which is the same address shown for alpine1 in the previous step.</p><ol><li>From within alpine1, make sure you can connect to the internet by pinging google.com. The -c 2 flag limits the command to two ping attempts.</li><li><h1>ping -c 2 google.com</h1></li><li>PING google.com (172.217.3.174): 56 data bytes</li><li>64 bytes from 172.217.3.174: seq=0 ttl=41 time=9.841 ms</li><li>64 bytes from 172.217.3.174: seq=1 ttl=41 time=9.897 ms</li><li>--- google.com ping statistics ---</li><li>2 packets transmitted, 2 packets received, 0% packet loss</li><li>round-trip min/avg/max = 9.841/9.869/9.897 ms</li><li>Now try to ping the second container. First, ping it by its IP address, 172.17.0.3:</li><li><h1>ping -c 2 172.17.0.3</h1></li><li>PING 172.17.0.3 (172.17.0.3): 56 data bytes</li><li>64 bytes from 172.17.0.3: seq=0 ttl=64 time=0.086 ms</li><li>64 bytes from 172.17.0.3: seq=1 ttl=64 time=0.094 ms</li><li>--- 172.17.0.3 ping statistics ---</li><li>2 packets transmitted, 2 packets received, 0% packet loss</li><li>round-trip min/avg/max = 0.086/0.090/0.094 ms</li></ol><p>This succeeds. Next, try pinging the alpine2 container by container name. This will fail.</p><h1>ping -c 2 alpine2</h1><p>ping: bad address \&#x27;alpine2\&#x27;</p><ol><li>Detach from alpine1 without stopping it by using the detach sequence, CTRL + p CTRL + q (hold down CTRL and type p followed by q). If you wish, attach to alpine2 and repeat steps 4, 5, and 6 there, substituting alpine1 for alpine2.</li><li>Stop and remove both containers.</li><li>$ docker container stop alpine1 alpine2</li><li>$ docker container rm alpine1 alpine2</li></ol><p>Remember, the default bridge network is not recommended for production. To learn about user-defined bridge networks, continue to the <a href="https://docs.docker.com/network/network-tutorial-standalone/#use-user-defined-bridge-networks">next tutorial</a>.</p><h4>Use user-defined bridge networks</h4><p>In this example, we again start two alpine containers, but attach them to a user-defined network called alpine-net which we have already created. These containers are not connected to the default bridge network at all. We then start a third alpine container which is connected to the bridgenetwork but not connected to alpine-net, and a fourth alpine container which is connected to both networks.</p><ol><li>Create the alpine-net network. You do not need the --driver bridge flag since it&#x27;s the default, but this example shows how to specify it.</li><li>$ docker network create --driver bridge alpine-net</li><li>List Docker&#x27;s networks:</li><li>$ docker network ls</li><li>NETWORK ID NAME DRIVER SCOPE</li><li>e9261a8c9a19 alpine-net bridge local</li><li>17e324f45964 bridge bridge local</li><li>6ed54d316334 host host local</li><li>7092879f2cc8 none null local</li></ol><p>Inspect the alpine-net network. This shows you its IP address and the fact that no containers are connected to it:</p><p>$ docker network inspect alpine-net</p><p>[</p><p>{</p><p>&quot;Name&quot;: &quot;alpine-net&quot;,</p><p>&quot;Id&quot;: &quot;e9261a8c9a19eabf2bf1488bf5f208b99b1608f330cff585c273d39481c9b0ec&quot;,</p><p>&quot;Created&quot;: &quot;2017-09-25T21:38:12.620046142Z&quot;,</p><p>&quot;Scope&quot;: &quot;local&quot;,</p><p>&quot;Driver&quot;: &quot;bridge&quot;,</p><p>&quot;EnableIPv6&quot;: false,</p><p>&quot;IPAM&quot;: {</p><p>&quot;Driver&quot;: &quot;default&quot;,</p><p>&quot;Options&quot;: {},</p><p>&quot;Config&quot;: [</p><p>{</p><p>&quot;Subnet&quot;: &quot;172.18.0.0/16&quot;,</p><p>&quot;Gateway&quot;: &quot;172.18.0.1&quot;</p><p>}</p><p>]</p><p>},</p><p>&quot;Internal&quot;: false,</p><p>&quot;Attachable&quot;: false,</p><p>&quot;Containers&quot;: {},</p><p>&quot;Options&quot;: {},</p><p>&quot;Labels&quot;: {}</p><p>}</p><p>]</p><p>Notice that this network&#x27;s gateway is 172.18.0.1, as opposed to the default bridge network, whose gateway is 172.17.0.1. The exact IP address may be different on your system.</p><ol><li>Create your four containers. Notice the --network flags. You can only connect to one network during the docker run command, so you need to use docker network attach afterward to connect alpine4 to the bridge network as well.</li><li>$ docker run -dit --name alpine1 --network alpine-net alpine ash</li><li>$ docker run -dit --name alpine2 --network alpine-net alpine ash</li><li>$ docker run -dit --name alpine3 alpine ash</li><li>$ docker run -dit --name alpine4 --network alpine-net alpine ash</li><li>$ docker network connect bridge alpine4</li></ol><p>Verify that all containers are running:</p><p>$ docker container ls</p><p>CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES</p><p>156849ccd902 alpine &quot;ash&quot; 41 seconds ago Up 41 seconds alpine4</p><p>fa1340b8d83e alpine &quot;ash&quot; 51 seconds ago Up 51 seconds alpine3</p><p>a535d969081e alpine &quot;ash&quot; About a minute ago Up About a minute alpine2</p><p>0a02c449a6e9 alpine &quot;ash&quot; About a minute ago Up About a minute alpine1</p><ol><li>Inspect the bridge network and the alpine-net network again:</li><li>$ docker network inspect bridge</li><li>[</li><li>{</li><li>&quot;Name&quot;: &quot;bridge&quot;,</li><li>&quot;Id&quot;: &quot;17e324f459648a9baaea32b248d3884da102dde19396c25b30ec800068ce6b10&quot;,</li><li>&quot;Created&quot;: &quot;2017-06-22T20:27:43.826654485Z&quot;,</li><li>&quot;Scope&quot;: &quot;local&quot;,</li><li>&quot;Driver&quot;: &quot;bridge&quot;,</li><li>&quot;EnableIPv6&quot;: false,</li><li>&quot;IPAM&quot;: {</li><li>&quot;Driver&quot;: &quot;default&quot;,</li><li>&quot;Options&quot;: null,</li><li>&quot;Config&quot;: [</li><li>{</li><li>&quot;Subnet&quot;: &quot;172.17.0.0/16&quot;,</li><li>&quot;Gateway&quot;: &quot;172.17.0.1&quot;</li><li>}</li><li>]</li><li>},</li><li>&quot;Internal&quot;: false,</li><li>&quot;Attachable&quot;: false,</li><li>&quot;Containers&quot;: {</li><li>&quot;156849ccd902b812b7d17f05d2d81532ccebe5bf788c9a79de63e12bb92fc621&quot;: {</li><li>&quot;Name&quot;: &quot;alpine4&quot;,</li><li>&quot;EndpointID&quot;: &quot;7277c5183f0da5148b33d05f329371fce7befc5282d2619cfb23690b2adf467d&quot;,</li><li>&quot;MacAddress&quot;: &quot;02:42:ac:11:00:03&quot;,</li><li>&quot;IPv4Address&quot;: &quot;172.17.0.3/16&quot;,</li><li>&quot;IPv6Address&quot;: &quot;&quot;</li><li>},</li><li>&quot;fa1340b8d83eef5497166951184ad3691eb48678a3664608ec448a687b047c53&quot;: {</li><li>&quot;Name&quot;: &quot;alpine3&quot;,</li><li>&quot;EndpointID&quot;: &quot;5ae767367dcbebc712c02d49556285e888819d4da6b69d88cd1b0d52a83af95f&quot;,</li><li>&quot;MacAddress&quot;: &quot;02:42:ac:11:00:02&quot;,</li><li>&quot;IPv4Address&quot;: &quot;172.17.0.2/16&quot;,</li><li>&quot;IPv6Address&quot;: &quot;&quot;</li><li>}</li><li>},</li><li>&quot;Options&quot;: {</li><li>&quot;com.docker.network.bridge.default_bridge&quot;: &quot;true&quot;,</li><li>&quot;com.docker.network.bridge.enable_icc&quot;: &quot;true&quot;,</li><li>&quot;com.docker.network.bridge.enable_ip_masquerade&quot;: &quot;true&quot;,</li><li>&quot;com.docker.network.bridge.host_binding_ipv4&quot;: &quot;0.0.0.0&quot;,</li><li>&quot;com.docker.network.bridge.name&quot;: &quot;docker0&quot;,</li><li>&quot;com.docker.network.driver.mtu&quot;: &quot;1500&quot;</li><li>},</li><li>&quot;Labels&quot;: {}</li><li>}</li><li>]</li></ol><p>Containers alpine3 and alpine4 are connected to the bridge network.</p><p>$ docker network inspect alpine-net</p><p>[</p><p>{</p><p>&quot;Name&quot;: &quot;alpine-net&quot;,</p><p>&quot;Id&quot;: &quot;e9261a8c9a19eabf2bf1488bf5f208b99b1608f330cff585c273d39481c9b0ec&quot;,</p><p>&quot;Created&quot;: &quot;2017-09-25T21:38:12.620046142Z&quot;,</p><p>&quot;Scope&quot;: &quot;local&quot;,</p><p>&quot;Driver&quot;: &quot;bridge&quot;,</p><p>&quot;EnableIPv6&quot;: false,</p><p>&quot;IPAM&quot;: {</p><p>&quot;Driver&quot;: &quot;default&quot;,</p><p>&quot;Options&quot;: {},</p><p>&quot;Config&quot;: [</p><p>{</p><p>&quot;Subnet&quot;: &quot;172.18.0.0/16&quot;,</p><p>&quot;Gateway&quot;: &quot;172.18.0.1&quot;</p><p>}</p><p>]</p><p>},</p><p>&quot;Internal&quot;: false,</p><p>&quot;Attachable&quot;: false,</p><p>&quot;Containers&quot;: {</p><p>&quot;0a02c449a6e9a15113c51ab2681d72749548fb9f78fae4493e3b2e4e74199c4a&quot;: {</p><p>&quot;Name&quot;: &quot;alpine1&quot;,</p><p>&quot;EndpointID&quot;: &quot;c83621678eff9628f4e2d52baf82c49f974c36c05cba152db4c131e8e7a64673&quot;,</p><p>&quot;MacAddress&quot;: &quot;02:42:ac:12:00:02&quot;,</p><p>&quot;IPv4Address&quot;: &quot;172.18.0.2/16&quot;,</p><p>&quot;IPv6Address&quot;: &quot;&quot;</p><p>},</p><p>&quot;156849ccd902b812b7d17f05d2d81532ccebe5bf788c9a79de63e12bb92fc621&quot;: {</p><p>&quot;Name&quot;: &quot;alpine4&quot;,</p><p>&quot;EndpointID&quot;: &quot;058bc6a5e9272b532ef9a6ea6d7f3db4c37527ae2625d1cd1421580fd0731954&quot;,</p><p>&quot;MacAddress&quot;: &quot;02:42:ac:12:00:04&quot;,</p><p>&quot;IPv4Address&quot;: &quot;172.18.0.4/16&quot;,</p><p>&quot;IPv6Address&quot;: &quot;&quot;</p><p>},</p><p>&quot;a535d969081e003a149be8917631215616d9401edcb4d35d53f00e75ea1db653&quot;: {</p><p>&quot;Name&quot;: &quot;alpine2&quot;,</p><p>&quot;EndpointID&quot;: &quot;198f3141ccf2e7dba67bce358d7b71a07c5488e3867d8b7ad55a4c695ebb8740&quot;,</p><p>&quot;MacAddress&quot;: &quot;02:42:ac:12:00:03&quot;,</p><p>&quot;IPv4Address&quot;: &quot;172.18.0.3/16&quot;,</p><p>&quot;IPv6Address&quot;: &quot;&quot;</p><p>}</p><p>},</p><p>&quot;Options&quot;: {},</p><p>&quot;Labels&quot;: {}</p><p>}</p><p>]</p><p>Containers alpine1, alpine2, and alpine4 are connected to the alpine-net network.</p><ol><li>On user-defined networks like alpine-net, containers can not only communicate by IP address, but can also resolve a container name to an IP address. This capability is called <strong>automatic service discovery</strong>. Let&#x27;s connect to alpine1 and test this out. alpine1 should be able to resolvealpine2 and alpine4 (and alpine1, itself) to IP addresses.</li><li>$ docker container attach alpine1</li><li><h1>ping -c 2 alpine2</h1></li><li>PING alpine2 (172.18.0.3): 56 data bytes</li><li>64 bytes from 172.18.0.3: seq=0 ttl=64 time=0.085 ms</li><li>64 bytes from 172.18.0.3: seq=1 ttl=64 time=0.090 ms</li><li>--- alpine2 ping statistics ---</li><li>2 packets transmitted, 2 packets received, 0% packet loss</li><li>round-trip min/avg/max = 0.085/0.087/0.090 ms</li><li><h1>ping -c 2 alpine4</h1></li><li>PING alpine4 (172.18.0.4): 56 data bytes</li><li>64 bytes from 172.18.0.4: seq=0 ttl=64 time=0.076 ms</li><li>64 bytes from 172.18.0.4: seq=1 ttl=64 time=0.091 ms</li><li>--- alpine4 ping statistics ---</li><li>2 packets transmitted, 2 packets received, 0% packet loss</li><li>round-trip min/avg/max = 0.076/0.083/0.091 ms</li><li><h1>ping -c 2 alpine1</h1></li><li>PING alpine1 (172.18.0.2): 56 data bytes</li><li>64 bytes from 172.18.0.2: seq=0 ttl=64 time=0.026 ms</li><li>64 bytes from 172.18.0.2: seq=1 ttl=64 time=0.054 ms</li><li>--- alpine1 ping statistics ---</li><li>2 packets transmitted, 2 packets received, 0% packet loss</li><li>round-trip min/avg/max = 0.026/0.040/0.054 ms</li><li>From alpine1, you should not be able to connect to alpine3 at all, since it is not on the alpine-net network.</li><li><h1>ping -c 2 alpine3</h1></li><li>ping: bad address \&#x27;alpine3\&#x27;</li></ol><p>Not only that, but you can&#x27;t connect to alpine3 from alpine1 by its IP address either. Look back at the docker network inspect output for the bridge network and find alpine3&#x27;s IP address: 172.17.0.2 Try to ping it.</p><h1>ping -c 2 172.17.0.2</h1><p>PING 172.17.0.2 (172.17.0.2): 56 data bytes</p><p>--- 172.17.0.2 ping statistics ---</p><p>2 packets transmitted, 0 packets received, 100% packet loss</p><p>Detach from alpine1 using detach sequence, CTRL + p CTRL + q (hold down CTRL and type p followed by q).</p><ol><li>Remember that alpine4 is connected to both the default bridge network and alpine-net. It should be able to reach all of the other containers. However, you will need to address alpine3by its IP address. Attach to it and run the tests.</li><li>$ docker container attach alpine4</li><li><h1>ping -c 2 alpine1</h1></li><li>PING alpine1 (172.18.0.2): 56 data bytes</li><li>64 bytes from 172.18.0.2: seq=0 ttl=64 time=0.074 ms</li><li>64 bytes from 172.18.0.2: seq=1 ttl=64 time=0.082 ms</li><li>--- alpine1 ping statistics ---</li><li>2 packets transmitted, 2 packets received, 0% packet loss</li><li>round-trip min/avg/max = 0.074/0.078/0.082 ms</li><li><h1>ping -c 2 alpine2</h1></li><li>PING alpine2 (172.18.0.3): 56 data bytes</li><li>64 bytes from 172.18.0.3: seq=0 ttl=64 time=0.075 ms</li><li>64 bytes from 172.18.0.3: seq=1 ttl=64 time=0.080 ms</li><li>--- alpine2 ping statistics ---</li><li>2 packets transmitted, 2 packets received, 0% packet loss</li><li>round-trip min/avg/max = 0.075/0.077/0.080 ms</li><li><h1>ping -c 2 alpine3</h1></li><li>ping: bad address \&#x27;alpine3\&#x27;</li><li><h1>ping -c 2 172.17.0.2</h1></li><li>PING 172.17.0.2 (172.17.0.2): 56 data bytes</li><li>64 bytes from 172.17.0.2: seq=0 ttl=64 time=0.089 ms</li><li>64 bytes from 172.17.0.2: seq=1 ttl=64 time=0.075 ms</li><li>--- 172.17.0.2 ping statistics ---</li><li>2 packets transmitted, 2 packets received, 0% packet loss</li><li>round-trip min/avg/max = 0.075/0.082/0.089 ms</li><li><h1>ping -c 2 alpine4</h1></li><li>PING alpine4 (172.18.0.4): 56 data bytes</li><li>64 bytes from 172.18.0.4: seq=0 ttl=64 time=0.033 ms</li><li>64 bytes from 172.18.0.4: seq=1 ttl=64 time=0.064 ms</li><li>--- alpine4 ping statistics ---</li><li>2 packets transmitted, 2 packets received, 0% packet loss</li><li>round-trip min/avg/max = 0.033/0.048/0.064 ms</li><li>As a final test, make sure your containers can all connect to the internet by pinging google.com. You are already attached to alpine4 so start by trying from there. Next, detach from alpine4and connect to alpine3 (which is only attached to the bridge network) and try again. Finally, connect to alpine1 (which is only connected to the alpine-net network) and try again.</li><li><h1>ping -c 2 google.com</h1></li><li>PING google.com (172.217.3.174): 56 data bytes</li><li>64 bytes from 172.217.3.174: seq=0 ttl=41 time=9.778 ms</li><li>64 bytes from 172.217.3.174: seq=1 ttl=41 time=9.634 ms</li><li>--- google.com ping statistics ---</li><li>2 packets transmitted, 2 packets received, 0% packet loss</li><li>round-trip min/avg/max = 9.634/9.706/9.778 ms</li><li>CTRL+p CTRL+q</li><li>$ docker container attach alpine3</li><li><h1>ping -c 2 google.com</h1></li><li>PING google.com (172.217.3.174): 56 data bytes</li><li>64 bytes from 172.217.3.174: seq=0 ttl=41 time=9.706 ms</li><li>64 bytes from 172.217.3.174: seq=1 ttl=41 time=9.851 ms</li><li>--- google.com ping statistics ---</li><li>2 packets transmitted, 2 packets received, 0% packet loss</li><li>round-trip min/avg/max = 9.706/9.778/9.851 ms</li><li>CTRL+p CTRL+q</li><li>$ docker container attach alpine1</li><li><h1>ping -c 2 google.com</h1></li><li>PING google.com (172.217.3.174): 56 data bytes</li><li>64 bytes from 172.217.3.174: seq=0 ttl=41 time=9.606 ms</li><li>64 bytes from 172.217.3.174: seq=1 ttl=41 time=9.603 ms</li><li>--- google.com ping statistics ---</li><li>2 packets transmitted, 2 packets received, 0% packet loss</li><li>round-trip min/avg/max = 9.603/9.604/9.606 ms</li><li>CTRL+p CTRL+q</li><li>Stop and remove all containers and the alpine-net network.</li><li>$ docker container stop alpine1 alpine2 alpine3 alpine4</li><li>$ docker container rm alpine1 alpine2 alpine3 alpine4</li><li>$ docker network rm alpine-net</li></ol><h4>Other networking tutorials</h4><p>Now that you have completed the networking tutorials for standalone containers, you might want to run through these other networking tutorials:</p><ul><li><a href="https://docs.docker.com/network/network-tutorial-host/">Host networking tutorial</a></li><li><a href="https://docs.docker.com/network/network-tutorial-overlay/">Overlay networking tutorial</a></li><li><a href="https://docs.docker.com/network/network-tutorial-macvlan/">Macvlan networking tutorial</a></li></ul><h3>Networking using the host network</h3><p><em>Estimated reading time: 2 minutes</em></p><p>This series of tutorials deals with networking standalone containers which bind directly to the Docker host&#x27;s network, with no network isolation. For other networking topics, see the <a href="https://docs.docker.com/network/">overview</a>.</p><h4>Goal</h4><p>The goal of this tutorial is to start a nginx container which binds directly to port 80 on the Docker host. From a networking point of view, this is the same level of isolation as if the nginx process were running directly on the Docker host and not in a container. However, in all other ways, such as storage, process namespace, and user namespace, the nginx process is isolated from the host.</p><h4>Prerequisites</h4><ul><li>This procedure requires port 80 to be available on the Docker host. To make Nginx listen on a different port, see the <a href="https://hub.docker.com/_/nginx/">documentation for the nginx image</a></li><li>The host networking driver only works on Linux hosts, and is not supported on Docker for Mac, Docker for Windows, or Docker EE for Windows Server.</li></ul><h4>Procedure</h4><ol><li>Create and start the container as a detached process.</li><li>docker run --rm -itd --network host --name my_nginx nginx</li><li>Access Nginx by browsing to <a href="http://localhost/">http://localhost:80/</a>.</li><li>Examine your network stack using the following commands:<ul><li>Examine all network interfaces and verify that a new one was not created.</li><li>ip addr show</li><li>Verify which process is bound to port 80, using the netstat command. You need to use sudo because the process is owned by the Docker daemon user and you otherwise won&#x27;t be able to see its name or PID.</li><li>sudo netstat -tulpn | grep :80</li></ul></li><li>Stop the container.</li><li>docker container stop my_nginx</li><li>docker container rm my_nginx</li></ol><h4>Other networking tutorials</h4><p>Now that you have completed the networking tutorials for standalone containers, you might want to run through these other networking tutorials:</p><ul><li><a href="https://docs.docker.com/network/network-tutorial-standalone/">Standalone networking tutorial</a></li><li><a href="https://docs.docker.com/network/network-tutorial-overlay/">Overlay networking tutorial</a></li><li><a href="https://docs.docker.com/network/network-tutorial-macvlan/">Macvlan networking tutorial</a></li></ul><h3>Networking with overlay networks</h3><p><em>Estimated reading time: 21 minutes</em></p><p>This series of tutorials deals with networking for swarm services. For networking with standalone containers, see <a href="https://docs.docker.com/network/network-tutorial-standalone/">Networking with standalone containers</a>. If you need to learn more about Docker networking in general, see the <a href="https://docs.docker.com/network/">overview</a>.</p><p>This topic includes four different tutorials. You can run each of them on Linux, Windows, or a Mac, but for the last two, you need a second Docker host running elsewhere.</p><ul><li><a href="https://docs.docker.com/network/network-tutorial-overlay/#use-the-default-overlay-network">Use the default overlay network</a> demonstrates how to use the default overlay network that Docker sets up for you automatically when you initialize or join a swarm. This network is not the best choice for production systems.</li><li><a href="https://docs.docker.com/network/network-tutorial-overlay/#use-a-user-defined-overlay-network">Use user-defined overlay networks</a> shows how to create and use your own custom overlay networks, to connect services. This is recommended for services running in production.</li><li><a href="https://docs.docker.com/network/network-tutorial-overlay/#use-an-overlay-network-for-standalone-containers">Use an overlay network for standalone containers</a> shows how to communicate between standalone containers on different Docker daemons using an overlay network.</li><li><a href="https://docs.docker.com/network/network-tutorial-overlay/#communicate-between-a-container-and-a-swarm-service">Communicate between a container and a swarm service</a> sets up communication between a standalone container and a swarm service, using an attachable overlay network. This is supported in Docker 17.06 and higher.</li></ul><h4>Prerequisites</h4><p>These requires you to have at least a single-node swarm, which means that you have started Docker and run docker swarm init on the host. You can run the examples on a multi-node swarm as well.</p><p>The last example requires Docker 17.06 or higher.</p><h4>Use the default overlay network</h4><p>In this example, you start an alpine service and examine the characteristics of the network from the point of view of the individual service containers.</p><p>This tutorial does not go into operation-system-specific details about how overlay networks are implemented, but focuses on how the overlay functions from the point of view of a service.</p><h5><strong>Prerequisites</strong></h5><p>This tutorial requires three physical or virtual Docker hosts which can all communicate with one another, all running new installations of Docker 17.03 or higher. This tutorial assumes that the three hosts are running on the same network with no firewall involved.</p><p>These hosts will be referred to as manager, worker-1, and worker-2. The manager host will function as both a manager and a worker, which means it can both run service tasks and manage the swarm. worker-1 and worker-2 will function as workers only,</p><p>If you don&#x27;t have three hosts handy, an easy solution is to set up three Ubuntu hosts on a cloud provider such as Amazon EC2, all on the same network with all communications allowed to all hosts on that network (using a mechanism such as EC2 security groups), and then to follow the <a href="https://docs.docker.com/engine/installation/linux/docker-ce/ubuntu/">installation instructions for Docker CE on Ubuntu</a>.</p><h5><strong>Walkthrough</strong></h5><h6><strong>CREATE THE SWARM</strong></h6><p>At the end of this procedure, all three Docker hosts will be joined to the swarm and will be connected together using an overlay network called ingress.</p><ol><li>On master. initialize the swarm. If the host only has one network interface, the --advertise-addr flag is optional.</li><li>$ docker swarm init --advertise-addr=<code>&lt;IP-ADDRESS-OF-MANAGER&gt;</code></li></ol><p>Make a note of the text that is printed, as this contains the token that you will use to join worker-1 and worker-2 to the swarm. It is a good idea to store the token in a password manager.</p><ol><li>On worker-1, join the swarm. If the host only has one network interface, the --advertise-addrflag is optional.</li><li>$ docker swarm --join --token <code>&lt;TOKEN&gt;</code> \</li><li>--advertise-addr <code>&lt;IP-ADDRESS-OF-WORKER-1&gt;</code> \</li><li><code>&lt;IP-ADDRESS-OF-MANAGER&gt;</code>:2377</li><li>On worker-2, join the swarm. If the host only has one network interface, the --advertise-addrflag is optional.</li><li>$ docker swarm --join --token <code>&lt;TOKEN&gt;</code> \</li><li>--advertise-addr <code>&lt;IP-ADDRESS-OF-WORKER-2&gt;</code> \</li><li><code>&lt;IP-ADDRESS-OF-MANAGER&gt;</code>:2377</li><li>On manager, list all the nodes. This command can only be done from a manager.</li><li>$ docker node ls</li><li>ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS</li><li>d68ace5iraw6whp7llvgjpu48 * ip-172-31-34-146 Ready Active Leader</li><li>nvp5rwavvb8lhdggo8fcf7plg ip-172-31-35-151 Ready Active</li><li>ouvx2l7qfcxisoyms8mtkgahw ip-172-31-36-89 Ready Active</li></ol><p>You can also use the --filter flag to filter by role:</p><p>$ docker node ls --filter role=manager</p><p>ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS</p><p>d68ace5iraw6whp7llvgjpu48 * ip-172-31-34-146 Ready Active Leader</p><p>$ docker node ls --filter role=worker</p><p>ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS</p><p>nvp5rwavvb8lhdggo8fcf7plg ip-172-31-35-151 Ready Active</p><p>ouvx2l7qfcxisoyms8mtkgahw ip-172-31-36-89 Ready Active</p><ol><li>List the Docker networks on manager, worker-1, and worker-2 and notice that each of them now has an overlay network called ingress and a bridge network called docker_gwbridge. Only the listing for manager is shown here:</li><li>$ docker network ls</li><li>NETWORK ID NAME DRIVER SCOPE</li><li>495c570066be bridge bridge local</li><li>961c6cae9945 docker_gwbridge bridge local</li><li>ff35ceda3643 host host local</li><li>trtnl4tqnc3n ingress overlay swarm</li><li>c8357deec9cb none null local</li></ol><p>The docker_gwbridge connects the ingress network to the Docker host&#x27;s network interface so that traffic can flow to and from swarm managers and workers. If you create swarm services and do not specify a network, they are connected to the ingress network. It is recommended that you use separate overlay networks for each application or group of applications which will work together. In the next procedure, you will create two overlay networks and connect a service to each of them.</p><h6><strong>CREATE THE SERVICES</strong></h6><ol><li>On manager, create a new overlay network called nginx-net:</li><li>$ docker network create -d overlay nginx-net</li></ol><p>You don&#x27;t need to create the overlay network on the other nodes, beacause it will be automatically created when one of those nodes starts running a service task which requires it.</p><ol><li>On manager, create a 5-replica Nginx service connected to nginx-net. The service will publish port 80 to the outside world. All of the service task containers can communicate with each other without opening any ports.</li></ol><p><strong>Note</strong>: Services can only be created on a manager.</p><p>$ docker service create \</p><p>--name my-nginx \</p><p>--publish target=80,published=80 \</p><p>--replicas=5 \</p><p>--network nginx-net \</p><p>nginx</p><p>The default publish mode of ingress, which is used when you do not specify a mode for the --publish flag, means that if you browse to port 80 on manager, worker-1, or worker-2, you will be connected to port 80 on one of the 5 service tasks, even if no tasks are currently running on the node you browse to. If you want to publish the port using host mode, you can add mode=host to the --publish output. However, you should also use --mode global instead of --replicas=5 in this case, since only one service task can bind a given port on a given node.</p><ol><li>Run docker service ls to monitor the progress of service bring-up, which may take a few seconds.</li><li>Inspect the nginx-net network on master, worker-1, and worker-2. Remember that you did not need to create it manually on worker-1 and worker-2 because Docker created it for you. The output will be long, but notice the Containers and Peers sections. Containers lists all service tasks (or standalone containers) connected to the overlay network from that host.</li><li>From manager, inspect the service using docker service inspect my-nginx and notice the information about the ports and endpoints used by the service.</li><li>Create a new network nginx-net-2, then update the service to use this network instead of nginx-net:</li><li>$ docker network create -d overlay nginx-net-2</li><li>$ docker service update \</li><li>--network-add nginx-net-2 \</li><li>--network-rm nginx-net \</li><li>my-nginx</li><li>Run docker service ls to verify that the service has been updated and all tasks have been redeployed. Run docker network inspect nginx-net to verify that no containers are connected to it. Run the same command for nginx-net-2 and notice that all the service task containers are connected to it.</li></ol><p><strong>Note</strong>: Even though overlay networks are automatically created on swarm worker nodes as needed, they are not automatically removed.</p><ol><li>Clean up the service and the networks. From manager, run the following commands. The manager will direct the workers to remove the networks automatically.</li><li>$ docker service rm my-nginx</li><li>$ docker network rm nginx-net nginx-net-2</li></ol><h4>Use a user-defined overlay network</h4><h5><strong>Prerequisites</strong></h5><p>This tutorial assumes the swarm is already set up and you are on a manager.</p><h5><strong>Walkthrough</strong></h5><ol><li>Create the user-defined overlay network.</li><li>$ docker network create -d overlay my-overlay</li><li>Start a service using the overlay network and publishing port 80 to port 8080 on the Docker host.</li><li>$ docker service create \</li><li>--name my-nginx \</li><li>--network my-overlay \</li><li>--replicas 1 \</li><li>--publish published=8080,target=80 \</li><li>nginx:latest</li><li>Run docker network inspect my-overlay and verify that the my-nginx service task is connected to it, by looking at the Containers section.</li><li>Remove the service and the network.</li><li>$ docker service rm my-nginx</li><li>$ docker network rm my-overlay</li></ol><h4>Use an overlay network for standalone containers</h4><p>This example does the following:</p><ul><li>initializes a swarm on host1</li><li>joins host2 to the swarm</li><li>creates an attachable overlay network</li><li>creates an alpine service with 3 replicas, connected to the overlay network</li><li>creates a single alpine container on host2, which is also attached to the overlay network</li><li>proves that the standalone container can communicate with the service tasks, and vice versa.</li></ul><h5><strong>Prerequisites</strong></h5><p>For this test, you need two different Docker hosts, which can communicate with each other. Each host needs to be running Docker 17.06 or higher. The following ports must be open between the two Docker hosts:</p><ul><li>TCP port 2377</li><li>TCP and UDP port 7946</li><li>UDP port 4789</li></ul><p>One easy way to set this is up is to have two VMs (either local or on a cloud provider like AWS), each with Docker installed and running. If you&#x27;re using AWS or a similar cloud computing platform, the easiest configuration is to use a security group which opens all incoming ports between the two hosts and the SSH port from your client&#x27;s IP address.</p><p>This example will refer to the hosts as host1 and host2, and the command prompts will be labelled accordingly.</p><p>The example uses Linux hosts, but the same commands work on Windows.</p><h5><strong>Walk-through</strong></h5><ol><li>Set up the swarm.<ol><li>On host1, run docker swarm init, specifying the IP address for the interface which will communicate with the other host (for instance, the private IP address on AWS).</li><li>(host1) $ docker swarm init --advertise-addr 192.0.2.1</li><li>Swarm initialized: current node (l9ozqg3m6gysdnemmhoychk9p) is now a manager.</li><li>To add a worker to this swarm, run the following command:</li><li>docker swarm join \</li><li>--token SWMTKN-1-3mtj3k6tkuts4cpecpgjdvgj1u5jre5zwgiapox0tcjs1trqim-bfwb0ve6kf42go1rznrn0lycx \</li><li>192.0.2.1:2377</li><li>To add a manager to this swarm, run \&#x27;docker swarm join-token manager\&#x27; and follow the instructions.</li></ol></li></ol><p>The swarm is initialized and host1 runs both manager and worker roles.</p><ul><li><ol><li>Copy the docker swarm join command. Open a new terminal, connect to host2, and execute the command. Add the --advertise-addr flag, specifying the IP address for the interface that will communicate with the other host (for instance, the private IP address on AWS). The last argument is the IP address of host1.</li><li>(host2) $ docker swarm join \</li><li>--token SWMTKN-1-3mtj3k6tkuts4cpecpgjdvgj1u5jre5zwgiapox0tcjs1trqim-bfwb0ve6kf42go1rznrn0lycx \</li><li>--advertise-addr 192.0.2.2:2377 \</li><li>192.0.2.1:2377</li></ol></li></ul><p>If the command succeeds, the following message is shown:</p><p>This node joined a swarm as a worker.</p><p>Otherwise, the docker swarm join command will time out. In this case, run docker swarm leave --force on node2, verify your network and firewall settings, and try again.</p><ol><li>Create an attachable overlay network called test-net on host1.</li><li>$ docker network create --driver=overlay --attachable test-net</li></ol><p>You don&#x27;t need to manually create the overlay on host2 because it will be created when a container or service tries to connect to it from host2.</p><ol><li>On host1, start a container that connects to test-net:</li><li>(host1) $ docker run -dit \</li><li>--name alpine1 \</li><li>--network test-net \</li><li>alpine</li><li>On host2, start a container that connects to test-net:</li><li>(host2) $ docker run -dit \</li><li>--name alpine2 \</li><li>--network test-net \</li><li>alpine</li></ol><p>The -dit flags mean to start the container detached (in the background), interactive (with the ability to type into it), and with a TTY (so you can see the input and output).</p><p><strong>Note</strong>: There is nothing to prevent you from using the same container name on multiple hosts, but automatic service discovery will not work if you do, and you will need to refer to the containers by IP address.</p><p>Verify that test-net was created on host2:</p><p>(host2) $ docker network ls</p><p>NETWORK ID NAME DRIVER SCOPE</p><p>6e327b25443d bridge bridge local</p><p>10eda0b42471 docker_gwbridge bridge local</p><p>1b16b7e2a72c host host local</p><p>lgsov6d3c6hh ingress overlay swarm</p><p>6af747d9ae1e none null local</p><p>uw9etrdymism test-net overlay swarm</p><ol><li>Remember that you created alpine1 from host1 and alpine2 from host2. Now, attach to alpine2 from host1:</li><li>(host1) $ docker container attach alpine2</li><li><h1></h1></li></ol><p>Automatic service discovery worked between two containers across the overlay network!</p><p>Within the attached session, try pinging alpine1 from alpine2:</p><h1>ping -c 2 alpine1</h1><p>PING alpine1 (10.0.0.2): 56 data bytes</p><p>64 bytes from 10.0.0.2: seq=0 ttl=64 time=0.523 ms</p><p>64 bytes from 10.0.0.2: seq=1 ttl=64 time=0.547 ms</p><p>--- alpine1 ping statistics ---</p><p>2 packets transmitted, 2 packets received, 0% packet loss</p><p>round-trip min/avg/max = 0.523/0.535/0.547 ms</p><p>This proves that the two containers can communicate with each other using the overlay network which is connecting host1 and host2.</p><p>Detach from alpine2 using the CTRL + P CTRL + Q sequence.</p><ol><li>Stop the containers and remove test-net from each host. Because the Docker daemons are operating independently and these are standalone containers, you need to run the commands on the individual hosts.</li><li>(host1) $ docker container stop alpine1</li><li>$ docker container rm alpine1</li><li>$ docker network rm test-net</li><li>(host2) $ docker container stop alpine2</li><li>$ docker container rm alpine2</li><li>$ docker network rm test-net</li></ol><h4>Communicate between a container and a swarm service</h4><h5><strong>Prerequisites</strong></h5><p>You need Docker 17.06 or higher for this example.</p><h5><strong>Walkthrough</strong></h5><p>In this example, you start two different alpine containers on the same Docker host and do some tests to understand how they communicate with each other. You need to have Docker installed and running.</p><ol><li>Open a terminal window. List current networks before you do anything else. Here&#x27;s what you should see if you&#x27;ve never added a network or initialized a swarm on this Docker daemon. You may see different networks, but you should at least see these (the network IDs will be different):</li><li>$ docker network ls</li><li>NETWORK ID NAME DRIVER SCOPE</li><li>17e324f45964 bridge bridge local</li><li>6ed54d316334 host host local</li><li>7092879f2cc8 none null local</li></ol><p>The default bridge network is listed, along with host and none. The latter two are not fully-fledged networks, but are used to start a container connected directly to the Docker daemon host&#x27;s networking stack, or to start a container with no network devices. <strong>This tutorial will connect two containers to the bridge network.</strong></p><ol><li>Start two alpine containers running ash, which is Alpine&#x27;s default shell rather than bash. The -dit flags mean to start the container detached (in the background), interactive (with the ability to type into it), and with a TTY (so you can see the input and output). Since you are starting it detached, you won&#x27;t be connected to the container right away. Instead, the container&#x27;s ID will be printed. Because you have not specified any --network flags, the containers connect to the default bridge network.</li><li>$ docker run -dit --name alpine1 alpine ash</li><li>$ docker run -dit --name alpine2 alpine ash</li></ol><p>Check that both containers are actually started:</p><p>$ docker container ls</p><p>CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES</p><p>602dbf1edc81 alpine &quot;ash&quot; 4 seconds ago Up 3 seconds alpine2</p><p>da33b7aa74b0 alpine &quot;ash&quot; 17 seconds ago Up 16 seconds alpine1</p><ol><li>Inspect the bridge network to see what containers are connected to it.</li><li>$ docker network inspect bridge</li><li>[</li><li>{</li><li>&quot;Name&quot;: &quot;bridge&quot;,</li><li>&quot;Id&quot;: &quot;17e324f459648a9baaea32b248d3884da102dde19396c25b30ec800068ce6b10&quot;,</li><li>&quot;Created&quot;: &quot;2017-06-22T20:27:43.826654485Z&quot;,</li><li>&quot;Scope&quot;: &quot;local&quot;,</li><li>&quot;Driver&quot;: &quot;bridge&quot;,</li><li>&quot;EnableIPv6&quot;: false,</li><li>&quot;IPAM&quot;: {</li><li>&quot;Driver&quot;: &quot;default&quot;,</li><li>&quot;Options&quot;: null,</li><li>&quot;Config&quot;: [</li><li>{</li><li>&quot;Subnet&quot;: &quot;172.17.0.0/16&quot;,</li><li>&quot;Gateway&quot;: &quot;172.17.0.1&quot;</li><li>}</li><li>]</li><li>},</li><li>&quot;Internal&quot;: false,</li><li>&quot;Attachable&quot;: false,</li><li>&quot;Containers&quot;: {</li><li>&quot;602dbf1edc81813304b6cf0a647e65333dc6fe6ee6ed572dc0f686a3307c6a2c&quot;: {</li><li>&quot;Name&quot;: &quot;alpine2&quot;,</li><li>&quot;EndpointID&quot;: &quot;03b6aafb7ca4d7e531e292901b43719c0e34cc7eef565b38a6bf84acf50f38cd&quot;,</li><li>&quot;MacAddress&quot;: &quot;02:42:ac:11:00:03&quot;,</li><li>&quot;IPv4Address&quot;: &quot;172.17.0.3/16&quot;,</li><li>&quot;IPv6Address&quot;: &quot;&quot;</li><li>},</li><li>&quot;da33b7aa74b0bf3bda3ebd502d404320ca112a268aafe05b4851d1e3312ed168&quot;: {</li><li>&quot;Name&quot;: &quot;alpine1&quot;,</li><li>&quot;EndpointID&quot;: &quot;46c044a645d6afc42ddd7857d19e9dcfb89ad790afb5c239a35ac0af5e8a5bc5&quot;,</li><li>&quot;MacAddress&quot;: &quot;02:42:ac:11:00:02&quot;,</li><li>&quot;IPv4Address&quot;: &quot;172.17.0.2/16&quot;,</li><li>&quot;IPv6Address&quot;: &quot;&quot;</li><li>}</li><li>},</li><li>&quot;Options&quot;: {</li><li>&quot;com.docker.network.bridge.default_bridge&quot;: &quot;true&quot;,</li><li>&quot;com.docker.network.bridge.enable_icc&quot;: &quot;true&quot;,</li><li>&quot;com.docker.network.bridge.enable_ip_masquerade&quot;: &quot;true&quot;,</li><li>&quot;com.docker.network.bridge.host_binding_ipv4&quot;: &quot;0.0.0.0&quot;,</li><li>&quot;com.docker.network.bridge.name&quot;: &quot;docker0&quot;,</li><li>&quot;com.docker.network.driver.mtu&quot;: &quot;1500&quot;</li><li>},</li><li>&quot;Labels&quot;: {}</li><li>}</li><li>]</li></ol><p>Near the top, information about the bridge network is listed, including the IP address of the gateway between the Docker host and the bridge network (172.17.0.1). Under the Containers key, each connected container is listed, along with information about its IP address (172.17.0.2 for alpine1 and 172.17.0.3 for alpine2).</p><ol><li>The containers are running in the background. Use the docker attach command to connect to alpine1.</li><li>$ docker attach alpine1</li><li>/ #</li></ol><p>The prompt changes to # to indicate that you are the root user within the container. Use the ip addr show command to show the network interfaces for alpine1 as they look from within the container:</p><h1>ip addr show</h1><p>1: lo: <code style="background-color:lightgray">&lt;LOOPBACK,UP,LOWER_UP&gt;</code> mtu 65536 qdisc noqueue state UNKNOWN qlen 1</p><p>link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</p><p>inet 127.0.0.1/8 scope host lo</p><p>valid_lft forever preferred_lft forever</p><p>inet6 ::1/128 scope host</p><p>valid_lft forever preferred_lft forever</p><p>27: eth0\@if28: <code style="background-color:lightgray">&lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt;</code> mtu 1500 qdisc noqueue state UP</p><p>link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff</p><p>inet 172.17.0.2/16 scope global eth0</p><p>valid_lft forever preferred_lft forever</p><p>inet6 fe80::42:acff:fe11:2/64 scope link</p><p>valid_lft forever preferred_lft forever</p><p>The first interface is the loopback device. Ignore it for now. Notice that the second interface has the IP address 172.17.0.2, which is the same address shown for alpine1 in the previous step.</p><ol><li>From within alpine1, make sure you can connect to the internet by pinging google.com. The -c 2 flag limits the command two two ping attempts.</li><li><h1>ping -c 2 google.com</h1></li><li>PING google.com (172.217.3.174): 56 data bytes</li><li>64 bytes from 172.217.3.174: seq=0 ttl=41 time=9.841 ms</li><li>64 bytes from 172.217.3.174: seq=1 ttl=41 time=9.897 ms</li><li>--- google.com ping statistics ---</li><li>2 packets transmitted, 2 packets received, 0% packet loss</li><li>round-trip min/avg/max = 9.841/9.869/9.897 ms</li><li>Now try to ping the second container. First, ping it by its IP address, 172.17.0.3:</li><li><h1>ping -c 2 172.17.0.3</h1></li><li>PING 172.17.0.3 (172.17.0.3): 56 data bytes</li><li>64 bytes from 172.17.0.3: seq=0 ttl=64 time=0.086 ms</li><li>64 bytes from 172.17.0.3: seq=1 ttl=64 time=0.094 ms</li><li>--- 172.17.0.3 ping statistics ---</li><li>2 packets transmitted, 2 packets received, 0% packet loss</li><li>round-trip min/avg/max = 0.086/0.090/0.094 ms</li></ol><p>This succeeds. Next, try pinging the alpine2 container by container name. This will fail.</p><h1>ping -c 2 alpine2</h1><p>ping: bad address \&#x27;alpine2\&#x27;</p><ol><li>Detach from alpine2 without stopping it by using the detach sequence, CTRL + p CTRL + q (hold down CTRL and type p followed by q). If you wish, attach to alpine2 and repeat steps 4, 5, and 6 there, substituting alpine1 for alpine2.</li><li>Stop and remove both containers.</li><li>$ docker container stop alpine1 alpine2</li><li>$ docker container rm alpine1 alpine2</li></ol><p>Remember, the default bridge network is not recommended for production. To learn about user-defined bridge networks, continue to the <a href="https://docs.docker.com/network/network-tutorial-overlay/#use-user-defined-bridge-networks">next tutorial</a>.</p><h4>Other networking tutorials</h4><p>Now that you have completed the networking tutorials for overlay networks, you might want to run through these other networking tutorials:</p><ul><li><a href="https://docs.docker.com/network/network-tutorial-host/">Host networking tutorial</a></li><li><a href="https://docs.docker.com/network/network-tutorial-standalone/">Standalone networking tutorial</a></li><li><a href="https://docs.docker.com/network/network-tutorial-macvlan/">Macvlan networking tutorial</a></li></ul><h3>Networking using a macvlan network</h3><p><em>Estimated reading time: 5 minutes</em></p><p>This series of tutorials deals with networking standalone containers which connect to macvlannetworks. In this type of network, the Docker host accepts requests for multiple MAC addresses at its IP address, and routes those requests to the appropriate container. For other networking topics, see the<a href="https://docs.docker.com/network/">overview</a>.</p><h4>Goal</h4><p>The goal of these tutorials is to set up a bridged macvlan network and attach a container to it, then set up an 802.1q trunked macvlan network and attach a container to it.</p><h4>Prerequisites</h4><ul><li>Most cloud providers block macvlan networking. You may need physical access to your networking equipment.</li><li>The macvlan networking driver only works on Linux hosts, and is not supported on Docker for Mac, Docker for Windows, or Docker EE for Windows Server.</li><li>You need at least version 3.9 of the Linux kernel, and version 4.0 or higher is recommended.</li><li>The examples assume your ethernet interface is eth0. If your device has a different name, use that instead.</li></ul><h4>Bridge example</h4><p>In the simple bridge example, your traffic flows through eth0 and Docker routes traffic to your container using its MAC address. To network devices on your network, your container appears to be physically attached to the network.</p><ol><li>Create a macvlan network called my-macvlan-net. Modify the subnet, gateway, and parentvalues to values that make sense in your environment.</li><li>$ docker network create -d macvlan \</li><li>--subnet=172.16.86.0/24 \</li><li>--gateway=172.16.86.1 \</li><li>-o parent=eth0 \</li><li>my-macvlan-net</li></ol><p>You can use docker network ls and docker network inspect pub_net commands to verify that the network exists and is a macvlan network.</p><ol><li>Start an alpine container and attach it to the my-macvlan-net network. The -dit flags start the container in the background but allow you to attach to it. The --rm flag means the container is removed when it is stopped.</li><li>$ docker run --rm -itd \</li><li>--network my-macvlan-net \</li><li>--name my-macvlan-alpine \</li><li>alpine:latest \</li><li>ash</li><li>Inspect the my-macvlan-alpine container and notice the MacAddress key within the Networkskey:</li><li>$ docker container inspect my-macvlan-alpine</li><li>...truncated...</li><li>&quot;Networks&quot;: {</li><li>&quot;my-macvlan-net&quot;: {</li><li>&quot;IPAMConfig&quot;: null,</li><li>&quot;Links&quot;: null,</li><li>&quot;Aliases&quot;: [</li><li>&quot;bec64291cd4c&quot;</li><li>],</li><li>&quot;NetworkID&quot;: &quot;5e3ec79625d388dbcc03dcf4a6dc4548644eb99d58864cf8eee2252dcfc0cc9f&quot;,</li><li>&quot;EndpointID&quot;: &quot;8caf93c862b22f379b60515975acf96f7b54b7cf0ba0fb4a33cf18ae9e5c1d89&quot;,</li><li>&quot;Gateway&quot;: &quot;172.16.86.1&quot;,</li><li>&quot;IPAddress&quot;: &quot;172.16.86.2&quot;,</li><li>&quot;IPPrefixLen&quot;: 24,</li><li>&quot;IPv6Gateway&quot;: &quot;&quot;,</li><li>&quot;GlobalIPv6Address&quot;: &quot;&quot;,</li><li>&quot;GlobalIPv6PrefixLen&quot;: 0,</li><li>&quot;MacAddress&quot;: &quot;02:42:ac:10:56:02&quot;,</li><li>&quot;DriverOpts&quot;: null</li><li>}</li><li>}</li><li>...truncated</li><li>Check out how the container sees its own network interfaces by running a couple of docker exec commands.</li><li>$ docker exec my-macvlan-alpine ip addr show eth0</li><li>9: eth0\@tunl0: <code>&lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt;</code> mtu 1500 qdisc noqueue state UP</li><li>link/ether 02:42:ac:10:56:02 brd ff:ff:ff:ff:ff:ff</li><li>inet 172.16.86.2/24 brd 172.16.86.255 scope global eth0</li><li>valid_lft forever preferred_lft forever</li><li>$ docker exec my-macvlan-alpine ip route</li><li>default via 172.16.86.1 dev eth0</li><li>172.16.86.0/24 dev eth0 scope link src 172.16.86.2</li><li>Stop the container (Docker removes it because of the --rm flag), and remove the network.</li><li>$ docker container stop my-macvlan-alpine</li><li>$ docker network rm my-macvlan-net</li></ol><h4>802.1q trunked bridge example</h4><p>In the 802.1q trunked bridge example, your traffic flows through a sub-interface of eth0 (called eth0.10) and Docker routes traffic to your container using its MAC address. To network devices on your network, your container appears to be physically attached to the network.</p><ol><li>Create a macvlan network called my-8021q-macvlan-net. Modify the subnet, gateway, and parent values to values that make sense in your environment.</li><li>$ docker network create -d macvlan \</li><li>--subnet=172.16.86.0/24 \</li><li>--gateway=172.16.86.1 \</li><li>-o parent=eth0.10 \</li><li>my-8021q-macvlan-net</li></ol><p>You can use docker network ls and docker network inspect pub_net commands to verify that the network exists, is a macvlan network, and has parent eth0.10. You can use ip addr showon the Docker host to verify that the interface eth0.10 exists and has a separate IP address</p><ol><li>Start an alpine container and attach it to the my-8021q-macvlan-net network. The -dit flags start the container in the background but allow you to attach to it. The --rm flag means the container is removed when it is stopped.</li><li>$ docker run --rm -itd \</li><li>--network my-8021q-macvlan-net \</li><li>--name my-second-macvlan-alpine \</li><li>alpine:latest \</li><li>ash</li><li>Inspect the my-second-macvlan-alpine container and notice the MacAddress key within the Networks key:</li><li>$ docker container inspect my-second-macvlan-alpine</li><li>...truncated...</li><li>&quot;Networks&quot;: {</li><li>&quot;my-8021q-macvlan-net&quot;: {</li><li>&quot;IPAMConfig&quot;: null,</li><li>&quot;Links&quot;: null,</li><li>&quot;Aliases&quot;: [</li><li>&quot;12f5c3c9ba5c&quot;</li><li>],</li><li>&quot;NetworkID&quot;: &quot;c6203997842e654dd5086abb1133b7e6df627784fec063afcbee5893b2bb64db&quot;,</li><li>&quot;EndpointID&quot;: &quot;aa08d9aa2353c68e8d2ae0bf0e11ed426ea31ed0dd71c868d22ed0dcf9fc8ae6&quot;,</li><li>&quot;Gateway&quot;: &quot;172.16.86.1&quot;,</li><li>&quot;IPAddress&quot;: &quot;172.16.86.2&quot;,</li><li>&quot;IPPrefixLen&quot;: 24,</li><li>&quot;IPv6Gateway&quot;: &quot;&quot;,</li><li>&quot;GlobalIPv6Address&quot;: &quot;&quot;,</li><li>&quot;GlobalIPv6PrefixLen&quot;: 0,</li><li>&quot;MacAddress&quot;: &quot;02:42:ac:10:56:02&quot;,</li><li>&quot;DriverOpts&quot;: null</li><li>}</li><li>}</li><li>...truncated</li><li>Check out how the container sees its own network interfaces by running a couple of docker exec commands.</li><li>$ docker exec my-second-macvlan-alpine ip addr show eth0</li><li>11: eth0\@if10: <code>&lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt;</code> mtu 1500 qdisc noqueue state UP</li><li>link/ether 02:42:ac:10:56:02 brd ff:ff:ff:ff:ff:ff</li><li>inet 172.16.86.2/24 brd 172.16.86.255 scope global eth0</li><li>valid_lft forever preferred_lft forever</li><li>$ docker exec my-second-macvlan-alpine ip route</li><li>default via 172.16.86.1 dev eth0</li><li>172.16.86.0/24 dev eth0 scope link src 172.16.86.2</li><li>Stop the container (Docker removes it because of the --rm flag), and remove the network.</li><li>$ docker container stop my-second-macvlan-alpin</li><li>$ docker network rm my-8021q-macvlan-net</li></ol><h4>Other networking tutorials</h4><p>Now that you have completed the networking tutorial for macvlan networks, you might want to run through these other networking tutorials:</p><ul><li><a href="https://docs.docker.com/network/network-tutorial-standalone/">Standalone networking tutorial</a></li><li><a href="https://docs.docker.com/network/network-tutorial-overlay/">Overlay networking tutorial</a></li><li><a href="https://docs.docker.com/network/network-tutorial-host/">Host networking tutorial</a></li></ul><h3>Configure the Daemon and the Containers</h3><h4>Enable IPv6 support</h4><p><em>Estimated reading time: 1 minute</em></p><p>Before you can use IPv6 in Docker containers or swarm services, you need to enable IPv6 support in the Docker daemon. Afterward, you can choose to use either IPv4 or IPv6 (or both) with any container, service, or network.</p><p><strong>Note</strong>: IPv6 networking is only supported on Docker daemons running on Linux hosts.</p><ol><li>Edit /etc/docker/daemon.json and set the ipv6 key to true.</li><li>{</li><li>&quot;ipv6&quot;: true</li><li>}</li></ol><p>Save the file.</p><ol><li>Reload the Docker configuration file.</li><li>$ systemctl reload docker</li></ol><p>You can now create networks with the --ipv6 flag and assign containers IPv6 addresses using the --ip6 flag.</p><h5><strong>Next steps</strong></h5><ul><li><a href="https://docs.docker.com/network/">Networking overview</a></li><li><a href="https://docs.docker.com/config/containers/container-networking/">Container networking</a></li></ul><h4>Docker and iptables</h4><p><em>Estimated reading time: 2 minutes</em></p><p>On Linux, Docker manipulates iptables rules to provide network isolation. This is an implementation detail, and you should not modify the rules Docker inserts into your iptables policies.</p><h5><strong>Add iptables policies before Docker&#x27;s rules</strong></h5><p>All of Docker&#x27;s iptables rules are added to the DOCKER chain. Do not manipulate this table manually. If you need to add rules which load before Docker&#x27;s rules, add them to the DOCKER-USER chain. These rules are loaded before any rules Docker creates automatically.</p><h6><strong>Restrict connections to the Docker daemon</strong></h6><p>By default, all external source IPs are allowed to connect to the Docker daemon. To allow only a specific IP or network to access the containers, insert a negated rule at the top of the DOCKER filter chain. For example, the following rule restricts external access to all IP addresses except 192.168.1.1:</p><p>$ iptables -I DOCKER-USER -i ext_if ! -s 192.168.1.1 -j DROP</p><p>You could instead allow connections from a source subnet. The following rule only allows access from the subnet 192.168.1.0/24:</p><p>$ iptables -I DOCKER-USER -i ext_if ! -s 192.168.1.0/24 -j DROP</p><p>Finally, you can specify a range of IP addresses to accept using --src-range (Remember to also add -m iprange when using --src-range or --dst-range):</p><p>$ iptables -I DOCKER-USER -m iprange -i ext_if ! --src-range 192.168.1.1-192.168.1.3 -j DROP</p><p>You can combine -s or --src-range with -d or --dst-range to control both the source and destination. For instance, if the Docker daemon listens on both 192.168.1.99 and 10.1.2.3, you can make rules specific to 10.1.2.3 and leave 192.168.1.99 open.</p><p>iptables is complicated and more complicated rule are out of scope for this topic. See the <a href="https://www.netfilter.org/documentation/HOWTO/NAT-HOWTO.html">Netfilter.org HOWTO</a> for a lot more information.</p><h5><strong>Prevent Docker from manipulating iptables</strong></h5><p>To prevent Docker from manipulating the iptables policies at all, set the iptables key to false in /etc/docker/daemon.json. This is inappropriate for most users, because the iptables policies then need to be managed by hand.</p><h5><strong>Next steps</strong></h5><ul><li>Read <a href="https://success.docker.com/Architecture/Docker_Reference_Architecture%3A_Designing_Scalable%2C_Portable_Docker_Container_Networks">Docker Reference Architecture: Designing Scalable, Portable Docker Container Networks</a></li></ul><h4>Container networking</h4><p><em>Estimated reading time: 3 minutes</em></p><p>The type of network a container uses, whether it is a <a href="https://docs.docker.com/config/containers/bridges/">bridge</a>, an <a href="https://docs.docker.com/config/containers/overlay/">overlay</a>, a <a href="https://docs.docker.com/config/containers/macvlan/">macvlan network</a>, or a custom network plugin, is transparent from within the container. From the container&#x27;s point of view, it has a network interface with an IP address, a gateway, a routing table, DNS services, and other networking details (assuming the container is not using the none network driver). This topic is about networking concerns from the point of view of the container.</p><h5><strong>Published ports</strong></h5><p>By default, when you create a container, it does not publish any of its ports to the outside world. To make a port available to services outside of Docker, or to Docker containers which are not connected to the container&#x27;s network, use the --publish or -p flag. This creates a firewall rule which maps a container port to a port on the Docker host. Here are some examples.</p><p>  <strong>Flag value</strong>                  <strong>Description</strong></p><hr/><p>  -p 8080:80                      Map TCP port 80 in the container to port 8080 on the Docker host.
-p 8080:80/udp                  Map UDP port 80 in the container to port 8080 on the Docker host.
-p 8080:80/tcp -p 8080:80/udp   Map TCP port 80 in the container to TCP port 8080 on the Docker host, and map UDP port 80 in the container to UDP port 8080 on the Docker host.</p><h5><strong>IP address and hostname</strong></h5><p>By default, the container is assigned an IP address for every Docker network it connects to. The IP address is assigned from the pool assigned to the network, so the Docker daemon effectively acts as a DHCP server for each container. Each network also has a default subnet mask and gateway.</p><p>When the container starts, it can only be connected to a single network, using --network. However, you can connect a running container to multiple networks using docker network connect. When you start a container using the --network flag, you can specify the IP address assigned to the container on that network using the --ip or --ip6 flags.</p><p>When you connect an existing container to a different network using docker network connect, you can use the --ip or --ip6 flags on that command to specify the container&#x27;s IP address on the additional network.</p><p>In the same way, a container&#x27;s hostname defaults to be the container&#x27;s name in Docker. You can override the hostname using --hostname. When connecting to an existing network using docker network connect, you can use the --alias flag to specify an additional network alias for the container on that network.</p><h5><strong>DNS services</strong></h5><p>By default, a container inherits the DNS settings of the Docker daemon, including the /etc/hosts and /etc/resolv.conf.You can override these settings on a per-container basis.</p><p>  <strong>Flag</strong>        <strong>Description</strong></p><hr/><p>  --dns          The IP address of a DNS server. To specify multiple DNS servers, use multiple --dns flags. If the container cannot reach any of the IP addresses you specify, Google&#x27;s public DNS server 8.8.8.8 is added, so that your container can resolve internet domains.
--dns-search   A DNS search domain to search non-fully-qualified hostnames. To specify multiple DNS search prefixes, use multiple --dns-search flags.
--dns-opt      A key-value pair representing a DNS option and its value. See your operating system&#x27;s documentation for resolv.conf for valid options.
--hostname     The hostname a container uses for itself. Defaults to the container&#x27;s name if not specified.</p><h5><strong>Proxy server</strong></h5><p>If your container needs to use a proxy server, see <a href="https://docs.docker.com/network/proxy/">Use a proxy server</a>.</p><h4>Configure Docker to use a proxy server</h4><p><em>Estimated reading time: 2 minutes</em></p><p>If your container needs to use an HTTP, HTTPS, or FTP proxy server, you can configure it in different ways:</p><ul><li>In Docker 17.07 and higher, you can <a href="https://docs.docker.com/network/proxy/#configure-the-docker-client">configure the Docker client</a> to pass proxy information to containers automatically.</li><li>In Docker 17.06 and lower, you must <a href="https://docs.docker.com/network/proxy/#use-environment-variables">set appropriate environment variables</a> within the container. You can do this when you build the image (which makes the image less portable) or when you create or run the container.</li></ul><h5><strong>Configure the Docker client</strong></h5><ol><li>On the Docker client, create or edit the file <!-- -->~<!-- -->/.docker/config.json in the home directory of the user which starts containers. Add JSON such as the following, substituting the type of proxy with httpsProxy or ftpProxy if necessary, and substituting the address and port of the proxy server. You can configure multiple proxy servers at the same time.</li></ol><p>You can optionally exclude hosts or ranges from going through the proxy server by setting a noProxy key to one or more comma-separated IP addresses or hosts. Using the * character as a wildcard is supported, as shown in this example.</p><p>{</p><p>&quot;proxies&quot;:</p><p>{</p><p>&quot;default&quot;:</p><p>{</p><p>&quot;httpProxy&quot;: &quot;<a href="http://127.0.0.1:3001%22">http://127.0.0.1:3001&quot;</a>,</p><p>&quot;noProxy&quot;: &quot;*.test.example.com,.example2.com&quot;</p><p>}</p><p>}</p><p>}</p><p>Save the file.</p><ol><li>When you create or start new containers, the environment variables are set automatically within the container.</li></ol><h5><strong>Use environment variables</strong></h5><h6><strong>Set the environment variables manually</strong></h6><p>When you build the image, or using the --env flag when you create or run the container, you can set one or more of the following variables to the appropriate value. This method makes the image less portable, so if you have Docker 17.07 or higher, you should <a href="https://docs.docker.com/network/proxy/#configure-the-docker-client">configure the Docker client</a> instead.</p><p>  <strong>Variable</strong>   <strong>Dockerfile example</strong>                               <strong>docker run Example</strong></p><hr/><p>  HTTP_PROXY     ENV HTTP_PROXY &quot;<a href="http://127.0.0.1:3001%22">http://127.0.0.1:3001&quot;</a>             --env HTTP_PROXY &quot;<a href="http://127.0.0.1:3001%22">http://127.0.0.1:3001&quot;</a>
HTTPS_PROXY    ENV HTTPS_PROXY &quot;<a href="https://127.0.0.1:3001%22">https://127.0.0.1:3001&quot;</a>           --env HTTPS_PROXY &quot;<a href="https://127.0.0.1:3001%22">https://127.0.0.1:3001&quot;</a>
FTP_PROXY      ENV FTP_PROXY &quot;ftp://127.0.0.1:3001&quot;               --env FTP_PROXY &quot;ftp://127.0.0.1:3001&quot;
NO_PROXY       ENV NO_PROXY &quot;<em>.test.example.com,.example2.com&quot;   --env NO_PROXY &quot;</em>.test.example.com,.e</p><h2>Legacy Networing Content</h2><h3>Legacy container links</h3><p><em>Estimated reading time: 14 minutes</em></p><p><strong>Warning: The --link flag is a legacy feature of Docker. It may eventually be removed. Unless you absolutely need to continue using it, we recommend that you use user-defined networks to facilitate communication between two containers instead of using --link. One feature that user-defined networks do not support that you can do with --link is sharing environmental variables between containers. However, you can use other mechanisms such as volumes to share environment variables between containers in a more controlled way.</strong></p><p>See <a href="https://docs.docker.com/network/bridge/##differences-between-user-defined-bridges-and-the-default-bridge">Differences between user-defined bridges and the default bridge</a> for some alternatives to using --link.</p><p>The information in this section explains legacy container links within the Docker default bridgenetwork which is created automatically when you install Docker.</p><p>Before the <a href="https://docs.docker.com/engine/userguide/networking/">Docker networks feature</a>, you could use the Docker link feature to allow containers to discover each other and securely transfer information about one container to another container. With the introduction of the Docker networks feature, you can still create links but they behave differently between default bridge network and <a href="https://docs.docker.com/engine/userguide/networking/work-with-networks/#linking-containers-in-user-defined-networks">user defined networks</a>.</p><p>This section briefly discusses connecting via a network port and then goes into detail on container linking in default bridge network.</p><h4>Connect using network port mapping</h4><p>Let&#x27;s say you used this command to run a simple Python Flask application:</p><p>$ docker run -d -P training/webapp python app.py</p><p><strong>Note</strong>: Containers have an internal network and an IP address. Docker can have a variety of network configurations. You can see more information on Docker networking <a href="https://docs.docker.com/engine/userguide/networking/">here</a>.</p><p>When that container was created, the -P flag was used to automatically map any network port inside it to a random high port within an ephemeral port range on your Docker host. Next, when docker pswas run, you saw that port 5000 in the container was bound to port 49155 on the host.</p><p>$ docker ps nostalgic_morse</p><p>CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES</p><p>bc533791f3f5 training/webapp:latest python app.py 5 seconds ago Up 2 seconds 0.0.0.0:49155-&gt;5000/tcp nostalgic_morse</p><p>You also saw how you can bind a container&#x27;s ports to a specific port using the -p flag. Here port 80 of the host is mapped to port 5000 of the container:</p><p>$ docker run -d -p 80:5000 training/webapp python app.py</p><p>And you saw why this isn&#x27;t such a great idea because it constrains you to only one container on that specific port.</p><p>Instead, you may specify a range of host ports to bind a container port to that is different than the default ephemeral port range:</p><p>$ docker run -d -p 8000-9000:5000 training/webapp python app.py</p><p>This would bind port 5000 in the container to a randomly available port between 8000 and 9000 on the host.</p><p>There are also a few other ways you can configure the -p flag. By default the -p flag binds the specified port to all interfaces on the host machine. But you can also specify a binding to a specific interface, for example only to the localhost.</p><p>$ docker run -d -p 127.0.0.1:80:5000 training/webapp python app.py</p><p>This would bind port 5000 inside the container to port 80 on the localhost or 127.0.0.1 interface on the host machine.</p><p>Or, to bind port 5000 of the container to a dynamic port but only on the localhost, you could use:</p><p>$ docker run -d -p 127.0.0.1::5000 training/webapp python app.py</p><p>You can also bind UDP ports by adding a trailing /udp. For example:</p><p>$ docker run -d -p 127.0.0.1:80:5000/udp training/webapp python app.py</p><p>You also learned about the useful docker port shortcut which showed us the current port bindings. This is also useful for showing you specific port configurations. For example, if you&#x27;ve bound the container port to the localhost on the host machine, then the docker port output reflects that.</p><p>$ docker port nostalgic_morse 5000</p><p>127.0.0.1:49155</p><p><strong>Note</strong>: The -p flag can be used multiple times to configure multiple ports.</p><h4>Connect with the linking system</h4><p><strong>Note</strong>: This section covers the legacy link feature in the default bridge network. Refer to <a href="https://docs.docker.com/engine/userguide/networking/work-with-networks/#linking-containers-in-user-defined-networks">linking containers in user-defined networks</a> for more information on links in user-defined networks.</p><p>Network port mappings are not the only way Docker containers can connect to one another. Docker also has a linking system that allows you to link multiple containers together and send connection information from one to another. When containers are linked, information about a source container can be sent to a recipient container. This allows the recipient to see selected data describing aspects of the source container.</p><h5><strong>The importance of naming</strong></h5><p>To establish links, Docker relies on the names of your containers. You&#x27;ve already seen that each container you create has an automatically created name; indeed you&#x27;ve become familiar with our old friend nostalgic_morse during this guide. You can also name containers yourself. This naming provides two useful functions:</p><ol><li>It can be useful to name containers that do specific functions in a way that makes it easier for you to remember them, for example naming a container containing a web application web.</li><li>It provides Docker with a reference point that allows it to refer to other containers, for example, you can specify to link the container web to container db.</li></ol><p>You can name your container by using the --name flag, for example:</p><p>$ docker run -d -P --name web training/webapp python app.py</p><p>This launches a new container and uses the --name flag to name the container web. You can see the container&#x27;s name using the docker ps command.</p><p>$ docker ps -l</p><p>CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES</p><p>aed84ee21bde training/webapp:latest python app.py 12 hours ago Up 2 seconds 0.0.0.0:49154-&gt;5000/tcp web</p><p>You can also use docker inspect to return the container&#x27;s name.</p><p><strong>Note</strong>: Container names must be unique. That means you can only call one container web. If you want to re-use a container name you must delete the old container (with docker container rm) before you can create a new container with the same name. As an alternative you can use the --rm flag with the docker run command. This deletes the container immediately after it is stopped.</p><h4>Communication across links</h4><p>Links allow containers to discover each other and securely transfer information about one container to another container. When you set up a link, you create a conduit between a source container and a recipient container. The recipient can then access select data about the source. To create a link, you use the --link flag. First, create a new container, this time one containing a database.</p><p>$ docker run -d --name db training/postgres</p><p>This creates a new container called db from the training/postgres image, which contains a PostgreSQL database.</p><p>Now, you need to delete the web container you created previously so you can replace it with a linked one:</p><p>$ docker container rm -f web</p><p>Now, create a new web container and link it with your db container.</p><p>$ docker run -d -P --name web --link db:db training/webapp python app.py</p><p>This links the new web container with the db container you created earlier. The --link flag takes the form:</p><p>--link <code style="background-color:lightgray">&lt;name or id&gt;</code>:alias</p><p>Where name is the name of the container we&#x27;re linking to and alias is an alias for the link name. That alias is used shortly. The --link flag also takes the form:</p><p>--link <code style="background-color:lightgray">&lt;name or id&gt;</code></p><p>In this case the alias matches the name. You could write the previous example as:</p><p>$ docker run -d -P --name web --link db training/webapp python app.py</p><p>Next, inspect your linked containers with docker inspect:</p><p>$ docker inspect -f &quot;{{ .HostConfig.Links }}&quot; web</p><p>[/db:/web/db]</p><p>You can see that the web container is now linked to the db container web/db. Which allows it to access information about the db container.</p><p>So what does linking the containers actually do? You&#x27;ve learned that a link allows a source container to provide information about itself to a recipient container. In our example, the recipient, web, can access information about the source db. To do this, Docker creates a secure tunnel between the containers that doesn&#x27;t need to expose any ports externally on the container; when we started the db container we did not use either the -P or -p flags. That&#x27;s a big benefit of linking: we don&#x27;t need to expose the source container, here the PostgreSQL database, to the network.</p><p>Docker exposes connectivity information for the source container to the recipient container in two ways:</p><ul><li>Environment variables,</li><li>Updating the /etc/hosts file.</li></ul><h5><strong>Environment variables</strong></h5><p>Docker creates several environment variables when you link containers. Docker automatically creates environment variables in the target container based on the --link parameters. It also exposes all environment variables originating from Docker from the source container. These include variables from:</p><ul><li>the ENV commands in the source container&#x27;s Dockerfile</li><li>the -e, --env, and --env-file options on the docker run command when the source container is started</li></ul><p>These environment variables enable programmatic discovery from within the target container of information related to the source container.</p><p><strong>Warning</strong>: It is important to understand that all environment variables originating from Docker within a container are made available to any container that links to it. This could have serious security implications if sensitive data is stored in them.</p><p>Docker sets an <code style="background-color:lightgray">&lt;alias&gt;</code>_NAME environment variable for each target container listed in the --linkparameter. For example, if a new container called web is linked to a database container called db via --link db:webdb, then Docker creates a WEBDB_NAME=/web/webdb variable in the web container.</p><p>Docker also defines a set of environment variables for each port exposed by the source container. Each variable has a unique prefix in the form:</p><p><code style="background-color:lightgray">&lt;name&gt;_PORT_&lt;port&gt;_&lt;protocol&gt;</code></p><p>The components in this prefix are:</p><ul><li>the alias <code>&lt;name&gt;</code> specified in the --link parameter (for example, webdb)</li><li>the <code>&lt;port&gt;</code> number exposed</li><li>a <code>&lt;protocol&gt;</code> which is either TCP or UDP</li></ul><p>Docker uses this prefix format to define three distinct environment variables:</p><ul><li>The prefix_ADDR variable contains the IP Address from the URL, for example WEBDB_PORT_5432_TCP_ADDR=172.17.0.82.</li><li>The prefix_PORT variable contains just the port number from the URL for example WEBDB_PORT_5432_TCP_PORT=5432.</li><li>The prefix_PROTO variable contains just the protocol from the URL for example WEBDB_PORT_5432_TCP_PROTO=tcp.</li></ul><p>If the container exposes multiple ports, an environment variable set is defined for each one. This means, for example, if a container exposes 4 ports that Docker creates 12 environment variables, 3 for each port.</p><p>Additionally, Docker creates an environment variable called <code style="background-color:lightgray">&lt;alias&gt;</code>_PORT. This variable contains the URL of the source container&#x27;s first exposed port. The &#x27;first&#x27; port is defined as the exposed port with the lowest number. For example, consider the WEBDB_PORT=tcp://172.17.0.82:5432 variable. If that port is used for both tcp and udp, then the tcp one is specified.</p><p>Finally, Docker also exposes each Docker originated environment variable from the source container as an environment variable in the target. For each variable Docker creates an <code style="background-color:lightgray">&lt;alias&gt;_ENV_&lt;name&gt;</code>variable in the target container. The variable&#x27;s value is set to the value Docker used when it started the source container.</p><p>Returning back to our database example, you can run the env command to list the specified container&#x27;s environment variables.</p><p>$ docker run --rm --name web2 --link db:db training/webapp env</p><p>. . .</p><p>DB_NAME=/web2/db</p><p>DB_PORT=tcp://172.17.0.5:5432</p><p>DB_PORT_5432_TCP=tcp://172.17.0.5:5432</p><p>DB_PORT_5432_TCP_PROTO=tcp</p><p>DB_PORT_5432_TCP_PORT=5432</p><p>DB_PORT_5432_TCP_ADDR=172.17.0.5</p><p>. . .</p><p>You can see that Docker has created a series of environment variables with useful information about the source db container. Each variable is prefixed with DB<em>, which is populated from the alias you specified above. If the alias were db1, the variables would be prefixed with DB1</em>. You can use these environment variables to configure your applications to connect to the database on the dbcontainer. The connection is secure and private; only the linked web container can communicate with the db container.</p><h5><strong>Important notes on Docker environment variables</strong></h5><p>Unlike host entries in the <a href="https://docs.docker.com/network/links/#updating-the-etchosts-file">/etc/hosts file</a>, IP addresses stored in the environment variables are not automatically updated if the source container is restarted. We recommend using the host entries in/etc/hosts to resolve the IP address of linked containers.</p><p>These environment variables are only set for the first process in the container. Some daemons, such as sshd, scrub them when spawning shells for connection.</p><h5><strong>Updating the /etc/hosts file</strong></h5><p>In addition to the environment variables, Docker adds a host entry for the source container to the /etc/hosts file. Here&#x27;s an entry for the web container:</p><p>$ docker run -t -i --rm --link db:webdb training/webapp /bin/bash</p><p>root\@aed84ee21bde:/opt/webapp# cat /etc/hosts</p><p>172.17.0.7 aed84ee21bde</p><p>. . .</p><p>172.17.0.5 webdb 6e5cdeb2d300 db</p><p>You can see two relevant host entries. The first is an entry for the web container that uses the Container ID as a host name. The second entry uses the link alias to reference the IP address of the dbcontainer. In addition to the alias you provide, the linked container&#x27;s name, if unique from the alias provided to the --link parameter, and the linked container&#x27;s hostname are also added to /etc/hosts for the linked container&#x27;s IP address. You can ping that host via any of these entries:</p><p>root\@aed84ee21bde:/opt/webapp# apt-get install -yqq inetutils-ping</p><p>root\@aed84ee21bde:/opt/webapp# ping webdb</p><p>PING webdb (172.17.0.5): 48 data bytes</p><p>56 bytes from 172.17.0.5: icmp_seq=0 ttl=64 time=0.267 ms</p><p>56 bytes from 172.17.0.5: icmp_seq=1 ttl=64 time=0.250 ms</p><p>56 bytes from 172.17.0.5: icmp_seq=2 ttl=64 time=0.256 ms</p><p><strong>Note</strong>: In the example, you had to install ping because it was not included in the container initially.</p><p>Here, you used the ping command to ping the db container using its host entry, which resolves to 172.17.0.5. You can use this host entry to configure an application to make use of your dbcontainer.</p><p><strong>Note</strong>: You can link multiple recipient containers to a single source. For example, you could have multiple (differently named) web containers attached to your db container.</p><p>If you restart the source container, the /etc/hosts files on the linked containers are automatically updated with the source container&#x27;s new IP address, allowing linked communication to continue.</p><p>$ docker restart db</p><p>db</p><p>$ docker run -t -i --rm --link db:db training/webapp /bin/bash</p><p>root\@aed84ee21bde:/opt/webapp# cat /etc/hosts</p><p>172.17.0.7 aed84ee21bde</p><p>. . .</p><p>172.17.0.9 db</p><h3>Multi-host networking with standalone swarms</h3><p><em>Estimated reading time: 12 minutes</em></p><h4>Standalone swarm only!</h4><p>This article only applies to users who need to use a standalone swarm with Docker, as opposed to swarm mode. Standalone swarms (sometimes known as Swarm Classic) rely on an external key-value store to store networking information. Docker swarm mode stores networking information in the Raft logs on the swarm managers. If you use swarm mode, see <a href="https://docs.docker.com/engine/swarm/networking/">swarm mode networking</a> instead of this article.</p><p>Users of Universal Control Plane <strong>do</strong> use an external key-value store, but UCP manages it for you, and you do not need to manually intervene. If you run into issues with the key-value store, see <a href="https://docs.docker.com/datacenter/ucp/2.2/guides/admin/monitor-and-troubleshoot/troubleshoot-configurations/#troubleshoot-the-etcd-key-value-store">Troubleshoot the etcd key-value store</a></p><p>If you are using standalone swarms and not using UCP, this article may be useful to you. This article uses an example to explain the basics of creating a multi-host network using a standalone swarm and the overlay network driver. Unlike bridge networks, overlay networks require some pre-existing conditions before you can create one:</p><h4>Overlay networking with an external key-value store</h4><p>To use Docker with an external key-value store, you need the following:</p><ul><li>Access to the key-value store. Docker supports Consul, Etcd, and ZooKeeper (Distributed store) key-value stores. This example uses Consul.</li><li>A cluster of hosts with connectivity to the key-value store.</li><li>Docker running on each host in the cluster.</li><li>Hosts within the cluster must have unique hostnames because the key-value store uses the hostnames to identify cluster members.</li></ul><p>Docker Machine and Docker Swarm are not mandatory to experience Docker multi-host networking with a key-value store. However, this example uses them to illustrate how they are integrated. You use Machine to create both the key-value store server and the host cluster using a standalone swarm.</p><p><strong>Note</strong>: These examples are not relevant to Docker running in swarm mode and do not work in such a configuration.</p><h5><strong>Prerequisites</strong></h5><p>Before you begin, make sure you have a system on your network with the latest version of Docker and Docker Machine installed. The example also relies on VirtualBox. If you installed on a Mac or Windows with Docker Toolbox, you have all of these installed already.</p><p>If you have not already done so, make sure you upgrade Docker and Docker Machine to the latest versions.</p><h5><strong>Set up a key-value store</strong></h5><p>An overlay network requires a key-value store. The key-value store holds information about the network state which includes discovery, networks, endpoints, IP addresses, and more. Docker supports Consul, Etcd, and ZooKeeper key-value stores. This example uses Consul.</p><ol><li>Log into a system prepared with Docker and Docker Machine installed.</li><li>Provision a VirtualBox machine called mh-keystore.</li><li>$ docker-machine create -d virtualbox mh-keystore</li></ol><p>When you provision a new machine, the process adds Docker to the host. This means rather than installing Consul manually, you can create an instance using the <a href="https://hub.docker.com/_/consul/">consul image from Docker Hub</a>. You do this in the next step.</p><ol><li>Set your local environment to the mh-keystore machine.</li><li>$ eval &quot;$(docker-machine env mh-keystore)&quot;</li><li>Start a consul container running on the mh-keystore Docker machine.</li><li>$ docker run -d \</li><li>--name consul \</li><li>-p &quot;8500:8500&quot; \</li><li>-h &quot;consul&quot; \</li><li>consul agent -server -bootstrap -client &quot;0.0.0.0&quot;</li></ol><p>The client starts a consul image running in the mh-keystore Docker machine. The server is called consul and is listening on port 8500.</p><ol><li>Run the docker ps command to see the consul container.</li><li>$ docker ps</li><li>CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES</li><li>a47492d6c4d1 consul &quot;docker-entrypoint...&quot; 2 seconds ago Up 1 second 8300-8302/tcp, 8301-8302/udp, 8600/tcp, 8600/udp, 0.0.0.0:8500-&gt;8500/tcp consul</li></ol><p>Keep your terminal open and move on to <a href="https://docs.docker.com/network/overlay-standalone.swarm/#create-a-swarm-cluster">Create a swarm cluster</a>.</p><h5><strong>Create a swarm cluster</strong></h5><p>In this step, you use docker-machine to provision the hosts for your network. You don&#x27;t actually create the network yet. You create several Docker machines in VirtualBox. One of the machines acts as the swarm manager and you create that first. As you create each host, you pass the Docker daemon on that machine options that are needed by the overlay network driver.</p><p><strong>Note</strong>: This creates a standalone swarm cluster, rather than using Docker in swarm mode. These examples are not relevant to Docker running in swarm mode and do not work in such a configuration.</p><ol><li>Create a swarm manager.</li><li>$ docker-machine create \</li><li>-d virtualbox \</li><li>--swarm --swarm-master \</li><li>--swarm-discovery=&quot;consul://$(docker-machine ip mh-keystore):8500&quot; \</li><li>--engine-opt=&quot;cluster-store=consul://$(docker-machine ip mh-keystore):8500&quot; \</li><li>--engine-opt=&quot;cluster-advertise=eth1:2376&quot; \</li><li>mhs-demo0</li></ol><p>At creation time, you supply the Docker daemon with the --cluster-store option. This option tells the Engine the location of the key-value store for the overlay network. The bash expansion $(docker-machine ip mh-keystore) resolves to the IP address of the Consul server you created in &quot;STEP 1&quot;. The --cluster-advertise option advertises the machine on the network.</p><ol><li>Create another host and add it to the swarm.</li><li>$ docker-machine create -d virtualbox \</li><li>--swarm \</li><li>--swarm-discovery=&quot;consul://$(docker-machine ip mh-keystore):8500&quot; \</li><li>--engine-opt=&quot;cluster-store=consul://$(docker-machine ip mh-keystore):8500&quot; \</li><li>--engine-opt=&quot;cluster-advertise=eth1:2376&quot; \</li><li>mhs-demo1</li><li>List your Docker machines to confirm they are all up and running.</li><li>$ docker-machine ls</li><li>NAME ACTIVE DRIVER STATE URL SWARM</li><li>default - virtualbox Running tcp://192.168.99.100:2376</li><li>mh-keystore * virtualbox Running tcp://192.168.99.103:2376</li><li>mhs-demo0 - virtualbox Running tcp://192.168.99.104:2376 mhs-demo0 (master)</li><li>mhs-demo1 - virtualbox Running tcp://192.168.99.105:2376 mhs-demo0</li></ol><p>At this point you have a set of hosts running on your network. You are ready to create a multi-host network for containers using these hosts.</p><p>Leave your terminal open and go on to <a href="https://docs.docker.com/network/overlay-standalone.swarm/#create-the-overlay-network">Create the overlay network</a>.</p><h5><strong>Create the overlay network</strong></h5><p>To create an overlay network:</p><ol><li>Set your docker environment to the swarm manager.</li><li>$ eval $(docker-machine env --swarm mhs-demo0)</li></ol><p>Using the --swarm flag with docker-machine restricts the docker commands to swarm information alone.</p><ol><li>Use the docker info command to view the swarm.</li><li>$ docker info</li><li>Containers: 3</li><li>Images: 2</li><li>Role: primary</li><li>Strategy: spread</li><li>Filters: affinity, health, constraint, port, dependency</li><li>Nodes: 2</li><li>mhs-demo0: 192.168.99.104:2376</li><li>└ Containers: 2</li><li>└ Reserved CPUs: 0 / 1</li><li>└ Reserved Memory: 0 B / 1.021 GiB</li><li>└ Labels: executiondriver=native-0.2, kernelversion=4.1.10-boot2docker, operatingsystem=Boot2Docker 1.9.0 (TCL 6.4); master : 4187d2c - Wed Oct 14 14:00:28 UTC 2015, provider=virtualbox, storagedriver=aufs</li><li>mhs-demo1: 192.168.99.105:2376</li><li>└ Containers: 1</li><li>└ Reserved CPUs: 0 / 1</li><li>└ Reserved Memory: 0 B / 1.021 GiB</li><li>└ Labels: executiondriver=native-0.2, kernelversion=4.1.10-boot2docker, operatingsystem=Boot2Docker 1.9.0 (TCL 6.4); master : 4187d2c - Wed Oct 14 14:00:28 UTC 2015, provider=virtualbox, storagedriver=aufs</li><li>CPUs: 2</li><li>Total Memory: 2.043 GiB</li><li>Name: 30438ece0915</li></ol><p>This output shows that you are running three containers and two images on the manager.</p><ol><li>Create your overlay network.</li><li>$ docker network create --driver overlay --subnet=10.0.9.0/24 my-net</li></ol><p>You only need to create the network on a single host in the cluster. In this case, you used the swarm manager but you could easily have run it on any host in the swarm.</p><p><strong>Note</strong>: It is highly recommended to use the --subnet option when creating a network. If the --subnet is not specified, Docker automatically chooses and assigns a subnet for the network and it could overlap with another subnet in your infrastructure that is not managed by Docker. Such overlaps can cause connectivity issues or failures when containers are connected to that network.</p><ol><li>Check that the network exists:</li><li>$ docker network ls</li><li>NETWORK ID NAME DRIVER</li><li>412c2496d0eb mhs-demo1/host host</li><li>dd51763e6dd2 mhs-demo0/bridge bridge</li><li>6b07d0be843f my-net overlay</li><li>b4234109bd9b mhs-demo0/none null</li><li>1aeead6dd890 mhs-demo0/host host</li><li>d0bb78cbe7bd mhs-demo1/bridge bridge</li><li>1c0eb8f69ebb mhs-demo1/none null</li></ol><p>Since you are in the swarm manager environment, you see all the networks on all the swarm participants: the default networks on each Docker daemon and the single overlay network. Each network has a unique ID and a namespaced name.</p><ol><li>Switch to each swarm agent in turn and list the networks.</li><li>$ eval $(docker-machine env mhs-demo0)</li><li>$ docker network ls</li><li>NETWORK ID NAME DRIVER</li><li>6b07d0be843f my-net overlay</li><li>dd51763e6dd2 bridge bridge</li><li>b4234109bd9b none null</li><li>1aeead6dd890 host host</li><li>$ eval $(docker-machine env mhs-demo1)</li><li>$ docker network ls</li><li>NETWORK ID NAME DRIVER</li><li>d0bb78cbe7bd bridge bridge</li><li>1c0eb8f69ebb none null</li><li>412c2496d0eb host host</li><li>6b07d0be843f my-net overlay</li></ol><p>Both agents report they have the my-net network with the 6b07d0be843f ID. You now have a multi-host container network running!</p><h5><strong>Run an application on your network</strong></h5><p>Once your network is created, you can start a container on any of the hosts and it automatically is part of the network.</p><ol><li>Set your environment to the swarm manager.</li><li>$ eval $(docker-machine env --swarm mhs-demo0)</li><li>Start an Nginx web server on the mhs-demo0 instance.</li><li>$ docker run -itd \</li><li>--name=web \</li><li>--network=my-net \</li><li>--env=&quot;constraint:node==mhs-demo0&quot; \</li><li>nginx:alpine</li><li>Run a busybox instance on the mhs-demo1 instance and get the contents of the Nginx server&#x27;s home page.</li><li>$ docker run -it --rm \</li><li>--network=my-net \</li><li>--env=&quot;constraint:node==mhs-demo1&quot; \</li><li>busybox wget -O- http://web</li><li>Unable to find image \&#x27;busybox:latest\&#x27; locally</li><li>latest: Pulling from library/busybox</li><li>ab2b8a86ca6c: Pull complete</li><li>2c5ac3f849df: Pull complete</li><li>Digest: sha256:5551dbdfc48d66734d0f01cafee0952cb6e8eeecd1e2492240bf2fd9640c2279</li><li>Status: Downloaded newer image for busybox:latest</li><li>Connecting to web (10.0.9.2:80)</li><li><code>&lt;!DOCTYPE html&gt;</code></li><li><code>&lt;html&gt;</code></li><li><code>&lt;head&gt;</code></li><li><code>&lt;title&gt;Welcome to nginx!&lt;/title&gt;</code></li><li><code>&lt;style&gt;</code></li><li>body {</li><li>width: 35em;</li><li>margin: 0 auto;</li><li>font-family: Tahoma, Verdana, Arial, sans-serif;</li><li>}</li><li><code>&lt;/style&gt;</code></li><li><code>&lt;/head&gt;</code></li><li><code>&lt;body&gt;</code></li><li><code>&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;</code></li><li><code>&lt;p&gt;</code>If you see this page, the nginx web server is successfully installed and</li><li>working. Further configuration is required.<code>&lt;/p&gt;</code></li><li><code>&lt;p&gt;</code>For online documentation and support, refer to</li><li><code>&lt;a href=&quot;http://nginx.org/&quot;&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;</code></li><li>Commercial support is available at</li><li><code>&lt;a href=&quot;http://nginx.com/&quot;&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;</code></li><li><code>&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;</code></li><li><code>&lt;/body&gt;</code></li><li><code>&lt;/html&gt;</code></li><li><ul><li>100% |<strong><strong><strong><strong><strong><strong><strong>***</strong></strong></strong></strong></strong></strong></strong>| 612 0:00:00 ETA</li></ul></li></ol><h5><strong>Check external connectivity</strong></h5><p>As you&#x27;ve seen, Docker&#x27;s built-in overlay network driver provides out-of-the-box connectivity between the containers on multiple hosts within the same network. Additionally, containers connected to the multi-host network are automatically connected to the docker_gwbridge network. This network allows the containers to have external connectivity outside of their cluster.</p><ol><li>Change your environment to the swarm agent.</li><li>$ eval $(docker-machine env mhs-demo1)</li><li>View the docker_gwbridge network, by listing the networks.</li><li>$ docker network ls</li><li>NETWORK ID NAME DRIVER</li><li>6b07d0be843f my-net overlay</li><li>dd51763e6dd2 bridge bridge</li><li>b4234109bd9b none null</li><li>1aeead6dd890 host host</li><li>e1dbd5dff8be docker_gwbridge bridge</li><li>Repeat steps 1 and 2 on the swarm manager.</li><li>$ eval $(docker-machine env mhs-demo0)</li><li>$ docker network ls</li><li>NETWORK ID NAME DRIVER</li><li>6b07d0be843f my-net overlay</li><li>d0bb78cbe7bd bridge bridge</li><li>1c0eb8f69ebb none null</li><li>412c2496d0eb host host</li><li>97102a22e8d2 docker_gwbridge bridge</li><li>Check the Nginx container&#x27;s network interfaces.</li><li>$ docker container exec web ip addr</li><li>1: lo: <code>&lt;LOOPBACK,UP,LOWER_UP&gt;</code> mtu 65536 qdisc noqueue state UNKNOWN group default</li><li>link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</li><li>inet 127.0.0.1/8 scope host lo</li><li>valid_lft forever preferred_lft forever</li><li>inet6 ::1/128 scope host</li><li>valid_lft forever preferred_lft forever</li><li>22: eth0: <code>&lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt;</code> mtu 1450 qdisc noqueue state UP group default</li><li>link/ether 02:42:0a:00:09:03 brd ff:ff:ff:ff:ff:ff</li><li>inet 10.0.9.2/24 scope global eth0</li><li>valid_lft forever preferred_lft forever</li><li>inet6 fe80::42:aff:fe00:903/64 scope link</li><li>valid_lft forever preferred_lft forever</li><li>24: eth1: <code>&lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt;</code> mtu 1500 qdisc noqueue state UP group default</li><li>link/ether 02:42:ac:12:00:02 brd ff:ff:ff:ff:ff:ff</li><li>inet 172.18.0.2/16 scope global eth1</li><li>valid_lft forever preferred_lft forever</li><li>inet6 fe80::42:acff:fe12:2/64 scope link</li><li>valid_lft forever preferred_lft forever</li></ol><p>The eth0 interface represents the container interface that is connected to the my-net overlay network. While the eth1 interface represents the container interface that is connected to the docker_gwbridge network.</p><h4>Use Docker Compose with swarm classic</h4><p>Refer to the Networking feature introduced in <a href="https://docs.docker.com/compose/networking/">Compose V2 format</a> and execute the multi-host networking scenario in the swarm cluster used above.</p><h4>Next steps</h4><ul><li><a href="https://docs.docker.com/network/">Networking overview</a></li><li><a href="https://docs.docker.com/network/overlay/">Overlay networks</a></li></ul><p>Manage Application Data</p><h1>Manage data in Docker</h1><p><em>Estimated reading time: 8 minutes</em></p><p>It is possible to store data within the writable layer of a container, but there are some downsides:</p><ul><li>The data doesn&#x27;t persist when that container is no longer running, and it can be difficult to get the data out of the container if another process needs it.</li><li>A container&#x27;s writable layer is tightly coupled to the host machine where the container is running. You can&#x27;t easily move the data somewhere else.</li><li>Writing into a container&#x27;s writable layer requires a <a href="https://docs.docker.com/storage/storagedriver/">storage driver</a> to manage the filesystem. The storage driver provides a union filesystem, using the Linux kernel. This extra abstraction reduces performance as compared to using data volumes, which write directly to the host filesystem.</li></ul><p>Docker offers three different ways to mount data into a container from the Docker host: volumes, bind mounts, or <em>tmpfs</em> volumes. When in doubt, volumes are almost always the right choice. Keep reading for more information about each mechanism for mounting data into containers.</p><h2>Choose the right type of mount</h2><p>No matter which type of mount you choose to use, the data looks the same from within the container. It is exposed as either a directory or an individual file in the container&#x27;s filesystem.</p><p>An easy way to visualize the difference among volumes, bind mounts, and tmpfs mounts is to think about where the data lives on the Docker host.</p><ul><li><strong>Volumes</strong> are stored in a part of the host filesystem which is managed by Docker(/var/lib/docker/volumes/ on Linux). Non-Docker processes should not modify this part of the filesystem. Volumes are the best way to persist data in Docker.</li><li><strong>Bind mounts</strong> may be stored anywhere on the host system. They may even be important system files or directories. Non-Docker processes on the Docker host or a Docker container can modify them at any time.</li><li><strong>tmpfs mounts</strong> are stored in the host system&#x27;s memory only, and are never written to the host system&#x27;s filesystem.</li></ul><h3>More details about mount types</h3><ul><li><a href="https://docs.docker.com/storage/volumes/"><strong>Volumes</strong></a>: Created and managed by Docker. You can create a volume explicitly using the docker volume create command, or Docker can create a volume during container or service creation.</li></ul><p>When you create a volume, it is stored within a directory on the Docker host. When you mount the volume into a container, this directory is what is mounted into the container. This is similar to the way that bind mounts work, except that volumes are managed by Docker and are isolated from the core functionality of the host machine.</p><p>A given volume can be mounted into multiple containers simultaneously. When no running container is using a volume, the volume is still available to Docker and is not removed automatically. You can remove unused volumes using docker volume prune.</p><p>When you mount a volume, it may be <strong>named</strong> or <strong>anonymous</strong>. Anonymous volumes are not given an explicit name when they are first mounted into a container, so Docker gives them a random name that is guaranteed to be unique within a given Docker host. Besides the name, named and anonymous volumes behave in the same ways.</p><p>Volumes also support the use of volume drivers, which allow you to store your data on remote hosts or cloud providers, among other possibilities.</p><ul><li><a href="https://docs.docker.com/storage/bind-mounts/"><strong>Bind mounts</strong></a>: Available since the early days of Docker. Bind mounts have limited functionality compared to volumes. When you use a bind mount, a file or directory on the host machine is mounted into a container. The file or directory is referenced by its full path on the host machine. The file or directory does not need to exist on the Docker host already. It is created on demand if it does not yet exist. Bind mounts are very performant, but they rely on the host machine&#x27;s filesystem having a specific directory structure available. If you are developing new Docker applications, consider using named volumes instead. You can&#x27;t use Docker CLI commands to directly manage bind mounts.</li></ul><p><strong>Warning</strong>: One side effect of using bind mounts, for better or for worse, is that you can change the <strong>host</strong> filesystem via processes running in a <strong>container</strong>, including creating, modifying, or deleting important system files or directories. This is a powerful ability which can have security implications, including impacting non-Docker processes on the host system.</p><ul><li><a href="https://docs.docker.com/storage/tmpfs/"><strong>tmpfs mounts</strong></a>: A tmpfs mount is not persisted on disk, either on the Docker host or within a container. It can be used by a container during the lifetime of the container, to store non-persistent state or sensitive information. For instance, internally, swarm services use tmpfsmounts to mount <a href="https://docs.docker.com/engine/swarm/secrets/">secrets</a> into a service&#x27;s containers.</li></ul><p>Bind mounts and volumes can both mounted into containers using the -v or --volume flag, but the syntax for each is slightly different. For tmpfs mounts, you can use the --tmpfs flag. However, in Docker 17.06 and higher, we recommend using the --mount flag for both containers and services, for bind mounts, volumes, or tmpfs mounts, as the syntax is more clear.</p><h3>Good use cases for volumes</h3><p>Volumes are the preferred way to persist data in Docker containers and services. Some use cases for volumes include:</p><ul><li>Sharing data among multiple running containers. If you don&#x27;t explicitly create it, a volume is created the first time it is mounted into a container. When that container stops or is removed, the volume still exists. Multiple containers can mount the same volume simultaneously, either read-write or read-only. Volumes are only removed when you explicitly remove them.</li><li>When the Docker host is not guaranteed to have a given directory or file structure. Volumes help you decouple the configuration of the Docker host from the container runtime.</li><li>When you want to store your container&#x27;s data on a remote host or a cloud provider, rather than locally.</li><li>When you need to back up, restore, or migrate data from one Docker host to another, volumes are a better choice. You can stop containers using the volume, then back up the volume&#x27;s directory (such as /var/lib/docker/volumes/<code>&lt;volume-name&gt;</code>).</li></ul><h3>Good use cases for bind mounts</h3><p>In general, you should use volumes where possible. Bind mounts are appropriate for the following types of use case:</p><ul><li>Sharing configuration files from the host machine to containers. This is how Docker provides DNS resolution to containers by default, by mounting /etc/resolv.conf from the host machine into each container.</li><li>Sharing source code or build artifacts between a development environment on the Docker host and a container. For instance, you may mount a Maven target/ directory into a container, and each time you build the Maven project on the Docker host, the container gets access to the rebuilt artifacts.</li></ul><p>If you use Docker for development this way, your production Dockerfile would copy the production-ready artifacts directly into the image, rather than relying on a bind mount.</p><ul><li>When the file or directory structure of the Docker host is guaranteed to be consistent with the bind mounts the containers require.</li></ul><h3>Good use cases for tmpfs mounts</h3><p>tmpfs mounts are best used for cases when you do not want the data to persist either on the host machine or within the container. This may be for security reasons or to protect the performance of the container when your application needs to write a large volume of non-persistent state data.</p><h3>Tips for using bind mounts or volumes</h3><p>If you use either bind mounts or volumes, keep the following in mind:</p><ul><li>If you mount an <strong>empty volume</strong> into a directory in the container in which files or directories exist, these files or directories are propagated (copied) into the volume. Similarly, if you start a container and specify a volume which does not already exist, an empty volume is created for you. This is a good way to pre-populate data that another container needs.</li><li>If you mount a <strong>bind mount or non-empty volume</strong> into a directory in the container in which some files or directories exist, these files or directories are obscured by the mount, just as if you saved files into /mnt on a Linux host and then mounted a USB drive into /mnt. The contents of /mnt would be obscured by the contents of the USB drive until the USB drive were unmounted. The obscured files are not removed or altered, but are not accessible while the bind mount or volume is mounted.</li></ul><h3>Next steps</h3><ul><li>Learn more about <a href="https://docs.docker.com/storage/volumes/">volumes</a>.</li><li>Learn more about <a href="https://docs.docker.com/storage/bind-mounts/">bind mounts</a>.</li><li>Learn more about <a href="https://docs.docker.com/storage/tmpfs/">tmpfs mounts</a>.</li><li>Learn more about <a href="https://docs.docker.com/storage/storagedriver/">storage drivers</a>, which are not related to bind mounts or volumes, but allow you to store data in a container&#x27;s writable layer.</li></ul><h2>Use volumes</h2><p><em>Estimated reading time: 12 minutes</em></p><p>Volumes are the preferred mechanism for persisting data generated by and used by Docker containers. While <a href="https://docs.docker.com/storage/bind-mounts/">bind mounts</a> are dependent on the directory structure of the host machine, volumes are completely managed by Docker. Volumes have several advantages over bind mounts:</p><ul><li>Volumes are easier to back up or migrate than bind mounts.</li><li>You can manage volumes using Docker CLI commands or the Docker API.</li><li>Volumes work on both Linux and Windows containers.</li><li>Volumes can be more safely shared among multiple containers.</li><li>Volume drivers allow you to store volumes on remote hosts or cloud providers, to encrypt the contents of volumes, or to add other functionality.</li><li>A new volume&#x27;s contents can be pre-populated by a container.</li></ul><p>In addition, volumes are often a better choice than persisting data in a container&#x27;s writable layer, because using a volume does not increase the size of containers using it, and the volume&#x27;s contents exist outside the lifecycle of a given container.</p><p>If your container generates non-persistent state data, consider using a <a href="https://docs.docker.com/storage/tmpfs/">tmpfs mount</a> to avoid storing the data anywhere permanently, and to increase the container&#x27;s performance by avoiding writing into the container&#x27;s writable layer.</p><p>Volumes use rprivate bind propagation, and bind propagation is not configurable for volumes.</p><h3>Choose the -v or --mount flag</h3><p>Originally, the -v or --volume flag was used for standalone containers and the --mount flag was used for swarm services. However, starting with Docker 17.06, you can also use --mount with standalone containers. In general, --mount is more explicit and verbose. The biggest difference is that the -v syntax combines all the options together in one field, while the --mount syntax separates them. Here is a comparison of the syntax for each flag.</p><p><strong>Tip</strong>: New users should use the --mount syntax. Experienced users may be more familiar with the -v or --volume syntax, but are encouraged to use --mount, because research has shown it to be easier to use.</p><p>If you need to specify volume driver options, you must use --mount.</p><ul><li><strong>-v or --volume</strong>: Consists of three fields, separated by colon characters (:). The fields must be in the correct order, and the meaning of each field is not immediately obvious.<ul><li>In the case of named volumes, the first field is the name of the volume, and is unique on a given host machine. For anonymous volumes, the first field is omitted.</li><li>The second field is the path where the file or directory are mounted in the container.</li><li>The third field is optional, and is a comma-separated list of options, such as ro. These options are discussed below.</li></ul></li><li><strong>--mount</strong>: Consists of multiple key-value pairs, separated by commas and each consisting of a <code>&lt;key&gt;=&lt;value&gt;</code> tuple. The --mount syntax is more verbose than -v or --volume, but the order of the keys is not significant, and the value of the flag is easier to understand.<ul><li>The type of the mount, which can be <a href="https://docs.docker.com/storage/bind-mounts/">bind</a>, volume, or <a href="https://docs.docker.com/storage/tmpfs/">tmpfs</a>. This topic discusses volumes, so the type is always volume.</li><li>The source of the mount. For named volumes, this is the name of the volume. For anonymous volumes, this field is omitted. May be specified as source or src.</li><li>The destination takes as its value the path where the file or directory is mounted in the container. May be specified as destination, dst, or target.</li><li>The readonly option, if present, causes the bind mount to be <a href="https://docs.docker.com/storage/volumes/#use-a-read-only-volume">mounted into the container as read-only</a>.</li><li>The volume-opt option, which can be specified more than once, takes a key-value pair consisting of the option name and its value.</li></ul></li></ul><p>The examples below show both the --mount and -v syntax where possible, and --mount is presented first.</p><h4>Differences between -v and --mount behavior</h4><p>As opposed to bind mounts, all options for volumes are available for both --mount and -v flags.</p><p>When using volumes with services, only --mount is supported.</p><h3>Create and manage volumes</h3><p>Unlike a bind mount, you can create and manage volumes outside the scope of any container.</p><p><strong>Create a volume</strong>:</p><p>$ docker volume create my-vol</p><p><strong>List volumes</strong>:</p><p>$ docker volume ls</p><p>local my-vol</p><p><strong>Inspect a volume</strong>:</p><p>$ docker volume inspect my-vol</p><p>[</p><p>{</p><p>&quot;Driver&quot;: &quot;local&quot;,</p><p>&quot;Labels&quot;: {},</p><p>&quot;Mountpoint&quot;: &quot;/var/lib/docker/volumes/my-vol/_data&quot;,</p><p>&quot;Name&quot;: &quot;my-vol&quot;,</p><p>&quot;Options&quot;: {},</p><p>&quot;Scope&quot;: &quot;local&quot;</p><p>}</p><p>]</p><p><strong>Remove a volume</strong>:</p><p>$ docker volume rm my-vol</p><h3>Start a container with a volume</h3><p>If you start a container with a volume that does not yet exist, Docker creates the volume for you. The following example mounts the volume myvol2 into /app/ in the container.</p><p>The -v and --mount examples below produce the same result. You can&#x27;t run them both unless you remove the devtest container and the myvol2 volume after running the first one.</p><ul><li>--mount</li><li>-v</li></ul><p>$ docker run -d \</p><p>--name devtest \</p><p>-v myvol2:/app \</p><p>nginx:latest</p><p>Use docker inspect devtest to verify that the volume was created and mounted correctly. Look for the Mounts section:</p><p>&quot;Mounts&quot;: [</p><p>{</p><p>&quot;Type&quot;: &quot;volume&quot;,</p><p>&quot;Name&quot;: &quot;myvol2&quot;,</p><p>&quot;Source&quot;: &quot;/var/lib/docker/volumes/myvol2/_data&quot;,</p><p>&quot;Destination&quot;: &quot;/app&quot;,</p><p>&quot;Driver&quot;: &quot;local&quot;,</p><p>&quot;Mode&quot;: &quot;&quot;,</p><p>&quot;RW&quot;: true,</p><p>&quot;Propagation&quot;: &quot;&quot;</p><p>}</p><p>],</p><p>This shows that the mount is a volume, it shows the correct source and destination, and that the mount is read-write.</p><p>Stop the container and remove the volume.</p><p>$ docker container stop devtest</p><p>$ docker container rm devtest</p><p>$ docker volume rm myvol2</p><h4>Start a service with volumes</h4><p>When you start a service and define a volume, each service container uses its own local volume. None of the containers can share this data if you use the local volume driver, but some volume drivers do support shared storage. Docker for AWS and Docker for Azure both support persistent storage using the Cloudstor plugin.</p><p>The following example starts a nginx service with four replicas, each of which uses a local volume called myvol2.</p><p>$ docker service create -d \</p><p>--replicas=4 \</p><p>--name devtest-service \</p><p>--mount source=myvol2,target=/app \</p><p>nginx:latest</p><p>Use docker service ps devtest-service to verify that the service is running:</p><p>$ docker service ps devtest-service</p><p>ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS</p><p>4d7oz1j85wwn devtest-service.1 nginx:latest moby Running Running 14 seconds ago</p><p>Remove the service, which stops all its tasks:</p><p>$ docker service rm devtest-service</p><h5><strong>SYNTAX DIFFERENCES FOR SERVICES</strong></h5><p>The docker service create command does not support the -v or --volume flag. When mounting a volume into a service&#x27;s containers, you must use the --mount flag.</p><h4>Populate a volume using a container</h4><p>If you start a container which creates a new volume, as above, and the container has files or directories in the directory to be mounted (such as /app/ above), the directory&#x27;s contents are copied into the volume. The container then mounts and uses the volume, and other containers which use the volume also have access to the pre-populated content.</p><p>To illustrate this, this example starts an nginx container and populates the new volume nginx-volwith the contents of the container&#x27;s /usr/share/nginx/html directory, which is where Nginx stores its default HTML content.</p><p>The --mount and -v examples have the same end result.</p><ul><li>--mount</li><li>-v</li></ul><p>$ docker run -d \</p><p>--name=nginxtest \</p><p>-v nginx-vol:/usr/share/nginx/html \</p><p>nginx:latest</p><p>After running either of these examples, run the following commands to clean up the containers and volumes.</p><p>$ docker container stop nginxtest</p><p>$ docker container rm nginxtest</p><p>$ docker volume rm nginx-vol</p><h3>Use a read-only volume</h3><p>For some development applications, the container needs to write into the bind mount so that changes are propagated back to the Docker host. At other times, the container only needs read access to the data. Remember that multiple containers can mount the same volume, and it can be mounted read-write for some of them and read-only for others, at the same time.</p><p>This example modifies the one above but mounts the directory as a read-only volume, by adding ro to the (empty by default) list of options, after the mount point within the container. Where multiple options are present, separate them by commas.</p><p>The --mount and -v examples have the same result.</p><ul><li>--mount</li><li>-v</li></ul><p>$ docker run -d \</p><p>--name=nginxtest \</p><p>-v nginx-vol:/usr/share/nginx/html:ro \</p><p>nginx:latest</p><p>Use docker inspect nginxtest to verify that the bind mount was created correctly. Look for the Mounts section:</p><p>&quot;Mounts&quot;: [</p><p>{</p><p>&quot;Type&quot;: &quot;volume&quot;,</p><p>&quot;Name&quot;: &quot;nginx-vol&quot;,</p><p>&quot;Source&quot;: &quot;/var/lib/docker/volumes/nginx-vol/_data&quot;,</p><p>&quot;Destination&quot;: &quot;/usr/share/nginx/html&quot;,</p><p>&quot;Driver&quot;: &quot;local&quot;,</p><p>&quot;Mode&quot;: &quot;&quot;,</p><p>&quot;RW&quot;: false,</p><p>&quot;Propagation&quot;: &quot;&quot;</p><p>}</p><p>],</p><p>Stop and remove the container, and remove the volume:</p><p>$ docker container stop nginxtest</p><p>$ docker container rm nginxtest</p><p>$ docker volume rm nginx-vol</p><h3>Use a volume driver</h3><p>When you create a volume using docker volume create, or when you start a container which uses a not-yet-created volume, you can specify a volume driver. The following examples use the vieux/sshfsvolume driver, first when creating a standalone volume, and then when starting a container which creates a new volume.</p><h4>Initial set-up</h4><p>This example assumes that you have two nodes, the first of which is a Docker host and can connect to the second using SSH.</p><p>On the Docker host, install the vieux/sshfs plugin:</p><p>$ docker plugin install --grant-all-permissions vieux/sshfs</p><h4>Create a volume using a volume driver</h4><p>This example specifies a SSH password, but if the two hosts have shared keys configured, you can omit the password. Each volume driver may have zero or more configurable options, each of which is specified using an -o flag.</p><p>$ docker volume create --driver vieux/sshfs \</p><p>-o sshcmd=test\@node2:/home/test \</p><p>-o password=testpassword \</p><p>sshvolume</p><h4>Start a container which creates a volume using a volume driver</h4><p>This example specifies a SSH password, but if the two hosts have shared keys configured, you can omit the password. Each volume driver may have zero or more configurable options. <strong>If the volume driver requires you to pass options, you must use the --mount flag to mount the volume, rather than -v.</strong></p><p>$ docker run -d \</p><p>--name sshfs-container \</p><p>--volume-driver vieux/sshfs \</p><p>--mount src=sshvolume,target=/app,volume-opt=sshcmd=test\@node2:/home/test,volume-opt=password=testpassword \</p><p>nginx:latest</p><h3>Next steps</h3><ul><li>Learn about <a href="https://docs.docker.com/storage/bind-mounts/">bind mounts</a>.</li><li>Learn about <a href="https://docs.docker.com/storage/tmpfs/">tmpfs mounts</a>.</li><li>Learn about <a href="https://docs.docker.com/storage/storagedriver/">storage drivers</a>.</li></ul><h2>Use bind mounts</h2><p><em>Estimated reading time: 15 minutes</em></p><p>Bind mounts have been around since the early days of Docker. Bind mounts have limited functionality compared to <a href="https://docs.docker.com/storage/volumes/">volumes</a>. When you use a bind mount, a file or directory on the host machine is mounted into a container. The file or directory is referenced by its full or relative path on the host machine. By contrast, when you use a volume, a new directory is created within Docker&#x27;s storage directory on the host machine, and Docker manages that directory&#x27;s contents.</p><p>The file or directory does not need to exist on the Docker host already. It is created on demand if it does not yet exist. Bind mounts are very performant, but they rely on the host machine&#x27;s filesystem having a specific directory structure available. If you are developing new Docker applications, consider using <a href="https://docs.docker.com/storage/volumes/">named volumes</a> instead. You can&#x27;t use Docker CLI commands to directly manage bind mounts.</p><h3>Choosing the -v or --mount flag</h3><p>Originally, the -v or --volume flag was used for standalone containers and the --mount flag was used for swarm services. However, starting with Docker 17.06, you can also use --mount with standalone containers. In general, --mount is more explicit and verbose. The biggest difference is that the -v syntax combines all the options together in one field, while the --mount syntax separates them. Here is a comparison of the syntax for each flag.</p><p><strong>Tip</strong>: New users should use the --mount syntax. Experienced users may be more familiar with the -v or --volume syntax, but are encouraged to use --mount, because research has shown it to be easier to use.</p><ul><li><strong>-v or --volume</strong>: Consists of three fields, separated by colon characters (:). The fields must be in the correct order, and the meaning of each field is not immediately obvious.<ul><li>In the case of bind mounts, the first field is the path to the file or directory on the <strong>host machine</strong>.</li><li>The second field is the path where the file or directory is mounted in the container.</li><li>The third field is optional, and is a comma-separated list of options, such as ro, consistent, delegated, cached, z, and Z. These options are discussed below.</li></ul></li><li><strong>--mount</strong>: Consists of multiple key-value pairs, separated by commas and each consisting of a <code>&lt;key&gt;=&lt;value&gt;</code> tuple. The --mount syntax is more verbose than -v or --volume, but the order of the keys is not significant, and the value of the flag is easier to understand.<ul><li>The type of the mount, which can be bind, volume, or tmpfs. This topic discusses bind mounts, so the type is always bind.</li><li>The source of the mount. For bind mounts, this is the path to the file or directory on the Docker daemon host. May be specified as source or src.</li><li>The destination takes as its value the path where the file or directory is mounted in the container. May be specified as destination, dst, or target.</li><li>The readonly option, if present, causes the bind mount to be <a href="https://docs.docker.com/storage/bind-mounts/#use-a-read-only-bind-mount">mounted into the container as read-only</a>.</li><li>The bind-propagation option, if present, changes the <a href="https://docs.docker.com/storage/bind-mounts/#configure-bind-propagation">bind propagation</a>. May be one of rprivate, private, rshared, shared, rslave, slave.</li><li>The <a href="https://docs.docker.com/storage/bind-mounts/#configure-mount-consistency-for-macos">consistency</a> option, if present, may be one of consistent, delegated, or cached. This setting only applies to Docker for Mac, and is ignored on all other platforms.</li><li>The --mount flag does not support z or Z options for modifying selinux labels.</li></ul></li></ul><p>The examples below show both the --mount and -v syntax where possible, and --mount is presented first.</p><h4>Differences between -v and --mount behavior</h4><p>Because the -v and --volume flags have been a part of Docker for a long time, their behavior cannot be changed. This means that <strong>there is one behavior that is different between -v and --mount.</strong></p><p>If you use -v or --volume to bind-mount a file or directory that does not yet exist on the Docker host, -v creates the endpoint for you. <strong>It is always created as a directory.</strong></p><p>If you use --mount to bind-mount a file or directory that does not yet exist on the Docker host, Docker does <strong>not</strong> automatically create it for you, but generates an error.</p><h3>Start a container with a bind mount</h3><p>Consider a case where you have a directory source and that when you build the source code, the artifacts are saved into another directory source/target/. You want the artifacts to be available to the container at /app/, and you want the container to get access to a new build each time you build the source on your development host. Use the following command to bind-mount the target/ directory into your container at /app/. Run the command from within the source directory. The $(pwd) sub-command expands to the current working directory on Linux or macOS hosts.</p><p>The --mount and -v examples below produce the same result. You can&#x27;t run them both unless you remove the devtest container after running the first one.</p><ul><li>--mount</li><li>-v</li></ul><p>$ docker run -d \</p><p>-it \</p><p>--name devtest \</p><p>--mount type=bind,source=&quot;$(pwd)&quot;/target,target=/app \</p><p>nginx:latest</p><p>Use docker inspect devtest to verify that the bind mount was created correctly. Look for the Mountssection:</p><p>&quot;Mounts&quot;: [</p><p>{</p><p>&quot;Type&quot;: &quot;bind&quot;,</p><p>&quot;Source&quot;: &quot;/tmp/source/target&quot;,</p><p>&quot;Destination&quot;: &quot;/app&quot;,</p><p>&quot;Mode&quot;: &quot;&quot;,</p><p>&quot;RW&quot;: true,</p><p>&quot;Propagation&quot;: &quot;rprivate&quot;</p><p>}</p><p>],</p><p>This shows that the mount is a bind mount, it shows the correct source and destination, it shows that the mount is read-write, and that the propagation is set to rprivate.</p><p>Stop the container:</p><p>$ docker container stop devtest</p><p>$ docker container rm devtest</p><h4>Mounting into a non-empty directory on the container</h4><p>If you bind-mount into a non-empty directory on the container, the directory&#x27;s existing contents are obscured by the bind mount. This can be beneficial, such as when you want to test a new version of your application without building a new image. However, it can also be surprising and this behavior differs from that of <a href="https://docs.docker.com/storage/volumes/">docker volumes</a>.</p><p>This example is contrived to be extreme, but replaces the contents of the container&#x27;s /usr/ directory with the /tmp/ directory on the host machine. In most cases, this would result in a non-functioning container.</p><p>The --mount and -v examples have the same end result.</p><ul><li>--mount</li><li>-v</li></ul><p>$ docker run -d \</p><p>-it \</p><p>--name broken-container \</p><p>--mount type=bind,source=/tmp,target=/usr \</p><p>nginx:latest</p><p>docker: Error response from daemon: oci runtime error: container_linux.go:262:</p><p>starting container process caused &quot;exec: \&quot;nginx\&quot;: executable file not found in $PATH&quot;.</p><p>The container is created but does not start. Remove it:</p><p>$ docker container rm broken-container</p><h3>Use a read-only bind mount</h3><p>For some development applications, the container needs to write into the bind mount, so changes are propagated back to the Docker host. At other times, the container only needs read access.</p><p>This example modifies the one above but mounts the directory as a read-only bind mount, by adding ro to the (empty by default) list of options, after the mount point within the container. Where multiple options are present, separate them by commas.</p><p>The --mount and -v examples have the same result.</p><ul><li>--mount</li><li>-v</li></ul><p>$ docker run -d \</p><p>-it \</p><p>--name devtest \</p><p>--mount type=bind,source=&quot;$(pwd)&quot;/target,target=/app,readonly \</p><p>nginx:latest</p><p>Use docker inspect devtest to verify that the bind mount was created correctly. Look for the Mountssection:</p><p>&quot;Mounts&quot;: [</p><p>{</p><p>&quot;Type&quot;: &quot;bind&quot;,</p><p>&quot;Source&quot;: &quot;/tmp/source/target&quot;,</p><p>&quot;Destination&quot;: &quot;/app&quot;,</p><p>&quot;Mode&quot;: &quot;ro&quot;,</p><p>&quot;RW&quot;: false,</p><p>&quot;Propagation&quot;: &quot;rprivate&quot;</p><p>}</p><p>],</p><p>Stop the container:</p><p>$ docker container stop devtest</p><p>$ docker container rm devtest</p><h3>Configure bind propagation</h3><p>Bind propagation defaults to rprivate for both bind mounts and volumes. It is only configurable for bind mounts, and only on Linux host machines. Bind propagation is an advanced topic and many users never need to configure it.</p><p>Bind propagation refers to whether or not mounts created within a given bind-mount or named volume can be propagated to replicas of that mount. Consider a mount point /mnt, which is also mounted on /tmp. The propagation settings control whether a mount on /tmp/a would also be available on /mnt/a. Each propagation setting has a recursive counterpoint. In the case of recursion, consider that /tmp/a is also mounted as /foo. The propagation settings control whether /mnt/a and/or /tmp/awould exist.</p><p>  <strong>Propagation setting</strong>   <strong>Description</strong></p><hr/><p>  shared                    Sub-mounts of the original mount are exposed to replica mounts, and sub-mounts of replica mounts are also propagated to the original mount.
slave                     similar to a shared mount, but only in one direction. If the original mount exposes a sub-mount, the replica mount can see it. However, if the replica mount exposes a sub-mount, the original mount cannot see it.
private                   The mount is private. Sub-mounts within it are not exposed to replica mounts, and sub-mounts of replica mounts are not exposed to the original mount.
rshared                   The same as shared, but the propagation also extends to and from mount points nested within any of the original or replica mount points.
rslave                    The same as slave, but the propagation also extends to and from mount points nested within any of the original or replica mount points.
rprivate                  The default. The same as private, meaning that no mount points anywhere within the original or replica mount points propagate in either direction.</p><p>Before you can set bind propagation on a mount point, the host filesystem needs to already support bind propagation.</p><p>For more information about bind propagation, see the <a href="https://www.kernel.org/doc/Documentation/filesystems/sharedsubtree.txt">Linux kernel documentation for shared subtree</a>.</p><p>The following example mounts the target/ directory into the container twice, and the second mount sets both the ro option and the rslave bind propagation option.</p><p>The --mount and -v examples have the same result.</p><ul><li>--mount</li><li>-v</li></ul><p>$ docker run -d \</p><p>-it \</p><p>--name devtest \</p><p>--mount type=bind,source=&quot;$(pwd)&quot;/target,target=/app \</p><p>--mount type=bind,source=&quot;$(pwd)&quot;/target,target=/app2,readonly,bind-propagation=rslave \</p><p>nginx:latest</p><p>Now if you create /app/foo/, /app2/foo/ also exists.</p><h3>Configure the selinux label</h3><p>If you use selinux you can add the z or Z options to modify the selinux label of the <strong>host file or directory</strong> being mounted into the container. This affects the file or directory on the host machine itself and can have consequences outside of the scope of Docker.</p><ul><li>The z option indicates that the bind mount content is shared among multiple containers.</li><li>The Z option indicates that the bind mount content is private and unshared.</li></ul><p>Use <strong>extreme</strong> caution with these options. Bind-mounting a system directory such as /home or /usrwith the Z option renders your host machine inoperable and you may need to relabel the host machine files by hand.</p><p><strong>Important</strong>: When using bind mounts with services, selinux labels (:Z and :z), as well as :ro are ignored. See <a href="https://github.com/moby/moby/issues/32579">moby/moby #32579</a> for details.</p><p>This example sets the z option to specify that multiple containers can share the bind mount&#x27;s contents:</p><p>It is not possible to modify the selinux label using the --mount flag.</p><p>$ docker run -d \</p><p>-it \</p><p>--name devtest \</p><p>-v &quot;$(pwd)&quot;/target:/app:z \</p><p>nginx:latest</p><h3>Configure mount consistency for macOS</h3><p>Docker for Mac uses osxfs to propagate directories and files shared from macOS to the Linux VM. This propagation makes these directories and files available to Docker containers running on Docker for Mac.</p><p>By default, these shares are fully-consistent, meaning that every time a write happens on the macOS host or through a mount in a container, the changes are flushed to disk so that all participants in the share have a fully-consistent view. Full consistency can severely impact performance in some cases. Docker 17.05 and higher introduce options to tune the consistency setting on a per-mount, per-container basis. The following options are available:</p><ul><li>consistent or default: The default setting with full consistency, as described above.</li><li>delegated: The container runtime&#x27;s view of the mount is authoritative. There may be delays before updates made in a container are visible on the host.</li><li>cached: The macOS host&#x27;s view of the mount is authoritative. There may be delays before updates made on the host are visible within a container.</li></ul><p>These options are completely ignored on all host operating systems except macOS.</p><p>The --mount and -v examples have the same result.</p><ul><li>--mount</li><li>-v</li></ul><p>$ docker run -d \</p><p>-it \</p><p>--name devtest \</p><p>--mount type=bind,source=&quot;$(pwd)&quot;/target,destination=/app,consistency=cached \</p><p>nginx:latest</p><h3>Next steps</h3><ul><li>Learn about <a href="https://docs.docker.com/storage/volumes/">volumes</a>.</li><li>Learn about <a href="https://docs.docker.com/storage/tmpfs/">tmpfs mounts</a>.</li><li>Learn about <a href="https://docs.docker.com/storage/storagedriver/">storage drivers</a>.</li></ul><h2>Use tmpfs mounts</h2><p><em>Estimated reading time: 4 minutes</em></p><p><a href="https://docs.docker.com/storage/volumes/">Volumes</a> and <a href="https://docs.docker.com/storage/bind-mounts/">bind mounts</a> are mounted into the container&#x27;s filesystem by default, and their contents are stored on the host machine.</p><p>There may be cases where you do not want to store a container&#x27;s data on the host machine, but you also don&#x27;t want to write the data into the container&#x27;s writable layer, for performance or security reasons, or if the data relates to non-persistent application state. An example might be a temporary one-time password that the container&#x27;s application creates and uses as-needed.</p><p>To give the container access to the data without writing it anywhere permanently, you can use a tmpfsmount, which is only stored in the host machine&#x27;s memory (or swap, if memory is low). When the container stops, the tmpfs mount is removed. If a container is committed, the tmpfs mount is not saved.</p><h3>Choosing the --tmpfs or --mount flag</h3><p>Originally, the --tmpfs flag was used for standalone containers and the --mount flag was used for swarm services. However, starting with Docker 17.06, you can also use --mount with standalone containers. In general, --mount is more explicit and verbose. The biggest difference is that the--tmpfs flag does not support any configurable options.</p><p><strong>Tip</strong>: New users should use the --mount syntax. Experienced users may be more familiar with the --tmpfs syntax, but are encouraged to use --mount, because research has shown it to be easier to use.</p><ul><li><strong>--tmpfs</strong>: Mounts a tmpfs mount without allowing you to specify any configurable options, and can only be used with standalone containers.</li><li><strong>--mount</strong>: Consists of multiple key-value pairs, separated by commas and each consisting of a <code>&lt;key&gt;=&lt;value&gt;</code> tuple. The --mount syntax is more verbose than -v or --volume, but the order of the keys is not significant, and the value of the flag is easier to understand.<ul><li>The type of the mount, which can be <a href="https://docs.docker.com/storage/bind-mounts-md">bind</a>, volume, or <a href="https://docs.docker.com/storage/tmpfs/">tmpfs</a>. This topic discusses tmpfs, so the type is always tmpfs.</li><li>The destination takes as its value the path where the tmpfs mount is mounted in the container. May be specified as destination, dst, or target.</li><li>The tmpfs-type and tmpfs-mode options. See <a href="https://docs.docker.com/storage/tmpfs/#tmpfs-options">tmpfs options</a>.</li></ul></li></ul><p>The examples below show both the --mount and --tmpfs syntax where possible, and --mount is presented first.</p><h4>Differences between --tmpfs and --mount behavior</h4><ul><li>The --tmpfs flag does not allow you to specify any configurable options.</li><li>The --tmpfs flag cannot be used with swarm services. You must use --mount.</li></ul><h3>Limitations of tmpfs containers</h3><ul><li>tmpfs mounts cannot be shared among containers.</li><li>tmpfs mounts only work on Linux containers, and not on Windows containers.</li></ul><h3>Use a tmpfs mount in a container</h3><p>To use a tmpfs mount in a container, use the --tmpfs flag, or use the --mount flag with type=tmpfs and destination options. There is no source for tmpfs mounts. The following example creates a tmpfs mount at /app in a Nginx container. The first example uses the --mountflag and the second uses the --tmpfs flag.</p><ul><li>--mount</li><li>--tmpfs</li></ul><p>$ docker run -d \</p><p>-it \</p><p>--name tmptest \</p><p>--mount type=tmpfs,destination=/app \</p><p>nginx:latest</p><p>Verify that the mount is a tmpfs mount by running docker container inspect tmptest and looking for the Mounts section:</p><p>&quot;Tmpfs&quot;: {</p><p>&quot;/app&quot;: &quot;&quot;</p><p>},</p><p>Remove the container:</p><p>$ docker container stop tmptest</p><p>$ Docker container rm tmptest</p><h4>Specify tmpfs options</h4><p>tmpfs mounts allow for two configuration options, neither of which is required. If you need to specify these options, you must use the --mount flag, as the --tmpfs flag does not support them.</p><p>  <strong>Option</strong>   <strong>Description</strong></p><hr/><p>  tmpfs-size   Size of the tmpfs mount in bytes. Unlimited by default.
tmpfs-mode   File mode of the tmpfs in octal. For instance, 700 or 0770. Defaults to 1777 or world-writable.</p><p>The following example sets the tmpfs-mode to 1770, so that it is not world-readable within the container.</p><p>docker run -d \</p><p>-it \</p><p>--name tmptest \</p><p>--mount type=tmpfs,destination=/app,tmpfs-mode=1770 \</p><p>nginx:latest</p><h3>Next steps</h3><ul><li>Learn about <a href="https://docs.docker.com/storage/volumes/">volumes</a></li><li>Learn about <a href="https://docs.docker.com/storage/bind-mounts/">bind mounts</a></li><li>Learn about <a href="https://docs.docker.com/storage/storagedriver/">storage drivers</a></li></ul><h2>Troubleshoot volume errors</h2><p><em>Estimated reading time: 1 minute</em></p><p>This topic discusses errors which may occur when you use Docker volumes or bind mounts.</p><h3>Error: Unable to remove filesystem</h3><p>Some container-based utilities, such as <a href="https://github.com/google/cadvisor">Google cAdvisor</a>, mount Docker system directories, such as /var/lib/docker/, into a container. For instance, the documentation for cadvisor instructs you to run the cadvisor container as follows:</p><p>$ sudo docker run \</p><p>--volume=/:/rootfs:ro \</p><p>--volume=/var/run:/var/run:rw \</p><p>--volume=/sys:/sys:ro \</p><p>--volume=/var/lib/docker/:/var/lib/docker:ro \</p><p>--publish=8080:8080 \</p><p>--detach=true \</p><p>--name=cadvisor \</p><p>google/cadvisor:latest</p><p>When you bind-mount /var/lib/docker/, this effectively mounts all resources of all other running containers as filesystems within the container which mounts /var/lib/docker/. When you attempt to remove any of these containers, the removal attempt may fail with an error like the following:</p><p>Error: Unable to remove filesystem for</p><p>74bef250361c7817bee19349c93139621b272bc8f654ae112dd4eb9652af9515:</p><p>remove /var/lib/docker/containers/74bef250361c7817bee19349c93139621b272bc8f654ae112dd4eb9652af9515/shm:</p><p>Device or resource busy</p><p>The problem occurs if the container which bind-mounts /var/lib/docker/ uses statfs or fstatfson filesystem handles within /var/lib/docker/ and does not close them.</p><p>Typically, we would advise against bind-mounting /var/lib/docker in this way. However, cAdvisorrequires this bind-mount for core functionality.</p><p>If you are unsure which process is causing the path mentioned in the error to be busy and preventing it from being removed, you can use the lsof command to find its process. For instance, for the error above:</p><p>$ sudo lsof /var/lib/docker/containers/74bef250361c7817bee19349c93139621b272bc8f654ae112dd4eb9652af9515/shm</p><p>To work around this problem, stop the container which bind-mounts /var/lib/docker and try again to remove the other container.</p><h2>Store Data within Containers</h2><h3>About storage drivers</h3><p><em>Estimated reading time: 16 minutes</em></p><p>To use storage drivers effectively, it&#x27;s important to know how Docker builds and stores images, how these images are used by containers. You can use this information to make informed choices about the best way to persist data from your applications and avoid performance problems along the way.</p><p><strong>Note</strong>: Storage drivers allow you to persist data in the writable layer of your container. This is the least efficient way to persist data. <a href="https://docs.docker.com/storage/volumes/">Volumes</a> or <a href="https://docs.docker.com/storage/bind-mounts/">bind mounts</a> provide much better read and write performance, and volumes provide more security and isolation than either storage drivers or bind mounts. Neither volumes nor bind mounts use most of the concepts described in this topic.</p><h4>Images and layers</h4><p>A Docker image is built up from a series of layers. Each layer represents an instruction in the image&#x27;s Dockerfile. Each layer except the very last one is read-only. Consider the following Dockerfile:</p><p>FROM ubuntu:15.04</p><p>COPY . /app</p><p>RUN make /app</p><p>CMD python /app/app.py</p><p>This Dockerfile contains four commands, each of which creates a layer. The FROM statement starts out by creating a layer from the ubuntu:15.04 image. The COPY command adds some files from your Docker client&#x27;s current directory. The RUN command builds your application using the makecommand. Finally, the last layer specifies what command to run within the container.</p><p>Each layer is only a set of differences from the layer before it. The layers are stacked on top of each other. When you create a new container, you add a new writable layer on top of the underlying layers. This layer is often called the &quot;container layer&quot;. All changes made to the running container, such as writing new files, modifying existing files, and deleting files, are written to this thin writable container layer. The diagram below shows a container based on the Ubuntu 15.04 image.</p><p>A storage driver handles the details about the way these layers interact with each other. Different storage drivers are available, which have advantages and disadvantages in different situations.</p><h4>Container and layers</h4><p>The major difference between a container and an image is the top writable layer. All writes to the container that add new or modify existing data are stored in this writable layer. When the container is deleted, the writable layer is also deleted. The underlying image remains unchanged.</p><p>Because each container has its own writable container layer, and all changes are stored in this container layer, multiple containers can share access to the same underlying image and yet have their own data state. The diagram below shows multiple containers sharing the same Ubuntu 15.04 image.</p><p><strong>Note</strong>: If you need multiple images to have shared access to the exact same data, store this data in a Docker volume and mount it into your containers.</p><p>Docker uses storage drivers to manage the contents of the image layers and the writable container layer. Each storage driver handles the implementation differently, but all drivers use stackable image layers and the copy-on-write (CoW) strategy.</p><h4>Container size on disk</h4><p>To view the approximate size of a running container, you can use the docker ps -s command. Two different columns relate to size.</p><ul><li>size: the amount of data (on disk) that is used for the writable layer of each container</li><li>virtual size: the amount of data used for the read-only image data used by the container plus the container&#x27;s writable layer size. Multiple containers may share some or all read-only image data. Two containers started from the same image share 100% of the read-only data, while two containers with different images which have layers in common share those common layers. Therefore, you can&#x27;t just total the virtual sizes. This over-estimates the total disk usage by a potentially non-trivial amount.</li></ul><p>The total disk space used by all of the running containers on disk is some combination of each container&#x27;s size and the virtual size values. If multiple containers started from the same exact image, the total size on disk for these containers would be SUM (size of containers) plus one container&#x27;s (virtual size- size).</p><p>This also does not count the following additional ways a container can take up disk space:</p><ul><li>Disk space used for log files if you use the json-file logging driver. This can be non-trivial if your container generates a large amount of logging data and log rotation is not configured.</li><li>Volumes and bind mounts used by the container.</li><li>Disk space used for the container&#x27;s configuration files, which are typically small.</li><li>Memory written to disk (if swapping is enabled).</li><li>Checkpoints, if you&#x27;re using the experimental checkpoint/restore feature.</li></ul><h4>The copy-on-write (CoW) strategy</h4><p>Copy-on-write is a strategy of sharing and copying files for maximum efficiency. If a file or directory exists in a lower layer within the image, and another layer (including the writable layer) needs read access to it, it just uses the existing file. The first time another layer needs to modify the file (when building the image or running the container), the file is copied into that layer and modified. This minimizes I/O and the size of each of the subsequent layers. These advantages are explained in more depth below.</p><h5><strong>Sharing promotes smaller images</strong></h5><p>When you use docker pull to pull down an image from a repository, or when you create a container from an image that does not yet exist locally, each layer is pulled down separately, and stored in Docker&#x27;s local storage area, which is usually /var/lib/docker/ on Linux hosts. You can see these layers being pulled in this example:</p><p>$ docker pull ubuntu:15.04</p><p>15.04: Pulling from library/ubuntu</p><p>1ba8ac955b97: Pull complete</p><p>f157c4e5ede7: Pull complete</p><p>0b7e98f84c4c: Pull complete</p><p>a3ed95caeb02: Pull complete</p><p>Digest: sha256:5e279a9df07990286cce22e1b0f5b0490629ca6d187698746ae5e28e604a640e</p><p>Status: Downloaded newer image for ubuntu:15.04</p><p>Each of these layers is stored in its own directory inside the Docker host&#x27;s local storage area. To examine the layers on the filesystem, list the contents of /var/lib/docker/<code style="background-color:lightgray">&lt;storage-driver&gt;</code>/layers/. This example uses aufs, which is the default storage driver:</p><p>$ ls /var/lib/docker/aufs/layers</p><p>1d6674ff835b10f76e354806e16b950f91a191d3b471236609ab13a930275e24</p><p>5dbb0cbe0148cf447b9464a358c1587be586058d9a4c9ce079320265e2bb94e7</p><p>bef7199f2ed8e86fa4ada1309cfad3089e0542fec8894690529e4c04a7ca2d73</p><p>ebf814eccfe98f2704660ca1d844e4348db3b5ccc637eb905d4818fbfb00a06a</p><p>The directory names do not correspond to the layer IDs (this has been true since Docker 1.10).</p><p>Now imagine that you have two different Dockerfiles. You use the first one to create an image called acme/my-base-image:1.0.</p><p>FROM ubuntu:16.10</p><p>COPY . /app</p><p>The second one is based on acme/my-base-image:1.0, but has some additional layers:</p><p>FROM acme/my-base-image:1.0</p><p>CMD /app/hello.sh</p><p>The second image contains all the layers from the first image, plus a new layer with the CMDinstruction, and a read-write container layer. Docker already has all the layers from the first image, so it does not need to pull them again. The two images share any layers they have in common.</p><p>If you build images from the two Dockerfiles, you can use docker image ls and docker historycommands to verify that the cryptographic IDs of the shared layers are the same.</p><ol><li>Make a new directory cow-test/ and change into it.</li><li>Within cow-test/, create a new file with the following contents:</li><li>#!/bin/sh</li><li>echo &quot;Hello world&quot;</li></ol><p>Save the file, and make it executable:</p><p>chmod +x hello.sh</p><ol><li>Copy the contents of the first Dockerfile above into a new file called Dockerfile.base.</li><li>Copy the contents of the second Dockerfile above into a new file called Dockerfile.</li><li>Within the cow-test/ directory, build the first image. Don&#x27;t forget to include the final . in the command. That sets the PATH, which tells Docker where to look for any files that need to be added to the image.</li><li>$ docker build -t acme/my-base-image:1.0 -f Dockerfile.base .</li><li>Sending build context to Docker daemon 4.096kB</li><li>Step 1/2 : FROM ubuntu:16.10</li><li>---&gt; 31005225a745</li><li>Step 2/2 : COPY . /app</li><li>---&gt; Using cache</li><li>---&gt; bd09118bcef6</li><li>Successfully built bd09118bcef6</li><li>Successfully tagged acme/my-base-image:1.0</li><li>Build the second image.</li><li>$ docker build -t acme/my-final-image:1.0 -f Dockerfile .</li><li>Sending build context to Docker daemon 4.096kB</li><li>Step 1/2 : FROM acme/my-base-image:1.0</li><li>---&gt; bd09118bcef6</li><li>Step 2/2 : CMD /app/hello.sh</li><li>---&gt; Running in a07b694759ba</li><li>---&gt; dbf995fc07ff</li><li>Removing intermediate container a07b694759ba</li><li>Successfully built dbf995fc07ff</li><li>Successfully tagged acme/my-final-image:1.0</li><li>Check out the sizes of the images:</li><li>$ docker image ls</li><li>REPOSITORY TAG IMAGE ID CREATED SIZE</li><li>acme/my-final-image 1.0 dbf995fc07ff 58 seconds ago 103MB</li><li>acme/my-base-image 1.0 bd09118bcef6 3 minutes ago 103MB</li><li>Check out the layers that comprise each image:</li><li>$ docker history bd09118bcef6</li><li>IMAGE CREATED CREATED BY SIZE COMMENT</li><li>bd09118bcef6 4 minutes ago /bin/sh -c #(nop) COPY dir:35a7eb158c1504e... 100B</li><li>31005225a745 3 months ago /bin/sh -c #(nop) CMD <!-- -->[&quot;/bin/bash&quot;]<!-- --> 0B</li><li><code>&lt;missing&gt;</code> 3 months ago /bin/sh -c mkdir -p /run/systemd &amp;&amp; echo \&#x27;... 7B</li><li><code>&lt;missing&gt;</code> 3 months ago /bin/sh -c sed -i \&#x27;s/\^#\s<em>(<!-- -->deb.</em>universe<!-- -->.<!-- -->.. 2.78kB</li><li><code>&lt;missing&gt;</code> 3 months ago /bin/sh -c rm -rf /var/lib/apt/lists/* 0B</li><li><code>&lt;missing&gt; 3 months ago /bin/sh -c set -xe &amp;&amp; echo \&#x27;#!/bin/sh\&#x27; &gt;</code>... 745B</li><li><code>&lt;missing&gt;</code> 3 months ago /bin/sh -c #(nop) ADD file:eef57983bd66e3a... 103MB</li><li>$ docker history dbf995fc07ff</li><li>IMAGE CREATED CREATED BY SIZE COMMENT</li><li>dbf995fc07ff 3 minutes ago /bin/sh -c #(nop) CMD [&quot;/bin/sh&quot; &quot;-c&quot; &quot;/a... 0B</li><li>bd09118bcef6 5 minutes ago /bin/sh -c #(nop) COPY dir:35a7eb158c1504e... 100B</li><li>31005225a745 3 months ago /bin/sh -c #(nop) CMD <!-- -->[&quot;/bin/bash&quot;]<!-- --> 0B</li><li><code>&lt;missing&gt;</code> 3 months ago /bin/sh -c mkdir -p /run/systemd &amp;&amp; echo \&#x27;... 7B</li><li><code>&lt;missing&gt;</code> 3 months ago /bin/sh -c sed -i \&#x27;s/\^#\s<em>(<!-- -->deb.</em>universe<!-- -->.<!-- -->.. 2.78kB</li><li><code>&lt;missing&gt;</code> 3 months ago /bin/sh -c rm -rf /var/lib/apt/lists/* 0B</li><li><code>&lt;missing&gt; 3 months ago /bin/sh -c set -xe &amp;&amp; echo \&#x27;#!/bin/sh\&#x27; &gt;</code>... 745B</li><li><code>&lt;missing&gt;</code> 3 months ago /bin/sh -c #(nop) ADD file:eef57983bd66e3a... 103MB</li></ol><p>Notice that all the layers are identical except the top layer of the second image. All the other layers are shared between the two images, and are only stored once in /var/lib/docker/. The new layer actually doesn&#x27;t take any room at all, because it is not changing any files, but only running a command.</p><p><strong>Note</strong>: The <code style="background-color:lightgray">&lt;missing&gt;</code> lines in the docker history output indicate that those layers were built on another system and are not available locally. This can be ignored.</p><h5><strong>Copying makes containers efficient</strong></h5><p>When you start a container, a thin writable container layer is added on top of the other layers. Any changes the container makes to the filesystem are stored here. Any files the container does not change do not get copied to this writable layer. This means that the writable layer is as small as possible.</p><p>When an existing file in a container is modified, the storage driver performs a copy-on-write operation. The specifics steps involved depend on the specific storage driver. For the default aufs driver and the overlay and overlay2 drivers, the copy-on-write operation follows this rough sequence:</p><ul><li>Search through the image layers for the file to update. The process starts at the newest layer and works down to the base layer one layer at a time. When results are found, they are added to a cache to speed future operations.</li><li>Perform a copy_up operation on the first copy of the file that is found, to copy the file to the container&#x27;s writable layer.</li><li>Any modifications are made to this copy of the file, and the container cannot see the read-only copy of the file that exists in the lower layer.</li></ul><p>Btrfs, ZFS, and other drivers handle the copy-on-write differently. You can read more about the methods of these drivers later in their detailed descriptions.</p><p>Containers that write a lot of data consume more space than containers that do not. This is because most write operations consume new space in the container&#x27;s thin writable top layer.</p><p><strong>Note</strong>: for write-heavy applications, you should not store the data in the container. Instead, use Docker volumes, which are independent of the running container and are designed to be efficient for I/O. In addition, volumes can be shared among containers and do not increase the size of your container&#x27;s writable layer.</p><p>A copy_up operation can incur a noticeable performance overhead. This overhead is different depending on which storage driver is in use. Large files, lots of layers, and deep directory trees can make the impact more noticeable. This is mitigated by the fact that each copy_up operation only occurs the first time a given file is modified.</p><p>To verify the way that copy-on-write works, the following procedures spins up 5 containers based on the acme/my-final-image:1.0 image we built earlier and examines how much room they take up.</p><p><strong>Note</strong>: This procedure doesn&#x27;t work on Docker for Mac or Docker for Windows.</p><ol><li>From a terminal on your Docker host, run the following docker run commands. The strings at the end are the IDs of each container.</li><li>$ docker run -dit --name my_container_1 acme/my-final-image:1.0 bash \</li><li>&amp;&amp; docker run -dit --name my_container_2 acme/my-final-image:1.0 bash \</li><li>&amp;&amp; docker run -dit --name my_container_3 acme/my-final-image:1.0 bash \</li><li>&amp;&amp; docker run -dit --name my_container_4 acme/my-final-image:1.0 bash \</li><li>&amp;&amp; docker run -dit --name my_container_5 acme/my-final-image:1.0 bash</li><li>c36785c423ec7e0422b2af7364a7ba4da6146cbba7981a0951fcc3fa0430c409</li><li>dcad7101795e4206e637d9358a818e5c32e13b349e62b00bf05cd5a4343ea513</li><li>1e7264576d78a3134fbaf7829bc24b1d96017cf2bc046b7cd8b08b5775c33d0c</li><li>38fa94212a419a082e6a6b87a8e2ec4a44dd327d7069b85892a707e3fc818544</li><li>1a174fc216cccf18ec7d4fe14e008e30130b11ede0f0f94a87982e310cf2e765</li><li>Run the docker ps command to verify the 5 containers are running.</li><li>CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES</li><li>1a174fc216cc acme/my-final-image:1.0 &quot;bash&quot; About a minute ago Up About a minute my_container_5</li><li>38fa94212a41 acme/my-final-image:1.0 &quot;bash&quot; About a minute ago Up About a minute my_container_4</li><li>1e7264576d78 acme/my-final-image:1.0 &quot;bash&quot; About a minute ago Up About a minute my_container_3</li><li>dcad7101795e acme/my-final-image:1.0 &quot;bash&quot; About a minute ago Up About a minute my_container_2</li><li>c36785c423ec acme/my-final-image:1.0 &quot;bash&quot; About a minute ago Up About a minute my_container_1</li><li>List the contents of the local storage area.</li><li>$ sudo ls /var/lib/docker/containers</li><li>1a174fc216cccf18ec7d4fe14e008e30130b11ede0f0f94a87982e310cf2e765</li><li>1e7264576d78a3134fbaf7829bc24b1d96017cf2bc046b7cd8b08b5775c33d0c</li><li>38fa94212a419a082e6a6b87a8e2ec4a44dd327d7069b85892a707e3fc818544</li><li>c36785c423ec7e0422b2af7364a7ba4da6146cbba7981a0951fcc3fa0430c409</li><li>dcad7101795e4206e637d9358a818e5c32e13b349e62b00bf05cd5a4343ea513</li><li>Now check out their sizes:</li><li>$ sudo du -sh /var/lib/docker/containers/*</li><li>32K /var/lib/docker/containers/1a174fc216cccf18ec7d4fe14e008e30130b11ede0f0f94a87982e310cf2e765</li><li>32K /var/lib/docker/containers/1e7264576d78a3134fbaf7829bc24b1d96017cf2bc046b7cd8b08b5775c33d0c</li><li>32K /var/lib/docker/containers/38fa94212a419a082e6a6b87a8e2ec4a44dd327d7069b85892a707e3fc818544</li><li>32K /var/lib/docker/containers/c36785c423ec7e0422b2af7364a7ba4da6146cbba7981a0951fcc3fa0430c409</li><li>32K /var/lib/docker/containers/dcad7101795e4206e637d9358a818e5c32e13b349e62b00bf05cd5a4343ea513</li></ol><p>Each of these containers only takes up 32k of space on the filesystem.</p><p>Not only does copy-on-write save space, but it also reduces start-up time. When you start a container (or multiple containers from the same image), Docker only needs to create the thin writable container layer.</p><p>If Docker had to make an entire copy of the underlying image stack each time it started a new container, container start times and disk space used would be significantly increased. This would be similar to the way that virtual machines work, with one or more virtual disks per virtual machine.</p><h4>Data volumes and the storage driver</h4><p>When a container is deleted, any data written to the container that is not stored in a data volume is deleted along with the container.</p><p>A data volume is a directory or file in the Docker host&#x27;s filesystem that is mounted directly into a container. Data volumes are not controlled by the storage driver. Reads and writes to data volumes bypass the storage driver and operate at native host speeds. You can mount any number of data volumes into a container. Multiple containers can also share one or more data volumes.</p><p>The diagram below shows a single Docker host running two containers. Each container exists inside of its own address space within the Docker host&#x27;s local storage area (/var/lib/docker/...). There is also a single shared data volume located at /data on the Docker host. This is mounted directly into both containers.</p><p>Data volumes reside outside of the local storage area on the Docker host, further reinforcing their independence from the storage driver&#x27;s control. When a container is deleted, any data stored in data volumes persists on the Docker host.</p><p>For detailed information about data volumes, see <a href="https://docs.docker.com/engine/tutorials/dockervolumes/">Managing data in containers</a>.</p><h4>Related information</h4><ul><li><a href="https://docs.docker.com/storage/volumes/">Volumes</a></li><li><a href="https://docs.docker.com/storage/storagedriver/select-storage-driver/">Select a storage driver</a></li></ul><h3>Docker storage drivers</h3><p><em>Estimated reading time: 9 minutes</em></p><p>Ideally, very little data is written to a container&#x27;s writable layer, and you use Docker volumes to write data. However, some workloads require you to be able to write to the container&#x27;s writable layer. This is where storage drivers come in.</p><p>Docker supports several different storage drivers, using a pluggable architecture. The storage driver controls how images and containers are stored and managed on your Docker host.</p><p>After you have read the <a href="https://docs.docker.com/storage/storagedriver/">storage driver overview</a>, the next step is to choose the best storage driver for your workloads. In making this decision, there are three high-level factors to consider:</p><ul><li>If multiple storage drivers are supported in your kernel, Docker has a prioritized list of which storage driver to use if no storage driver is explicitly configured, assuming that the prerequisites for that storage driver are met:<ul><li>If possible, the storage driver with the least amount of configuration is used, such as btrfs or zfs. Each of these relies on the backing filesystem being configured correctly.</li><li>Otherwise, try to use the storage driver with the best overall performance and stability in the most usual scenarios.<ul><li>overlay2 is preferred, followed by overlay. Neither of these requires extra configuration. overlay2 is the default choice for Docker CE.</li><li>devicemapper is next, but requires direct-lvm for production environments, because loopback-lvm, while zero-configuration, has very poor performance.</li></ul></li></ul></li></ul><p>The selection order is defined in Docker&#x27;s source code. You can see the order by looking at <a href="https://github.com/docker/docker-ce/blob/18.03/components/engine/daemon/graphdriver/driver_linux.go#L50">the source code for Docker CE 18.03</a> You can use the branch selector at the top of the file viewer to choose a different branch, if you run a different version of Docker.</p><ul><li>Your choice may be limited by your Docker edition, operating system, and distribution. For instance, aufs is only supported on Ubuntu and Debian, and may require extra packages to be installed, while btrfs is only supported on SLES, which is only supported with Docker EE. See<a href="https://docs.docker.com/storage/storagedriver/select-storage-driver/#supported-storage-drivers-per-linux-distribution">Support storage drivers per Linux distribution</a>.</li><li>Some storage drivers require you to use a specific format for the backing filesystem. If you have external requirements to use a specific backing filesystem, this may limit your choices. See<a href="https://docs.docker.com/storage/storagedriver/select-storage-driver/#supported-backing-filesystems">Supported backing filesystems</a>.</li><li>After you have narrowed down which storage drivers you can choose from, your choice are determined by the characteristics of your workload and the level of stability you need. See <a href="https://docs.docker.com/storage/storagedriver/select-storage-driver/#other-considerations">Other considerations</a> for help making the final decision.</li></ul><h4>Supported storage drivers per Linux distribution</h4><p>At a high level, the storage drivers you can use is partially determined by the Docker edition you use.</p><p>In addition, Docker does not recommend any configuration that requires you to disable security features of your operating system, such as the need to disable selinux if you use the overlay or overlay2 driver on CentOS.</p><h5><strong>Docker EE and CS-Engine</strong></h5><p>For Docker EE and CS-Engine, the definitive resource for which storage drivers are supported is the<a href="https://success.docker.com/Policies/Compatibility_Matrix">Product compatibility matrix</a>. To get commercial support from Docker, you must use a supported configuration.</p><h5><strong>Docker CE</strong></h5><p>For Docker CE, only some configurations are tested, and your operating system&#x27;s kernel may not support every storage driver. In general, the following configurations work on recent versions of the Linux distribution:</p><p>  <strong>Linux distribution</strong>   <strong>Recommended storage drivers</strong></p><hr/><p>  Docker CE on Ubuntu      aufs, devicemapper, overlay2 (Ubuntu 14.04.4 or later, 16.04 or later), overlay, zfs, vfs
Docker CE on Debian      aufs, devicemapper, overlay2 (Debian Stretch), overlay, vfs
Docker CE on CentOS      devicemapper, vfs
Docker CE on Fedora      devicemapper, overlay2 (Fedora 26 or later, experimental), overlay(experimental), vfs</p><p>When possible, overlay2 is the recommended storage driver. When installing Docker for the first time, overlay2 is used by default. Previously, aufs was used by default when available, but this is no longer the case. If you want to use aufs on new installations going forward, you need to explicitly configure it, and you may need to install extra packages, such as linux-image-extra. See <a href="https://docs.docker.com/storage/storagedriver/aufs-driver/">aufs</a>.</p><p>On existing installations using aufs, it is still used.</p><p>When in doubt, the best all-around configuration is to use a modern Linux distribution with a kernel that supports the overlay2 storage driver, and to use Docker volumes for write-heavy workloads instead of relying on writing data to the container&#x27;s writable layer.</p><p>The vfs storage driver is usually not the best choice. Before using the vfs storage driver, be sure to read about <a href="https://docs.docker.com/storage/storagedriver/vfs-driver/">its performance and storage characteristics and limitations</a>.</p><p><strong>Expectations for non-recommended storage drivers: Commercial support is not available for Docker CE, and you can technically use any storage driver that is available for your platform. For instance, you can use btrfs with Docker CE, even though it is not recommended on any platform for Docker CE, and you do so at your own risk.</strong></p><p>The recommendations in the table above are based on automated regression testing and the configurations that are known to work for a large number of users. If you use a recommended configuration and find a reproducible issue, it is likely to be fixed very quickly. If the driver that you want to use is not recommended according to this table, you can run it at your own risk. You can and should still report any issues you run into. However, such issues have a lower priority than issues encountered when using a recommended configuration.</p><h5><strong>Docker for Mac and Docker for Windows</strong></h5><p>Docker for Mac and Docker for Windows are intended for development, rather than production. Modifying the storage driver on these platforms is not possible.</p><h4>Supported backing filesystems</h4><p>With regard to Docker, the backing filesystem is the filesystem where /var/lib/docker/ is located. Some storage drivers only work with specific backing filesystems.</p><p>  <strong>Storage driver</strong>   <strong>Supported backing filesystems</strong></p><hr/><p>  overlay, overlay2    ext4, xfs
aufs                 ext4, xfs
devicemapper         direct-lvm
btrfs                btrfs
zfs                  zfs</p><h4>Other considerations</h4><h5><strong>Suitability for your workload</strong></h5><p>Among other things, each storage driver has its own performance characteristics that make it more or less suitable for different workloads. Consider the following generalizations:</p><ul><li>aufs, overlay, and overlay2 all operate at the file level rather than the block level. This uses memory more efficiently, but the container&#x27;s writable layer may grow quite large in write-heavy workloads.</li><li>Block-level storage drivers such as devicemapper, btrfs, and zfs perform better for write-heavy workloads (though not as well as Docker volumes).</li><li>For lots of small writes or containers with many layers or deep filesystems, overlay may perform better than overlay2.</li><li>btrfs and zfs require a lot of memory.</li><li>zfs is a good choice for high-density workloads such as PaaS.</li></ul><p>More information about performance, suitability, and best practices is available in the documentation for each storage driver.</p><h5><strong>Shared storage systems and the storage driver</strong></h5><p>If your enterprise uses SAN, NAS, hardware RAID, or other shared storage systems, they may provide high availability, increased performance, thin provisioning, deduplication, and compression. In many cases, Docker can work on top of these storage systems, but Docker does not closely integrate with them.</p><p>Each Docker storage driver is based on a Linux filesystem or volume manager. Be sure to follow existing best practices for operating your storage driver (filesystem or volume manager) on top of your shared storage system. For example, if using the ZFS storage driver on top of a shared storage system, be sure to follow best practices for operating ZFS filesystems on top of that specific shared storage system.</p><h5><strong>Stability</strong></h5><p>For some users, stability is more important than performance. Though Docker considers all of the storage drivers mentioned here to be stable, some are newer and are still under active development. In general, aufs, overlay, and devicemapper are the choices with the highest stability.</p><h5><strong>Experience and expertise</strong></h5><p>Choose a storage driver that your organization is comfortable maintaining. For example, if you use RHEL or one of its downstream forks, you may already have experience with LVM and Device Mapper. If so, the devicemapper driver might be the best choice.</p><h5><strong>Test with your own workloads</strong></h5><p>You can test Docker&#x27;s performance when running your own workloads on different storage drivers. Make sure to use equivalent hardware and workloads to match production conditions, so you can see which storage driver offers the best overall performance.</p><h4>Check your current storage driver</h4><p>The detailed documentation for each individual storage driver details all of the set-up steps to use a given storage driver.</p><p>To see what storage driver Docker is currently using, use docker info and look for the Storage Driver line:</p><p>$ docker info</p><p>Containers: 0</p><p>Images: 0</p><p>Storage Driver: overlay</p><p>Backing Filesystem: extfs</p><p><code style="background-color:lightgray">&lt;output truncated&gt;</code></p><p>To change the storage driver, see the specific instructions for the new storage driver. Some drivers require additional configuration, including configuration to physical or logical disks on the Docker host.</p><p><strong>Important</strong>: When you change the storage driver, any existing images and containers become inaccessible. This is because their layers cannot be used by the new storage driver. If you revert your changes, you can access the old images and containers again, but any that you pulled or created using the new driver are then inaccessible.</p><h4>Related information</h4><ul><li><a href="https://docs.docker.com/storage/storagedriver/">About images, containers, and storage drivers</a></li><li><a href="https://docs.docker.com/storage/storagedriver/aufs-driver/">aufs storage driver in practice</a></li><li><a href="https://docs.docker.com/storage/storagedriver/device-mapper-driver/">devicemapper storage driver in practice</a></li><li><a href="https://docs.docker.com/storage/storagedriver/overlayfs-driver/">overlay and overlay2 storage drivers in practice</a></li><li><a href="https://docs.docker.com/storage/storagedriver/btrfs-driver/">btrfs storage driver in practice</a></li><li><a href="https://docs.docker.com/storage/storagedriver/zfs-driver/">zfs storage driver in practice</a></li></ul><h3>Use the AUFS storage driver</h3><p><em>Estimated reading time: 8 minutes</em></p><p>AUFS is a union filesystem. The aufs storage driver was previously the default storage driver used for managing images and layers on Docker for Ubuntu, and for Debian versions prior to Stretch. If your Linux kernel is version 4.0 or higher, and you use Docker CE, consider using the newer <a href="https://docs.docker.com/storage/storagedriver/overlayfs-driver/">overlay2</a>, which has potential performance advantages over the aufs storage driver.</p><p><strong>Note</strong>: AUFS is not supported on some distributions and Docker editions. See <a href="https://docs.docker.com/storage/storagedriver/aufs-driver/#prerequisites">Prerequisites</a> &gt; for more information about supported platforms, and see also <a href="https://docs.docker.com/storage/storagedriver/selectadriver/#storage-driver-order">the order of preferences for storage drivers</a>.</p><h4>Prerequisites</h4><ul><li>For Docker CE, AUFS is supported on Ubuntu, and on Debian versions prior to Stretch.</li><li>For Docker EE, AUFS is supported on Ubuntu.</li><li>If you use Ubuntu, you need to <a href="https://docs.docker.com/install/linux/ubuntu/#recommended-extra-packages-for-trusty-1404">install extra packages</a> to add the AUFS module to the kernel. If you do not install these packages, you need to use devicemapper on Ubuntu 14.04 (which is not recommended), or overlay2 on Ubuntu 16.04 and higher, which is also supported.</li><li>AUFS cannot use the following backing filesystems: aufs, btrfs, or ecryptfs. This means that the filesystem which contains /var/lib/docker/aufs cannot be one of these filesystem types.</li></ul><h4>Configure Docker with the aufs storage driver</h4><p>If the AUFS driver is loaded into the kernel when you start Docker, and no other storage driver is configured, Docker uses it by default.</p><ol><li>Use the following command to verify that your kernel supports AUFS.</li><li>$ grep aufs /proc/filesystems</li><li>nodev aufs</li><li>Check which storage driver Docker is using.</li><li>$ docker info</li><li><code>&lt;truncated output&gt;</code></li><li>Storage Driver: aufs</li><li>Root Dir: /var/lib/docker/aufs</li><li>Backing Filesystem: extfs</li><li>Dirs: 0</li><li>Dirperm1 Supported: true</li><li><code>&lt;truncated output&gt;</code></li><li>If you are using a different storage driver, either AUFS is not included in the kernel (in which case a different default driver is used) or that Docker has been explicitly configured to use a different driver. Check /etc/docker/daemon.json or the output of ps auxw | grep dockerd to see if Docker has been started with the --storage-driver flag.</li></ol><h4>How the aufs storage driver works</h4><p>AUFS is a union filesystem, which means that it layers multiple directories on a single Linux host and presents them as a single directory. These directories are called branches in AUFS terminology, and layers in Docker terminology. The unification process is referred to a a union mount.</p><p>The diagram below shows a Docker container based on the ubuntu:latest image.</p><p>Each image layer, and the container layer, are represented on the Docker host as subdirectories within /var/lib/docker/. The union mount provides the unified view of all layers. The directory names do not directly correspond to the IDs of the layers themselves.</p><p>AUFS uses the Copy-on-Write (CoW) strategy to maximize storage efficiency and minimize overhead.</p><h5><strong>Example: Image and container on-disk constructs</strong></h5><p>The following docker pull command shows a Docker host downloading a Docker image comprising five layers.</p><p>$ docker pull ubuntu</p><p>Using default tag: latest</p><p>latest: Pulling from library/ubuntu</p><p>b6f892c0043b: Pull complete</p><p>55010f332b04: Pull complete</p><p>2955fb827c94: Pull complete</p><p>3deef3fcbd30: Pull complete</p><p>cf9722e506aa: Pull complete</p><p>Digest: sha256:382452f82a8bbd34443b2c727650af46aced0f94a44463c62a9848133ecb1aa8</p><p>Status: Downloaded newer image for ubuntu:latest</p><h6><strong>THE IMAGE LAYERS</strong></h6><p><strong>Warning</strong>: Do not directly manipulate any files or directories within /var/lib/docker/. These files and directories are managed by Docker.</p><p>All of the information about the image and container layers is stored in subdirectories of /var/lib/docker/aufs/.</p><ul><li>diff/: the <strong>contents</strong> of each layer, each stored in a separate subdirectory</li><li>layers/: metadata about how image layers are stacked. This directory contains one file for each image or container layer on the Docker host. Each file contains the IDs of all the layers below it in the stack (its parents).</li><li>mnt/: Mount points, one per image or container layer, which are used to assemble and mount the unified filesystem for a container. For images, which are read-only, these directories are always empty.</li></ul><h6><strong>THE CONTAINER LAYER</strong></h6><p>If a container is running, the contents of /var/lib/docker/aufs/ change in the following ways:</p><ul><li>diff/: Differences introduced in the writable container layer, such as new or modified files.</li><li>layers/: Metadata about the writable container layer&#x27;s parent layers.</li><li>mnt/: A mount point for each running container&#x27;s unified filesystem, exactly as it appears from within the container.</li></ul><h4>How container reads and writes work with aufs</h4><h5><strong>Reading files</strong></h5><p>Consider three scenarios where a container opens a file for read access with overlay.</p><ul><li><strong>The file does not exist in the container layer</strong>: If a container opens a file for read access and the file does not already exist in the container layer, the storage driver searches for the file in the image layers, starting with the layer just below the container layer. It is read from the layer where it is found.</li><li><strong>The file only exists in the container layer</strong>: If a container opens a file for read access and the file exists in the container layer, it is read from there.</li><li><strong>The file exists in both the container layer and the image layer</strong>: If a container opens a file for read access and the file exists in the container layer and one or more image layers, the file is read from the container layer. Files in the container layer obscure files with the same name in the image layers.</li></ul><h5><strong>Modifying files or directories</strong></h5><p>Consider some scenarios where files in a container are modified.</p><ul><li><strong>Writing to a file for the first time</strong>: The first time a container writes to an existing file, that file does not exist in the container (upperdir). The aufs driver performs a copy_up operation to copy the file from the image layer where it exists to the writable container layer. The container then writes the changes to the new copy of the file in the container layer.</li></ul><p>However, AUFS works at the file level rather than the block level. This means that all copy_up operations copy the entire file, even if the file is very large and only a small part of it is being modified. This can have a noticeable impact on container write performance. AUFS, which can suffer noticeable latencies when searching for files in images with many layers. However, it is worth noting that the copy_up operation only occurs the first time a given file is written to. Subsequent writes to the same file operate against the copy of the file already copied up to the container.</p><ul><li><strong>Deleting files and directories</strong>:<ul><li>When a file is deleted within a container, a whiteout file is created in the container layer. The version of the file in the image layer is not deleted (because the image layers are read-only). However, the whiteout file prevents it from being available to the container.</li><li>When a directory is deleted within a container, an opaque file is created in the container layer. This works in the same way as a whiteout file and effectively prevents the directory from being accessed, even though it still exists in the image layer.</li></ul></li><li><strong>Renaming directories</strong>: Calling rename(2) for a directory is not fully supported on AUFS. It returns EXDEV (&quot;cross-device link not permitted&quot;), even when both of the source and the destination path are on a same AUFS layer, unless the directory has no children. Your application needs to be designed to handle EXDEV and fall back to a &quot;copy and unlink&quot; strategy.</li></ul><h4>AUFS and Docker performance</h4><p>To summarize some of the performance related aspects already mentioned:</p><ul><li>The AUFS storage driver is less performant than the overlay2 driver, but is a good choice for PaaS and other similar use-cases where container density is important. This is because AUFS efficiently shares images between multiple running containers, enabling fast container start times and minimal use of disk space.</li><li>The underlying mechanics of how AUFS shares files between image layers and containers uses the page cache very efficiently.</li><li>The AUFS storage driver can introduce significant latencies into container write performance. This is because the first time a container writes to any file, the file needs to be located and copied into the containers top writable layer. These latencies increase and are compounded when these files exist below many image layers and the files themselves are large.</li></ul><h5><strong>Performance best practices</strong></h5><p>The following generic performance best practices also apply to AUFS.</p><ul><li><strong>Solid State Devices (SSD)</strong> provide faster reads and writes than spinning disks.</li><li><strong>Use volumes for write-heavy workloads</strong>: Volumes provide the best and most predictable performance for write-heavy workloads. This is because they bypass the storage driver and do not incur any of the potential overheads introduced by thin provisioning and copy-on-write. Volumes have other benefits, such as allowing you to share data among containers and persisting even when no running container is using them.</li></ul><h4>Related information</h4><ul><li><a href="https://docs.docker.com/storage/volumes/">Volumes</a></li><li><a href="https://docs.docker.com/storage/storagedriver/imagesandcontainers/">Understand images, containers, and storage drivers</a></li><li><a href="https://docs.docker.com/storage/storagedriver/selectadriver/">Select a storage driver</a></li></ul><h3>Use the BTRFS storage driver</h3><p><em>Estimated reading time: 11 minutes</em></p><p>Btrfs is a next generation copy-on-write filesystem that supports many advanced storage technologies that make it a good fit for Docker. Btrfs is included in the mainline Linux kernel.</p><p>Docker&#x27;s btrfs storage driver leverages many Btrfs features for image and container management. Among these features are block-level operations, thin provisioning, copy-on-write snapshots, and ease of administration. You can easily combine multiple physical block devices into a single Btrfs filesystem.</p><p>This article refers to Docker&#x27;s Btrfs storage driver as btrfs and the overall Btrfs Filesystem as Btrfs.</p><p><strong>Note</strong>: The btrfs storage driver is only supported on Docker CE on Ubuntu or Debian, and Docker EE / CS Engine on SLES.</p><h4>Prerequisites</h4><p>btrfs is supported if you meet the following prerequisites:</p><ul><li><strong>Docker CE</strong>: For Docker CE, btrfs is only recommended on Ubuntu or Debian.</li><li><strong>Docker EE</strong>: For Docker EE and CS-Engine, btrfs is only supported on SLES. See the <a href="https://success.docker.com/Policies/Compatibility_Matrix">Product compatibility matrix</a> for all supported configurations for commercially-supported Docker.</li><li>Changing the storage driver makes any containers you have already created inaccessible on the local system. Use docker save to save containers, and push existing images to Docker Hub or a private repository, so that you not need to re-create them later.</li><li>btrfs requires a dedicated block storage device such as a physical disk. This block device must be formatted for Btrfs and mounted into /var/lib/docker/. The configuration instructions below walk you through this procedure. By default, the SLES / filesystem is formatted with BTRFS, so for SLES, you do not need to use a separate block device, but you can choose to do so for performance reasons.</li><li>btrfs support must exist in your kernel. To check this, run the following command:</li><li>$ sudo cat /proc/filesystems | grep btrfs</li><li>btrfs</li><li>To manage BTRFS filesystems at the level of the operating system, you need the btrfscommand. If you do not have this command, install the btrfsprogs package (SLES) or btrfs-tools package (Ubuntu).</li></ul><h4>Configure Docker to use the btrfs storage driver</h4><p>This procedure is essentially identical on SLES and Ubuntu.</p><ol><li>Stop Docker.</li><li>Copy the contents of /var/lib/docker/ to a backup location, then empty the contents of /var/lib/docker/:</li><li>$ sudo cp -au /var/lib/docker /var/lib/docker.bk</li><li>$ sudo rm -rf /var/lib/docker/*</li><li>Format your dedicated block device or devices as a Btrfs filesystem. This example assumes that you are using two block devices called /dev/xvdf and /dev/xvdg. Double-check the block device names because this is a destructive operation.</li><li>$ sudo mkfs.btrfs -f /dev/xvdf /dev/xvdg</li></ol><p>There are many more options for Btrfs, including striping and RAID. See the <a href="https://btrfs.wiki.kernel.org/index.php/Using_Btrfs_with_Multiple_Devices">Btrfs documentation</a>.</p><ol><li>Mount the new Btrfs filesystem on the /var/lib/docker/ mount point. You can specify any of the block devices used to create the Btrfs filesystem.</li><li>$ sudo mount -t btrfs /dev/xvdf /var/lib/docker</li></ol><p>Don&#x27;t forget to make the change permanent across reboots by adding an entry to /etc/fstab.</p><ol><li>Copy the contents of /var/lib/docker.bk to /var/lib/docker/.</li><li>$ sudo cp -au /var/lib/docker.bk/* /var/lib/docker/</li><li>Configure Docker to use the btrfs storage driver. This is required even though /var/lib/docker/ is now using a Btrfs filesystem. Edit or create the file /etc/docker/daemon.json. If it is a new file, add the following contents. If it is an existing file, add the key and value only, being careful to end the line with a comma if it is not the final line before an ending curly bracket (}).</li><li>{</li><li>&quot;storage-driver&quot;: &quot;btrfs&quot;</li><li>}</li></ol><p>See all storage options for each storage driver:</p><ul><li><ul><li><a href="https://docs.docker.com/engine/reference/commandline/dockerd/#storage-driver-options">Stable</a></li><li><a href="https://docs.docker.com/edge/engine/reference/commandline/dockerd/#storage-driver-options">Edge</a></li></ul></li></ul><ol><li>Start Docker. After it is running, verify that btrfs is being used as the storage driver.</li><li>$ docker info</li><li>Containers: 0</li><li>Running: 0</li><li>Paused: 0</li><li>Stopped: 0</li><li>Images: 0</li><li>Server Version: 17.03.1-ce</li><li>Storage Driver: btrfs</li><li>Build Version: Btrfs v4.4</li><li>Library Version: 101</li><li><code>&lt;output truncated&gt;</code></li><li>When you are ready, remove the /var/lib/docker.bk directory.</li></ol><h4>Manage a Btrfs volume</h4><p>One of the benefits of Btrfs is the ease of managing Btrfs filesystems without the need to unmount the filesystem or restart Docker.</p><p>When space gets low, Btrfs automatically expands the volume in chunks of roughly 1 GB.</p><p>To add a block device to a Btrfs volume, use the btrfs device add and btrfs filesystem balancecommands.</p><p>$ sudo btrfs device add /dev/svdh /var/lib/docker</p><p>$ sudo btrfs filesystem balance /var/lib/docker</p><p><strong>Note</strong>: While you can do these operations with Docker running, performance suffers. It might be best to plan an outage window to balance the Btrfs filesystem.</p><h4>How the btrfs storage driver works</h4><p>The btrfs storage driver works differently from devicemapper or other storage drivers in that your entire /var/lib/docker/ directory is stored on a Btrfs volume.</p><h5><strong>Image and container layers on-disk</strong></h5><p>Information about image layers and writable container layers is stored in/var/lib/docker/btrfs/subvolumes/. This subdirectory contains one directory per image or container layer, with the unified filesystem built from a layer plus all its parent layers. Subvolumes are natively copy-on-write and have space allocated to them on-demand from an underlying storage pool. They can also be nested and snapshotted. The diagram below shows 4 subvolumes. &#x27;Subvolume 2&#x27; and &#x27;Subvolume 3&#x27; are nested, whereas &#x27;Subvolume 4&#x27; shows its own internal directory tree.</p><p>Only the base layer of an image is stored as a true subvolume. All the other layers are stored as snapshots, which only contain the differences introduced in that layer. You can create snapshots of snapshots as shown in the diagram below.</p><p>On disk, snapshots look and feel just like subvolumes, but in reality they are much smaller and more space-efficient. Copy-on-write is used to maximize storage efficiency and minimize layer size, and writes in the container&#x27;s writable layer are managed at the block level. The following image shows a subvolume and its snapshot sharing data.</p><p>For maximum efficiency, when a container needs more space, it is allocated in chunks of roughly 1 GB in size.</p><p>Docker&#x27;s btrfs storage driver stores every image layer and container in its own Btrfs subvolume or snapshot. The base layer of an image is stored as a subvolume whereas child image layers and containers are stored as snapshots. This is shown in the diagram below.</p><p>The high level process for creating images and containers on Docker hosts running the btrfs driver is as follows:</p><ol><li>The image&#x27;s base layer is stored in a Btrfs subvolume under /var/lib/docker/btrfs/subvolumes.</li><li>Subsequent image layers are stored as a Btrfs snapshot of the parent layer&#x27;s subvolume or snapshot, but with the changes introduced by this layer. These differences are stored at the block level.</li><li>The container&#x27;s writable layer is a Btrfs snapshot of the final image layer, with the differences introduced by the running container. These differences are stored at the block level.</li></ol><h4>How container reads and writes work with btrfs</h4><h5><strong>Reading files</strong></h5><p>A container is a space-efficient snapshot of an image. Metadata in the snapshot points to the actual data blocks in the storage pool. This is the same as with a subvolume. Therefore, reads performed against a snapshot are essentially the same as reads performed against a subvolume.</p><h5><strong>Writing files</strong></h5><ul><li><strong>Writing new files</strong>: Writing a new file to a container invokes an allocate-on-demand operation to allocate new data block to the container&#x27;s snapshot. The file is then written to this new space. The allocate-on-demand operation is native to all writes with Btrfs and is the same as writing new data to a subvolume. As a result, writing new files to a container&#x27;s snapshot operates at native Btrfs speeds.</li><li><strong>Modifying existing files</strong>: Updating an existing file in a container is a copy-on-write operation (redirect-on-write is the Btrfs terminology). The original data is read from the layer where the file currently exists, and only the modified blocks are written into the container&#x27;s writable layer. Next, the Btrfs driver updates the filesystem metadata in the snapshot to point to this new data. This behavior incurs very little overhead.</li><li><strong>Deleting files or directories</strong>: If a container deletes a file or directory that exists in a lower layer, Btrfs masks the existence of the file or directory in the lower layer. If a container creates a file and then deletes it, this operation is performed in the Btrfs filesystem itself and the space is reclaimed.</li></ul><p>With Btrfs, writing and updating lots of small files can result in slow performance.</p><h4>Btrfs and Docker performance</h4><p>There are several factors that influence Docker&#x27;s performance under the btrfs storage driver.</p><p><strong>Note</strong>: Many of these factors are mitigated by using Docker volumes for write-heavy workloads, rather than relying on storing data in the container&#x27;s writable layer. However, in the case of Btrfs, Docker volumes still suffer from these draw-backs unless /var/lib/docker/volumes/ is <strong>not</strong>backed by Btrfs.</p><ul><li><strong>Page caching</strong>. Btrfs does not support page cache sharing. This means that each process accessing the same file copies the file into the Docker hosts&#x27;s memory. As a result, the btrfs driver may not be the best choice high-density use cases such as PaaS.</li><li><strong>Small writes</strong>. Containers performing lots of small writes (this usage pattern matches what happens when you start and stop many containers in a short period of time, as well) can lead to poor use of Btrfs chunks. This can prematurely fill the Btrfs filesystem and lead to out-of-space conditions on your Docker host. Use btrfs filesys show to closely monitor the amount of free space on your Btrfs device.</li><li><strong>Sequential writes</strong>. Btrfs uses a journaling technique when writing to disk. This can impact the performance of sequential writes, reducing performance by up to 50%.</li><li><strong>Fragmentation</strong>. Fragmentation is a natural byproduct of copy-on-write filesystems like Btrfs. Many small random writes can compound this issue. Fragmentation can manifest as CPU spikes when using SSDs or head thrashing when using spinning disks. Either of these issues can harm performance.</li></ul><p>If your Linux kernel version is 3.9 or higher, you can enable the autodefrag feature when mounting a Btrfs volume. Test this feature on your own workloads before deploying it into production, as some tests have shown a negative impact on performance.</p><ul><li><strong>SSD performance</strong>: Btrfs includes native optimizations for SSD media. To enable these features, mount the Btrfs filesystem with the -o ssd mount option. These optimizations include enhanced SSD write performance by avoiding optimization such as seek optimizations which do not apply to solid-state media.</li><li><strong>Balance Btrfs filesystems often</strong>: Use operating system utilities such as a cron job to balance the Btrfs filesystem regularly, during non-peak hours. This reclaims unallocated blocks and helps to prevent the filesystem from filling up unnecessarily. You cannot rebalance a totally full Btrfs filesystem unless you add additional physical block devices to the filesystem. See the <a href="https://btrfs.wiki.kernel.org/index.php/Balance_Filters#Balancing_to_fix_filesystem_full_errors">BTRFS Wiki</a>.</li><li><strong>Use fast storage</strong>: Solid-state drives (SSDs) provide faster reads and writes than spinning disks.</li><li><strong>Use volumes for write-heavy workloads</strong>: Volumes provide the best and most predictable performance for write-heavy workloads. This is because they bypass the storage driver and do not incur any of the potential overheads introduced by thin provisioning and copy-on-write. Volumes have other benefits, such as allowing you to share data among containers and persisting even when no running container is using them.</li></ul><h4>Related Information</h4><ul><li><a href="https://docs.docker.com/storage/volumes/">Volumes</a></li><li><a href="https://docs.docker.com/storage/storagedriver/imagesandcontainers/">Understand images, containers, and storage drivers</a></li><li><a href="https://docs.docker.com/storage/storagedriver/selectadriver/">Select a storage driver</a></li></ul><h3>Use the Device Mapper storage driver</h3><p><em>Estimated reading time: 26 minutes</em></p><p>Device Mapper is a kernel-based framework that underpins many advanced volume management technologies on Linux. Docker&#x27;s devicemapper storage driver leverages the thin provisioning and snapshotting capabilities of this framework for image and container management. This article refers to the Device Mapper storage driver as devicemapper, and the kernel framework as Device Mapper.</p><p>For the systems where it is supported, devicemapper support is included in the Linux kernel. However, specific configuration is required to use it with Docker. For instance, on a stock installation of RHEL or CentOS, Docker defaults to overlay, which is not a supported configuration.</p><p>The devicemapper driver uses block devices dedicated to Docker and operates at the block level, rather than the file level. These devices can be extended by adding physical storage to your Docker host, and they perform better than using a filesystem at the level of the operating system.</p><h4>Prerequisites</h4><ul><li>devicemapper storage driver is the only supported storage driver for Docker EE and Commercially Supported Docker Engine (CS-Engine) on RHEL, CentOS, and Oracle Linux. See the<a href="https://success.docker.com/Policies/Compatibility_Matrix">Product compatibility matrix</a>.</li><li>devicemapper is also supported on Docker CE running on CentOS, Fedora, Ubuntu, or Debian.</li><li>Changing the storage driver makes any containers you have already created inaccessible on the local system. Use docker save to save containers, and push existing images to Docker Hub or a private repository, so that you not need to re-create them later.</li></ul><h4>Configure Docker with the devicemapper storage driver</h4><p>Before following these procedures, you must first meet all the <a href="https://docs.docker.com/storage/storagedriver/device-mapper-driver/#prerequisites">prerequisites</a>.</p><h5><strong>Configure loop-lvm mode for testing</strong></h5><p>This configuration is only appropriate for testing. Loopback devices are slow and resource-intensive, and require you to create file on disk at specific sizes. They can also introduce race conditions. They are supposed for testing because the set-up is easier.</p><p>For production systems, see <a href="https://docs.docker.com/storage/storagedriver/device-mapper-driver/#configure-direct-lvm-mode-for-production">Configure direct-lvm mode for production</a>.</p><ol><li>Stop Docker.</li><li>$ sudo systemctl stop docker</li><li>Edit /etc/docker/daemon.json. If it does not yet exist, create it. Assuming that the file was empty, add the following contents.</li><li>{</li><li>&quot;storage-driver&quot;: &quot;devicemapper&quot;</li><li>}</li></ol><p>See all storage options for each storage driver:</p><ul><li><ul><li><a href="https://docs.docker.com/engine/reference/commandline/dockerd/#storage-driver-options">Stable</a></li><li><a href="https://docs.docker.com/edge/engine/reference/commandline/dockerd/#storage-driver-options">Edge</a></li></ul></li></ul><p>Docker does not start if the daemon.json file contains badly-formed JSON.</p><ol><li>Start Docker.</li><li>$ sudo systemctl start docker</li><li>Verify that the daemon is using the devicemapper storage driver. Use the docker infocommand and look for Storage Driver.</li><li>$ docker info</li><li>Containers: 0</li><li>Running: 0</li><li>Paused: 0</li><li>Stopped: 0</li><li>Images: 0</li><li>Server Version: 17.03.1-ce</li><li>Storage Driver: devicemapper</li><li>Pool Name: docker-202:1-8413957-pool</li><li>Pool Blocksize: 65.54 kB</li><li>Base Device Size: 10.74 GB</li><li>Backing Filesystem: xfs</li><li>Data file: /dev/loop0</li><li>Metadata file: /dev/loop1</li><li>Data Space Used: 11.8 MB</li><li>Data Space Total: 107.4 GB</li><li>Data Space Available: 7.44 GB</li><li>Metadata Space Used: 581.6 kB</li><li>Metadata Space Total: 2.147 GB</li><li>Metadata Space Available: 2.147 GB</li><li>Thin Pool Minimum Free Space: 10.74 GB</li><li>Udev Sync Supported: true</li><li>Deferred Removal Enabled: false</li><li>Deferred Deletion Enabled: false</li><li>Deferred Deleted Device Count: 0</li><li>Data loop file: /var/lib/docker/devicemapper/data</li><li>Metadata loop file: /var/lib/docker/devicemapper/metadata</li><li>Library Version: 1.02.135-RHEL7 (2016-11-16)</li><li><code>&lt;output truncated&gt;</code></li></ol><p>This host is running in loop-lvm mode, which is <strong>not</strong> supported on production systems. This is indicated by the fact that the Data loop file and a Metadata loop file are on files under/var/lib/docker/devicemapper. These are loopback-mounted sparse files. For production systems, see<a href="https://docs.docker.com/storage/storagedriver/device-mapper-driver/#configure-direct-lvm-mode-for-production">Configure direct-lvm mode for production</a>.</p><h5><strong>Configure direct-lvm mode for production</strong></h5><p>Production hosts using the devicemapper storage driver must use direct-lvm mode. This mode uses block devices to create the thin pool. This is faster than using loopback devices, uses system resources more efficiently, and block devices can grow as needed. However, more set-up is required than loop-lvm mode.</p><p>After you have satisfied the <a href="https://docs.docker.com/storage/storagedriver/device-mapper-driver/#prerequisites">prerequisites</a>, follow the steps below to configure Docker to use the devicemapper storage driver in direct-lvm mode.</p><p><strong>Warning</strong>: Changing the storage driver makes any containers you have already created inaccessible on the local system. Use docker save to save containers, and push existing images to Docker Hub or a private repository, so that you don&#x27;t need to recreate them later.</p><h6><strong>ALLOW DOCKER TO CONFIGURE DIRECT-LVM MODE</strong></h6><p>In Docker 17.06 and higher, Docker can manage the block device for you, simplifying configuration of direct-lvm mode. <strong>This is appropriate for fresh Docker set-ups only.</strong> You can only use a single block device. If you need to use multiple block devices, <a href="https://docs.docker.com/storage/storagedriver/device-mapper-driver/#configure-direct-lvm-mode-manually">configure direct-lvm mode manually</a> instead. The following new configuration options have been added:</p><p>  <strong>Option</strong>                      <strong>Description</strong>                                                                                                                                                                    <strong>Required?</strong>   <strong>Default</strong>   <strong>Example</strong></p><hr/><p>  dm.directlvm_device             The path to the block device to configure for direct-lvm.                                                                                                                          Yes                           dm.directlvm_device=&quot;/dev/xvdf&quot;
dm.thinp_percent                The percentage of space to use for storage from the passed in block device.                                                                                                        No              95            dm.thinp_percent=95
dm.thinp_metapercent            The percentage of space to for metadata storage from the passed-in block device.                                                                                                   No              1             dm.thinp_metapercent=1
dm.thinp_autoextend_threshold   The threshold for when lvm should automatically extend the thin pool as a percentage of the total storage space.                                                                   No              80            dm.thinp_autoextend_threshold=80
dm.thinp_autoextend_percent     The percentage to increase the thin pool by when an autoextend is triggered.                                                                                                       No              20            dm.thinp_autoextend_percent=20
dm.directlvm_device_force       Whether to format the block device even if a filesystem already exists on it. If set to false and a filesystem is present, an error is logged and the filesystem is left intact.   No              false         dm.directlvm_device_force=true</p><p>Edit the daemon.json file and set the appropriate options, then restart Docker for the changes to take effect. The following daemon.json sets all of the options in the table above.</p><p>{</p><p>&quot;storage-driver&quot;: &quot;devicemapper&quot;,</p><p>&quot;storage-opts&quot;: [</p><p>&quot;dm.directlvm_device=/dev/xdf&quot;,</p><p>&quot;dm.thinp_percent=95&quot;,</p><p>&quot;dm.thinp_metapercent=1&quot;,</p><p>&quot;dm.thinp_autoextend_threshold=80&quot;,</p><p>&quot;dm.thinp_autoextend_percent=20&quot;,</p><p>&quot;dm.directlvm_device_force=false&quot;</p><p>]</p><p>}</p><p>See all storage options for each storage driver:</p><ul><li><a href="https://docs.docker.com/engine/reference/commandline/dockerd/#storage-driver-options">Stable</a></li><li><a href="https://docs.docker.com/edge/engine/reference/commandline/dockerd/#storage-driver-options">Edge</a></li></ul><p>Restart Docker for the changes to take effect. Docker invokes the commands to configure the block device for you.</p><p><strong>Warning</strong>: Changing these values after Docker has prepared the block device for you is not supported and causes an error.</p><p>You still need to <a href="https://docs.docker.com/storage/storagedriver/device-mapper-driver/#manage-devicemapper">perform periodic maintenance tasks</a>.</p><h6><strong>CONFIGURE DIRECT-LVM MODE MANUALLY</strong></h6><p>The procedure below creates a logical volume configured as a thin pool to use as backing for the storage pool. It assumes that you have a spare block device at /dev/xvdf with enough free space to complete the task. The device identifier and volume sizes may be different in your environment and you should substitute your own values throughout the procedure. The procedure also assumes that the Docker daemon is in the stopped state.</p><ol><li>Identify the block device you want to use. The device is located under /dev/ (such as /dev/xvdf) and needs enough free space to store the images and container layers for the workloads that host runs. A solid state drive is ideal.</li><li>Stop Docker.</li><li>$ sudo systemctl stop docker</li><li>Install the following packages:<ul><li><strong>RHEL / CentOS</strong>: device-mapper-persistent-data, lvm2, and all dependencies</li><li><strong>Ubuntu / Debian</strong>: thin-provisioning-tools, lvm2, and all dependencies</li></ul></li><li>Create a physical volume on your block device from step 1, using the pvcreate command. Substitute your device name for /dev/xvdf.</li></ol><p><strong>Warning</strong>: The next few steps are destructive, so be sure that you have specified the correct device!</p><p>$ sudo pvcreate /dev/xvdf</p><p>Physical volume &quot;/dev/xvdf&quot; successfully created.</p><ol><li>Create a docker volume group on the same device, using the vgcreate command.</li><li>$ sudo vgcreate docker /dev/xvdf</li><li>Volume group &quot;docker&quot; successfully created</li><li>Create two logical volumes named thinpool and thinpoolmeta using the lvcreate command. The last parameter specifies the amount of free space to allow for automatic expanding of the data or metadata if space runs low, as a temporary stop-gap. These are the recommended values.</li><li>$ sudo lvcreate --wipesignatures y -n thinpool docker -l 95%VG</li><li>Logical volume &quot;thinpool&quot; created.</li><li>$ sudo lvcreate --wipesignatures y -n thinpoolmeta docker -l 1%VG</li><li>Logical volume &quot;thinpoolmeta&quot; created.</li><li>Convert the volumes to a thin pool and a storage location for metadata for the thin pool, using the lvconvert command.</li><li>$ sudo lvconvert -y \</li><li>--zero n \</li><li>-c 512K \</li><li>--thinpool docker/thinpool \</li><li>--poolmetadata docker/thinpoolmeta</li><li>WARNING: Converting logical volume docker/thinpool and docker/thinpoolmeta to</li><li>thin pool\&#x27;s data and metadata volumes with metadata wiping.</li><li>THIS WILL DESTROY CONTENT OF LOGICAL VOLUME (filesystem etc.)</li><li>Converted docker/thinpool to thin pool.</li><li>Configure autoextension of thin pools via an lvm profile.</li><li>$ sudo vi /etc/lvm/profile/docker-thinpool.profile</li><li>Specify thin_pool_autoextend_threshold and thin_pool_autoextend_percent values.</li></ol><p>thin_pool_autoextend_threshold is the percentage of space used before lvm attempts to autoextend the available space (100 = disabled, not recommended).</p><p>thin_pool_autoextend_percent is the amount of space to add to the device when automatically extending (0 = disabled).</p><p>The example below adds 20% more capacity when the disk usage reaches 80%.</p><p>activation {</p><p>thin_pool_autoextend_threshold=80</p><p>thin_pool_autoextend_percent=20</p><p>}</p><p>Save the file.</p><ol><li>Apply the LVM profile, using the lvchange command.</li><li>$ sudo lvchange --metadataprofile docker-thinpool docker/thinpool</li><li>Logical volume docker/thinpool changed.</li><li>Enable monitoring for logical volumes on your host. Without this step, automatic extension does not occur even in the presence of the LVM profile.</li><li>$ sudo lvs -o+seg_monitor</li><li>LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert Monitor</li><li>thinpool docker twi-a-t--- 95.00g 0.00 0.01 monitored</li><li>If you have ever run Docker on this host before, or if /var/lib/docker/ exists, move it out of the way so that Docker can use the new LVM pool to store the contents of image and containers.</li><li>$ mkdir /var/lib/docker.bk</li><li>$ mv /var/lib/docker/* /var/lib/docker.bk</li></ol><p>If any of the following steps fail and you need to restore, you can remove /var/lib/docker and replace it with /var/lib/docker.bk.</p><ol><li>Edit /etc/docker/daemon.json and configure the options needed for the devicemapper storage driver. If the file was previously empty, it should now contain the following contents:</li><li>{</li><li>&quot;storage-driver&quot;: &quot;devicemapper&quot;,</li><li>&quot;storage-opts&quot;: [</li><li>&quot;dm.thinpooldev=/dev/mapper/docker-thinpool&quot;,</li><li>&quot;dm.use_deferred_removal=true&quot;,</li><li>&quot;dm.use_deferred_deletion=true&quot;</li><li>]</li><li>}</li><li>Start Docker.</li></ol><p><strong>systemd</strong>:</p><p>$ sudo systemctl start docker</p><p><strong>service</strong>:</p><p>$ sudo service docker start</p><ol><li>Verify that Docker is using the new configuration using docker info.</li><li>$ docker info</li><li>Containers: 0</li><li>Running: 0</li><li>Paused: 0</li><li>Stopped: 0</li><li>Images: 0</li><li>Server Version: 17.03.1-ce</li><li>Storage Driver: devicemapper</li><li>Pool Name: docker-thinpool</li><li>Pool Blocksize: 524.3 kB</li><li>Base Device Size: 10.74 GB</li><li>Backing Filesystem: xfs</li><li>Data file:</li><li>Metadata file:</li><li>Data Space Used: 19.92 MB</li><li>Data Space Total: 102 GB</li><li>Data Space Available: 102 GB</li><li>Metadata Space Used: 147.5 kB</li><li>Metadata Space Total: 1.07 GB</li><li>Metadata Space Available: 1.069 GB</li><li>Thin Pool Minimum Free Space: 10.2 GB</li><li>Udev Sync Supported: true</li><li>Deferred Removal Enabled: true</li><li>Deferred Deletion Enabled: true</li><li>Deferred Deleted Device Count: 0</li><li>Library Version: 1.02.135-RHEL7 (2016-11-16)</li><li><code>&lt;output truncated&gt;</code></li></ol><p>If Docker is configured correctly, the Data file and Metadata file is blank, and the pool name is docker-thinpool.</p><ol><li>After you have verified that the configuration is correct, you can remove the /var/lib/docker.bkdirectory which contains the previous configuration.</li><li>$ rm -rf /var/lib/docker.bk</li></ol><h4>Manage devicemapper</h4><h5><strong>Monitor the thin pool</strong></h5><p>Do not rely on LVM auto-extension alone. The volume group automatically extends, but the volume can still fill up. You can monitor free space on the volume using lvs or lvs -a. Consider using a monitoring tool at the OS level, such a Nagios.</p><p>To view the LVM logs, you can use journalctl:</p><p>$ journalctl -fu dm-event.service</p><p>If you run into repeated problems with thin pool, you can set the storage option dm.min_free_space to a value (representing a percentage) in /etc/docker.daemon.json. For instance, setting it to 10ensures that operations fail with a warning when the free space is at or near 10%. See the <a href="https://docs.docker.com/engine/reference/commandline/dockerd/#storage-driver-options">storage driver options in the Engine daemon reference</a>.</p><h5><strong>Increase capacity on a running device</strong></h5><p>You can increase the capacity of the pool on a running thin-pool device. This is useful if the data&#x27;s logical volume is full and the volume group is at full capacity. The specific procedure depends on whether you are using a <a href="https://docs.docker.com/storage/storagedriver/device-mapper-driver/#resize-a-loop-lvm-thin-pool">loop-lvm thin pool</a> or a <a href="https://docs.docker.com/storage/storagedriver/device-mapper-driver/#resize-a-direct-lvm-thin-pool">direct-lvm thin pool</a>.</p><h6><strong>RESIZE A LOOP-LVM THIN POOL</strong></h6><p>The easiest way to resize a loop-lvm thin pool is to <a href="https://docs.docker.com/storage/storagedriver/device-mapper-driver/#use-the-device_tool-utility">use the device_tool utility</a>, but you can <a href="https://docs.docker.com/storage/storagedriver/device-mapper-driver/#use-operating-system-utilities">use operating system utilities</a> instead.</p><p><strong>Use the device_tool utility</strong></p><p>A community-contributed script called device_tool.go is available in the <a href="https://github.com/moby/moby/tree/master/contrib/docker-device-tool">moby/moby</a> Github repository. You can use this tool to resize a loop-lvm thin pool, avoiding the long process above. This tool is not guaranteed to work, but you should only be using loop-lvm on non-production systems.</p><p>If you do not want to use device_tool, you can <a href="https://docs.docker.com/storage/storagedriver/device-mapper-driver/#use-operating-system-utilities">resize the thin pool manually</a> instead.</p><ol><li>To use the tool, clone the Github repository, change to the contrib/docker-device-tool, and follow the instructions in the README.md to compile the tool.</li><li>Use the tool. The following example resizes the thin pool to 200GB.</li><li>$ ./device_tool resize 200GB</li></ol><p><strong>Use operating system utilities</strong></p><p>If you do not want to <a href="https://docs.docker.com/storage/storagedriver/device-mapper-driver/#use-the-device_tool-utility">use the device-tool utility</a>, you can resize a loop-lvm thin pool manually using the following procedure.</p><p>In loop-lvm mode, a loopback device is used to store the data, and another to store the metadata. loop-lvm mode is only supported for testing, because it has significant performance and stability drawbacks.</p><p>If you are using loop-lvm mode, the output of docker info shows file paths for Data loop file and Metadata loop file:</p><p>$ docker info |grep \&#x27;loop file\&#x27;</p><p>Data loop file: /var/lib/docker/devicemapper/data</p><p>Metadata loop file: /var/lib/docker/devicemapper/metadata</p><p>Follow these steps to increase the size of the thin pool. In this example, the thin pool is 100 GB, and is increased to 200 GB.</p><ol><li>List the sizes of the devices.</li><li>$ sudo ls -lh /var/lib/docker/devicemapper/</li><li>total 1175492</li><li>-rw------- 1 root root 100G Mar 30 05:22 data</li><li>-rw------- 1 root root 2.0G Mar 31 11:17 metadata</li><li>Increase the size of the data file to 200 G using the truncate command, which is used to increase <strong>or</strong> decrease the size of a file. Note that decreasing the size is a destructive operation.</li><li>$ sudo truncate -s 200G /var/lib/docker/devicemapper/data</li><li>Verify the file size changed.</li><li>$ sudo ls -lh /var/lib/docker/devicemapper/</li><li>total 1.2G</li><li>-rw------- 1 root root 200G Apr 14 08:47 data</li><li>-rw------- 1 root root 2.0G Apr 19 13:27 metadata</li><li>The loopback file has changed on disk but not in memory. List the size of the loopback device in memory, in GB. Reload it, then list the size again. After the reload, the size is 200 GB.</li><li>$ echo $<!-- -->[ $(sudo blockdev --getsize64 /dev/loop0) / 1024 / 1024 / 1024 ]</li><li>100</li><li>$ sudo losetup -c /dev/loop0</li><li>$ echo $<!-- -->[ $(sudo blockdev --getsize64 /dev/loop0) / 1024 / 1024 / 1024 ]</li><li>200</li><li>Reload the devicemapper thin pool.</li></ol><p>a. Get the pool name first. The pool name is the first field, delimited by <code style="background-color:lightgray"> :</code>. This command extracts it.</p><p>$ sudo dmsetup status | grep \&#x27; thin-pool \&#x27; | awk -F \&#x27;: \&#x27; {\&#x27;print $1\&#x27;}</p><p>docker-8:1-123141-pool</p><p>b. Dump the device mapper table for the thin pool.</p><p>$ sudo dmsetup table docker-8:1-123141-pool</p><p>0 209715200 thin-pool 7:1 7:0 128 32768 1 skip_block_zeroing</p><p>c. Calculate the total sectors of the thin pool using the second field of the output. The number is expressed in 512-k sectors. A 100G file has 209715200 512-k sectors. If you double this number to 200G, you get 419430400 512-k sectors.</p><p>d. Reload the thin pool with the new sector number, using the following three dmsetupcommands.</p><p>$ sudo dmsetup suspend docker-8:1-123141-pool</p><p>$ sudo dmsetup reload docker-8:1-123141-pool --table \&#x27;0 419430400 thin-pool 7:1 7:0 128 32768 1 skip_block_zeroing\&#x27;</p><p>$ sudo dmsetup resume docker-8:1-123141-pool</p><h6><strong>RESIZE A DIRECT-LVM THIN POOL</strong></h6><p>To extend a direct-lvm thin pool, you need to first attach a new block device to the Docker host, and make note of the name assigned to it by the kernel. In this example, the new block device is /dev/xvdg.</p><p>Follow this procedure to extend a direct-lvm thin pool, substituting your block device and other parameters to suit your situation.</p><ol><li>Gather information about your volume group.</li></ol><p>Use the pvdisplay command to find the physical block devices currently in use by your thin pool, and the volume group&#x27;s name.</p><p>$ sudo pvdisplay |grep \&#x27;VG Name\&#x27;</p><p>PV Name /dev/xvdf</p><p>VG Name docker</p><p>In the following steps, substitute your block device or volume group name as appropriate.</p><ol><li>Extend the volume group, using the vgextend command with the VG Name from the previous step, and the name of your <strong>new</strong> block device.</li><li>$ sudo vgextend docker /dev/xvdg</li><li>Physical volume &quot;/dev/xvdg&quot; successfully created.</li><li>Volume group &quot;docker&quot; successfully extended</li><li>Extend the docker/thinpool logical volume. This command uses 100% of the volume right away, without auto-extend. To extend the metadata thinpool instead, use docker/thinpool_tmeta.</li><li>$ sudo lvextend -l+100%FREE -n docker/thinpool</li><li>Size of logical volume docker/thinpool_tdata changed from 95.00 GiB (24319 extents) to 198.00 GiB (50688 extents).</li><li>Logical volume docker/thinpool_tdata successfully resized.</li><li>Verify the new thin pool size using the Data Space Available field in the output of docker info. If you extended the docker/thinpool_tmeta logical volume instead, look for Metadata Space Available.</li><li>Storage Driver: devicemapper</li><li>Pool Name: docker-thinpool</li><li>Pool Blocksize: 524.3 kB</li><li>Base Device Size: 10.74 GB</li><li>Backing Filesystem: xfs</li><li>Data file:</li><li>Metadata file:</li><li>Data Space Used: 212.3 MB</li><li>Data Space Total: 212.6 GB</li><li>Data Space Available: 212.4 GB</li><li>Metadata Space Used: 286.7 kB</li><li>Metadata Space Total: 1.07 GB</li><li>Metadata Space Available: 1.069 GB</li><li><code>&lt;output truncated&gt;</code></li></ol><h5><strong>Activate the devicemapper after reboot</strong></h5><p>If you reboot the host and find that the docker service failed to start, look for the error, &quot;Non existing device&quot;. You need to re-activate the logical volumes with this command:</p><p>sudo lvchange -ay docker/thinpool</p><h4>How the devicemapper storage driver works</h4><p><strong>Warning</strong>: Do not directly manipulate any files or directories within /var/lib/docker/. These files and directories are managed by Docker.</p><p>Use the lsblk command to see the devices and their pools, from the operating system&#x27;s point of view:</p><p>$ sudo lsblk</p><p>NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT</p><p>xvda 202:0 0 8G 0 disk</p><p>└─xvda1 202:1 0 8G 0 part /</p><p>xvdf 202:80 0 100G 0 disk</p><p>├─docker-thinpool_tmeta 253:0 0 1020M 0 lvm</p><p>│ └─docker-thinpool 253:2 0 95G 0 lvm</p><p>└─docker-thinpool_tdata 253:1 0 95G 0 lvm</p><p>└─docker-thinpool 253:2 0 95G 0 lvm</p><p>Use the mount command to see the mount-point Docker is using:</p><p>$ mount |grep devicemapper</p><p>/dev/xvda1 on /var/lib/docker/devicemapper type xfs (rw,relatime,seclabel,attr2,inode64,noquota)</p><p>When you use devicemapper, Docker stores image and layer contents in the thinpool, and exposes them to containers by mounting them under subdirectories of /var/lib/docker/devicemapper/.</p><h5><strong>Image and container layers on-disk</strong></h5><p>The /var/lib/docker/devicemapper/metadata/ directory contains metadata about the Devicemapper configuration itself and about each image and container layer that exist. The devicemapper storage driver uses snapshots, and this metadata include information about those snapshots. These files are in JSON format.</p><p>The /var/lib/devicemapper/mnt/ directory contains a mount point for each image and container layer that exists. Image layer mount points are empty, but a container&#x27;s mount point shows the container&#x27;s filesystem as it appears from within the container.</p><h5><strong>Image layering and sharing</strong></h5><p>The devicemapper storage driver uses dedicated block devices rather than formatted filesystems, and operates on files at the block level for maximum performance during copy-on-write (CoW) operations.</p><h6><strong>SNAPSHOTS</strong></h6><p>Another feature of devicemapper is its use of snapshots (also sometimes called thin devices or virtual devices), which store the differences introduced in each layer as very small, lightweight thin pools. Snapshots provide many benefits:</p><ul><li>Layers which are shared in common between containers are only stored on disk once, unless they are writable. For instance, if you have 10 different images which are all based on alpine, the alpine image and all its parent images are only stored once each on disk.</li><li>Snapshots are an implementation of a copy-on-write (CoW) strategy. This means that a given file or directory is only copied to the container&#x27;s writable layer when it is modified or deleted by that container.</li><li>Because devicemapper operates at the block level, multiple blocks in a writable layer can be modified simultaneously.</li><li>Snapshots can be backed up using standard OS-level backup utilities. Just make a copy of /var/lib/docker/devicemapper/.</li></ul><h6><strong>DEVICEMAPPER WORKFLOW</strong></h6><p>When you start Docker with the devicemapper storage driver, all objects related to image and container layers are stored in /var/lib/docker/devicemapper/, which is backed by one or more block-level devices, either loopback devices (testing only) or physical disks.</p><ul><li>The base device is the lowest-level object. This is the thin pool itself. You can examine it using docker info. It contains a filesystem. This base device is the starting point for every image and container layer. The base device is a Device Mapper implementation detail, rather than a Docker layer.</li><li>Metadata about the base device and each image or container layer is stored in/var/lib/docker/devicemapper/metadata/ in JSON format. These layers are copy-on-write snapshots, which means that they are empty until they diverge from their parent layers.</li><li>Each container&#x27;s writable layer is mounted on a mountpoint in/var/lib/docker/devicemapper/mnt/. An empty directory exists for each read-only image layer and each stopped container.</li></ul><p>Each image layer is a snapshot of the layer below it. The lowest layer of each image is a snapshot of the base device that exists in the pool. When you run a container, it is a snapshot of the image the container is based on. The following example shows a Docker host with two running containers. The first is a ubuntu container and the second is a busybox container.</p><h4>How container reads and writes work with devicemapper</h4><h5><strong>Reading files</strong></h5><p>With devicemapper, reads happen at the block level. The diagram below shows the high level process for reading a single block (0x44f) in an example container.</p><p>An application makes a read request for block 0x44f in the container. Because the container is a thin snapshot of an image, it doesn&#x27;t have the block, but it has a pointer to the block on the nearest parent image where it does exist, and it reads the block from there. The block now exists in the container&#x27;s memory.</p><h5><strong>Writing files</strong></h5><p><strong>Writing a new file</strong>: With the devicemapper driver, writing new data to a container is accomplished by an allocate-on-demand operation. Each block of the new file is allocated in the container&#x27;s writable layer and the block is written there.</p><p><strong>Updating an existing file</strong>: The relevant block of the file is read from the nearest layer where it exists. When the container writes the file, only the modified blocks are written to the container&#x27;s writable layer.</p><p><strong>Deleting a file or directory</strong>: When you delete a file or directory in a container&#x27;s writable layer, or when an image layer deletes a file that exists in its parent layer, the devicemapper storage driver intercepts further read attempts on that file or directory and responds that the file or directory does not exist.</p><p><strong>Writing and then deleting a file</strong>: If a container writes to a file and later deletes the file, all of those operations happen in the container&#x27;s writable layer. In that case, if you are using direct-lvm, the blocks are freed. If you use loop-lvm, the blocks may not be freed. This is another reason not to useloop-lvm in production.</p><h4>Device Mapper and Docker performance</h4><ul><li><strong>allocate-on demand performance impact</strong>:</li></ul><p>The devicemapper storage driver uses an allocate-on-demand operation to allocate new blocks from the thin pool into a container&#x27;s writable layer. Each block is 64KB, so this is the minimum amount of space that is used for a write.</p><ul><li><strong>Copy-on-write performance impact</strong>: The first time a container modifies a specific block, that block is written to the container&#x27;s writable layer. Because these writes happen at the level of the block rather than the file, performance impact is minimized. However, writing a large number of blocks can still negatively impact performance, and the devicemapper storage driver may actually perform worse than other storage drivers in this scenario. For write-heavy workloads, you should use data volumes, which bypass the storage driver completely.</li></ul><h5><strong>Performance best practices</strong></h5><p>Keep these things in mind to maximize performance when using the devicemapper storage driver.</p><ul><li><strong>Use direct-lvm</strong>: The loop-lvm mode is not performant and should never be used in production.</li><li><strong>Use fast storage</strong>: Solid-state drives (SSDs) provide faster reads and writes than spinning disks.</li><li><strong>Memory usage</strong>: the devicemapper uses more memory than some other storage drivers. Each launched container loads one or more copies of its files into memory, depending on how many blocks of the same file are being modified at the same time. Due to the memory pressure, the devicemapper storage driver may not be the right choice for certain workloads in high-density use cases.</li><li><strong>Use volumes for write-heavy workloads</strong>: Volumes provide the best and most predictable performance for write-heavy workloads. This is because they bypass the storage driver and do not incur any of the potential overheads introduced by thin provisioning and copy-on-write. Volumes have other benefits, such as allowing you to share data among containers and persisting even when no running container is using them.</li></ul><h4>Related Information</h4><ul><li><a href="https://docs.docker.com/storage/volumes/">Volumes</a></li><li><a href="https://docs.docker.com/storage/storagedriver/imagesandcontainers/">Understand images, containers, and storage drivers</a></li><li><a href="https://docs.docker.com/storage/storagedriver/selectadriver/">Select a storage driver</a></li></ul><h3>Use the OverlayFS storage driver</h3><p><em>Estimated reading time: 19 minutes</em></p><p>OverlayFS is a modern union filesystem that is similar to AUFS, but faster and with a simpler implementation. Docker provides two storage drivers for OverlayFS: the original overlay, and the newer and more stable overlay2.</p><p>This topic refers to the Linux kernel driver as OverlayFS and to the Docker storage driver as overlayor overlay2.</p><p><strong>Note: If you use OverlayFS, use the overlay2 driver rather than the overlay driver, because it is more efficient in terms of inode utilization. To use the new driver, you need version 4.0 or higher of the Linux kernel, unless you are a Docker EE user on RHEL or CentOS, in which case you need version 3.10.0-693 or higher of the kernel and to follow some extra steps.</strong></p><p>For more information about differences between overlay vs overlay2, check <a href="https://docs.docker.com/storage/storagedriver/select-storage-driver/">Docker storage drivers</a>.</p><h4>Prerequisites</h4><p>OverlayFS is supported if you meet the following prerequisites:</p><ul><li>The overlay2 driver is supported for Docker EE and recommended for Docker CE.</li><li>The overlay driver is allowed but not recommended for Docker CE.</li><li>Version 4.0 or higher of the Linux kernel, or RHEL or CentOS using version 3.10.0-693 of the kernel or higher. Docker EE users using kernels older than 4.0 need to follow some extra steps, outlined below. If you use an older kernel, you need to use the overlay driver, which is not recommended.</li><li>The following backing filesystems are supported:<ul><li>ext4 (RHEL 7.1 only)</li><li>xfs (RHEL 7.2 and higher), but only with d_type=true enabled. Use xfs_info to verify that the ftype option is set to 1. To format an xfs filesystem correctly, use the flag -n ftype=1.</li></ul></li></ul><p><strong>Warning</strong>: Running on XFS without d_type support now causes Docker to skip the attempt to use the overlay or overlay2 driver. Existing installs will continue to run, but produce an error. This is to allow users to migrate their data. In a future version, this will be a fatal error, which will prevent Docker from starting.</p><ul><li>Changing the storage driver makes any containers you have already created inaccessible on the local system. Use docker save to save containers, and push existing images to Docker Hub or a private repository, so that you not need to re-create them later.</li></ul><h4>Configure Docker with the overlay or overlay2storage driver</h4><p>It is highly recommended that you use the overlay2 driver if possible, rather than the overlaydriver. The overlay driver is <strong>not</strong> supported for Docker EE.</p><p>To configure Docker to use the overlay storage driver your Docker host must be running version 3.18 of the Linux kernel (preferably newer) with the overlay kernel module loaded. For the overlay2 driver, the version of your kernel must be 4.0 or newer.</p><p>Before following this procedure, you must first meet all the <a href="https://docs.docker.com/storage/storagedriver/overlayfs-driver/#prerequisites">prerequisites</a>.</p><ol><li>Stop Docker.</li><li>$ sudo systemctl stop docker</li><li>Copy the contents of /var/lib/docker to a temporary location.</li><li>$ cp -au /var/lib/docker /var/lib/docker.bk</li><li>If you want to use a separate backing filesystem from the one used by /var/lib/, format the filesystem and mount it into /var/lib/docker. Make sure add this mount to /etc/fstab to make it permanent.</li><li>Edit /etc/docker/daemon.json. If it does not yet exist, create it. Assuming that the file was empty, add the following contents.</li><li>{</li><li>&quot;storage-driver&quot;: &quot;overlay2&quot;</li><li>}</li></ol><p><strong>Note: RHEL and CentOS users on Docker EE 17.06</strong></p><p>You need to add a second option to the daemon.json to disable the check for version 4.0 or higher of the Linux kernel. Your daemon.json should look like the following. <strong>This is only needed for Docker EE users of RHEL or CentOS.</strong> Do not attempt to use overlay2 with kernel versions older than 3.10.0-693.</p><p>{</p><p>&quot;storage-driver&quot;: &quot;overlay2&quot;,</p><p>&quot;storage-opts&quot;: [</p><p>&quot;overlay2.override_kernel_check=true&quot;</p><p>]</p><p>}</p><p>If you need to use the legacy overlay driver, specify it instead.</p><p>More storage options are available. See all storage options for each storage driver:</p><ul><li><ul><li><a href="https://docs.docker.com/engine/reference/commandline/dockerd/#storage-driver-options">Stable</a></li><li><a href="https://docs.docker.com/edge/engine/reference/commandline/dockerd/#storage-driver-options">Edge</a></li></ul></li></ul><p>Docker does not start if the daemon.json file contains badly-formed JSON.</p><ol><li>Start Docker.</li><li>$ sudo systemctl start docker</li><li>Verify that the daemon is using the overlay/overlay2 storage driver. Use the docker infocommand and look for Storage Driver and Backing filesystem.</li><li>$ docker info</li><li>Containers: 0</li><li>Images: 0</li><li>Storage Driver: overlay</li><li>Backing Filesystem: extfs</li><li><code>&lt;output truncated&gt;</code></li></ol><p>Docker is now using the overlay2 storage driver. Docker has automatically created the overlaymount with the required lowerdir, upperdir, merged, and workdir constructs.</p><p>Continue reading for details about how OverlayFS works within your Docker containers, as well as performance advice and information about limitations of its compatibility with different backing filesystems.</p><h4>How the overlay2 driver works</h4><p>If you are still using the overlay driver rather than overlay2, see <a href="https://docs.docker.com/storage/storagedriver/overlayfs-driver/#how-the-overlay-driver-works">How the overlay driver works</a>instead.</p><p>OverlayFS layers two directories on a single Linux host and presents them as a single directory. These directories are called layers and the unification process is referred to as a union mount. OverlayFS refers to the lower directory as lowerdir and the upper directory a upperdir. The unified view is exposed through its own directory called merged.</p><p>While the overlay driver only works with a single lower OverlayFS layer and hence requires hard links for implementation of multi-layered images, the overlay2 driver natively supports up to 128 lower OverlayFS layers. This capability provides better performance for layer-related Docker commands such as docker build and docker commit, and consumes fewer inodes on the backing filesystem.</p><h5><strong>Image and container layers on-disk</strong></h5><p>After downloading a five-layer image using docker pull ubuntu, you can see six directories under /var/lib/docker/overlay2.</p><p><strong>Warning</strong>: Do not directly manipulate any files or directories within /var/lib/docker/. These files and directories are managed by Docker.</p><p>$ ls -l /var/lib/docker/overlay2</p><p>total 24</p><p>drwx------ 5 root root 4096 Jun 20 07:36 223c2864175491657d238e2664251df13b63adb8d050924fd1bfcdb278b866f7</p><p>drwx------ 3 root root 4096 Jun 20 07:36 3a36935c9df35472229c57f4a27105a136f5e4dbef0f87905b2e506e494e348b</p><p>drwx------ 5 root root 4096 Jun 20 07:36 4e9fa83caff3e8f4cc83693fa407a4a9fac9573deaf481506c102d484dd1e6a1</p><p>drwx------ 5 root root 4096 Jun 20 07:36 e8876a226237217ec61c4baf238a32992291d059fdac95ed6303bdff3f59cff5</p><p>drwx------ 5 root root 4096 Jun 20 07:36 eca1e4e1694283e001f200a667bb3cb40853cf2d1b12c29feda7422fed78afed</p><p>drwx------ 2 root root 4096 Jun 20 07:36 l</p><p>The new l (lowercase L) directory contains shortened layer identifiers as symbolic links. These identifiers are used to avoid hitting the page size limitation on arguments to the mount command.</p><p>$ ls -l /var/lib/docker/overlay2/l</p><p>total 20</p><p>lrwxrwxrwx 1 root root 72 Jun 20 07:36 6Y5IM2XC7TSNIJZZFLJCS6I4I4 -&gt; ../3a36935c9df35472229c57f4a27105a136f5e4dbef0f87905b2e506e494e348b/diff</p><p>lrwxrwxrwx 1 root root 72 Jun 20 07:36 B3WWEFKBG3PLLV737KZFIASSW7 -&gt; ../4e9fa83caff3e8f4cc83693fa407a4a9fac9573deaf481506c102d484dd1e6a1/diff</p><p>lrwxrwxrwx 1 root root 72 Jun 20 07:36 JEYMODZYFCZFYSDABYXD5MF6YO -&gt; ../eca1e4e1694283e001f200a667bb3cb40853cf2d1b12c29feda7422fed78afed/diff</p><p>lrwxrwxrwx 1 root root 72 Jun 20 07:36 NFYKDW6APBCCUCTOUSYDH4DXAT -&gt; ../223c2864175491657d238e2664251df13b63adb8d050924fd1bfcdb278b866f7/diff</p><p>lrwxrwxrwx 1 root root 72 Jun 20 07:36 UL2MW33MSE3Q5VYIKBRN4ZAGQP -&gt; ../e8876a226237217ec61c4baf238a32992291d059fdac95ed6303bdff3f59cff5/diff</p><p>The lowest layer contains a file called link, which contains the name of the shortened identifier, and a directory called diff which contains the layer&#x27;s contents.</p><p>$ ls /var/lib/docker/overlay2/3a36935c9df35472229c57f4a27105a136f5e4dbef0f87905b2e506e494e348b/</p><p>diff link</p><p>$ cat /var/lib/docker/overlay2/3a36935c9df35472229c57f4a27105a136f5e4dbef0f87905b2e506e494e348b/link</p><p>6Y5IM2XC7TSNIJZZFLJCS6I4I4</p><p>$ ls /var/lib/docker/overlay2/3a36935c9df35472229c57f4a27105a136f5e4dbef0f87905b2e506e494e348b/diff</p><p>bin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var</p><p>The second-lowest layer, and each higher layer, contain a file called lower, which denotes its parent, and a directory called diff which contains its contents. It also contains a merged directory, which contains the unified contents of its parent layer and itself, and a work directory which is used internally by OverlayFS.</p><p>$ ls /var/lib/docker/overlay2/223c2864175491657d238e2664251df13b63adb8d050924fd1bfcdb278b866f7</p><p>diff link lower merged work</p><p>$ cat /var/lib/docker/overlay2/223c2864175491657d238e2664251df13b63adb8d050924fd1bfcdb278b866f7/lower</p><p>l/6Y5IM2XC7TSNIJZZFLJCS6I4I4</p><p>$ ls /var/lib/docker/overlay2/223c2864175491657d238e2664251df13b63adb8d050924fd1bfcdb278b866f7/diff/</p><p>etc sbin usr var</p><p>To view the mounts which exist when you use the overlay storage driver with Docker, use the mountcommand. The output below is truncated for readability.</p><p>$ mount | grep overlay</p><p>overlay on /var/lib/docker/overlay2/9186877cdf386d0a3b016149cf30c208f326dca307529e646afce5b3f83f5304/merged</p><p>type overlay (rw,relatime,</p><p>lowerdir=l/DJA75GUWHWG7EWICFYX54FIOVT:l/B3WWEFKBG3PLLV737KZFIASSW7:l/JEYMODZYFCZFYSDABYXD5MF6YO:l/UL2MW33MSE3Q5VYIKBRN4ZAGQP:l/NFYKDW6APBCCUCTOUSYDH4DXAT:l/6Y5IM2XC7TSNIJZZFLJCS6I4I4,</p><p>upperdir=9186877cdf386d0a3b016149cf30c208f326dca307529e646afce5b3f83f5304/diff,</p><p>workdir=9186877cdf386d0a3b016149cf30c208f326dca307529e646afce5b3f83f5304/work)</p><p>The rw on the second line shows that the overlay mount is read-write.</p><h4>How the overlay driver works</h4><p>This content applies to the overlay driver only. Docker recommends using the overlay2 driver, which works differently. See <a href="https://docs.docker.com/storage/storagedriver/overlayfs-driver/#how-the-overlay2-driver-works">How the overlay2 driver works</a> for overlay2.</p><p>OverlayFS layers two directories on a single Linux host and presents them as a single directory. These directories are called layers and the unification process is referred to a a union mount. OverlayFS refers to the lower directory as lowerdir and the upper directory a upperdir. The unified view is exposed through its own directory called merged.</p><p>The diagram below shows how a Docker image and a Docker container are layered. The image layer is the lowerdir and the container layer is the upperdir. The unified view is exposed through a directory called merged which is effectively the containers mount point. The diagram shows how Docker constructs map to OverlayFS constructs.</p><p>Where the image layer and the container layer contain the same files, the container layer &quot;wins&quot; and obscures the existence of the same files in the image layer.</p><p>The overlay driver only works with two layers. This means that multi-layered images cannot be implemented as multiple OverlayFS layers. Instead, each image layer is implemented as its own directory under /var/lib/docker/overlay. Hard links are then used as a space-efficient way to reference data shared with lower layers. As of Docker 1.10, image layer IDs no longer correspond to directory names in /var/lib/docker/.</p><p>To create a container, the overlay driver combines the directory representing the image&#x27;s top layer plus a new directory for the container. The image&#x27;s top layer is the lowerdir in the overlay and is read-only. The new directory for the container is the upperdir and is writable.</p><h5><strong>Image and container layers on-disk</strong></h5><p>The following docker pull command shows a Docker host downloading a Docker image comprising five layers.</p><p>$ docker pull ubuntu</p><p>Using default tag: latest</p><p>latest: Pulling from library/ubuntu</p><p>5ba4f30e5bea: Pull complete</p><p>9d7d19c9dc56: Pull complete</p><p>ac6ad7efd0f9: Pull complete</p><p>e7491a747824: Pull complete</p><p>a3ed95caeb02: Pull complete</p><p>Digest: sha256:46fb5d001b88ad904c5c732b086b596b92cfb4a4840a3abd0e35dbb6870585e4</p><p>Status: Downloaded newer image for ubuntu:latest</p><h6><strong>THE IMAGE LAYERS</strong></h6><p>Each image layer has its own directory within /var/lib/docker/overlay/, which contains its contents, as shown below. The image layer IDs do not correspond to the directory IDs.</p><p><strong>Warning</strong>: Do not directly manipulate any files or directories within /var/lib/docker/. These files and directories are managed by Docker.</p><p>$ ls -l /var/lib/docker/overlay/</p><p>total 20</p><p>drwx------ 3 root root 4096 Jun 20 16:11 38f3ed2eac129654acef11c32670b534670c3a06e483fce313d72e3e0a15baa8</p><p>drwx------ 3 root root 4096 Jun 20 16:11 55f1e14c361b90570df46371b20ce6d480c434981cbda5fd68c6ff61aa0a5358</p><p>drwx------ 3 root root 4096 Jun 20 16:11 824c8a961a4f5e8fe4f4243dab57c5be798e7fd195f6d88ab06aea92ba931654</p><p>drwx------ 3 root root 4096 Jun 20 16:11 ad0fe55125ebf599da124da175174a4b8c1878afe6907bf7c78570341f308461</p><p>drwx------ 3 root root 4096 Jun 20 16:11 edab9b5e5bf73f2997524eebeac1de4cf9c8b904fa8ad3ec43b3504196aa3801</p><p>The image layer directories contain the files unique to that layer as well as hard links to the data that is shared with lower layers. This allows for efficient use of disk space.</p><p>$ ls -i /var/lib/docker/overlay/38f3ed2eac129654acef11c32670b534670c3a06e483fce313d72e3e0a15baa8/root/bin/ls</p><p>19793696 /var/lib/docker/overlay/38f3ed2eac129654acef11c32670b534670c3a06e483fce313d72e3e0a15baa8/root/bin/ls</p><p>$ ls -i /var/lib/docker/overlay/55f1e14c361b90570df46371b20ce6d480c434981cbda5fd68c6ff61aa0a5358/root/bin/ls</p><p>19793696 /var/lib/docker/overlay/55f1e14c361b90570df46371b20ce6d480c434981cbda5fd68c6ff61aa0a5358/root/bin/ls</p><h6><strong>THE CONTAINER LAYER</strong></h6><p>Containers also exist on-disk in the Docker host&#x27;s filesystem under /var/lib/docker/overlay/. If you list a running container&#x27;s subdirectory using the ls -l command, three directories and one file exist:</p><p>$ ls -l /var/lib/docker/overlay/<code style="background-color:lightgray">&lt;directory-of-running-container&gt;</code></p><p>total 16</p><p>-rw-r--r-- 1 root root 64 Jun 20 16:39 lower-id</p><p>drwxr-xr-x 1 root root 4096 Jun 20 16:39 merged</p><p>drwxr-xr-x 4 root root 4096 Jun 20 16:39 upper</p><p>drwx------ 3 root root 4096 Jun 20 16:39 work</p><p>The lower-id file contains the ID of the top layer of the image the container is based on, which is the OverlayFS lowerdir.</p><p>$ cat /var/lib/docker/overlay/ec444863a55a9f1ca2df72223d459c5d940a721b2288ff86a3f27be28b53be6c/lower-id</p><p>55f1e14c361b90570df46371b20ce6d480c434981cbda5fd68c6ff61aa0a5358</p><p>The upper directory contains the contents of the container&#x27;s read-write layer, which corresponds to the OverlayFS upperdir.</p><p>The merged directory is the union mount of the lowerdir and upperdir, which comprises the view of the filesystem from within the running container.</p><p>The work directory is internal to OverlayFS.</p><p>To view the mounts which exist when you use the overlay storage driver with Docker, use the mountcommand. The output below is truncated for readability.</p><p>$ mount | grep overlay</p><p>overlay on /var/lib/docker/overlay/ec444863a55a.../merged</p><p>type overlay (rw,relatime,lowerdir=/var/lib/docker/overlay/55f1e14c361b.../root,</p><p>upperdir=/var/lib/docker/overlay/ec444863a55a.../upper,</p><p>workdir=/var/lib/docker/overlay/ec444863a55a.../work)</p><p>The rw on the second line shows that the overlay mount is read-write.</p><h4>How container reads and writes work with overlayor overlay2</h4><h5><strong>Reading files</strong></h5><p>Consider three scenarios where a container opens a file for read access with overlay.</p><ul><li><strong>The file does not exist in the container layer</strong>: If a container opens a file for read access and the file does not already exist in the container (upperdir) it is read from the image (lowerdir). This incurs very little performance overhead.</li><li><strong>The file only exists in the container layer</strong>: If a container opens a file for read access and the file exists in the container (upperdir) and not in the image (lowerdir), it is read directly from the container.</li><li><strong>The file exists in both the container layer and the image layer</strong>: If a container opens a file for read access and the file exists in the image layer and the container layer, the file&#x27;s version in the container layer is read. Files in the container layer (upperdir) obscure files with the same name in the image layer (lowerdir).</li></ul><h5><strong>Modifying files or directories</strong></h5><p>Consider some scenarios where files in a container are modified.</p><ul><li><strong>Writing to a file for the first time</strong>: The first time a container writes to an existing file, that file does not exist in the container (upperdir). The overlay/overlay2 driver performs a copy_upoperation to copy the file from the image (lowerdir) to the container (upperdir). The container then writes the changes to the new copy of the file in the container layer.</li></ul><p>However, OverlayFS works at the file level rather than the block level. This means that all OverlayFS copy_up operations copy the entire file, even if the\ file is very large and only a small part of it is being modified. This can have a noticeable impact on container write performance. However, two things are worth noting:</p><ul><li><ul><li>The copy_up operation only occurs the first time a given file is written to. Subsequent writes to the same file operate against the copy of the file already copied up to the container.</li><li>OverlayFS only works with two layers. This means that performance should be better than AUFS, which can suffer noticeable latencies when searching for files in images with many layers. This advantage applies to both overlay and overlay2 drivers. overlayfs2 is slightly less performant than overlayfs on initial read, because it must look through more layers, but it caches the results so this is only a small penalty.</li></ul></li><li><p><strong>Deleting files and directories</strong>:</p><ul><li>When a file is deleted within a container, a whiteout file is created in the container (upperdir). The version of the file in the image layer (lowerdir) is not deleted (because the lowerdir is read-only). However, the whiteout file prevents it from being available to the container.</li><li>When a directory is deleted within a container, an opaque directory is created within the container (upperdir). This works in the same way as a whiteout file and effectively prevents the directory from being accessed, even though it still exists in the image (lowerdir).</li></ul></li><li><p><strong>Renaming directories</strong>: Calling rename(2) for a directory is allowed only when both the source and the destination path are on the top layer. Otherwise, it returns EXDEV error (&quot;cross-device link not permitted&quot;). Your application needs to be designed to handle EXDEV and fall back to a &quot;copy and unlink&quot; strategy.</p></li></ul><h4>OverlayFS and Docker Performance</h4><p>Both overlay2 and overlay drivers are more performant than aufs and devicemapper. In certain circumstances, overlay2 may perform better than btrfs as well. However, be aware of the following details.</p><ul><li><strong>Page Caching</strong>. OverlayFS supports page cache sharing. Multiple containers accessing the same file share a single page cache entry for that file. This makes the overlay and overlay2 drivers efficient with memory and a good option for high-density use cases such as PaaS.</li><li><strong>copy_up</strong>. As with AUFS, OverlayFS performs copy-up operations whenever a container writes to a file for the first time. This can add latency into the write operation, especially for large files. However, once the file has been copied up, all subsequent writes to that file occur in the upper layer, without the need for further copy-up operations.</li></ul><p>The OverlayFS copy_up operation is faster than the same operation with AUFS, because AUFS supports more layers than OverlayFS and it is possible to incur far larger latencies if searching through many AUFS layers. overlay2 supports multiple layers as well, but mitigates any performance hit with caching.</p><ul><li><strong>Inode limits</strong>. Use of the overlay storage driver can cause excessive inode consumption. This is especially true in the presence of a large number of images and containers on the Docker host. The only way to increase the number of inodes available to a filesystem is to reformat it. To avoid running into this issue, it is highly recommended that you use overlay2 if at all possible.</li></ul><h5><strong>Performance best practices</strong></h5><p>The following generic performance best practices also apply to OverlayFS.</p><ul><li><strong>Use fast storage</strong>: Solid-state drives (SSDs) provide faster reads and writes than spinning disks.</li><li><strong>Use volumes for write-heavy workloads</strong>: Volumes provide the best and most predictable performance for write-heavy workloads. This is because they bypass the storage driver and do not incur any of the potential overheads introduced by thin provisioning and copy-on-write. Volumes have other benefits, such as allowing you to share data among containers and persisting even when no running container is using them.</li></ul><h4>Limitations on OverlayFS compatibility</h4><p>To summarize the OverlayFS&#x27;s aspect which is incompatible with other filesystems:</p><ul><li><strong>open(2)</strong>: OverlayFS only implements a subset of the POSIX standards. This can result in certain OverlayFS operations breaking POSIX standards. One such operation is the copy-up operation. Suppose that your application calls fd1=open(&quot;foo&quot;, O_RDONLY) and then fd2=open(&quot;foo&quot;, O_RDWR). In this case, your application expects fd1 and fd2 to refer to the same file. However, due to a copy-up operation that occurs after the second calling to open(2), the descriptors refer to different files. The fd1 continues to reference the file in the image (lowerdir) and the fd2 references the file in the container (upperdir). A workaround for this is to touch the files which causes the copy-up operation to happen. All subsequent open(2)operations regardless of read-only or read-write access mode reference the file in the container (upperdir).</li></ul><p>yum is known to be affected unless the yum-plugin-ovl package is installed. If the yum-plugin-ovl package is not available in your distribution such as RHEL/CentOS prior to 6.8 or 7.2, you may need to run touch /var/lib/rpm/* before running yum install. This package implements the touch workaround referenced above for yum.</p><ul><li><strong>rename(2)</strong>: OverlayFS does not fully support the rename(2) system call. Your application needs to detect its failure and fall back to a &quot;copy and unlink&quot; strategy.</li></ul><h3>Use the ZFS storage driver</h3><p><em>Estimated reading time: 9 minutes</em></p><p>ZFS is a next generation filesystem that supports many advanced storage technologies such as volume management, snapshots, checksumming, compression and deduplication, replication and more.</p><p>It was created by Sun Microsystems (now Oracle Corporation) and is open sourced under the CDDL license. Due to licensing incompatibilities between the CDDL and GPL, ZFS cannot be shipped as part of the mainline Linux kernel. However, the ZFS On Linux (ZoL) project provides an out-of-tree kernel module and userspace tools which can be installed separately.</p><p>The ZFS on Linux (ZoL) port is healthy and maturing. However, at this point in time it is not recommended to use the zfs Docker storage driver for production use unless you have substantial experience with ZFS on Linux.</p><p><strong>Note</strong>: There is also a FUSE implementation of ZFS on the Linux platform. This is not recommended. The native ZFS driver (ZoL) is more tested, more performant, and is more widely used. The remainder of this document refers to the native ZoL port.</p><h4>Prerequisites</h4><ul><li>ZFS requires one or more dedicated block devices, preferrably solid-state drives (SSDs).</li><li>ZFS is only supported on Docker CE with Ubuntu 14.04 or higher, with the zfs package (16.04 and higher) or zfs-native and ubuntu-zfs packages (14.04) installed.<ul><li>For Ubuntu 14.04, you need to enable a supplemental package repositoryppa:zfs-native/stable before you can install the package. See <code>&lt;https://launchpad.net/~zfs-native/+archive/ubuntu/stable&gt;</code> for instructions.</li></ul></li><li>ZFS is not supported on Docker EE or CS-Engine, or any other Linux platforms.</li><li>The /var/lib/docker/ directory must be mounted on a ZFS-formatted filesystem.</li><li>Changing the storage driver makes any containers you have already created inaccessible on the local system. Use docker save to save containers, and push existing images to Docker Hub or a private repository, so that you not need to re-create them later.</li></ul><h4>Configure Docker with the zfs storage driver</h4><ol><li>Stop Docker.</li><li>Copy the contents of /var/lib/docker/ to /var/lib/docker.bk and remove the contents of /var/lib/docker/.</li><li>$ sudo cp -au /var/lib/docker /var/lib/docker.bk</li><li>$ sudo rm -rf /var/lib/docker/*</li><li>Create a new zpool on your dedicated block device or devices, and mount it into /var/lib/docker/. Be sure you have specified the correct devices, because this is a destructive operation. This example adds two devices to the pool.</li><li>$ sudo zpool create -f zpool-docker -m /var/lib/docker /dev/xvdf /dev/xvdg</li></ol><p>The command creates the zpool and names it zpool-docker. The name is for display purposes only, and you can use a different name. Check that the pool was created and mounted correctly using zfs list.</p><p>$ sudo zfs list</p><p>NAME USED AVAIL REFER MOUNTPOINT</p><p>zpool-docker 55K 96.4G 19K /var/lib/docker</p><ol><li>Configure Docker to use zfs. Edit /etc/docker/daemon.json and set the storage-driver to zfs. If the file was empty before, it should now look like this:</li><li>{</li><li>&quot;storage-driver&quot;: &quot;zfs&quot;</li><li>}</li></ol><p>Save and close the file.</p><ol><li>Start Docker. Use docker info to verify that the storage driver is zfs.</li><li>$ sudo docker info</li><li>Containers: 0</li><li>Running: 0</li><li>Paused: 0</li><li>Stopped: 0</li><li>Images: 0</li><li>Server Version: 17.03.1-ce</li><li>Storage Driver: zfs</li><li>Zpool: zpool-docker</li><li>Zpool Health: ONLINE</li><li>Parent Dataset: zpool-docker</li><li>Space Used By Parent: 249856</li><li>Space Available: 103498395648</li><li>Parent Quota: no</li><li>Compression: off</li><li><code>&lt;output truncated&gt;</code></li></ol><h4>Manage zfs</h4><h5><strong>Increase capacity on a running device</strong></h5><p>To increase the size of the zpool, you need to add a dedicated block device to the Docker host, and then add it to the zpool using the zpool add command:</p><p>$ sudo zpool add zpool-docker /dev/xvdh</p><h5><strong>Limit a container&#x27;s writable storage quota</strong></h5><p>If you want to implement a quota on a per-image/dataset basis, you can set the size storage option to limit the amount of space a single container can use for its writable layer.</p><p>Edit /etc/docker/daemon.json and add the following:</p><p>{</p><p>&quot;storage-driver&quot;: &quot;zfs&quot;,</p><p>&quot;storage-opts&quot;: <!-- -->[&quot;size=256M&quot;]</p><p>}</p><p>See all storage options for each storage driver:</p><ul><li><a href="https://docs.docker.com/engine/reference/commandline/dockerd/#storage-driver-options">Stable</a></li><li><a href="https://docs.docker.com/edge/engine/reference/commandline/dockerd/#storage-driver-options">Edge</a></li></ul><p>Save and close the file, and restart Docker.</p><h4>How the zfs storage driver works</h4><p>ZFS uses the following objects:</p><ul><li><strong>filesystems</strong>: thinly provisioned, with space allocated from the zpool on demand.</li><li><strong>snapshots</strong>: read-only space-efficient point-in-time copies of filesystems.</li><li><strong>clones</strong>: Read-write copies of snapshots. Used for storing the differences from the previous layer.</li></ul><p>The process of creating a clone:</p><ol><li>A read-only snapshot is created from the filesystem.</li><li>A writable clone is created from the snapshot. This contains any differences from the parent layer.</li></ol><p>Filesystems, snapshots, and clones all allocate space from the underlying zpool.</p><h5><strong>Image and container layers on-disk</strong></h5><p>Each running container&#x27;s unified filesystem is mounted on a mount point in/var/lib/docker/zfs/graph/. Continue reading for an explanation of how the unified filesystem is composed.</p><h5><strong>Image layering and sharing</strong></h5><p>The base layer of an image is a ZFS filesystem. Each child layer is a ZFS clone based on a ZFS snapshot of the layer below it. A container is a ZFS clone based on a ZFS Snapshot of the top layer of the image it&#x27;s created from.</p><p>The diagram below shows how this is put together with a running container based on a two-layer image.</p><p>When you start a container, the following steps happen in order:</p><ol><li>The base layer of the image exists on the Docker host as a ZFS filesystem.</li><li>Additional image layers are clones of the dataset hosting the image layer directly below it.</li></ol><p>In the diagram, &quot;Layer 1&quot; is added by taking a ZFS snapshot of the base layer and then creating a clone from that snapshot. The clone is writable and consumes space on-demand from the zpool. The snapshot is read-only, maintaining the base layer as an immutable object.</p><ol><li>When the container is launched, a writable layer is added above the image.</li></ol><p>In the diagram, the container&#x27;s read-write layer is created by making a snapshot of the top layer of the image (Layer 1) and creating a clone from that snapshot.</p><ol><li>As the container modifies the contents of its writable layer, space is allocated for the blocks that are changed. By default, these blocks are 128k.</li></ol><h4>How container reads and writes work with zfs</h4><h5><strong>Reading files</strong></h5><p>Each container&#x27;s writable layer is a ZFS clone which shares all its data with the dataset it was created from (the snapshots of its parent layers). Read operations are fasst, even if the data being read is from a deep layer. This diagram illustrates how block sharing works:</p><h5><strong>Writing files</strong></h5><p><strong>Writing a new file</strong>: space is allocated on demand from the underlying zpool and the blocks are written directly into the container&#x27;s writable layer.</p><p><strong>Modifying an existing file</strong>: space is allocated only for the changed blocks, and those blocks are written into the container&#x27;s writable layer using a copy-on-write (CoW) strategy. This minimizes the size of the layer and increases write performance.</p><p><strong>Deleting a file or directory</strong>:</p><ul><li>When you delete a file or directory that exists in a lower layer, the ZFS driver masks the existence of the file or directory in the container&#x27;s writable layer, even though the file or directory still exists in the lower read-only layers.</li><li>If you create and then delete a file or directory within the container&#x27;s writable layer, the blocks are reclaimed by the zpool.</li></ul><h4>ZFS and Docker performance</h4><p>There are several factors that influence the performance of Docker using the zfs storage driver.</p><ul><li><strong>Memory</strong>: Memory has a major impact on ZFS performance. ZFS was originally designed for large enterprise-grade servers with a large amount of memory.</li><li><strong>ZFS Features</strong>: ZFS includes a de-duplication feature. Using this feature may save disk space, but uses a large amount of memory. It is recommended that you disable this feature for the zpoolyou are using with Docker, unless you are using SAN, NAS, or other hardware RAID technologies.</li><li><strong>ZFS Caching</strong>: ZFS caches disk blocks in a memory structure called the adaptive replacement cache (ARC). The Single Copy ARC feature of ZFS allows a single cached copy of a block to be shared by multiple clones of a With this feature, multiple running containers can share a single copy of a cached block. This feature makes ZFS a good option for PaaS and other high-density use cases.</li><li><strong>Fragmentation</strong>: Fragmentation is a natural byproduct of copy-on-write filesystems like ZFS. ZFS mitigates this by using a small block size of 128k. The ZFS intent log (ZIL) and the coalescing of writes (delayed writes) also help to reduce fragmentation. You can monitor fragmentation usingzfs status. However, there is no way to defragment ZFS without reformatting and restoring the filesystem.</li><li><strong>Use the native ZFS driver for Linux</strong>: The ZFS FUSE implementation is not recommended, due to poor performance.</li></ul><h5><strong>Performance best practices</strong></h5><ul><li><strong>Use fast storage</strong>: Solid-state drives (SSDs) provide faster reads and writes than spinning disks.</li><li><strong>Use volumes for write-heavy workloads</strong>: Volumes provide the best and most predictable performance for write-heavy workloads. This is because they bypass the storage driver and do not incur any of the potential overheads introduced by thin provisioning and copy-on-write. Volumes have other benefits, such as allowing you to share data among containers and persisting even when no running container is using them.</li></ul><h3>Use the VFS storage driver</h3><p><em>Estimated reading time: 3 minutes</em></p><p>The VFS storage driver is not a union filesystem; instead, each layer is a directory on disk, and there is no copy-on-write support. To create a new layer, a &quot;deep copy&quot; is done of the previous layer. This leads to lower performance and more space used on disk than other storage drivers. However, it is robust, stable, and works in every environment. It can also be used as a mechanism to verify other storage back-ends against, in a testing environment.</p><p>Docker 17.12 and higher include support for quotas when using the VFS driver.</p><h4>Configure Docker with the vfs storage driver</h4><ol><li>Stop Docker.</li><li>$ sudo systemctl stop docker</li><li>Edit /etc/docker/daemon.json. If it does not yet exist, create it. Assuming that the file was empty, add the following contents.</li><li>{</li><li>&quot;storage-driver&quot;: &quot;vfs&quot;</li><li>}</li></ol><p>If you want to set a quota to control the maximum size the VFS storage driver can use, set the size option on the storage-drivers key. Quotas are only supported in Docker 17.12 CE and higher.</p><p>{</p><p>&quot;storage-opts&quot;: <!-- -->[&quot;size=256M&quot;]</p><p>}</p><p>Docker does not start if the daemon.json file contains badly-formed JSON.</p><ol><li>Start Docker.</li><li>$ sudo systemctl start docker</li><li>Verify that the daemon is using the vfs storage driver. Use the docker info command and look for Storage Driver and Backing filesystem.</li><li>$ docker info</li><li>Storage Driver: vfs</li><li><code>&lt;output truncated&gt;</code></li></ol><p>Docker is now using the vfs storage driver. Docker has automatically created the /var/lib/docker/vfs/ directory, which contains all the layers used by running containers.</p><h4>How the vfs storage driver works</h4><p>VFS is not a union filesystem. Instead, each image layer and the writable container layer are represented on the Docker host as subdirectories within /var/lib/docker/. The union mount provides the unified view of all layers. The directory names do not directly correspond to the IDs of the layers themselves.</p><p>VFS does not support copy-on-write (COW), so each time a new layer is created, it is a deep copy of its parent layer. These layers are all located under /var/lib/docker/dir/.</p><h5><strong>Example: Image and container on-disk constructs</strong></h5><p>The following docker pull command shows a Docker host downloading a Docker image comprising five layers.</p><p>$ docker pull ubuntu</p><p>Using default tag: latest</p><p>latest: Pulling from library/ubuntu</p><p>e0a742c2abfd: Pull complete</p><p>486cb8339a27: Pull complete</p><p>dc6f0d824617: Pull complete</p><p>4f7a5649a30e: Pull complete</p><p>672363445ad2: Pull complete</p><p>Digest: sha256:84c334414e2bfdcae99509a6add166bbb4fa4041dc3fa6af08046a66fed3005f</p><p>Status: Downloaded newer image for ubuntu:latest</p><p>After pulling, each of these layers is represented as a subdirectory of /var/lib/docker/vfs/dir/. The directory names do not correlate with the image layer IDs shown in the docker pull command. To see the size taken up on disk by each layer, you can use the du -sh command, which gives the size as a human-readable value.</p><p>$ ls -l /var/lib/docker/vfs/dir/</p><p>total 0</p><p>drwxr-xr-x. 2 root root 19 Aug 2 18:19 3262dfbe53dac3e1ab7dcc8ad5d8c4d586a11d2ac3c4234892e34bff7f6b821e</p><p>drwxr-xr-x. 21 root root 224 Aug 2 18:23 6af21814449345f55d88c403e66564faad965d6afa84b294ae6e740c9ded2561</p><p>drwxr-xr-x. 21 root root 224 Aug 2 18:23 6d3be4585ba32f9f5cbff0110e8d07aea5f5b9fbb1439677c27e7dfee263171c</p><p>drwxr-xr-x. 21 root root 224 Aug 2 18:23 9ecd2d88ca177413ab89f987e1507325285a7418fc76d0dcb4bc021447ba2bab</p><p>drwxr-xr-x. 21 root root 224 Aug 2 18:23 a292ac6341a65bf3a5da7b7c251e19de1294bd2ec32828de621d41c7ad31f895</p><p>drwxr-xr-x. 21 root root 224 Aug 2 18:23 e92be7a4a4e3ccbb7dd87695bca1a0ea373d4f673f455491b1342b33ed91446b</p><p>$ du -sh /var/lib/docker/vfs/dir/*</p><p>4.0K /var/lib/docker/vfs/dir/3262dfbe53dac3e1ab7dcc8ad5d8c4d586a11d2ac3c4234892e34bff7f6b821e</p><p>125M /var/lib/docker/vfs/dir/6af21814449345f55d88c403e66564faad965d6afa84b294ae6e740c9ded2561</p><p>104M /var/lib/docker/vfs/dir/6d3be4585ba32f9f5cbff0110e8d07aea5f5b9fbb1439677c27e7dfee263171c</p><p>125M /var/lib/docker/vfs/dir/9ecd2d88ca177413ab89f987e1507325285a7418fc76d0dcb4bc021447ba2bab</p><p>104M /var/lib/docker/vfs/dir/a292ac6341a65bf3a5da7b7c251e19de1294bd2ec32828de621d41c7ad31f895</p><p>104M /var/lib/docker/vfs/dir/e92be7a4a4e3ccbb7dd87695bca1a0ea373d4f673f455491b1342b33ed91446b</p><p>The above output shows that three layers each take 104M and two take 125M. These directories have only small differences from each other, but take up nearly the same amount of room on disk. This is one of the disadvantages of using the vfs storage driver.</p><h4>Related information</h4><ul><li><a href="https://docs.docker.com/storage/volumes/">Volumes</a></li><li><a href="https://docs.docker.com/storage/storagedriver/imagesandcontainers/">Understand images, containers, and storage drivers</a></li></ul><h4>Run Your App in Production</h4><h2>Configure All Objects</h2><h3>Docker object labels</h3><p><em>Estimated reading time: 3 minutes</em></p><p>Labels are a mechanism for applying metadata to Docker objects, including:</p><ul><li>Images</li><li>Containers</li><li>Local daemons</li><li>Volumes</li><li>Networks</li><li>Swarm nodes</li><li>Swarm services</li></ul><p>You can use labels to organize your images, record licensing information, annotate relationships between containers, volumes, and networks, or in any way that makes sense for your business or application.</p><h4>Label keys and values</h4><p>A label is a key-value pair, stored as a string. You can specify multiple labels for an object, but each key-value pair must be unique within an object. If the same key is given multiple values, the most-recently-written value overwrites all previous values.</p><h5><strong>Key format recommendations</strong></h5><p>A label key is the left-hand side of the key-value pair. Keys are alphanumeric strings which may contain periods (.) and hyphens (-). Most Docker users use images created by other organizations, and the following guidelines help to prevent inadvertent duplication of labels across objects, especially if you plan to use labels as a mechanism for automation.</p><ul><li>Authors of third-party tools should prefix each label key with the reverse DNS notation of a domain they own, such as com.example.some-label.</li><li>Do not use a domain in your label key without the domain owner&#x27;s permission.</li><li>The com.docker.<em>, io.docker.</em>, and org.dockerproject.* namespaces are reserved by Docker for internal use.</li><li>Label keys should begin and end with a lower-case letter and should only contain lower-case alphanumeric characters, the period character (.), and the hyphen character (-). Consecutive periods or hyphens are not allowed.</li><li>The period character (.) separates namespace &quot;fields&quot;. Label keys without namespaces are reserved for CLI use, allowing users of the CLI to interactively label Docker objects using shorter typing-friendly strings.</li></ul><p>These guidelines are not currently enforced and additional guidelines may apply to specific use cases.</p><h5><strong>Value guidelines</strong></h5><p>Label values can contain any data type that can be represented as a string, including (but not limited to) JSON, XML, CSV, or YAML. The only requirement is that the value be serialized to a string first, using a mechanism specific to the type of structure. For instance, to serialize JSON into a string, you might use the JSON.stringify() JavaScript method.</p><p>Since Docker does not deserialize the value, you cannot treat a JSON or XML document as a nested structure when querying or filtering by label value unless you build this functionality into third-party tooling.</p><h4>Manage labels on objects</h4><p>Each type of object with support for labels has mechanisms for adding and managing them and using them as they relate to that type of object. These links provide a good place to start learning about how you can use labels in your Docker deployments.</p><p>Labels on images, containers, local daemons, volumes, and networks are static for the lifetime of the object. To change these labels you must recreate the object. Labels on swarm nodes and services can be updated dynamically.</p><ul><li>Images and containers<ul><li><a href="https://docs.docker.com/engine/reference/builder/#label">Adding labels to images</a></li><li><a href="https://docs.docker.com/engine/reference/commandline/run/#set-metadata-on-container--l---label---label-file">Overriding a container&#x27;s labels at runtime</a></li><li><a href="https://docs.docker.com/engine/reference/commandline/inspect/">Inspecting labels on images or containers</a></li><li><a href="https://docs.docker.com/engine/reference/commandline/images/#filtering">Filtering images by label</a></li><li><a href="https://docs.docker.com/engine/reference/commandline/ps/#filtering">Filtering containers by label</a></li></ul></li><li>Local Docker daemons<ul><li><a href="https://docs.docker.com/engine/reference/commandline/dockerd/">Adding labels to a Docker daemon at runtime</a></li><li><a href="https://docs.docker.com/engine/reference/commandline/info/">Inspecting a Docker daemon&#x27;s labels</a></li></ul></li><li>Volumes<ul><li><a href="https://docs.docker.com/engine/reference/commandline/volume_create/">Adding labels to volumes</a></li><li><a href="https://docs.docker.com/engine/reference/commandline/volume_inspect/">Inspecting a volume&#x27;s labels</a></li><li><a href="https://docs.docker.com/engine/reference/commandline/volume_ls/#filtering">Filtering volumes by label</a></li></ul></li><li>Networks<ul><li><a href="https://docs.docker.com/engine/reference/commandline/network_create/">Adding labels to a network</a></li><li><a href="https://docs.docker.com/engine/reference/commandline/network_inspect/">Inspecting a network&#x27;s labels</a></li><li><a href="https://docs.docker.com/engine/reference/commandline/network_ls/#filtering">Filtering networks by label</a></li></ul></li><li>Swarm nodes<ul><li><a href="https://docs.docker.com/engine/reference/commandline/node_update/#add-label-metadata-to-a-node">Adding or updating a swarm node&#x27;s labels</a></li><li><a href="https://docs.docker.com/engine/reference/commandline/node_inspect/">Inspecting a swarm node&#x27;s labels</a></li><li><a href="https://docs.docker.com/engine/reference/commandline/node_ls/#filtering">Filtering swarm nodes by label</a></li></ul></li><li>Swarm services<ul><li><a href="https://docs.docker.com/engine/reference/commandline/service_create/#set-metadata-on-a-service-l-label">Adding labels when creating a swarm service</a></li><li><a href="https://docs.docker.com/engine/reference/commandline/service_update/">Updating a swarm service&#x27;s labels</a></li><li><a href="https://docs.docker.com/engine/reference/commandline/service_inspect/">Inspecting a swarm service&#x27;s labels</a></li><li><a href="https://docs.docker.com/engine/reference/commandline/service_ls/#filtering">Filtering swarm services by label</a></li></ul></li></ul><h3>Prune unused Docker objects</h3><p><em>Estimated reading time: 5 minutes</em></p><p>Docker takes a conservative approach to cleaning up unused objects (often referred to as &quot;garbage collection&quot;), such as images, containers, volumes, and networks: these objects are generally not removed unless you explicitly ask Docker to do so. This can cause Docker to use extra disk space. For each type of object, Docker provides a prune command. In addition, you can use docker system prune to clean up multiple types of objects at once. This topic shows how to use these prune commands.</p><h4>Prune images</h4><p>The docker image prune command allows you to clean up unused images. By default, docker image prune only cleans up dangling images. A dangling image is one that is not tagged and is not referenced by any container. To remove dangling images:</p><p>$ docker image prune</p><p>WARNING! This will remove all dangling images.</p><p>Are you sure you want to continue? <!-- -->[y/N]<!-- --> y</p><p>To remove all images which are not used by existing containers, use the -a flag:</p><p>$ docker image prune -a</p><p>WARNING! This will remove all images without at least one container associated to them.</p><p>Are you sure you want to continue? <!-- -->[y/N]<!-- --> y</p><p>By default, you are prompted to continue. To bypass the prompt, use the -f or --force flag.</p><p>You can limit which images are pruned using filtering expressions with the --filter flag. For example, to only consider images created more than 24 hours ago:</p><p>$ docker image prune -a --filter &quot;until=24h&quot;</p><p>Other filtering expressions are available. See the <a href="https://docs.docker.com/engine/reference/commandline/image_prune/">docker image prune reference</a> for more examples.</p><h4>Prune containers</h4><p>When you stop a container, it is not automatically removed unless you started it with the --rm flag. To see all containers on the Docker host, including stopped containers, use docker ps -a. You may be surprised how many containers exist, especially on a development system! A stopped container&#x27;s writable layers still take up disk space. To clean this up, you can use the docker container prunecommand.</p><p>$ docker container prune</p><p>WARNING! This will remove all stopped containers.</p><p>Are you sure you want to continue? <!-- -->[y/N]<!-- --> y</p><p>By default, you are prompted to continue. To bypass the prompt, use the -f or --force flag.</p><p>By default, all stopped containers are removed. You can limit the scope using the --filter flag. For instance, the following command only removes stopped containers older than 24 hours:</p><p>$ docker container prune --filter &quot;until=24h&quot;</p><p>Other filtering expressions are available. See the <a href="https://docs.docker.com/engine/reference/commandline/container_prune/">docker container prune reference</a> for more examples.</p><h4>Prune volumes</h4><p>Volumes can be used by one or more containers, and take up space on the Docker host. Volumes are never removed automatically, because to do so could destroy data.</p><p>$ docker volume prune</p><p>WARNING! This will remove all volumes not used by at least one container.</p><p>Are you sure you want to continue? <!-- -->[y/N]<!-- --> y</p><p>By default, you are prompted to continue. To bypass the prompt, use the -f or --force flag.</p><p>By default, all unused volumes are removed. You can limit the scope using the --filter flag. For instance, the following command only removes volumes which are not labelled with the keep label:</p><p>$ docker volume prune --filter &quot;label!=keep&quot;</p><p>Other filtering expressions are available. See the <a href="https://docs.docker.com/engine/reference/commandline/volume_prune/">docker volume prune reference</a> for more examples.</p><h4>Prune networks</h4><p>Docker networks don&#x27;t take up much disk space, but they do create iptables rules, bridge network devices, and routing table entries. To clean these things up, you can use docker network prune to clean up networks which aren&#x27;t used by any containers.</p><p>$ docker network prune</p><p>WARNING! This will remove all networks not used by at least one container.</p><p>Are you sure you want to continue? <!-- -->[y/N]<!-- --> y</p><p>By default, you are prompted to continue. To bypass the prompt, use the -f or --force flag.</p><p>By default, all unused networks are removed. You can limit the scope using the --filter flag. For instance, the following command only removes networks older than 24 hours:</p><p>$ docker network prune --filter &quot;until=24h&quot;</p><p>Other filtering expressions are available. See the <a href="https://docs.docker.com/engine/reference/commandline/network_prune/">docker network prune reference</a> for more examples.</p><h4>Prune everything</h4><p>The docker system prune command is a shortcut that prunes images, containers, and networks. In Docker 17.06.0 and earlier, volumes are also pruned. In Docker 17.06.1 and higher, you must specify the --volumes flag for docker system prune to prune volumes.</p><p>$ docker system prune</p><p>WARNING! This will remove:</p><ul><li><p>all stopped containers</p></li><li><p>all networks not used by at least one container</p></li><li><p>all dangling images</p></li><li><p>all build cache</p></li></ul><p>Are you sure you want to continue? <!-- -->[y/N]<!-- --> y</p><p>If you are on Docker 17.06.1 or higher and want to also prune volumes, add the --volumes flag:</p><p>$ docker system prune --volumes</p><p>WARNING! This will remove:</p><ul><li><p>all stopped containers</p></li><li><p>all networks not used by at least one container</p></li><li><p>all volumes not used by at least one container</p></li><li><p>all dangling images</p></li><li><p>all build cache</p></li></ul><p>Are you sure you want to continue? <!-- -->[y/N]<!-- --> y</p><p>By default, you are prompted to continue. To bypass the prompt, use the -f or --force flag.</p><h3>Format command and log output</h3><p><em>Estimated reading time: 1 minute</em></p><p>Docker uses <a href="https://golang.org/pkg/text/template/">Go templates</a> which you can use to manipulate the output format of certain commands and log drivers.</p><p>Docker provides a set of basic functions to manipulate template elements. All of these examples use the docker inspect command, but many other CLI commands have a --format flag, and many of the CLI command references include examples of customizing the output format.</p><h4>join</h4><p>join concatenates a list of strings to create a single string. It puts a separator between each element in the list.</p><p>$ docker inspect --format \&#x27;{{join .Args &quot; , &quot;}}\&#x27; container</p><h4>json</h4><p>json encodes an element as a json string.</p><p>$ docker inspect --format \&#x27;{{json .Mounts}}\&#x27; container</p><h4>lower</h4><p>lower transforms a string into its lowercase representation.</p><p>$ docker inspect --format &quot;{{lower .Name}}&quot; container</p><h4>split</h4><p>split slices a string into a list of strings separated by a separator.</p><p>$ docker inspect --format \&#x27;{{split (join .Names &quot;/&quot;) &quot;/&quot;}}\&#x27; container</p><h4>title</h4><p>title capitalizes the first character of a string.</p><p>$ docker inspect --format &quot;{{title .Name}}&quot; container</p><h4>upper</h4><p>upper transforms a string into its uppercase representation.</p><p>$ docker inspect --format &quot;{{upper .Name}}&quot; container</p><h4>println</h4><p>println prints each value on a new line.</p><p>$ docker inspect --format=\&#x27;{{range .NetworkSettings.Networks}}{{println .IPAddress}}{{end}}\&#x27; containe</p><h2>Configure the Daemon</h2><h3>Configure and troubleshoot the Docker daemon</h3><p><em>Estimated reading time: 9 minutes</em></p><p>After successfully installing and starting Docker, the dockerd daemon runs with its default configuration. This topic shows how to customize the configuration, start the daemon manually, and troubleshoot and debug the daemon if you run into issues.</p><h4>Start the daemon using operating system utilities</h4><p>The command to start Docker depends on your operating system. Check the correct page under <a href="https://docs.docker.com/install/">Install Docker</a>. To configure Docker to start automatically at system boot, see <a href="https://docs.docker.com/install/linux/linux-postinstall/#configure-docker-to-start-on-boot">Configure Docker to start on boot</a>.</p><h4>Start the daemon manually</h4><p>Typically, you start Docker using operating system utilities. For debugging purposes, you can start Docker manually using the dockerd command. You may need to use sudo, depending on your operating system configuration. When you start Docker this way, it runs in the foreground and sends its logs directly to your terminal.</p><p>$ dockerd</p><p>INFO<!-- -->[0000]<!-- --> +job init_networkdriver()</p><p>INFO<!-- -->[0000]<!-- --> +job serveapi(unix:///var/run/docker.sock)</p><p>INFO<!-- -->[0000]<!-- --> Listening for HTTP on unix (/var/run/docker.sock)</p><p>...</p><p>...</p><p>To stop Docker when you have started it manually, issue a Ctrl+C in your terminal.</p><h4>Configure the Docker daemon</h4><p>The daemon includes many configuration options, which you can pass as flags when starting Docker manually, or set in the daemon.json configuration file. The second method is recommended because those configuration changes persist when you restart Docker.</p><p>See <a href="https://docs.docker.com/engine/reference/commandline/dockerd/">dockerd</a> for a full list of configuration options.</p><p>Here is an example of starting the Docker daemon manually with some configuration options:</p><p>$ dockerd -D --tls=true --tlscert=/var/docker/server.pem --tlskey=/var/docker/serverkey.pem -H tcp://192.168.59.3:2376</p><p>This command enables debugging (-D), enables TLS (-tls), specifies the server certificate and key (--tlscert and --tlskey), and specifies the network interface where the daemon listens for connections (-H).</p><p>A better approach is to put these options into the daemon.json file and restart Docker. This method works for every Docker platform. The following daemon.json example sets all the same options as the above command:</p><p>{</p><p>&quot;debug&quot;: true,</p><p>&quot;tls&quot;: true,</p><p>&quot;tlscert&quot;: &quot;/var/docker/server.pem&quot;,</p><p>&quot;tlskey&quot;: &quot;/var/docker/serverkey.pem&quot;,</p><p>&quot;hosts&quot;: <!-- -->[&quot;tcp://192.168.59.3:2376&quot;]</p><p>}</p><p>Many specific configuration options are discussed throughout the Docker documentation. Some places to go next include:</p><ul><li><a href="https://docs.docker.com/engine/admin/host_integration/">Automatically start containers</a></li><li><a href="https://docs.docker.com/engine/admin/resource_constraints/">Limit a container&#x27;s resources</a></li><li><a href="https://docs.docker.com/engine/userguide/storagedriver/">Configure storage drivers</a></li><li><a href="https://docs.docker.com/engine/security/">Container security</a></li></ul><h5><strong>Troubleshoot conflicts between the daemon.json and startup scripts</strong></h5><p>If you use a daemon.json file and also pass options to the dockerd command manually or using start-up scripts, and these options conflict, Docker fails to start with an error such as:</p><p>unable to configure the Docker daemon with file /etc/docker/daemon.json:</p><p>the following directives are specified both as a flag and in the configuration</p><p>file: hosts: (from flag: <!-- -->[unix:///var/run/docker.sock]<!-- -->, from file: <!-- -->[tcp://127.0.0.1:2376]<!-- -->)</p><p>If you see an error similar to this one and you are starting the daemon manually with flags, you may need to adjust your flags or the daemon.json to remove the conflict.</p><p><strong>Note</strong>: If you see this specific error, continue to the <a href="https://docs.docker.com/config/daemon/#use-the-hosts-key-in-daemon-json-with-systemd">next section</a> for a workaround.</p><p>If you are starting Docker using your operating system&#x27;s init scripts, you may need to override the defaults in these scripts in ways that are specific to the operating system.</p><h6><strong>USE THE HOSTS KEY IN DAEMON.JSON WITH SYSTEMD</strong></h6><p>One notable example of a configuration conflict that is difficult to troubleshoot is when you want to specify a different daemon address from the default. Docker listens on a socket by default. On Debian and Ubuntu systems using systemd, this means that a host flag -H is always used when starting dockerd. If you specify a hosts entry in the daemon.json, this causes a configuration conflict (as in the above message) and Docker fails to start.</p><p>To work around this problem, create a new file /etc/systemd/system/docker.service.d/docker.confwith the following contents, to remove the -H argument that is used when starting the daemon by default.</p><p>[Service]</p><p>ExecStart=</p><p>ExecStart=/usr/bin/dockerd</p><p>There are other times when you might need to configure systemd with Docker, such as <a href="https://docs.docker.com/engine/admin/systemd/#httphttps-proxy">configuring a HTTP or HTTPS proxy</a>.</p><p><strong>Note</strong>: If you override this option and then do not specify a hosts entry in the daemon.json or a -H flag when starting Docker manually, Docker fails to start.</p><p>Run sudo systemctl daemon-reload before attempting to start Docker. If Docker starts successfully, it is now listening on the IP address specified in the hosts key of the daemon.json instead of a socket.</p><p><strong>Important</strong>: Setting hosts in the daemon.json is not supported on Docker for Windows or Docker for Mac.</p><h4>Troubleshoot the daemon</h4><p>You can enable debugging on the daemon to learn about the runtime activity of the daemon and to aid in troubleshooting. If the daemon is completely non-responsive, you can also <a href="https://docs.docker.com/config/daemon/#force-a-full-stack-trace-to-be-logged">force a full stack trace</a> of all threads to be added to the daemon log by sending the SIGUSR signal to the Docker daemon.</p><h5><strong>Out Of Memory Exceptions (OOME)</strong></h5><p>If your containers attempt to use more memory than the system has available, you may experience an Out Of Memory Exception (OOME) and a container, or the Docker daemon, might be killed by the kernel OOM killer. To prevent this from happening, ensure that your application runs on hosts with adequate memory and see <a href="https://docs.docker.com/engine/admin/resource_constraints/#understand-the-risks-of-running-out-of-memory">Understand the risks of running out of memory</a>.</p><h5><strong>Read the logs</strong></h5><p>The daemon logs may help you diagnose problems. The logs may be saved in one of a few locations, depending on the operating system configuration and the logging subsystem used:</p><p>  <strong>Operating system</strong>     <strong>Location</strong></p><hr/><p>  RHEL, Oracle Linux       /var/log/messages
Debian                   /var/log/daemon.log
Ubuntu 16.04+, CentOS    Use the command journalctl -u docker.service
Ubuntu 14.10-            /var/log/upstart/docker.log
macOS (Docker 18.01+)    <!-- -->~<!-- -->/Library/Containers/com.docker.docker/Data/vms/0/console-ring
macOS (Docker &lt;18.01)   <!-- -->~<!-- -->/Library/Containers/com.docker.docker/Data/com.docker.driver.amd64-linux/console-ring
Windows                  AppData\Local</p><h5><strong>Enable debugging</strong></h5><p>There are two ways to enable debugging. The recommended approach is to set the debug key to true in the daemon.json file. This method works for every Docker platform.</p><ol><li>Edit the daemon.json file, which is usually located in /etc/docker/. You may need to create this file, if it does not yet exist. On macOS or Windows, do not edit the file directly. Instead, go to<strong>Preferences</strong> / <strong>Daemon</strong> / <strong>Advanced</strong>.</li><li>If the file is empty, add the following:</li><li>{</li><li>&quot;debug&quot;: true</li><li>}</li></ol><p>If the file already contains JSON, just add the key &quot;debug&quot;: true, being careful to add a comma to the end of the line if it is not the last line before the closing bracket. Also verify that if the log-level key is set, it is set to either info or debug. info is the default, and possible values are debug, info, warn, error, fatal.</p><ol><li>Send a HUP signal to the daemon to cause it to reload its configuration. On Linux hosts, use the following command.</li><li>$ sudo kill -SIGHUP $(pidof dockerd)</li></ol><p>On Windows hosts, restart Docker.</p><p>Instead of following this procedure, you can also stop the Docker daemon and restart it manually with the debug flag -D. However, this may result in Docker restarting with a different environment than the one the hosts&#x27; startup scripts create, and this may make debugging more difficult.</p><h5><strong>Force a stack trace to be logged</strong></h5><p>If the daemon is unresponsive, you can force a full stack trace to be logged by sending a SIGUSR1signal to the daemon.</p><ul><li><strong>Linux</strong>:</li><li>$ sudo kill -SIGUSR1 $(pidof dockerd)</li><li><strong>Windows Server</strong>:</li></ul><p>Download <a href="https://github.com/jhowardmsft/docker-signal">docker-signal</a>.</p><p>Run the executable with the flag --pid=<code style="background-color:lightgray">&lt;PID of daemon&gt;</code>.</p><p>This forces a stack trace to be logged but does not stop the daemon. Daemon logs show the stack trace or the path to a file containing the stack trace if it was logged to a file.</p><p>The daemon continues operating after handling the SIGUSR1 signal and dumping the stack traces to the log. The stack traces can be used to determine the state of all goroutines and threads within the daemon.</p><h5><strong>View stack traces</strong></h5><p>The Docker daemon log can be viewed by using one of the following methods:</p><ul><li>By running journalctl -u docker.service on Linux systems using systemctl</li><li>/var/log/messages, /var/log/daemon.log, or /var/log/docker.log on older Linux systems</li><li>By running Get-EventLog -LogName Application -Source Docker -After (Get-Date).AddMinutes(-5) | Sort-Object Time | Export-CSV <!-- -->~<!-- -->/last5minutes.CSVon Docker EE for Windows Server</li></ul><p><strong>Note</strong>: It is not possible to manually generate a stack trace on Docker for Mac or Docker for Windows. However, you can click the Docker taskbar icon and choose <strong>Diagnose and feedback</strong> to send information to Docker if you run into issues.</p><p>Look in the Docker logs for a message like the following:</p><p>...goroutine stacks written to /var/run/docker/goroutine-stacks-2017-06-02T193336z.log</p><p>...daemon datastructure dump written to /var/run/docker/daemon-data-2017-06-02T193336z.log</p><p>The locations where Docker saves these stack traces and dumps depends on your operating system and configuration. You can sometimes get useful diagnostic information straight from the stack traces and dumps. Otherwise, you can provide this information to Docker for help diagnosing the problem.</p><h4>Check whether Docker is running</h4><p>The operating-system independent way to check whether Docker is running is to ask Docker, using the docker info command.</p><p>You can also use operating system utilities, such as sudo systemctl is-active docker or sudo status docker or sudo service docker status, or checking the service status using Windows utilities.</p><p>Finally, you can check in the process list for the dockerd process, using commands like ps or top.</p><h3>Control Docker with systemd</h3><p><em>Estimated reading time: 3 minutes</em></p><p>Many Linux distributions use systemd to start the Docker daemon. This document shows a few examples of how to customize Docker&#x27;s settings.</p><h4>Start the Docker daemon</h4><h5><strong>Start manually</strong></h5><p>Once Docker is installed, you need to start the Docker daemon. Most Linux distributions use systemctl to start services. If you do not have systemctl, use the service command.</p><ul><li><strong>systemctl</strong>:</li><li>$ sudo systemctl start docker</li><li><strong>service</strong>:</li><li>$ sudo service docker start</li></ul><h5><strong>Start automatically at system boot</strong></h5><p>If you want Docker to start at boot, see <a href="https://docs.docker.com/install/linux/linux-postinstall/#configure-docker-to-start-on-boot">Configure Docker to start on boot</a>.</p><h4>Custom Docker daemon options</h4><p>There are a number of ways to configure the daemon flags and environment variables for your Docker daemon. The recommended way is to use the platform-independent daemon.json file, which is located in /etc/docker/ on Linux by default. See <a href="https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-configuration-file">Daemon configuration file</a>.</p><p>You can configure nearly all daemon configuration options using daemon.json. The following example configures two options. One thing you cannot configure using daemon.json mechanism is a <a href="https://docs.docker.com/config/daemon/#http-proxy">HTTP proxy</a>.</p><h5><strong>Runtime directory and storage driver</strong></h5><p>You may want to control the disk space used for Docker images, containers, and volumes by moving it to a separate partition.</p><p>To accomplish this, set the following flags in the daemon.json file:</p><p>{</p><p>&quot;data-root&quot;: &quot;/mnt/docker-data&quot;,</p><p>&quot;storage-driver&quot;: &quot;overlay&quot;</p><p>}</p><h5><strong>HTTP/HTTPS proxy</strong></h5><p>The Docker daemon uses the HTTP_PROXY, HTTPS_PROXY, and NO_PROXY environmental variables in its start-up environment to configure HTTP or HTTPS proxy behavior. You cannot configure these environment variables using the daemon.json file.</p><p>This example overrides the default docker.service file.</p><p>If you are behind an HTTP or HTTPS proxy server, for example in corporate settings, you need to add this configuration in the Docker systemd service file.</p><ol><li>Create a systemd drop-in directory for the docker service:</li><li>$ sudo mkdir -p /etc/systemd/system/docker.service.d</li><li>Create a file called /etc/systemd/system/docker.service.d/http-proxy.conf that adds the HTTP_PROXY environment variable:</li><li>[Service]</li><li>Environment=&quot;HTTP_PROXY=<a href="http://proxy.example.com:80/%22">http://proxy.example.com:80/&quot;</a></li></ol><p>Or, if you are behind an HTTPS proxy server, create a file called/etc/systemd/system/docker.service.d/https-proxy.conf that adds the HTTPS_PROXYenvironment variable:</p><p>[Service]</p><p>Environment=&quot;HTTPS_PROXY=<a href="https://proxy.example.com:443/%22">https://proxy.example.com:443/&quot;</a></p><ol><li>If you have internal Docker registries that you need to contact without proxying you can specify them via the NO_PROXY environment variable:</li><li>[Service]</li><li>Environment=&quot;HTTP_PROXY=<a href="http://proxy.example.com:80/%22">http://proxy.example.com:80/&quot;</a> &quot;NO_PROXY=localhost,127.0.0.1,docker-registry.somecorporation.com&quot;</li></ol><p>Or, if you are behind an HTTPS proxy server:</p><p>[Service]</p><p>Environment=&quot;HTTPS_PROXY=<a href="https://proxy.example.com:443/%22">https://proxy.example.com:443/&quot;</a> &quot;NO_PROXY=localhost,127.0.0.1,docker-registry.somecorporation.com&quot;</p><ol><li>Flush changes:</li><li>$ sudo systemctl daemon-reload</li><li>Restart Docker:</li><li>$ sudo systemctl restart docker</li><li>Verify that the configuration has been loaded:</li><li>$ systemctl show --property=Environment docker</li><li>Environment=HTTP_PROXY=<a href="http://proxy.example.com:80/">http://proxy.example.com:80/</a></li></ol><p>Or, if you are behind an HTTPS proxy server:</p><p>$ systemctl show --property=Environment docker</p><p>Environment=HTTPS_PROXY=<a href="https://proxy.example.com:443/">https://proxy.example.com:443/</a></p><h4>Configure where the Docker daemon listens for connections</h4><p>See <a href="https://docs.docker.com/install/linux/linux-postinstall/#control-where-the-docker-daemon-listens-for-connections">Configure where the Docker daemon listens for connections</a>.</p><h4>Manually create the systemd unit files</h4><p>When installing the binary without a package, you may want to integrate Docker with systemd. For this, install the two unit files (service and socket) from <a href="https://github.com/moby/moby/tree/master/contrib/init/systemd">the github repository</a> to /etc/systemd/system.</p><h3>Collect Docker metrics with Prometheus</h3><p><em>Estimated reading time: 8 minutes</em></p><p><a href="https://prometheus.io/">Prometheus</a> is an open-source systems monitoring and alerting toolkit. You can configure Docker as a Prometheus target. This topic shows you how to configure Docker, set up Prometheus to run as a Docker container, and monitor your Docker instance using Prometheus.</p><p><strong>Warning</strong>: The available metrics and the names of those metrics are in active development and may change at any time.</p><p>Currently, you can only monitor Docker itself. You cannot currently monitor your application using the Docker target.</p><h4>Configure Docker</h4><p>To configure the Docker daemon as a Prometheus target, you need to specify themetrics-address. The best way to do this is via the daemon.json, which is located at one of the following locations by default. If the file does not exist, create it.</p><ul><li><strong>Linux</strong>: /etc/docker/daemon.json</li><li><strong>Windows Server</strong>: C:\ProgramData\docker\config\daemon.json</li><li><strong>Docker for Mac / Docker for Windows</strong>: Click the Docker icon in the toolbar, select <strong>Preferences</strong>, then select <strong>Daemon</strong>. Click <strong>Advanced</strong>.</li></ul><p>If the file is currently empty, paste the following:</p><p>{</p><p>&quot;metrics-addr&quot; : &quot;127.0.0.1:9323&quot;,</p><p>&quot;experimental&quot; : true</p><p>}</p><p>If the file is not empty, add those two keys, making sure that the resulting file is valid JSON. Be careful that every line ends with a comma (,) except for the last line.</p><p>Save the file, or in the case of Docker for Mac or Docker for Windows, save the configuration. Restart Docker.</p><p>Docker now exposes Prometheus-compatible metrics on port 9323.</p><h4>Configure and run Prometheus</h4><p>In this example, Prometheus runs as a Docker service on a Docker swarm.</p><p><strong>Prerequisites</strong></p><ol><li>One or more Docker engines are joined into a Docker swarm, using docker swarm init on one manager and docker swarm join on other managers and worker nodes.</li><li>You need an internet connection to pull the Prometheus image.</li></ol><p>Copy one of the following configuration files and save it to /tmp/prometheus.yml (Linux or Mac) or C:\tmp\prometheus.yml (Windows). This is a stock Prometheus configuration file, except for the addition of the Docker job definition at the bottom of the file. Docker for Mac and Docker for Windows need a slightly different configuration.</p><ul><li>Docker for Linux</li><li>Docker for Mac</li><li>Docker for Windows</li></ul><h1>my global config</h1><p>global:</p><p>scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.</p><p>evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.</p><h1>scrape_timeout is set to the global default (10s).</h1><h1>Attach these labels to any time series or alerts when communicating with</h1><h1>external systems (federation, remote storage, Alertmanager).</h1><p>external_labels:</p><p>monitor: \&#x27;codelab-monitor\&#x27;</p><h1>Load rules once and periodically evaluate them according to the global \&#x27;evaluation_interval\&#x27;.</h1><p>rule_files:</p><h1>- &quot;first.rules&quot;</h1><h1>- &quot;second.rules&quot;</h1><h1>A scrape configuration containing exactly one endpoint to scrape:</h1><h1>Here it\&#x27;s Prometheus itself.</h1><p>scrape_configs:</p><h1>The job name is added as a label <code>job=</code>&lt;job_name&gt;`` to any timeseries scraped from this config.</h1><ul><li>job_name: \&#x27;prometheus\&#x27;</li></ul><h1>metrics_path defaults to \&#x27;/metrics\&#x27;</h1><h1>scheme defaults to \&#x27;http\&#x27;.</h1><p>static_configs:</p><ul><li><p>targets: <!-- -->[\&#x27;localhost:9090\&#x27;]</p></li><li><p>job_name: \&#x27;docker\&#x27;</p></li></ul><h1>metrics_path defaults to \&#x27;/metrics\&#x27;</h1><h1>scheme defaults to \&#x27;http\&#x27;.</h1><p>static_configs:</p><ul><li>targets: <!-- -->[\&#x27;localhost:9323\&#x27;]</li></ul><p>Next, start a single-replica Prometheus service using this configuration.</p><ul><li>Docker for Linux</li><li>Docker for Mac</li><li>Docker for Windows or Windows Server</li></ul><p>$ docker service create --replicas 1 --name my-prometheus \</p><p>--mount type=bind,source=/tmp/prometheus.yml,destination=/etc/prometheus/prometheus.yml \</p><p>--publish published=9090,target=9090,protocol=tcp \</p><p>prom/prometheus</p><p>Verify that the Docker target is listed at http://localhost:9090/targets/.</p><p>You can&#x27;t access the endpoint URLs directly if you use Docker for Mac or Docker for Windows.</p><h4>Use Prometheus</h4><p>Create a graph. Click the <strong>Graphs</strong> link in the Prometheus UI. Choose a metric from the combo box to the right of the <strong>Execute</strong> button, and click <strong>Execute</strong>. The screenshot below shows the graph forengine_daemon_network_actions_seconds_count.</p><p>The above graph shows a pretty idle Docker instance. Your graph might look different if you are running active workloads.</p><p>To make the graph more interesting, create some network actions by starting a service with 10 tasks that just ping Docker non-stop (you can change the ping target to anything you like):</p><p>$ docker service create \</p><p>--replicas 10 \</p><p>--name ping_service \</p><p>alpine ping docker.com</p><p>Wait a few minutes (the default scrape interval is 15 seconds) and reload your graph.</p><p>When you are ready, stop and remove the ping_service service, so that you are not flooding a host with pings for no reason.</p><p>$ docker service remove ping_service</p><p>Wait a few minutes and you should see that the graph falls back to the idle level.</p><h4>Next steps</h4><ul><li>Read the <a href="https://prometheus.io/docs/introduction/overview/">Prometheus documentation</a></li><li>Set up some <a href="https://prometheus.io/docs/alerting/overview/">alerts</a></li></ul><h2>Configure Containers</h2><h3>Start containers automatically</h3><p><em>Estimated reading time: 2 minutes</em></p><p>Docker provides <a href="https://docs.docker.com/engine/reference/run/#restart-policies---restart">restart policies</a> to control whether your containers start automatically when they exit, or when Docker restarts. Restart policies ensure that linked containers are started in the correct order. Docker recommends that you use restart policies, and avoid using process managers to start containers.</p><p>Restart policies are different from the --live-restore flag of the dockerd command. Using --live-restore allows you to keep your containers running during a Docker upgrade, though networking and user input are interrupted.</p><h4>Use a restart policy</h4><p>To configure the restart policy for a container, use the --restart flag when using the docker run command. The value of the --restart flag can be any of the following:</p><p>  <strong>Flag</strong>         <strong>Description</strong></p><hr/><p>  no               Do not automatically restart the container. (the default)
on-failure       Restart the container if it exits due to an error, which manifests as a non-zero exit code.
unless-stopped   Restart the container unless it is explicitly stopped or Docker itself is stopped or restarted.
always           Always restart the container if it stops.</p><p>The following example starts a Redis container and configures it to always restart unless it is explicitly stopped or Docker is restarted.</p><p>$ docker run -dit --restart unless-stopped redis</p><h5><strong>Restart policy details</strong></h5><p>Keep the following in mind when using restart policies:</p><ul><li>A restart policy only takes effect after a container starts successfully. In this case, starting successfully means that the container is up for at least 10 seconds and Docker has started monitoring it. This prevents a container which does not start at all from going into a restart loop.</li><li>If you manually stop a container, its restart policy is ignored until the Docker daemon restarts or the container is manually restarted. This is another attempt to prevent a restart loop.</li><li>Restart policies only apply to containers. Restart policies for swarm services are configured differently. See the <a href="https://docs.docker.com/engine/reference/commandline/service_create/">flags related to service restart</a>.</li></ul><h4>Use a process manager</h4><p>If restart policies don&#x27;t suit your needs, such as when processes outside Docker depend on Docker containers, you can use a process manager such as <a href="http://upstart.ubuntu.com/">upstart</a>, <a href="http://freedesktop.org/wiki/Software/systemd/">systemd</a>, or <a href="http://supervisord.org/">supervisor</a>instead.</p><p><strong>Warning</strong>: Do not try to combine Docker restart policies with host-level process managers, because this creates conflicts.</p><p>To use a process manager, configure it to start your container or service using the same docker start or docker service command you would normally use to start the container manually. Consult the documentation for the specific process manager for more details.</p><h5><strong>Using a process manager inside containers</strong></h5><p>Process managers can also run within the container to check whether a process is running and starts/restart it if not.</p><p><strong>Warning: These are not Docker-aware and just monitor operating system processes within the container.</strong></p><p>Docker does not recommend this approach, because it is platform-dependent and even differs within different versions of a given Linux distribution.</p><h3>Keep containers alive during daemon downtime</h3><p><em>Estimated reading time: 2 minutes</em></p><p>By default, when the Docker daemon terminates, it shuts down running containers. Starting with Docker Engine 1.12, you can configure the daemon so that containers remain running if the daemon becomes unavailable. This functionality is called live restore. The live restore option helps reduce container downtime due to daemon crashes, planned outages, or upgrades.</p><p><strong>Note</strong>: Live restore is not supported on Windows containers, but it does work for Linux containers running on Docker for Windows.</p><h4>Enable live restore</h4><p>There are two ways to enable the live restore setting to keep containers alive when the daemon becomes unavailable. <strong>Only do one of the following</strong>.</p><ul><li>Add the configuration to the daemon configuration file. On Linux, this defaults to /etc/docker/daemon.json. On Docker for Mac or Docker for Windows, select the Docker icon from the task bar, then click <strong>Preferences</strong> -&gt; <strong>Daemon</strong> -&gt; <strong>Advanced</strong>.<ul><li>Use the following JSON to enable live-restore.</li><li>{</li><li>&quot;live-restore&quot;: true</li><li>}</li><li>Restart the Docker daemon. On Linux, you can avoid a restart (and avoid any downtime for your containers) by reload the Docker daemon. If you use systemd, then use the command systemctl reload docker. Otherwise, send a SIGHUP signal to the dockerd process.</li></ul></li><li>If you prefer, you can start the dockerd process manually with the --live-restore flag. This approach is not recommended because it does not set up the environment that systemd or another process manager would use when starting the Docker process. This can cause unexpected behavior.</li></ul><h4>Live restore during upgrades</h4><p>The live restore feature supports restoring containers to the daemon for upgrades from one minor release to the next, such as when upgrading from Docker 1.12.1 to 1.12.2.</p><p>If you skip releases during an upgrade, the daemon may not restore its connection to the containers. If the daemon can&#x27;t restore the connection, it cannot manage the running containers and you must stop them manually.</p><h4>Live restore upon restart</h4><p>The live restore option only works to restore containers if the daemon options, such as bridge IP addresses and graph driver, did not change. If any of these daemon-level configuration options have changed, the live restore may not work and you may need to manually stop the containers.</p><h4>Impact of live restore on running containers</h4><p>If the daemon is down for a long time, running containers may fill up the FIFO log the daemon normally reads. A full log blocks containers from logging more data. The default buffer size is 64K. If the buffers fill, you must restart the Docker daemon to flush them.</p><p>On Linux, you can modify the kernel&#x27;s buffer size by changing /proc/sys/fs/pipe-max-size. You cannot modify the buffer size on Docker for Mac or Docker for Windows.</p><h4>Live restore and swarm mode</h4><p>The live restore option only pertains to standalone containers, and not to swarm services. Swarm services are managed by swarm managers. If swarm managers are not available, swarm services continue to run on worker nodes but cannot be managed until enough swarm managers are available to maintain a quorum.</p><h3>Run multiple services in a container</h3><p><em>Estimated reading time: 3 minutes</em></p><p>A container&#x27;s main running process is the ENTRYPOINT and/or CMD at the end of the Dockerfile. It is generally recommended that you separate areas of concern by using one service per container. That service may fork into multiple processes (for example, Apache web server starts multiple worker processes). It&#x27;s ok to have multiple processes, but to get the most benefit out of Docker, avoid one container being responsible for multiple aspects of your overall application. You can connect multiple containers using user-defined networks and shared volumes.</p><p>The container&#x27;s main process is responsible for managing all processes that it starts. In some cases, the main process isn&#x27;t well-designed, and doesn&#x27;t handle &quot;reaping&quot; (stopping) child processes gracefully when the container exits. If your process falls into this category, you can use the --init option when you run the container. The --init flag inserts a tiny init-process into the container as the main process, and handles reaping of all processes when the container exits. Handling such processes this way is superior to using a full-fledged init process such as sysvinit, upstart, or systemd to handle process lifecycle within your container.</p><p>If you need to run more than one service within a container, you can accomplish this in a few different ways.</p><ul><li>Put all of your commands in a wrapper script, complete with testing and debugging information. Run the wrapper script as your CMD. This is a very naive example. First, the wrapper script:</li><li>#!/bin/bash</li><li><h1>Start the first process</h1></li><li>./my_first_process -D</li><li>status=$?</li><li>if <!-- -->[ $status -ne 0 ]<!-- -->; then</li><li>echo &quot;Failed to start my_first_process: $status&quot;</li><li>exit $status</li><li>fi</li><li><h1>Start the second process</h1></li><li>./my_second_process -D</li><li>status=$?</li><li>if <!-- -->[ $status -ne 0 ]<!-- -->; then</li><li>echo &quot;Failed to start my_second_process: $status&quot;</li><li>exit $status</li><li>fi</li><li><h1>Naive check runs checks once a minute to see if either of the processes exited.</h1></li><li><h1>This illustrates part of the heavy lifting you need to do if you want to run</h1></li><li><h1>more than one service in a container. The container exits with an error</h1></li><li><h1>if it detects that either of the processes has exited.</h1></li><li><h1>Otherwise it loops forever, waking up every 60 seconds</h1></li><li>while sleep 60; do</li><li>ps aux |grep my_first_process |grep -q -v grep</li><li>PROCESS_1_STATUS=$?</li><li>ps aux |grep my_second_process |grep -q -v grep</li><li>PROCESS_2_STATUS=$?</li><li><h1>If the greps above find anything, they exit with 0 status</h1></li><li><h1>If they are not both 0, then something is wrong</h1></li><li>if <!-- -->[ $PROCESS_1_STATUS -ne 0 -o $PROCESS_2_STATUS -ne 0 ]<!-- -->; then</li><li>echo &quot;One of the processes has already exited.&quot;</li><li>exit 1</li><li>fi</li><li>done</li></ul><p>Next, the Dockerfile:</p><p>FROM ubuntu:latest</p><p>COPY my_first_process my_first_process</p><p>COPY my_second_process my_second_process</p><p>COPY my_wrapper_script.sh my_wrapper_script.sh</p><p>CMD ./my_wrapper_script.sh</p><ul><li>Use a process manager like supervisord. This is a moderately heavy-weight approach that requires you to package supervisord and its configuration in your image (or base your image on one that includes supervisord), along with the different applications it manages. Then you start supervisord, which manages your processes for you. Here is an example Dockerfile using this approach, that assumes the pre-written supervisord.conf, my_first_process, and my_second_process files all exist in the same directory as your Dockerfile.</li><li>FROM ubuntu:latest</li><li>RUN apt-get update &amp;&amp; apt-get install -y supervisor</li><li>RUN mkdir -p /var/log/supervisor</li><li>COPY supervisord.conf /etc/supervisor/conf.d/supervisord.conf</li><li>COPY my_first_process my_first_process</li><li>COPY my_second_process my_second_process</li></ul><p>CMD <!-- -->[&quot;/usr/bin/supervisord&quot;]</p><h3>Runtime metrics</h3><p><em>Estimated reading time: 17 minutes</em></p><h4>Docker stats</h4><p>You can use the docker stats command to live stream a container&#x27;s runtime metrics. The command supports CPU, memory usage, memory limit, and network IO metrics.</p><p>The following is a sample output from the docker stats command</p><p>$ docker stats redis1 redis2</p><p>CONTAINER CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O</p><p>redis1 0.07% 796 KB / 64 MB 1.21% 788 B / 648 B 3.568 MB / 512 KB</p><p>redis2 0.07% 2.746 MB / 64 MB 4.29% 1.266 KB / 648 B 12.4 MB / 0 B</p><p>The <a href="https://docs.docker.com/engine/reference/commandline/stats/">docker stats</a> reference page has more details about the docker stats command.</p><h4>Control groups</h4><p>Linux Containers rely on <a href="https://www.kernel.org/doc/Documentation/cgroup-v1/cgroups.txt">control groups</a> which not only track groups of processes, but also expose metrics about CPU, memory, and block I/O usage. You can access those metrics and obtain network usage metrics as well. This is relevant for &quot;pure&quot; LXC containers, as well as for Docker containers.</p><p>Control groups are exposed through a pseudo-filesystem. In recent distros, you should find this filesystem under /sys/fs/cgroup. Under that directory, you see multiple sub-directories, called devices, freezer, blkio, etc.; each sub-directory actually corresponds to a different cgroup hierarchy.</p><p>On older systems, the control groups might be mounted on /cgroup, without distinct hierarchies. In that case, instead of seeing the sub-directories, you see a bunch of files in that directory, and possibly some directories corresponding to existing containers.</p><p>To figure out where your control groups are mounted, you can run:</p><p>$ grep cgroup /proc/mounts</p><h5><strong>Enumerate cgroups</strong></h5><p>You can look into /proc/cgroups to see the different control group subsystems known to the system, the hierarchy they belong to, and how many groups they contain.</p><p>You can also look at /proc/<code style="background-color:lightgray">&lt;pid&gt;</code>/cgroup to see which control groups a process belongs to. The control group is shown as a path relative to the root of the hierarchy mountpoint. / means the process has not been assigned to a group, while /lxc/pumpkin indicates that the process is a member of a container named pumpkin.</p><h5><strong>Find the cgroup for a given container</strong></h5><p>For each container, one cgroup is created in each hierarchy. On older systems with older versions of the LXC userland tools, the name of the cgroup is the name of the container. With more recent versions of the LXC tools, the cgroup is lxc/<code style="background-color:lightgray">&lt;container_name&gt;</code>.</p><p>For Docker containers using cgroups, the container name is the full ID or long ID of the container. If a container shows up as ae836c95b4c3 in docker ps, its long ID might be something likeae836c95b4c3c9e9179e0e91015512da89fdec91612f63cebae57df9a5444c79. You can look it up with docker inspect or docker ps --no-trunc.</p><p>Putting everything together to look at the memory metrics for a Docker container, take a look at /sys/fs/cgroup/memory/docker/<code style="background-color:lightgray">&lt;longid&gt;</code>/.</p><h5><strong>Metrics from cgroups: memory, CPU, block I/O</strong></h5><p>For each subsystem (memory, CPU, and block I/O), one or more pseudo-files exist and contain statistics.</p><h6><strong>MEMORY METRICS: MEMORY.STAT</strong></h6><p>Memory metrics are found in the &quot;memory&quot; cgroup. The memory control group adds a little overhead, because it does very fine-grained accounting of the memory usage on your host. Therefore, many distros chose to not enable it by default. Generally, to enable it, all you have to do is to add some kernel command-line parameters: cgroup_enable=memory swapaccount=1.</p><p>The metrics are in the pseudo-file memory.stat. Here is what it looks like:</p><p>cache 11492564992</p><p>rss 1930993664</p><p>mapped_file 306728960</p><p>pgpgin 406632648</p><p>pgpgout 403355412</p><p>swap 0</p><p>pgfault 728281223</p><p>pgmajfault 1724</p><p>inactive_anon 46608384</p><p>active_anon 1884520448</p><p>inactive_file 7003344896</p><p>active_file 4489052160</p><p>unevictable 32768</p><p>hierarchical_memory_limit 9223372036854775807</p><p>hierarchical_memsw_limit 9223372036854775807</p><p>total_cache 11492564992</p><p>total_rss 1930993664</p><p>total_mapped_file 306728960</p><p>total_pgpgin 406632648</p><p>total_pgpgout 403355412</p><p>total_swap 0</p><p>total_pgfault 728281223</p><p>total_pgmajfault 1724</p><p>total_inactive_anon 46608384</p><p>total_active_anon 1884520448</p><p>total_inactive_file 7003344896</p><p>total_active_file 4489052160</p><p>total_unevictable 32768</p><p>The first half (without the total<em> prefix) contains statistics relevant to the processes within the cgroup, excluding sub-cgroups. The second half (with the total</em> prefix) includes sub-cgroups as well.</p><p>Some metrics are &quot;gauges&quot;, or values that can increase or decrease. For instance, swap isthe amount of swap space used by the members of the cgroup. Some others are &quot;counters&quot;, or values that can only go up, because they represent occurrences of a specific event. For instance, pgfault indicates the number of page faults since the creation of the cgroup.</p><p>  <strong>Metric</strong>                           <strong>Description</strong></p><hr/><p>  <strong>cache</strong>                            The amount of memory used by the processes of this control group that can be associated precisely with a block on a block device. When you read from and write to files on disk, this amount increases. This is the case if you use &quot;conventional&quot; I/O (open, read, write syscalls) as well as mapped files (with mmap). It also accounts for the memory used by tmpfsmounts, though the reasons are unclear.
<strong>rss</strong>                              The amount of memory that doesn&#x27;t correspond to anything on disk: stacks, heaps, and anonymous memory maps.
<strong>mapped_file</strong>                      Indicates the amount of memory mapped by the processes in the control group. It doesn&#x27;t give you information about how much memory is used; it rather tells you how it is used.
<strong>pgfault</strong>, <strong>pgmajfault</strong>          Indicate the number of times that a process of the cgroup triggered a &quot;page fault&quot; and a &quot;major fault&quot;, respectively. A page fault happens when a process accesses a part of its virtual memory space which is nonexistent or protected. The former can happen if the process is buggy and tries to access an invalid address (it is sent a SIGSEGV signal, typically killing it with the famous Segmentation fault message). The latter can happen when the process reads from a memory zone which has been swapped out, or which corresponds to a mapped file: in that case, the kernel loads the page from disk, and let the CPU complete the memory access. It can also happen when the process writes to a copy-on-write memory zone: likewise, the kernel preempts the process, duplicate the memory page, and resume the write operation on the process` own copy of the page. &quot;Major&quot; faults happen when the kernel actually needs to read the data from disk. When it just duplicates an existing page, or allocate an empty page, it&#x27;s a regular (or &quot;minor&quot;) fault.
<strong>swap</strong>                             The amount of swap currently used by the processes in this cgroup.
<strong>active_anon</strong>, <strong>inactive_anon</strong>   The amount of anonymous memory that has been identified has respectively active and inactive by the kernel. &quot;Anonymous&quot; memory is the memory that is not linked to disk pages. In other words, that&#x27;s the equivalent of the rss counter described above. In fact, the very definition of the rss counter is <strong>active_anon</strong> + <strong>inactive_anon</strong> - <strong>tmpfs</strong> (where tmpfs is the amount of memory used up by tmpfs filesystems mounted by this control group). Now, what&#x27;s the difference between &quot;active&quot; and &quot;inactive&quot;? Pages are initially &quot;active&quot;; and at regular intervals, the kernel sweeps over the memory, and tags some pages as &quot;inactive&quot;. Whenever they are accessed again, they are immediately retagged &quot;active&quot;. When the kernel is almost out of memory, and time comes to swap out to disk, the kernel swaps &quot;inactive&quot; pages.
<strong>active_file</strong>, <strong>inactive_file</strong>   Cache memory, with active and inactive similar to the anonmemory above. The exact formula is <strong>cache</strong> = <strong>active_file</strong> + <strong>inactive_file</strong> + <strong>tmpfs</strong>. The exact rules used by the kernel to move memory pages between active and inactive sets are different from the ones used for anonymous memory, but the general principle is the same. When the kernel needs to reclaim memory, it is cheaper to reclaim a clean (=non modified) page from this pool, since it can be reclaimed immediately (while anonymous pages and dirty/modified pages need to be written to disk first).
<strong>unevictable</strong>                      The amount of memory that cannot be reclaimed; generally, it accounts for memory that has been &quot;locked&quot; with mlock. It is often used by crypto frameworks to make sure that secret keys and other sensitive material never gets swapped out to disk.
<strong>memory_limit</strong>, <strong>memsw_limit</strong>    These are not really metrics, but a reminder of the limits applied to this cgroup. The first one indicates the maximum amount of physical memory that can be used by the processes of this control group; the second one indicates the maximum amount of RAM+swap.</p><p>Accounting for memory in the page cache is very complex. If two processes in different control groups both read the same file (ultimately relying on the same blocks on disk), the corresponding memory charge is split between the control groups. It&#x27;s nice, but it also means that when a cgroup is terminated, it could increase the memory usage of another cgroup, because they are not splitting the cost anymore for those memory pages.</p><h5><strong>CPU metrics: cpuacct.stat</strong></h5><p>Now that we&#x27;ve covered memory metrics, everything else is simple in comparison. CPU metrics are in the cpuacct controller.</p><p>For each container, a pseudo-file cpuacct.stat contains the CPU usage accumulated by the processes of the container, broken down into user and system time. The distinction is:</p><ul><li>user time is the amount of time a process has direct control of the CPU, executing process code.</li><li>system time is the time the kernel is executing system calls on behalf of the process.</li></ul><p>Those times are expressed in ticks of 1/100th of a second, also called &quot;user jiffies&quot;. There are USER_HZ &quot;jiffies&quot; per second, and on x86 systems, USER_HZ is 100. Historically, this mapped exactly to the number of scheduler &quot;ticks&quot; per second, but higher frequency scheduling and<a href="http://lwn.net/Articles/549580/">tickless kernels</a> have made the number of ticks irrelevant.</p><h6><strong>BLOCK I/O METRICS</strong></h6><p>Block I/O is accounted in the blkio controller. Different metrics are scattered across different files. While you can find in-depth details in the <a href="https://www.kernel.org/doc/Documentation/cgroup-v1/blkio-controller.txt">blkio-controller</a> file in the kernel documentation, here is a short list of the most relevant ones:</p><p>  <strong>Metric</strong>                   <strong>Description</strong></p><hr/><p>  <strong>blkio.sectors</strong>            Contains the number of 512-bytes sectors read and written by the processes member of the cgroup, device by device. Reads and writes are merged in a single counter.
<strong>blkio.io_service_bytes</strong>   Indicates the number of bytes read and written by the cgroup. It has 4 counters per device, because for each device, it differentiates between synchronous vs. asynchronous I/O, and reads vs. writes.
<strong>blkio.io_serviced</strong>        The number of I/O operations performed, regardless of their size. It also has 4 counters per device.
<strong>blkio.io_queued</strong>          Indicates the number of I/O operations currently queued for this cgroup. In other words, if the cgroup isn&#x27;t doing any I/O, this is zero. The opposite is not true. In other words, if there is no I/O queued, it does not mean that the cgroup is idle (I/O-wise). It could be doing purely synchronous reads on an otherwise quiescent device, which can therefore handle them immediately, without queuing. Also, while it is helpful to figure out which cgroup is putting stress on the I/O subsystem, keep in mind that it is a relative quantity. Even if a process group does not perform more I/O, its queue size can increase just because the device load increases because of other devices.</p><h5><strong>Network metrics</strong></h5><p>Network metrics are not exposed directly by control groups. There is a good explanation for that: network interfaces exist within the context of network namespaces. The kernel could probably accumulate metrics about packets and bytes sent and received by a group of processes, but those metrics wouldn&#x27;t be very useful. You want per-interface metrics (because traffic happening on the local lo interface doesn&#x27;t really count). But since processes in a single cgroup can belong to multiple network namespaces, those metrics would be harder to interpret: multiple network namespaces means multiple lo interfaces, potentially multiple eth0 interfaces, etc.; so this is why there is no easy way to gather network metrics with control groups.</p><p>Instead we can gather network metrics from other sources:</p><h6><strong>IPTABLES</strong></h6><p>IPtables (or rather, the netfilter framework for which iptables is just an interface) can do some serious accounting.</p><p>For instance, you can setup a rule to account for the outbound HTTP traffic on a web server:</p><p>$ iptables -I OUTPUT -p tcp --sport 80</p><p>There is no -j or -g flag, so the rule just counts matched packets and goes to the following rule.</p><p>Later, you can check the values of the counters, with:</p><p>$ iptables -nxvL OUTPUT</p><p>Technically, -n is not required, but it prevents iptables from doing DNS reverse lookups, which are probably useless in this scenario.</p><p>Counters include packets and bytes. If you want to setup metrics for container traffic like this, you could execute a for loop to add two iptables rules per container IP address (one in each direction), in the FORWARD chain. This only meters traffic going through the NAT layer; you also need to add traffic going through the userland proxy.</p><p>Then, you need to check those counters on a regular basis. If you happen to use collectd, there is a <a href="https://collectd.org/wiki/index.php/Table_of_Plugins">nice plugin</a> to automate iptables counters collection.</p><h6><strong>INTERFACE-LEVEL COUNTERS</strong></h6><p>Since each container has a virtual Ethernet interface, you might want to check directly the TX and RX counters of this interface. Each container is associated to a virtual Ethernet interface in your host, with a name like vethKk8Zqi. Figuring out which interface corresponds to which container is, unfortunately, difficult.</p><p>But for now, the best way is to check the metrics from within the containers. To accomplish this, you can run an executable from the host environment within the network namespace of a container using <strong>ip-netns magic</strong>.</p><p>The ip-netns exec command allows you to execute any program (present in the host system) within any network namespace visible to the current process. This means that your host can enter the network namespace of your containers, but your containers can&#x27;t access the host or other peer containers. Containers can interact with their sub-containers, though.</p><p>The exact format of the command is:</p><p>$ ip netns exec <code style="background-color:lightgray">&lt;nsname&gt; &lt;command...&gt;</code></p><p>For example:</p><p>$ ip netns exec mycontainer netstat -i</p><p>ip netns finds the &quot;mycontainer&quot; container by using namespaces pseudo-files. Each process belongs to one network namespace, one PID namespace, one mnt namespace, etc., and those namespaces are materialized under /proc/<code style="background-color:lightgray">&lt;pid&gt;</code>/ns/. For example, the network namespace of PID 42 is materialized by the pseudo-file /proc/42/ns/net.</p><p>When you run ip netns exec mycontainer ..., it expects /var/run/netns/mycontainer to be one of those pseudo-files. (Symlinks are accepted.)</p><p>In other words, to execute a command within the network namespace of a container, we need to:</p><ul><li>Find out the PID of any process within the container that we want to investigate;</li><li>Create a symlink from /var/run/netns/<code>&lt;somename&gt; to /proc/&lt;thepid&gt;</code>/ns/net</li><li>Execute ip netns exec <code>&lt;somename&gt;</code> ....</li></ul><p>Review <a href="https://docs.docker.com/config/containers/runmetrics/#enumerate-cgroups">Enumerate Cgroups</a> for how to find the cgroup of an in-container process whose network usage you want to measure. From there, you can examine the pseudo-file named tasks, which contains all the PIDs in the cgroup (and thus, in the container). Pick any one of the PIDs.</p><p>Putting everything together, if the &quot;short ID&quot; of a container is held in the environment variable $CID, then you can do this:</p><p>$ TASKS=/sys/fs/cgroup/devices/docker/$CID*/tasks</p><p>$ PID=$(head -n 1 $TASKS)</p><p>$ mkdir -p /var/run/netns</p><p>$ ln -sf /proc/$PID/ns/net /var/run/netns/$CID</p><p>$ ip netns exec $CID netstat -i</p><h4>Tips for high-performance metric collection</h4><p>Running a new process each time you want to update metrics is (relatively) expensive. If you want to collect metrics at high resolutions, and/or over a large number of containers (think 1000 containers on a single host), you do not want to fork a new process each time.</p><p>Here is how to collect metrics from a single process. You need to write your metric collector in C (or any language that lets you do low-level system calls). You need to use a special system call,setns(), which lets the current process enter any arbitrary namespace. It requires, however, an open file descriptor to the namespace pseudo-file (remember: that&#x27;s the pseudo-file in/proc/<code style="background-color:lightgray">&lt;pid&gt;</code>/ns/net).</p><p>However, there is a catch: you must not keep this file descriptor open. If you do, when the last process of the control group exits, the namespace is not destroyed, and its network resources (like the virtual interface of the container) stays around forever (or until you close that file descriptor).</p><p>The right approach would be to keep track of the first PID of each container, and re-open the namespace pseudo-file each time.</p><h4>Collect metrics when a container exits</h4><p>Sometimes, you do not care about real time metric collection, but when a container exits, you want to know how much CPU, memory, etc. it has used.</p><p>Docker makes this difficult because it relies on lxc-start, which carefully cleans up after itself. It is usually easier to collect metrics at regular intervals, and this is the way the collectd LXC plugin works.</p><p>But, if you&#x27;d still like to gather the stats when a container stops, here is how:</p><p>For each container, start a collection process, and move it to the control groups that you want to monitor by writing its PID to the tasks file of the cgroup. The collection process should periodically re-read the tasks file to check if it&#x27;s the last process of the control group. (If you also want to collect network statistics as explained in the previous section, you should also move the process to the appropriate network namespace.)</p><p>When the container exits, lxc-start attempts to delete the control groups. It fails, since the control group is still in use; but that&#x27;s fine. Your process should now detect that it is the only one remaining in the group. Now is the right time to collect all the metrics you need!</p><p>Finally, your process should move itself back to the root control group, and remove the container control group. To remove a control group, just rmdir its directory. It&#x27;s counter-intuitive tormdir a directory as it still contains files; but remember that this is a pseudo-filesystem, so usual rules don&#x27;t apply. After the cleanup is done, the collection process can exit safely.</p><h3>Limit a container\&#x27;s resources</h3><p><em>Estimated reading time: 13 minutes</em></p><p>By default, a container has no resource constraints and can use as much of a given resource as the host&#x27;s kernel scheduler allows. Docker provides ways to control how much memory, CPU, or block IO a container can use, setting runtime configuration flags of the docker run command. This section provides details on when you should set such limits and the possible implications of setting them.</p><p>Many of these features require your kernel to support Linux capabilities. To check for support, you can use the <a href="https://docs.docker.com/engine/reference/commandline/info/">docker info</a> command. If a capability is disabled in your kernel, you may see a warning at the end of the output like the following:</p><p>WARNING: No swap limit support</p><p>Consult your operating system&#x27;s documentation for enabling them. <a href="https://docs.docker.com/install/linux/linux-postinstall/#your-kernel-does-not-support-cgroup-swap-limit-capabilities">Learn more</a>.</p><h4>Memory</h4><h5><strong>Understand the risks of running out of memory</strong></h5><p>It is important not to allow a running container to consume too much of the host machine&#x27;s memory. On Linux hosts, if the kernel detects that there is not enough memory to perform important system functions, it throws an OOME, or Out Of Memory Exception, and starts killing processes to free up memory. Any process is subject to killing, including Docker and other important applications. This can effectively bring the entire system down if the wrong process is killed.</p><p>Docker attempts to mitigate these risks by adjusting the OOM priority on the Docker daemon so that it is less likely to be killed than other processes on the system. The OOM priority on containers is not adjusted. This makes it more likely for an individual container to be killed than for the Docker daemon or other system processes to be killed. You should not try to circumvent these safeguards by manually setting --oom-score-adj to an extreme negative number on the daemon or a container, or by setting --oom-disable-kill on a container.</p><p>For more information about the Linux kernel&#x27;s OOM management, see <a href="https://www.kernel.org/doc/gorman/html/understand/understand016.html">Out of Memory Management</a>.</p><p>You can mitigate the risk of system instability due to OOME by:</p><ul><li>Perform tests to understand the memory requirements of your application before placing it into production.</li><li>Ensure that your application runs only on hosts with adequate resources.</li><li>Limit the amount of memory your container can use, as described below.</li><li>Be mindful when configuring swap on your Docker hosts. Swap is slower and less performant than memory but can provide a buffer against running out of system memory.</li><li>Consider converting your container to a <a href="https://docs.docker.com/engine/swarm/services/">service</a>, and using service-level constraints and node labels to ensure that the application runs only on hosts with enough memory</li></ul><h5><strong>Limit a container&#x27;s access to memory</strong></h5><p>Docker can enforce hard memory limits, which allow the container to use no more than a given amount of user or system memory, or soft limits, which allow the container to use as much memory as it needs unless certain conditions are met, such as when the kernel detects low memory or contention on the host machine. Some of these options have different effects when used alone or when more than one option is set.</p><p>Most of these options take a positive integer, followed by a suffix of b, k, m, g, to indicate bytes, kilobytes, megabytes, or gigabytes.</p><p>  <strong>Option</strong>              <strong>Description</strong></p><hr/><p>  -m or --memory=        The maximum amount of memory the container can use. If you set this option, the minimum allowed value is 4m (4 megabyte).
--memory-swap*        The amount of memory this container is allowed to swap to disk. See <a href="https://docs.docker.com/config/containers/resource_constraints/#--memory-swap-details">--memory-swap details</a>.
--memory-swappiness    By default, the host kernel can swap out a percentage of anonymous pages used by a container. You can set --memory-swappiness to a value between 0 and 100, to tune this percentage. See <a href="https://docs.docker.com/config/containers/resource_constraints/#--memory-swappiness-details">--memory-swappiness details</a>.
--memory-reservation   Allows you to specify a soft limit smaller than --memory which is activated when Docker detects contention or low memory on the host machine. If you use --memory-reservation, it must be set lower than --memory for it to take precedence. Because it is a soft limit, it does not guarantee that the container doesn&#x27;t exceed the limit.
--kernel-memory        The maximum amount of kernel memory the container can use. The minimum allowed value is 4m. Because kernel memory cannot be swapped out, a container which is starved of kernel memory may block host machine resources, which can have side effects on the host machine and on other containers. See <a href="https://docs.docker.com/config/containers/resource_constraints/#--kernel-memory-details">--kernel-memorydetails</a>.
--oom-kill-disable     By default, if an out-of-memory (OOM) error occurs, the kernel kills processes in a container. To change this behavior, use the --oom-kill-disable option. Only disable the OOM killer on containers where you have also set the -m/--memory option. If the -m flag is not set, the host can run out of memory and the kernel may need to kill the host system&#x27;s processes to free memory.</p><p>For more information about cgroups and memory in general, see the documentation for <a href="https://www.kernel.org/doc/Documentation/cgroup-v1/memory.txt">Memory Resource Controller</a>.</p><h5><strong>--memory-swap details</strong></h5><p>--memory-swap is a modifier flag that only has meaning if --memory is also set. Using swap allows the container to write excess memory requirements to disk when the container has exhausted all the RAM that is available to it. There is a performance penalty for applications that swap memory to disk often.</p><p>Its setting can have complicated effects:</p><ul><li>If --memory-swap is set to a positive integer, then both --memory and --memory-swapmust be set. --memory-swap represents the total amount of memory and swap that can be used, and --memory controls the amount used by non-swap memory. So if --memory=&quot;300m&quot; and --memory-swap=&quot;1g&quot;, the container can use 300m of memory and 700m (1g - 300m) swap.</li><li>If --memory-swap is set to 0, the setting is ignored, and the value is treated as unset.</li><li>If --memory-swap is set to the same value as --memory, and --memory is set to a positive integer, <strong>the container does not have access to swap</strong>. See <a href="https://docs.docker.com/config/containers/resource_constraints/#prevent-a-container-from-using-swap">Prevent a container from using swap</a>.</li><li>If --memory-swap is unset, and --memory is set, the container can use twice as much swap as the --memory setting, if the host container has swap memory configured. For instance, if --memory=&quot;300m&quot; and --memory-swap is not set, the container can use 300m of memory and 600m of swap.</li><li>If --memory-swap is explicitly set to -1, the container is allowed to use unlimited swap, up to the amount available on the host system.</li></ul><h6><strong>PREVENT A CONTAINER FROM USING SWAP</strong></h6><p>If --memory and --memory-swap are set to the same value, this prevents containers from using any swap. This is because --memory-swap is the amount of combined memory and swap that can be used, while --memory is only the amount of physical memory that can be used.</p><h5><strong>--memory-swappiness details</strong></h5><ul><li>A value of 0 turns off anonymous page swapping.</li><li>A value of 100 sets all anonymous pages as swappable.</li><li>By default, if you do not set --memory-swappiness, the value is inherited from the host machine.</li></ul><h5><strong>--kernel-memory details</strong></h5><p>Kernel memory limits are expressed in terms of the overall memory allocated to a container. Consider the following scenarios:</p><ul><li><strong>Unlimited memory, unlimited kernel memory</strong>: This is the default behavior.</li><li><strong>Unlimited memory, limited kernel memory</strong>: This is appropriate when the amount of memory needed by all cgroups is greater than the amount of memory that actually exists on the host machine. You can configure the kernel memory to never go over what is available on the host machine, and containers which need more memory need to wait for it.</li><li><strong>Limited memory, unlimited kernel memory</strong>: The overall memory is limited, but the kernel memory is not.</li><li><strong>Limited memory, limited kernel memory</strong>: Limiting both user and kernel memory can be useful for debugging memory-related problems. If a container is using an unexpected amount of either type of memory, it runs out of memory without affecting other containers or the host machine. Within this setting, if the kernel memory limit is lower than the user memory limit, running out of kernel memory causes the container to experience an OOM error. If the kernel memory limit is higher than the user memory limit, the kernel limit does not cause the container to experience an OOM.</li></ul><p>When you turn on any kernel memory limits, the host machine tracks &quot;high water mark&quot; statistics on a per-process basis, so you can track which processes (in this case, containers) are using excess memory. This can be seen per process by viewing /proc/<code style="background-color:lightgray">&lt;PID&gt;</code>/status on the host machine.</p><h4>CPU</h4><p>By default, each container&#x27;s access to the host machine&#x27;s CPU cycles is unlimited. You can set various constraints to limit a given container&#x27;s access to the host machine&#x27;s CPU cycles. Most users use and configure the <a href="https://docs.docker.com/config/containers/resource_constraints/#configure-the-default-cfs-scheduler">default CFS scheduler</a>. In Docker 1.13 and higher, you can also configure the <a href="https://docs.docker.com/config/containers/resource_constraints/#configure-the-realtime-scheduler">realtime scheduler</a>.</p><h5><strong>Configure the default CFS scheduler</strong></h5><p>The CFS is the Linux kernel CPU scheduler for normal Linux processes. Several runtime flags allow you to configure the amount of access to CPU resources your container has. When you use these settings, Docker modifies the settings for the container&#x27;s cgroup on the host machine.</p><p>  <strong>Option</strong>                <strong>Description</strong></p><hr/><p>  --cpus=<code style="background-color:lightgray">&lt;value&gt;</code>         Specify how much of the available CPU resources a container can use. For instance, if the host machine has two CPUs and you set --cpus=&quot;1.5&quot;, the container is guaranteed at most one and a half of the CPUs. This is the equivalent of setting --cpu-period=&quot;100000&quot; and --cpu-quota=&quot;150000&quot;. Available in Docker 1.13 and higher.
--cpu-period=<code style="background-color:lightgray">&lt;value&gt;</code>   Specify the CPU CFS scheduler period, which is used alongside--cpu-quota. Defaults to 100 micro-seconds. Most users do not change this from the default. If you use Docker 1.13 or higher, use --cpus instead.
--cpu-quota=<code style="background-color:lightgray">&lt;value&gt;</code>    Impose a CPU CFS quota on the container. The number of microseconds per --cpu-period that the container is guaranteed CPU access. In other words, cpu-quota / cpu-period. If you use Docker 1.13 or higher, use --cpus instead.
--cpuset-cpus            Limit the specific CPUs or cores a container can use. A comma-separated list or hyphen-separated range of CPUs a container can use, if you have more than one CPU. The first CPU is numbered 0. A valid value might be 0-3 (to use the first, second, third, and fourth CPU) or 1,3 (to use the second and fourth CPU).
--cpu-shares             Set this flag to a value greater or less than the default of 1024 to increase or reduce the container&#x27;s weight, and give it access to a greater or lesser proportion of the host machine&#x27;s CPU cycles. This is only enforced when CPU cycles are constrained. When plenty of CPU cycles are available, all containers use as much CPU as they need. In that way, this is a soft limit. --cpu-shares does not prevent containers from being scheduled in swarm mode. It prioritizes container CPU resources for the available CPU cycles. It does not guarantee or reserve any specific CPU access.</p><p>If you have 1 CPU, each of the following commands guarantees the container at most 50% of the CPU every second.</p><p><strong>Docker 1.13 and higher</strong>:</p><p>docker run -it --cpus=&quot;.5&quot; ubuntu /bin/bash</p><p><strong>Docker 1.12 and lower</strong>:</p><p>$ docker run -it --cpu-period=100000 --cpu-quota=50000 ubuntu /bin/bash</p><h5><strong>Configure the realtime scheduler</strong></h5><p>In Docker 1.13 and higher, you can configure your container to use the realtime scheduler, for tasks which cannot use the CFS scheduler. You need to <a href="https://docs.docker.com/config/containers/resource_constraints/#configure-the-host-machines-kernel">make sure the host machine&#x27;s kernel is configured correctly</a> before you can <a href="https://docs.docker.com/config/containers/resource_constraints/#configure-the-docker-daemon">configure the Docker daemon</a> or <a href="https://docs.docker.com/config/containers/resource_constraints/#configure-individual-containers">configure individual containers</a>.</p><p><strong>Warning</strong>: CPU scheduling and prioritization are advanced kernel-level features. Most users do not need to change these values from their defaults. Setting these values incorrectly can cause your host system to become unstable or unusable.</p><h6><strong>CONFIGURE THE HOST MACHINE&#x27;S KERNEL</strong></h6><p>Verify that CONFIG_RT_GROUP_SCHED is enabled in the Linux kernel by runningzcat /proc/config.gz | grep CONFIG_RT_GROUP_SCHED or by checking for the existence of the file /sys/fs/cgroup/cpu.rt_runtime_us. For guidance on configuring the kernel realtime scheduler, consult the documentation for your operating system.</p><h6><strong>CONFIGURE THE DOCKER DAEMON</strong></h6><p>To run containers using the realtime scheduler, run the Docker daemon with the --cpu-rt-runtime flag set to the maximum number of microseconds reserved for realtime tasks per runtime period. For instance, with the default period of 1000000 microseconds (1 second), setting --cpu-rt-runtime=950000 ensures that containers using the realtime scheduler can run for 950000 microseconds for every 1000000-microsecond period, leaving at least 50000 microseconds available for non-realtime tasks. To make this configuration permanent on systems which use systemd, see <a href="https://docs.docker.com/config/daemon/systemd/">Control and configure Docker with systemd</a>.</p><h6><strong>CONFIGURE INDIVIDUAL CONTAINERS</strong></h6><p>You can pass several flags to control a container&#x27;s CPU priority when you start the container using docker run. Consult your operating system&#x27;s documentation or the ulimit command for information on appropriate values.</p><p>  <strong>Option</strong>                    <strong>Description</strong></p><hr/><p>  --cap-add=sys_nice           Grants the container the CAP_SYS_NICE capability, which allows the container to raise process nice values, set real-time scheduling policies, set CPU affinity, and other operations.
--cpu-rt-runtime=<code style="background-color:lightgray">&lt;value&gt;</code>   The maximum number of microseconds the container can run at realtime priority within the Docker daemon&#x27;s realtime scheduler period. You also need the --cap-add=sys_nice flag.
--ulimit rtprio=<code style="background-color:lightgray">&lt;value&gt;</code>    The maximum realtime priority allowed for the container. You also need the --cap-add=sys_nice flag.</p><p>The following example command sets each of these three flags on a debian:jessie container.</p><p>$ docker run --it --cpu-rt-runtime=950000 \</p><p>--ulimit rtprio=99 \</p><p>--cap-add=sys_nice \</p><p>debian:jessie</p><p>If the kernel or Docker daemon is not configured correctly, an error occurs.</p><h3>Logging</h3><h4>View logs for a container or service</h4><p><em>Estimated reading time: 2 minutes</em></p><p>The docker logs command shows information logged by a running container. Thedocker service logs command shows information logged by all containers participating in a service. The information that is logged and the format of the log depends almost entirely on the container&#x27;s endpoint command.</p><p>By default, docker logs or docker service logs shows the command&#x27;s output just as it would appear if you ran the command interactively in a terminal. UNIX and Linux commands typically open three I/O streams when they run, called STDIN, STDOUT, and STDERR. STDIN is the commmand&#x27;s input stream, which may include input from the keyboard or input from another command. STDOUT is usually a command&#x27;s normal output, and STDERR is typically used to output error messages. By default, docker logs shows the command&#x27;s STDOUT and STDERR. To read more about I/O and Linux, see the <a href="http://www.tldp.org/LDP/abs/html/io-redirection.html">Linux Documentation Project article on I/O redirection</a>.</p><p>In some cases, docker logs may not show useful information unless you take additional steps.</p><ul><li>If you use a <a href="https://docs.docker.com/config/containers/logging/configure/">logging driver</a> which sends logs to a file, an external host, a database, or another logging back-end, docker logs may not show useful information.</li><li>If your image runs a non-interactive process such as a web server or a database, that application may send its output to log files instead of STDOUT and STDERR.</li></ul><p>In the first case, your logs are processed in other ways and you may choose not to use docker logs. In the second case, the official nginx image shows one workaround, and the official Apache httpd image shows another.</p><p>The official nginx image creates a symbolic link from /dev/stdout to /var/log/nginx/access.log, and creates another symbolic link from /dev/stderr to /var/log/nginx/error.log, overwriting the log files and causing logs to be sent to the relevant special device instead. See the <a href="https://github.com/nginxinc/docker-nginx/blob/8921999083def7ba43a06fabd5f80e4406651353/mainline/jessie/Dockerfile#L21-L23">Dockerfile</a>.</p><p>The official httpd driver changes the httpd application&#x27;s configuration to write its normal output directly to /proc/self/fd/1 (which is STDOUT) and its errors to /proc/self/fd/2 (which is STDERR). See the <a href="https://github.com/docker-library/httpd/blob/b13054c7de5c74bbaa6d595dbe38969e6d4f860c/2.2/Dockerfile#L72-L75">Dockerfile</a>.</p><h5><strong>Next steps</strong></h5><ul><li>Configure <a href="https://docs.docker.com/config/containers/logging/configure/">logging drivers</a>.</li><li>Write a <a href="https://docs.docker.com/engine/reference/builder/">Dockerfile</a>.</li></ul><h4>Configure logging drivers</h4><p><em>Estimated reading time: 6 minutes</em></p><p>Docker includes multiple logging mechanisms to help you <a href="https://docs.docker.com/engine/admin/logging/view_container_logs/">get information from running containers and services</a>. These mechanisms are called logging drivers.</p><p>Each Docker daemon has a default logging driver, which each container uses unless you configure it to use a different logging driver.</p><p>In addition to using the logging drivers included with Docker, you can also implement and use <a href="https://docs.docker.com/engine/admin/logging/plugins/">logging driver plugins</a>. Logging driver plugins are available in Docker 17.05 and higher.</p><h5><strong>Configure the default logging driver</strong></h5><p>To configure the Docker daemon to default to a specific logging driver, set the value of log-driver to the name of the logging driver in the daemon.json file, which is located in /etc/docker/ on Linux hosts or C:\ProgramData\docker\config\ on Windows server hosts. The default logging driver is json-file. The following example explicitly sets the default logging driver to syslog:</p><p>{</p><p>&quot;log-driver&quot;: &quot;syslog&quot;</p><p>}</p><p>If the logging driver has configurable options, you can set them in the daemon.json file as a JSON array with the key log-opts. The following example sets two configurable options on the json-file logging driver:</p><p>{</p><p>&quot;log-driver&quot;: &quot;json-file&quot;,</p><p>&quot;log-opts&quot;: {</p><p>&quot;labels&quot;: &quot;production_status&quot;,</p><p>&quot;env&quot;: &quot;os,customer&quot;</p><p>}</p><p>}</p><p>If you do not specify a logging driver, the default is json-file. Thus, the default output for commands such as docker inspect <code style="background-color:lightgray">&lt;CONTAINER&gt;</code> is JSON.</p><p>To find the current default logging driver for the Docker daemon, run docker info and search for Logging Driver. You can use the following command on Linux, macOS, or PowerShell on Windows:</p><p>$ docker info | grep \&#x27;Logging Driver\&#x27;</p><p>Logging Driver: json-file</p><h5><strong>Configure the logging driver for a container</strong></h5><p>When you start a container, you can configure it to use a different logging driver than the Docker daemon&#x27;s default, using the --log-driver flag. If the logging driver has configurable options, you can set them using one or more instances of the --log-opt <code style="background-color:lightgray">&lt;NAME&gt;=&lt;VALUE&gt;</code> flag. Even if the container uses the default logging driver, it can use different configurable options.</p><p>The following example starts an Alpine container with the none logging driver.</p><p>$ docker run -it --log-driver none alpine ash</p><p>To find the current logging driver for a running container, if the daemon is using the json-filelogging driver, run the following docker inspect command, substituting the container name or ID for <code style="background-color:lightgray">&lt;CONTAINER&gt;</code>:</p><p>$ docker inspect -f \&#x27;{{.HostConfig.LogConfig.Type}}\&#x27; <code style="background-color:lightgray">&lt;CONTAINER&gt;</code></p><p>json-file</p><h5><strong>Configure the delivery mode of log messages from container to log driver</strong></h5><p>Docker provides two modes for delivering messages from the container to the log driver:</p><ul><li>(default) direct, blocking delivery from container to driver</li><li>non-blocking delivery that stores log messages in an intermediate per-container ring buffer for consumption by driver</li></ul><p>The non-blocking message delivery mode prevents applications from blocking due to logging back pressure. Applications are likely to fail in unexpected ways when STDERR or STDOUT streams block.</p><p><strong>WARNING</strong>: When the buffer is full and a new message is enqueued, the oldest message in memory is dropped. Dropping messages is often preferred to blocking the log-writing process of an application.</p><p>The mode log option controls whether to use the blocking (default) or non-blocking message delivery.</p><p>The max-buffer-size log option controls the size of the ring buffer used for intermediate message storage when mode is set to non-blocking. max-buffer-size defaults to 1 megabyte.</p><p>The following example starts an Alpine container with log output in non-blocking mode and a 4 megabyte buffer:</p><p>$ docker run -it --log-opt mode=non-blocking --log-opt max-buffer-size=4m alpine ping 127.0.0.1</p><h6><strong>Use environment variables or labels with logging drivers</strong></h6><p>Some logging drivers add the value of a container&#x27;s --env|-e or --label flags to the container&#x27;s logs. This example starts a container using the Docker daemon&#x27;s default logging driver (let&#x27;s assume json-file) but sets the environment variable os=ubuntu.</p><p>$ docker run -dit --label production_status=testing -e os=ubuntu alpine sh</p><p>If the logging driver supports it, this adds additional fields to the logging output. The following output is generated by the json-file logging driver:</p><p>&quot;attrs&quot;:{&quot;production_status&quot;:&quot;testing&quot;,&quot;os&quot;:&quot;ubuntu&quot;}</p><h5><strong>Supported logging drivers</strong></h5><p>The following logging drivers are supported. See the link to each driver&#x27;s documentation for its configurable options, if applicable. If you are using <a href="https://docs.docker.com/engine/admin/logging/plugins/">logging driver plugins</a>, you may see more options.</p><p>  <strong>Driver</strong>                                                                    <strong>Description</strong></p><hr/><p>  none                                                                          No logs are available for the container and docker logs does not return any output.
<a href="https://docs.docker.com/config/containers/logging/json-file/">json-file</a>     The logs are formatted as JSON. The default logging driver for Docker.
<a href="https://docs.docker.com/config/containers/logging/syslog/">syslog</a>           Writes logging messages to the syslog facility. The syslog daemon must be running on the host machine.
<a href="https://docs.docker.com/config/containers/logging/journald/">journald</a>       Writes log messages to journald. The journald daemon must be running on the host machine.
<a href="https://docs.docker.com/config/containers/logging/gelf/">gelf</a>               Writes log messages to a Graylog Extended Log Format (GELF) endpoint such as Graylog or Logstash.
<a href="https://docs.docker.com/config/containers/logging/fluentd/">fluentd</a>         Writes log messages to fluentd (forward input). The fluentd daemon must be running on the host machine.
<a href="https://docs.docker.com/config/containers/logging/awslogs/">awslogs</a>         Writes log messages to Amazon CloudWatch Logs.
<a href="https://docs.docker.com/config/containers/logging/splunk/">splunk</a>           Writes log messages to splunk using the HTTP Event Collector.
<a href="https://docs.docker.com/config/containers/logging/etwlogs/">etwlogs</a>         Writes log messages as Event Tracing for Windows (ETW) events. Only available on Windows platforms.
<a href="https://docs.docker.com/config/containers/logging/gcplogs/">gcplogs</a>         Writes log messages to Google Cloud Platform (GCP) Logging.
<a href="https://docs.docker.com/config/containers/logging/logentries/">logentries</a>   Writes log messages to Rapid7 Logentries.</p><h5><strong>Limitations of logging drivers</strong></h5><p>The docker logs command is not available for drivers other than json-file and journald.</p><h4>Use a logging driver plugin</h4><p><em>Estimated reading time: 1 minute</em></p><p>Docker logging plugins allow you to extend and customize Docker&#x27;s logging capabilities beyond those of the <a href="https://docs.docker.com/config/containers/logging/configure/">built-in logging drivers</a>. A logging service provider can <a href="https://docs.docker.com/engine/extend/plugins_logging/">implement their own plugins</a>and make them available on Docker Hub, Docker Store, or a private registry. This topic shows how a user of that logging service can configure Docker to use the plugin.</p><h5><strong>Install the logging driver plugin</strong></h5><p>To install a logging driver plugin, use docker plugin install <code style="background-color:lightgray">&lt;org/image&gt;</code>, using the information provided by the plugin developer.</p><p>You can list all installed plugins using docker plugin ls, and you can inspect a specific plugin using docker inspect.</p><h5><strong>Configure the plugin as the default logging driver</strong></h5><p>After the plugin is installed, you can configure the Docker daemon to use it as the default by setting the plugin&#x27;s name as the value of the logging-driver key in the daemon.json, as detailed in the <a href="https://docs.docker.com/config/containers/logging/configure/#configure-the-default-logging-driver">logging overview</a>. If the logging driver supports additional options, you can set those as the values of the log-opts array in the same file.</p><h5><strong>Configure a container to use the plugin as the logging driver</strong></h5><p>After the plugin is installed, you can configure a container to use the plugin as its logging driver by specifying the --log-driver flag to docker run, as detailed in the <a href="https://docs.docker.com/config/containers/logging/configure/#configure-the-logging-driver-for-a-container">logging overview</a>. If the logging driver supports additional options, you can specify them using one or more --log-optflags with the option name as the key and the option value as the value.</p><h4>Customize log driver output</h4><p><em>Estimated reading time: 1 minute</em></p><p>The tag log option specifies how to format a tag that identifies the container&#x27;s log messages. By default, the system uses the first 12 characters of the container ID. To override this behavior, specify a tag option:</p><p>$ docker run --log-driver=fluentd --log-opt fluentd-address=myhost.local:24224 --log-opt tag=&quot;mailer&quot;</p><p>Docker supports some special template markup you can use when specifying a tag&#x27;s value:</p><p>  <strong>Markup</strong>         <strong>Description</strong></p><hr/><p>  {{.ID}}            The first 12 characters of the container ID.
{{.FullID}}        The full container ID.
{{.Name}}          The container name.
{{.ImageID}}       The first 12 characters of the container&#x27;s image ID.
{{.ImageFullID}}   The container&#x27;s full image ID.
{{.ImageName}}     The name of the image used by the container.
{{.DaemonName}}    The name of the docker program (docker).</p><p>For example, specifying a --log-opt tag=&quot;{{.ImageName}}/{{.Name}}/{{.ID}}&quot; value yields syslog log lines like:</p><p>Aug 7 18:33:19 HOSTNAME hello-world/foobar/5790672ab6a0<!-- -->[9103]<!-- -->: Hello from Docker.</p><p>At startup time, the system sets the container_name field and {{.Name}} in the tags. If you use docker rename to rename a container, the new name is not reflected in the log messages. Instead, these messages continue to use the original container name.</p><h4>Logging Driver Details</h4><h5><strong>Logentries logging driver</strong></h5><p><em>Estimated reading time: 1 minute</em></p><p>The logentries logging driver sends container logs to the <a href="https://logentries.com/">Logentries</a> server.</p><h6><strong>Usage</strong></h6><p>Some options are supported by specifying --log-opt as many times as needed:</p><ul><li>logentries-token: specify the logentries log set token</li><li>line-only: send raw payload only</li></ul><p>Configure the default logging driver by passing the --log-driver option to the Docker daemon:</p><p>$ dockerd --log-driver=logentries</p><p>To set the logging driver for a specific container, pass the --log-driver option to docker run:</p><p>$ docker run --log-driver=logentries ...</p><p>Before using this logging driver, you need to create a new Log Set in the Logentries web interface and pass the token of that log set to Docker:</p><p>$ docker run --log-driver=logentries --log-opt logentries-token=abcd1234-12ab-34cd-5678-0123456789ab</p><h6><strong>Options</strong></h6><p>Users can use the --log-opt NAME=VALUE flag to specify additional Logentries logging driver options.</p><p><strong>logentries-token</strong></p><p>You need to provide your log set token for logentries driver to work:</p><p>$ docker run --log-driver=logentries --log-opt logentries-token=abcd1234-12ab-34cd-5678-0123456789ab</p><p><strong>line-only</strong></p><p>You could specify whether to send log message wrapped into container data (default) or to send raw log line</p><p>$ docker run --log-driver=logentries --log-opt logentries-token=abcd1234-12ab-34cd-5678-012</p><h4>JSON File logging driver</h4><p><em>Estimated reading time: 2 minutes</em></p><p>By default, Docker captures the standard output (and standard error) of all your containers, and writes them in files using the JSON format. The JSON format annotates each line with its origin (stdout or stderr) and its timestamp. Each log file contains information about only one container.</p><h5><strong>Usage</strong></h5><p>To use the json-file driver as the default logging driver, set the log-driver and log-optkeys to appropriate values in the daemon.json file, which is located in /etc/docker/ on Linux hosts or C:\ProgramData\docker\config\daemon.json on Windows Server. For more information about configuring Docker using daemon.json, see <a href="https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-configuration-file">daemon.json</a>.</p><p>The following example sets the log driver to json-file and sets the max-size option.</p><p>{</p><p>&quot;log-driver&quot;: &quot;json-file&quot;,</p><p>&quot;log-opts&quot;: {</p><p>&quot;max-size&quot;: &quot;10m&quot;</p><p>}</p><p>}</p><p>Restart Docker for the changes to take effect for newly created containers. Existing containers do not use the new logging configuration.</p><p>You can set the logging driver for a specific container by using the --log-driver flag to docker container create or docker run:</p><p>$ docker run \</p><p>--log-driver json-file --log-opt max-size=10m \</p><p>alpine echo hello world</p><h6><strong>Options</strong></h6><p>The json-file logging driver supports the following logging options:</p><p>  <strong>Option</strong>   <strong>Description</strong>                                                                                                                                                                                                                   <strong>Example value</strong></p><hr/><p>  max-size     The maximum size of the log before it is rolled. A positive integer plus a modifier representing the unit of measure (k, m, or g). Defaults to -1 (unlimited).                                                                    --log-opt max-size=10m
max-file     The maximum number of log files that can be present. If rolling the logs creates excess files, the oldest file is removed. <strong>Only effective when max-size is also set.</strong> A positive integer. Defaults to 1.                       --log-opt max-file=3
labels       Applies when starting the Docker daemon. A comma-separated list of logging-related labels this daemon accepts. Used for advanced <a href="https://docs.docker.com/config/containers/logging/log_tags/">log tag options</a>.                  --log-opt labels=production_status,geo
env          Applies when starting the Docker daemon. A comma-separated list of logging-related environment variables this daemon accepts. Used for advanced <a href="https://docs.docker.com/config/containers/logging/log_tags/">log tag options</a>.   --log-opt env=os,customer
env-regex    Similar to and compatible with env. A regular expression to match logging-related environment variables. Used for advanced <a href="https://docs.docker.com/config/containers/logging/log_tags/">log tag options</a>.                        --log-opt env-regex=\^(os|customer).</p><h6><strong>Examples</strong></h6><p>This example starts an alpine container which can have a maximum of 3 log files no larger than 10 megabytes each.</p><p>$ docker run -it --log-opt max-size=10m --log-opt max-file=3 alpine ash</p><h4>Graylog Extended Format logging driver</h4><p><em>Estimated reading time: 4 minutes</em></p><p>The gelf logging driver is a convenient format that is understood by a number of tools such as<a href="https://www.graylog.org/">Graylog</a>, <a href="https://www.elastic.co/products/logstash">Logstash</a>, and <a href="http://www.fluentd.org/">Fluentd</a>. Many tools use this format.</p><p>In GELF, every log message is a dict with the following fields:</p><ul><li>version</li><li>host (who sent the message in the first place)</li><li>timestamp</li><li>short and long version of the message</li><li>any custom fields you configure yourself</li></ul><h5><strong>Usage</strong></h5><p>To use the gelf driver as the default logging driver, set the log-driver and log-opt keys to appropriate values in the daemon.json file, which is located in /etc/docker/ on Linux hosts or C:\ProgramData\docker\config\daemon.json on Windows Server. For more about configuring Docker using daemon.json, see <a href="https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-configuration-file">daemon.json</a>.</p><p>The following example sets the log driver to gelf and sets the gelf-address option.</p><p>{</p><p>&quot;log-driver&quot;: &quot;gelf&quot;,</p><p>&quot;log-opts&quot;: {</p><p>&quot;gelf-address&quot;: &quot;udp://1.2.3.4:12201&quot;</p><p>}</p><p>}</p><p>Restart Docker for the changes to take effect.</p><p>To use gelf as the default logging driver for new containers, pass the --log-driver and --log-opt options to the Docker daemon:</p><p>dockerd</p><p>--log-driver gelf ---log-opt gelf-address=udp://1.2.3.4:12201 \</p><p>To make the configuration permanent, you can configure it in /etc/docker/daemon.json:</p><p>{</p><p>&quot;log-driver&quot;: &quot;gelf&quot;,</p><p>&quot;log-opts&quot;: {</p><p>&quot;gelf-address&quot;: &quot;udp://1.2.3.4:12201&quot;</p><p>}</p><p>}</p><p>You can set the logging driver for a specific container by setting the --log-driver flag when using docker container create or docker run:</p><p>$ docker run \</p><p>--log-driver gelf ---log-opt gelf-address=udp://1.2.3.4:12201 \</p><p>alpine echo hello world</p><h6><strong>GELF options</strong></h6><p>The gelf logging driver supports the following options:</p><p>  <strong>Option</strong>                 <strong>Required</strong>   <strong>Description</strong>                                                                                                                                                                                                                                                                                            <strong>Example value</strong></p><hr/><p>  gelf-address               required       The address of the GELF server. tcp and udpare the only supported URI specifier and you must specify the port.                                                                                                                                                                                             --log-opt gelf-address=udp://192.168.0.42:12201
gelf-compression-type      optional       UDP Only The type of compression the GELF driver uses to compress each log message. Allowed values are gzip, zlib and none. The default is gzip.                                                                                                                                                           --log-opt gelf-compression-type=gzip
gelf-compression-level     optional       UDP Only The level of compression when gzip or zlib is the gelf-compression-type. An integer in the range of -1 to 9(BestCompression). Default value is 1 (BestSpeed). Higher levels provide more compression at lower speed. Either -1 or 0disables compression.                                          --log-opt gelf-compression-level=2
gelf-tcp-max-reconnect     optional       TCP Only The maximum number of reconnection attempts when the connection drop. An positive integer. Default value is 3.                                                                                                                                                                                    --log-opt gelf-tcp-max-reconnect=3
gelf-tcp-reconnect-delay   optional       TCP Only The number of seconds to wait between reconnection attempts. A positive integer. Default value is 1.                                                                                                                                                                                              --log-opt gelf-tcp-reconnect-delay=1
tag                        optional       A string that is appended to the APP-NAME in the gelf message. By default, Docker uses the first 12 characters of the container ID to tag log messages. Refer to the <a href="https://docs.docker.com/config/containers/logging/log_tags/">log tag option documentation</a> for customizing the log tag format.       --log-opt tag=mailer
labels                     optional       Applies when starting the Docker daemon. A comma-separated list of logging-related labels this daemon accepts. Adds additional key on the extra fields, prefixed by an underscore (<em>). Used for advanced <a href="https://docs.docker.com/config/containers/logging/log_tags/">log tag options</a>.                  --log-opt labels=production_status,geo
env                        optional       Applies when starting the Docker daemon. A comma-separated list of logging-related environment variables this daemon accepts. Adds additional key on the extra fields, prefixed by an underscore (</em>). Used for advanced <a href="https://docs.docker.com/config/containers/logging/log_tags/">log tag options</a>.   --log-opt env=os,customer
env-regex                  optional       Similar to and compatible with env. A regular expression to match logging-related environment variables. Used for advanced <a href="https://docs.docker.com/config/containers/logging/log_tags/">log tag options</a>.                                                                                                 --log-opt env-regex=\^(os | customer).</p><h6><strong>Examples</strong></h6><p>This example configures the container to use the GELF server running at 192.168.0.42 on port 12201.</p><p>$ docker run -dit \</p><p>--log-driver=gelf \</p><p>--log-opt gelf-address=udp://192.168.0.42:12201 \</p><p>alpine sh</p><h4>Syslog logging driver</h4><p><em>Estimated reading time: 4 minutes</em></p><p>The syslog logging driver routes logs to a syslog server. The syslog protocol uses a raw string as the log message and supports a limited set of metadata. The syslog message must be formatted in a specific way to be valid. From a valid message, the receiver can extract the following information:</p><ul><li><strong>priority</strong>: the logging level, such as debug, warning, error, info.</li><li><strong>timestamp</strong>: when the event occurred.</li><li><strong>hostname</strong>: where the event happened.</li><li><strong>facility</strong>: which subsystem logged the message, such as mail or kernel.</li><li><strong>process name</strong> and <strong>process ID (PID)</strong>: The name and ID of the process that generated the log.</li></ul><p>The format is defined in <a href="https://tools.ietf.org/html/rfc5424">RFC 5424</a> and Docker&#x27;s syslog driver implements the <a href="https://tools.ietf.org/html/rfc5424#section-6">ABNF reference</a> in the following way:</p><p>TIMESTAMP SP HOSTNAME SP APP-NAME SP PROCID SP MSGID</p><p>+<!-- --> + + | +</p><p>| | | | |</p><p>| | | | |</p><p>+------------+ +----+ | +----+ +---------+</p><p>v v v v v</p><p>2017-04-01T17:41:05.616647+08:00 a.vm {taskid:aa,version:} 1787791 {taskid:aa,version:}</p><h5><strong>Usage</strong></h5><p>To use the syslog driver as the default logging driver, set the log-driver and log-opt keys to appropriate values in the daemon.json file, which is located in /etc/docker/ on Linux hosts orC:\ProgramData\docker\config\daemon.json on Windows Server. For more about configuring Docker using daemon.json, see <a href="https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-configuration-file">daemon.json</a>.</p><p>The following example sets the log driver to syslog and sets the syslog-address option.</p><p>{</p><p>&quot;log-driver&quot;: &quot;syslog&quot;,</p><p>&quot;log-opts&quot;: {</p><p>&quot;syslog-address&quot;: &quot;udp://1.2.3.4:1111&quot;</p><p>}</p><p>}</p><p>Restart Docker for the changes to take effect.</p><p><strong>Note</strong>: The syslog-address supports both UDP and TCP.</p><p>You can set the logging driver for a specific container by using the --log-driver flag to docker container create or docker run:</p><p>docker run \</p><p>---log-driver syslog ---log-opt syslog-address=udp://1.2.3.4:1111 \</p><p>alpine echo hello world</p><h5><strong>Options</strong></h5><p>The following logging options are supported as options for the syslog logging driver. They can be set as defaults in the daemon.json, by adding them as key-value pairs to the log-opts JSON array. They can also be set on a given container by adding a --log-opt <code style="background-color:lightgray">&lt;key&gt;=&lt;value&gt;</code> flag for each option when starting the container.</p><p>  <strong>Option</strong>               <strong>Description</strong>                                                                                                                                                                                                                                                                                            <strong>Example value</strong></p><hr/><p>  syslog-address           The address of an external syslogserver. The URI specifier may be <!-- -->[tcp | udp|tcp+tls]<!-- -->://host:port, unix://path, or unixgram://path. If the transport is tcp, udp, or tcp+tls, the default port is 514.                                                                                                 --log-opt syslog-address=tcp+tls://192.168.1.3:514, --log-opt syslog-address=unix:///tmp/syslog.sock
syslog-facility          The syslog facility to use. Can be the number or name for any valid syslog facility. See the <a href="https://tools.ietf.org/html/rfc5424#section-6.2.1">syslog documentation</a>.                                                                                                                                    --log-opt syslog-facility=daemon
syslog-tls-ca-cert       The absolute path to the trust certificates signed by the CA. <strong>Ignored if the address protocol is not tcp+tls.</strong>                                                                                                                                                                                          --log-opt syslog-tls-ca-cert=/etc/ca-certificates/custom/ca.pem
syslog-tls-cert          The absolute path to the TLS certificate file. <strong>Ignored if the address protocol is not tcp+tls</strong>.                                                                                                                                                                                                         --log-opt syslog-tls-cert=/etc/ca-certificates/custom/cert.pem
syslog-tls-key           The absolute path to the TLS key file. <strong>Ignored if the address protocol is not tcp+tls.</strong>                                                                                                                                                                                                                 --log-opt syslog-tls-key=/etc/ca-certificates/custom/key.pem
syslog-tls-skip-verify   If set to true, TLS verification is skipped when connecting to the syslog daemon. Defaults to false. <strong>Ignored if the address protocol is not tcp+tls.</strong>                                                                                                                                                   --log-opt syslog-tls-skip-verify=true
tag                      A string that is appended to the APP-NAME in the syslogmessage. By default, Docker uses the first 12 characters of the container ID to tag log messages. Refer to the <a href="https://docs.docker.com/config/containers/logging/log_tags/">log tag option documentation</a> for customizing the log tag format.      --log-opt tag=mailer
syslog-format            The syslog message format to use. If not specified the local UNIX syslog format is used, without a specified hostname. Specify rfc3164 for the RFC-3164 compatible format, rfc5424 for RFC-5424 compatible format, or rfc5424micro for RFC-5424 compatible format with microsecond timestamp resolution.   --log-opt syslog-format=rfc5424micro
labels                   Applies when starting the Docker daemon. A comma-separated list of logging-related labels this daemon accepts. Used for advanced <a href="https://docs.docker.com/config/containers/logging/log_tags/">log tag options</a>.                                                                                           --log-opt labels=production_status,geo
env                      Applies when starting the Docker daemon. A comma-separated list of logging-related environment variables this daemon accepts. Used for advanced <a href="https://docs.docker.com/config/containers/logging/log_tags/">log tag options</a>.                                                                            --log-opt env=os,customer
env-regex                Applies when starting the Docker daemon. Similar to and compatible with env. A regular expression to match logging-related environment variables. Used for advanced <a href="https://docs.docker.com/config/containers/logging/log_tags/">log tag options</a>.                                                        --log-opt env-regex=\^(os<!-- -->|<!-- -->customer)</p><h4>Amazon CloudWatch Logs logging driver</h4><p><em>Estimated reading time: 8 minutes</em></p><p>The awslogs logging driver sends container logs to <a href="https://aws.amazon.com/cloudwatch/details/#log-monitoring">Amazon CloudWatch Logs</a>. Log entries can be retrieved through the <a href="https://console.aws.amazon.com/cloudwatch/home#logs:">AWS Management Console</a> or the <a href="http://docs.aws.amazon.com/cli/latest/reference/logs/index.html">AWS SDKs and Command Line Tools</a>.</p><h5><strong>Usage</strong></h5><p>To use the awslogs driver as the default logging driver, set the log-driver and log-opt keys to appropriate values in the daemon.json file, which is located in /etc/docker/ on Linux hosts or C:\ProgramData\docker\config\daemon.json on Windows Server. For more about configuring Docker using daemon.json, see <a href="https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-configuration-file">daemon.json</a>. The following example sets the log driver to awslogs and sets the awslogs-region option.</p><p>{</p><p>&quot;log-driver&quot;: &quot;awslogs&quot;,</p><p>&quot;log-opts&quot;: {</p><p>&quot;awslogs-region&quot;: &quot;us-east-1&quot;</p><p>}</p><p>}</p><p>Restart Docker for the changes to take effect.</p><p>You can set the logging driver for a specific container by using the --log-driver option to docker run:</p><p>docker run --log-driver=awslogs ...</p><h5><strong>Amazon CloudWatch Logs options</strong></h5><p>You can add logging options to the daemon.json to set Docker-wide defaults, or use the --log-opt NAME=VALUE flag to specify Amazon CloudWatch Logs logging driver options when starting a container.</p><h6><strong>awslogs-region</strong></h6><p>The awslogs logging driver sends your Docker logs to a specific region. Use the awslogs-regionlog option or the AWS_REGION environment variable to set the region. By default, if your Docker daemon is running on an EC2 instance and no region is set, the driver uses the instance&#x27;s region.</p><p>docker run --log-driver=awslogs --log-opt awslogs-region=us-east-1 ...</p><h6><strong>awslogs-group</strong></h6><p>You must specify a <a href="http://docs.aws.amazon.com/AmazonCloudWatch/latest/DeveloperGuide/WhatIsCloudWatchLogs.html">log group</a> for the awslogs logging driver. You can specify the log group with the awslogs-group log option:</p><p>docker run --log-driver=awslogs --log-opt awslogs-region=us-east-1 --log-opt awslogs-group=myLogGroup ...</p><h6><strong>awslogs-stream</strong></h6><p>To configure which <a href="http://docs.aws.amazon.com/AmazonCloudWatch/latest/DeveloperGuide/WhatIsCloudWatchLogs.html">log stream</a> should be used, you can specify the awslogs-stream log option. If not specified, the container ID is used as the log stream.</p><p><strong>Note</strong>: Log streams within a given log group should only be used by one container at a time. Using the same log stream for multiple containers concurrently can cause reduced logging performance.</p><h6><strong>awslogs-create-group</strong></h6><p>Log driver returns an error by default if the log group does not exist. However, you can set theawslogs-create-group to true to automatically create the log group as needed. The awslogs-create-group option defaults to false.</p><p>$ docker run --log-driver=awslogs \</p><p>--log-opt awslogs-region=us-east-1 \</p><p>--log-opt awslogs-group=myLogGroup \</p><p>--log-opt awslogs-create-group=true \</p><p>...</p><p><strong>Note</strong>: Your AWS IAM policy must include the logs:CreateLogGroup permission before you attempt to use awslogs-create-group.</p><h6><strong>awslogs-datetime-format</strong></h6><p>The awslogs-datetime-format option defines a multiline start pattern in <a href="http://strftime.org/">Python strftimeformat</a>. A log message consists of a line that matches the pattern and any following lines that don&#x27;t match the pattern. Thus the matched line is the delimiter between log messages.</p><p>One example of a use case for using this format is for parsing output such as a stack dump, which might otherwise be logged in multiple entries. The correct pattern allows it to be captured in a single entry.</p><p>This option always takes precedence if both awslogs-datetime-format andawslogs-multiline-pattern are configured.</p><p><strong>Note</strong>: Multiline logging performs regular expression parsing and matching of all log messages, which may have a negative impact on logging performance.</p><p>Consider the following log stream, where new log messages start with a timestamp:</p><p>[May 01, 2017 19:00:01]<!-- --> A message was logged</p><p>[May 01, 2017 19:00:04]<!-- --> Another multiline message was logged</p><p>Some random message</p><p>with some random words</p><p>[May 01, 2017 19:01:32]<!-- --> Another message was logged</p><p>The format can be expressed as a strftime expression of <!-- -->[%b %d, %Y %H:%M:%S]<!-- -->, and the awslogs-datetime-format value can be set to that expression:</p><p>$ docker run --log-driver=awslogs \</p><p>--log-opt awslogs-region=us-east-1 \</p><p>--log-opt awslogs-group=myLogGroup \</p><p>--log-opt awslogs-datetime-format=\&#x27;<!-- -->[<!-- -->%b %d, %Y %H:%M:%S<!-- -->]<!-- -->\&#x27; \</p><p>...</p><p>This parses the logs into the following CloudWatch log events:</p><h1>First event</h1><p>[May 01, 2017 19:00:01]<!-- --> A message was logged</p><h1>Second event</h1><p>[May 01, 2017 19:00:04]<!-- --> Another multiline message was logged</p><p>Some random message</p><p>with some random words</p><h1>Third event</h1><p>[May 01, 2017 19:01:32]<!-- --> Another message was logged</p><p>The following strftime codes are supported:</p><p>  <strong>Code</strong>   <strong>Meaning</strong>                                                        <strong>Example</strong></p><hr/><p>  %a         Weekday abbreviated name.                                          Mon
%A         Weekday full name.                                                 Monday
%w         Weekday as a decimal number where 0 is Sunday and 6 is Saturday.   0
%d         Day of the month as a zero-padded decimal number.                  08
%b         Month abbreviated name.                                            Feb
%B         Month full name.                                                   February
%m         Month as a zero-padded decimal number.                             02
%Y         Year with century as a decimal number.                             2008
%y         Year without century as a zero-padded decimal number.              08
%H         Hour (24-hour clock) as a zero-padded decimal number.              19
%I         Hour (12-hour clock) as a zero-padded decimal number.              07
%p         AM or PM.                                                          AM
%M         Minute as a zero-padded decimal number.                            57
%S         Second as a zero-padded decimal number.                            04
%L         Milliseconds as a zero-padded decimal number.                      123
%f         Microseconds as a zero-padded decimal number.                      000345
%z         UTC offset in the form +HHMM or -HHMM.                             +1300
%Z         Time zone name.                                                    PST
%j         Day of the year as a zero-padded decimal number.                   363</p><h6><strong>awslogs-multiline-pattern</strong></h6><p>The awslogs-multiline-pattern option defines a multiline start pattern using a regular expression. A log message consists of a line that matches the pattern and any following lines that don&#x27;t match the pattern. Thus the matched line is the delimiter between log messages.</p><p>This option is ignored if awslogs-datetime-format is also configured.</p><p><strong>Note</strong>: Multiline logging performs regular expression parsing and matching of all log messages. This may have a negative impact on logging performance.</p><p>For example, to process the following log stream where new log messages start with the pattern INFO:</p><p>Consider the following log stream, where each log message should start with the patther INFO:</p><p>INFO A message was logged</p><p>INFO Another multiline message was logged</p><p>Some random message</p><p>INFO Another message was logged</p><p>You can use the regular expression of \^INFO:</p><p>$ docker run --log-driver=awslogs \</p><p>--log-opt awslogs-region=us-east-1 \</p><p>--log-opt awslogs-group=myLogGroup \</p><p>--log-opt awslogs-multiline-pattern=\&#x27;\^INFO\&#x27; \</p><p>...</p><p>This parses the logs into the following CloudWatch log events:</p><h1>First event</h1><p>INFO A message was logged</p><h1>Second event</h1><p>INFO Another multiline message was logged</p><p>Some random message</p><h1>Third event</h1><p>INFO Another message was logged</p><h6><strong>tag</strong></h6><p>Specify tag as an alternative to the awslogs-stream option. tag interprets Go template markup, such as {{.ID}}, {{.FullID}} or {{.Name}} docker.{{.ID}}. See the <a href="https://docs.docker.com/config/containers/logging/log_tags/">tag option documentation</a> for details on all supported template substitutions.</p><p>When both awslogs-stream and tag are specified, the value supplied for awslogs-streamoverrides the template specified with tag.</p><p>If not specified, the container ID is used as the log stream.</p><p><strong>Note</strong>: The CloudWatch log API doesn&#x27;t support : in the log name. This can cause some issues when using the {{ .ImageName }} as a tag, since a docker image has a format of IMAGE:TAG, such as alpine:latest. Template markup can be used to get the proper format. To get the image name and the first 12 characters of the container ID, you can use: --log-opt tag=\&#x27;{{ with split .ImageName &quot;:&quot; }}{{join . &quot;_&quot;}}{{end}}-{{.ID}}\&#x27; the output is something like: alpine_latest-bf0072049c76</p><h5><strong>Credentials</strong></h5><p>You must provide AWS credentials to the Docker daemon to use the awslogs logging driver. You can provide these credentials with the AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, and AWS_SESSION_TOKEN environment variables, the default AWS shared credentials file (<!-- -->~<!-- -->/.aws/credentials of the root user), or (if you are running the Docker daemon on an Amazon EC2 instance) the Amazon EC2 instance profile.</p><p>Credentials must have a policy applied that allows the logs:CreateLogStream and logs:PutLogEvents actions, as shown in the following example.</p><p>{</p><p>&quot;Version&quot;: &quot;2012-10-17&quot;,</p><p>&quot;Statement&quot;: [</p><p>{</p><p>&quot;Action&quot;: [</p><p>&quot;logs:CreateLogStream&quot;,</p><p>&quot;logs:PutLogEvents&quot;</p><p>],</p><p>&quot;Effect&quot;: &quot;Allow&quot;,</p><p>&quot;Resource&quot;: &quot;*&quot;</p><p>}</p><p>]</p><p>}</p><h4>ETW logging driver</h4><p><em>Estimated reading time: 2 minutes</em></p><p>The ETW logging driver forwards container logs as ETW events. ETW stands for Event Tracing in Windows, and is the common framework for tracing applications in Windows. Each ETW event contains a message with both the log and its context information. A client can then create an ETW listener to listen to these events.</p><p>The ETW provider that this logging driver registers with Windows, has the GUID identifier of: {a3693192-9ed6-46d2-a981-f8226c8363bd}. A client creates an ETW listener and registers to listen to events from the logging driver&#x27;s provider. It does not matter the order in which the provider and listener are created. A client can create their ETW listener and start listening for events from the provider, before the provider has been registered with the system.</p><h5><strong>Usage</strong></h5><p>Here is an example of how to listen to these events using the logman utility program included in most installations of Windows:</p><ol><li>logman start -ets DockerContainerLogs -p {a3693192-9ed6-46d2-a981-f8226c8363bd} 0 0 -o trace.etl</li><li>Run your container(s) with the etwlogs driver, by adding --log-driver=etwlogs to the Docker run command, and generate log messages.</li><li>logman stop -ets DockerContainerLogs</li><li>This generates an etl file that contains the events. One way to convert this file into human-readable form is to run: tracerpt -y trace.etl.</li></ol><p>Each ETW event contains a structured message string in this format:</p><p>container_name: %s, image_name: %s, container_id: %s, image_id: %s, source: <!-- -->[stdout | stderr]<!-- -->, log: %s</p><p>Details on each item in the message can be found below:</p><p>  <strong>Field</strong>        <strong>Description</strong></p><hr/><p>  container_name   The container name at the time it was started.
image_name       The name of the container&#x27;s image.
container_id     The full 64-character container ID.
image_id         The full ID of the container&#x27;s image.
source           stdout or stderr.
log              The container log message.</p><p>Here is an example event message:</p><p>container_name: backstabbing_spence,</p><p>image_name: windowsservercore,</p><p>container_id: f14bb55aa862d7596b03a33251c1be7dbbec8056bbdead1da8ec5ecebbe29731,</p><p>image_id: sha256:2f9e19bd998d3565b4f345ac9aaf6e3fc555406239a4fb1b1ba879673713824b,</p><p>source: stdout,</p><p>log: Hello world!</p><p>A client can parse this message string to get both the log message, as well as its context information. The timestamp is also available within the ETW event.</p><p><strong>Note</strong>: This ETW provider emits only a message string, and not a specially structured ETW event. Therefore, it is not required to register a manifest file with the system to read and interpret its ETW events.</p><h4>Fluentd logging driver</h4><p><em>Estimated reading time: 4 minutes</em></p><p>The fluentd logging driver sends container logs to the <a href="http://www.fluentd.org/">Fluentd</a> collector as structured log data. Then, users can use any of the <a href="http://www.fluentd.org/plugins">various output plugins of Fluentd</a> to write these logs to various destinations.</p><p>In addition to the log message itself, the fluentd log driver sends the following metadata in the structured log message:</p><p>  <strong>Field</strong>        <strong>Description</strong></p><hr/><p>  container_id     The full 64-character container ID.
container_name   The container name at the time it was started. If you use docker renameto rename a container, the new name is not reflected in the journal entries.
source           stdout or stderr
log              The container log</p><p>The docker logs command is not available for this logging driver.</p><h5><strong>Usage</strong></h5><p>Some options are supported by specifying --log-opt as many times as needed:</p><ul><li>fluentd-address: specify a socket address to connect to the Fluentd daemon, ex fluentdhost:24224 or unix:///path/to/fluentd.sock</li><li>tag: specify a tag for fluentd message, which interprets some markup, ex {{.ID}}, {{.FullID}} or {{.Name}} docker.{{.ID}}</li></ul><p>To use the fluentd driver as the default logging driver, set the log-driver and log-opt keys to appropriate values in the daemon.json file, which is located in /etc/docker/ on Linux hosts or C:\ProgramData\docker\config\daemon.json on Windows Server. For more about +configuring Docker using daemon.json, see +<a href="https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-configuration-file">daemon.json</a>.</p><p>The following example sets the log driver to fluentd and sets the fluentd-address option.</p><p>{</p><p>&quot;log-driver&quot;: &quot;fluentd&quot;,</p><p>&quot;log-opts&quot;: {</p><p>&quot;fluentd-address&quot;: &quot;fluentdhost:24224&quot;</p><p>}</p><p>}</p><p>Restart Docker for the changes to take effect.</p><p>To set the logging driver for a specific container, pass the --log-driver option to docker run:</p><p>docker run --log-driver=fluentd ...</p><p>Before using this logging driver, launch a Fluentd daemon. The logging driver connects to this daemon through localhost:24224 by default. Use the fluentd-address option to connect to a different address.</p><p>docker run --log-driver=fluentd --log-opt fluentd-address=fluentdhost:24224</p><p>If container cannot connect to the Fluentd daemon, the container stops immediately unless the fluentd-async-connect option is used.</p><h5><strong>Options</strong></h5><p>Users can use the --log-opt NAME=VALUE flag to specify additional Fluentd logging driver options.</p><h6><strong>fluentd-address</strong></h6><p>By default, the logging driver connects to localhost:24224. Supply the fluentd-address option to connect to a different address. tcp(default) and unix sockets are supported.</p><p>docker run --log-driver=fluentd --log-opt fluentd-address=fluentdhost:24224</p><p>docker run --log-driver=fluentd --log-opt fluentd-address=tcp://fluentdhost:24224</p><p>docker run --log-driver=fluentd --log-opt fluentd-address=unix:///path/to/fluentd.sock</p><p>Two of the above specify the same address, because tcp is default.</p><h6><strong>tag</strong></h6><p>By default, Docker uses the first 12 characters of the container ID to tag log messages. Refer to the <a href="https://docs.docker.com/config/containers/logging/log_tags/">log tag option documentation</a> for customizing the log tag format.</p><h6><strong>labels, env, and env-regex</strong></h6><p>The labels and env options each take a comma-separated list of keys. If there is collision between label and env keys, the value of the env takes precedence. Both options add additional fields to the extra attributes of a logging message.</p><p>The env-regex option is similar to and compatible with env. Its value is a regular expression to match logging-related environment variables. It is used for advanced <a href="https://docs.docker.com/config/containers/logging/log_tags/">log tag options</a>.</p><h6><strong>fluentd-async-connect</strong></h6><p>Docker connects to Fluentd in the background. Messages are buffered until the connection is established.</p><h6><strong>fluentd-buffer-limit</strong></h6><p>The amount of data to buffer before flushing to disk. Defaults to the amount of RAM available to the container.</p><h6><strong>fluentd-retry-wait</strong></h6><p>How long to wait between retries. Defaults to 1 second.</p><h6><strong>fluentd-max-retries</strong></h6><p>The maximum number of retries. Defaults to 10.</p><h6><strong>fluentd-sub-second-precision</strong></h6><p>Generates event logs in nanosecond resolution. Defaults to false.</p><h5><strong>Fluentd daemon management with Docker</strong></h5><p>About Fluentd itself, see <a href="http://www.fluentd.org/">the project webpage</a> and <a href="http://docs.fluentd.org/">its documents</a>.</p><p>To use this logging driver, start the fluentd daemon on a host. We recommend that you use <a href="https://hub.docker.com/r/fluent/fluentd/">the Fluentd docker image</a>. This image is especially useful if you want to aggregate multiple container logs on each host then, later, transfer the logs to another Fluentd node to create an aggregate store.</p><h6><strong>Test container loggers</strong></h6><ol><li>Write a configuration file (test.conf) to dump input logs:</li><li><code>&lt;source&gt;</code></li><li>\@type forward</li><li><code>&lt;/source&gt;</code></li><li><code>&lt;match *&gt;</code></li><li>\@type stdout</li><li><code>&lt;/match&gt;</code></li><li>Launch Fluentd container with this configuration file:</li><li>$ docker run -it -p 24224:24224 -v /path/to/conf/test.conf:/fluentd/etc/test.conf -e FLUENTD_CONF=test.conf fluent/fluentd:latest</li><li>Start one or more containers with the fluentd logging driver:</li></ol><p>$ docker run --log-driver=fluentd your/application</p><h4>Google Cloud Logging driver</h4><p><em>Estimated reading time: 3 minutes</em></p><p>The Google Cloud Logging driver sends container logs to <a href="https://cloud.google.com/logging/docs/">Google Cloud Logging</a> Logging.</p><h5><strong>Usage</strong></h5><p>To use the gcplogs driver as the default logging driver, set the log-driver and log-opt keys to appropriate values in the daemon.json file, which is located in /etc/docker/ on Linux hosts or C:\ProgramData\docker\config\daemon.json on Windows Server. For more about configuring Docker using daemon.json, see <a href="https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-configuration-file">daemon.json</a>.</p><p>The following example sets the log driver to gcplogs and sets the gcp-meta-name option.</p><p>{</p><p>&quot;log-driver&quot;: &quot;gcplogs&quot;,</p><p>&quot;log-opts&quot;: {</p><p>&quot;gcp-meta-name&quot;: &quot;example-instance-12345&quot;</p><p>}</p><p>}</p><p>Restart Docker for the changes to take effect.</p><p>You can set the logging driver for a specific container by using the --log-driver option to docker run:</p><p>docker run --log-driver=gcplogs ...</p><p>This log driver does not implement a reader so it is incompatible with docker logs.</p><p>If Docker detects that it is running in a Google Cloud Project, it discovers configuration from the<a href="https://cloud.google.com/compute/docs/metadata">instance metadata service</a>. Otherwise, the user must specify which project to log to using the --gcp-project log option and Docker attempts to obtain credentials from the <a href="https://developers.google.com/identity/protocols/application-default-credentials">Google Application Default Credential</a>. The --gcp-project flag takes precedence over information discovered from the metadata server so a Docker daemon running in a Google Cloud Project can be overridden to log to a different Google Cloud Project using --gcp-project.</p><p>Docker fetches the values for zone, instance name and instance ID from Google Cloud metadata server. Those values can be provided via options if metadata server is not available. They do not override the values from metadata server.</p><h5><strong>gcplogs options</strong></h5><p>You can use the --log-opt NAME=VALUE flag to specify these additional Google Cloud Logging driver options:</p><p>  <strong>Option</strong>      <strong>Required</strong>   <strong>Description</strong></p><hr/><p>  gcp-project     optional       Which GCP project to log to. Defaults to discovering this value from the GCE metadata service.
gcp-log-cmd     optional       Whether to log the command that the container was started with. Defaults to false.
labels          optional       Comma-separated list of keys of labels, which should be included in message, if these labels are specified for the container.
env             optional       Comma-separated list of keys of environment variables, which should be included in message, if these variables are specified for the container.
env-regex       optional       Similar to and compatible with env. A regular expression to match logging-related environment variables. Used for advanced <a href="https://docs.docker.com/config/containers/logging/log_tags/">log tag options</a>.
gcp-meta-zone   optional       Zone name for the instance.
gcp-meta-name   optional       Instance name.
gcp-meta-id     optional       Instance ID.</p><p>If there is collision between label and env keys, the value of the env takes precedence. Both options add additional fields to the attributes of a logging message.</p><p>Below is an example of the logging options required to log to the default logging destination which is discovered by querying the GCE metadata server.</p><p>docker run --log-driver=gcplogs \</p><p>--log-opt labels=location \</p><p>--log-opt env=TEST \</p><p>--log-opt gcp-log-cmd=true \</p><p>--env &quot;TEST=false&quot; \</p><p>--label location=west \</p><p>your/application</p><p>This configuration also directs the driver to include in the payload the label location, the environment variable ENV, and the command used to start the container.</p><p>An example of the logging options for running outside of GCE (the daemon must be configured with GOOGLE_APPLICATION_CREDENTIALS):</p><p>docker run --log-driver=gcplogs \</p><p>--log-opt gcp-project=test-project</p><p>--log-opt gcp-meta-zone=west1 \</p><p>--log-opt gcp-meta-name=<code style="background-color:lightgray">hostname</code> \</p><p>your/application</p><h4>Journald logging driver</h4><p><em>Estimated reading time: 5 minutes</em></p><p>The journald logging driver sends container logs to the <a href="http://www.freedesktop.org/software/systemd/man/systemd-journald.service.html">systemd journal</a>. Log entries can be retrieved using the journalctl command, through use of the journal API, or using the docker logs command.</p><p>In addition to the text of the log message itself, the journald log driver stores the following metadata in the journal with each message:</p><p>  <strong>Field</strong>                          <strong>Description</strong></p><hr/><p>  CONTAINER_ID                       The container ID truncated to 12 characters.
CONTAINER_ID_FULL                  The full 64-character container ID.
CONTAINER_NAME                     The container name at the time it was started. If you use docker rename to rename a container, the new name is not reflected in the journal entries.
CONTAINER_TAG, SYSLOG_IDENTIFIER   The container tag (<a href="https://docs.docker.com/config/containers/logging/log_tags/">log tag option documentation</a>).
CONTAINER_PARTIAL_MESSAGE          A field that flags log integrity. Improve logging of long log lines.</p><h5><strong>Usage</strong></h5><p>To use the journald driver as the default logging driver, set the log-driver and log-opt keys to appropriate values in the daemon.json file, which is located in /etc/docker/ on Linux hosts or C:\ProgramData\docker\config\daemon.json on Windows Server. For more about configuring Docker using daemon.json, see <a href="https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-configuration-file">daemon.json</a>.</p><p>The following example sets the log driver to journald:</p><p>{</p><p>&quot;log-driver&quot;: &quot;journald&quot;</p><p>}</p><p>Restart Docker for the changes to take effect.</p><p>To configure the logging driver for a specific container, use the --log-driver flag on the docker run command.</p><p>$ docker run --log-driver=journald ...</p><h5><strong>Options</strong></h5><p>Use the --log-opt NAME=VALUE flag to specify additional journald logging driver options.</p><p>  <strong>Option</strong>   <strong>Required</strong>   <strong>Description</strong></p><hr/><p>  tag          optional       Specify template to set CONTAINER_TAG and SYSLOG_IDENTIFIERvalue in journald logs. Refer to <a href="https://docs.docker.com/engine/admin/logging/log_tags/">log tag option documentation</a> to customize the log tag format
label        optional       Comma-separated list of keys of labels, which should be included in message, if these labels are specified for the container.
env          optional       Comma-separated list of keys of environment variables, which should be included in message, if these variables are specified for the container.
env-regex    optional       Similar to and compatible with env. A regular expression to match logging-related environment variables. Used for advanced <a href="https://docs.docker.com/engine/admin/logging/log_tags/">log tag options</a>.</p><p>If a collision occurs between label and env keys, the value of the env takes precedence. Each option adds additional fields to the attributes of a logging message.</p><p>Below is an example of the logging options required to log to journald.</p><p>$ docker run --log-driver=journald \</p><p>--log-opt labels=location \</p><p>--log-opt env=TEST \</p><p>--env &quot;TEST=false&quot; \</p><p>--label location=west \</p><p>your/application</p><p>This configuration also directs the driver to include in the payload the label location, and the environment variable TEST. If the --env &quot;TEST=false&quot; or --label location=west arguments were omitted, the corresponding key would not be set in the journald log.</p><h5><strong>Note regarding container names</strong></h5><p>The value logged in the CONTAINER_NAME field is the name of the container that was set at startup. If you use docker rename to rename a container, the new name <strong>is not reflected</strong> in the journal entries. Journal entries continue to use the original name.</p><h5><strong>Retrieve log messages with journalctl</strong></h5><p>Use the journalctl command to retrieve log messages. You can apply filter expressions to limit the retrieved messages to those associated with a specific container:</p><p>$ sudo journalctl CONTAINER_NAME=webserver</p><p>You can use additional filters to further limit the messages retrieved. The -b flag only retrieves messages generated since the last system boot:</p><p>$ sudo journalctl -b CONTAINER_NAME=webserver</p><p>The -o flag specifies the format for the retried log messages. Use -o json to return the log messages in JSON format.</p><p>$ sudo journalctl -o json CONTAINER_NAME=webserver</p><h6><strong>View logs for a container with a TTY enabled</strong></h6><p>If TTY is enabled on a container you may see <!-- -->[10B blob data]<!-- --> in the output when retrieving log messages. The reason for that is that \r is appended to the end of the line and journalctldoesn&#x27;t strip it automatically unless --all is set:</p><p>$ sudo journalctl -b CONTAINER_NAME=webserver --all</p><h5><strong>Retrieve log messages with the journal API</strong></h5><p>This example uses the systemd Python module to retrieve container logs:</p><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-python" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token keyword" style="color:rgb(86, 156, 214)">import</span><span class="token plain"> systemd</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">journal</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">reader </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> systemd</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">journal</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">Reader</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">reader</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">add_match</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">\&#x27;CONTAINER_NAME</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain">web\&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token keyword" style="color:rgb(86, 156, 214)">for</span><span class="token plain"> msg </span><span class="token keyword" style="color:rgb(86, 156, 214)">in</span><span class="token plain"> reader</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token keyword" style="color:rgb(86, 156, 214)">print</span><span class="token plain"> \&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">{</span><span class="token plain">CONTAINER_ID_FULL</span><span class="token punctuation" style="color:rgb(212, 212, 212)">}</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(212, 212, 212)">{</span><span class="token plain">MESSAGE</span><span class="token punctuation" style="color:rgb(212, 212, 212)">}</span><span class="token plain">\&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token builtin" style="color:rgb(86, 156, 214)">format</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token operator" style="color:rgb(212, 212, 212)">**</span><span class="token plain">msg</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span></div></pre></div><h4>Splunk logging driver</h4><p><em>Estimated reading time: 6 minutes</em></p><p>The splunk logging driver sends container logs to <a href="http://dev.splunk.com/view/event-collector/SP-CAAAE6M">HTTP Event Collector</a> in Splunk Enterprise and Splunk Cloud.</p><h5><strong>Usage</strong></h5><p>You can configure Docker logging to use the splunk driver by default or on a per-container basis.</p><p>To use the splunk driver as the default logging driver, set the keys log-driver and log-optsto appropriate values in the daemon.json configuration file and restart Docker. For example:</p><p>{</p><p>&quot;log-driver&quot;: &quot;splunk&quot;,</p><p>&quot;log-opts&quot;: {</p><p>&quot;splunk-token&quot;: &quot;&quot;,</p><p>&quot;splunk-url&quot;: &quot;&quot;,</p><p>...</p><p>}</p><p>}</p><p>The daemon.json file is located in /etc/docker/ on Linux hosts orC:\ProgramData\docker\config\daemon.json on Windows Server. For more about configuring Docker using daemon.json, see <a href="https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-configuration-file">daemon.json</a>.</p><p>To use the splunk driver for a specific container, use the commandline flags --log-driver and log-opt with docker run:</p><p>docker run --log-driver=splunk --log-opt splunk-token=VALUE --log-opt splunk-url=VALUE ...</p><h5><strong>Splunk options</strong></h5><p>The following properties let you configure the splunk logging driver.</p><ul><li><p>To configure the splunk driver across the Docker environment, edit daemon.json with the key, &quot;log-opts&quot;: {&quot;NAME&quot;: &quot;VALUE&quot;, ...}.</p></li><li><p>To configure the splunk driver for an indiviual container, use docker run with the flag, --log-opt NAME=VALUE ....</p><p><strong>Option</strong>                  <strong>Required</strong>   <strong>Description</strong></p><hr/><p>splunk-token                required       Splunk HTTP Event Collector token.
splunk-url                  required       Path to your Splunk Enterprise, self-service Splunk Cloud instance, or Splunk Cloud managed cluster (including port and scheme used by HTTP Event Collector) in one of the following formats: https://your_splunk_instance:8088 or <a href="https://input-prd-p-XXXXXXX.cloud.splunk.com:8088or">https://input-prd-p-XXXXXXX.cloud.splunk.com:8088or</a> <a href="https://http-inputs-XXXXXXXX.splunkcloud.com.">https://http-inputs-XXXXXXXX.splunkcloud.com.</a>
splunk-source               optional       Event source.
splunk-sourcetype           optional       Event source type.
splunk-index                optional       Event index.
splunk-capath               optional       Path to root certificate.
splunk-caname               optional       Name to use for validating server certificate; by default the hostname of the splunk-url is used.
splunk-insecureskipverify   optional       Ignore server certificate validation.
splunk-format               optional       Message format. Can be inline, json or raw. Defaults to inline.
splunk-verify-connection    optional       Verify on start, that docker can connect to Splunk server. Defaults to true.
splunk-gzip                 optional       Enable/disable gzip compression to send events to Splunk Enterprise or Splunk Cloud instance. Defaults to false.
splunk-gzip-level           optional       Set compression level for gzip. Valid values are -1 (default), 0 (no compression), 1 (best speed) ... 9 (best compression). Defaults to <a href="https://golang.org/pkg/compress/gzip/#DefaultCompression">DefaultCompression</a>.
tag                         optional       Specify tag for message, which interpret some markup. Default value is {{.ID}} (12 characters of the container ID). Refer to the <a href="https://docs.docker.com/config/containers/logging/log_tags/">log tag option documentation</a> for customizing the log tag format.
labels                      optional       Comma-separated list of keys of labels, which should be included in message, if these labels are specified for container.
env                         optional       Comma-separated list of keys of environment variables, which should be included in message, if these variables are specified for container.
env-regex                   optional       Similar to and compatible with env. A regular expression to match logging-related environment variables. Used for advanced <a href="https://docs.docker.com/config/containers/logging/log_tags/">log tag options</a>.</p></li></ul><p>If there is collision between the label and env keys, the value of the env takes precedence. Both options add additional fields to the attributes of a logging message.</p><p>Below is an example of the logging options specified for the Splunk Enterprise instance. The instance is installed locally on the same machine on which the Docker daemon is running.</p><p>The path to the root certificate and Common Name is specified using an HTTPS scheme. This is used for verification. The SplunkServerDefaultCert is automatically generated by Splunk certificates.</p><p>$ docker run --log-driver=splunk \</p><p>--log-opt splunk-token=176FCEBF-4CF5-4EDF-91BC-703796522D20 \</p><p>--log-opt splunk-url=https://splunkhost:8088 \</p><p>--log-opt splunk-capath=/path/to/cert/cacert.pem \</p><p>--log-opt splunk-caname=SplunkServerDefaultCert \</p><p>--log-opt tag=&quot;{{.Name}}/{{.FullID}}&quot; \</p><p>--log-opt labels=location \</p><p>--log-opt env=TEST \</p><p>--env &quot;TEST=false&quot; \</p><p>--label location=west \</p><p>your/application</p><p>The splunk-url for Splunk instances hosted on Splunk Cloud is in a format like <a href="https://http-inputs-XXXXXXXX.splunkcloud.com">https://http-inputs-XXXXXXXX.splunkcloud.com</a> and does not include a port specifier.</p><h6><strong>Message formats</strong></h6><p>There are three logging driver messaging formats: inline (default), json, and raw.</p><p>The default format is inline where each log message is embedded as a string. For example:</p><p>{</p><p>&quot;attrs&quot;: {</p><p>&quot;env1&quot;: &quot;val1&quot;,</p><p>&quot;label1&quot;: &quot;label1&quot;</p><p>},</p><p>&quot;tag&quot;: &quot;MyImage/MyContainer&quot;,</p><p>&quot;source&quot;: &quot;stdout&quot;,</p><p>&quot;line&quot;: &quot;my message&quot;</p><p>}</p><p>{</p><p>&quot;attrs&quot;: {</p><p>&quot;env1&quot;: &quot;val1&quot;,</p><p>&quot;label1&quot;: &quot;label1&quot;</p><p>},</p><p>&quot;tag&quot;: &quot;MyImage/MyContainer&quot;,</p><p>&quot;source&quot;: &quot;stdout&quot;,</p><p>&quot;line&quot;: &quot;{\&quot;foo\&quot;: \&quot;bar\&quot;}&quot;</p><p>}</p><p><strong>Note</strong>: If your messages are JSON objects, you may want to embed them in the message we send to Splunk.</p><p>To format messages as json objects, set --log-opt splunk-format=json. The driver trys to parse every line as a JSON object and send it as an embedded object. If it cannot parse the message, it is sent inline. For example:</p><p>{</p><p>&quot;attrs&quot;: {</p><p>&quot;env1&quot;: &quot;val1&quot;,</p><p>&quot;label1&quot;: &quot;label1&quot;</p><p>},</p><p>&quot;tag&quot;: &quot;MyImage/MyContainer&quot;,</p><p>&quot;source&quot;: &quot;stdout&quot;,</p><p>&quot;line&quot;: &quot;my message&quot;</p><p>}</p><p>{</p><p>&quot;attrs&quot;: {</p><p>&quot;env1&quot;: &quot;val1&quot;,</p><p>&quot;label1&quot;: &quot;label1&quot;</p><p>},</p><p>&quot;tag&quot;: &quot;MyImage/MyContainer&quot;,</p><p>&quot;source&quot;: &quot;stdout&quot;,</p><p>&quot;line&quot;: {</p><p>&quot;foo&quot;: &quot;bar&quot;</p><p>}</p><p>}</p><p>To format messages as raw, set --log-opt splunk-format=raw. Attributes (environment variables and labels) and tags are prefixed to the message. For example:</p><p>MyImage/MyContainer env1=val1 label1=label1 my message</p><p>MyImage/MyContainer env1=val1 label1=label1 {&quot;foo&quot;: &quot;bar&quot;}</p><h5><strong>Advanced options</strong></h5><p>Splunk Logging Driver allows you to configure few advanced options by specifying next environment variables for the Docker daemon.</p><p>  <strong>Environment variable name</strong>                    <strong>Default value</strong>   <strong>Description</strong></p><hr/><p>  SPLUNK_LOGGING_DRIVER_POST_MESSAGES_FREQUENCY    5s                  If there is nothing to batch how often driver posts messages. You can think about this as the maximum time to wait for more messages to batch.
SPLUNK_LOGGING_DRIVER_POST_MESSAGES_BATCH_SIZE   1000                How many messages driver should wait before sending them in one batch.
SPLUNK_LOGGING_DRIVER_BUFFER_MAX                 10 <em> 1000          If driver cannot connect to remote server, what is the maximum amount of messages it can hold in buffer for retries.
SPLUNK_LOGGING_DRIVER_CHANNEL_SIZE               4 </em> 1000           How many pending messages can be in the channel which is used to send messages to background logger worker, which batches them.</p><h3>Registry as a pull through cache</h3><p><em>Estimated reading time: 4 minutes</em></p><h4>Use-case</h4><p>If you have multiple instances of Docker running in your environment, such as multiple physical or virtual machines all running Docker, each daemon goes out to the internet and fetches an image it doesn&#x27;t have locally, from the Docker repository. You can run a local registry mirror and point all your daemons there, to avoid this extra internet traffic.</p><h5><strong>Alternatives</strong></h5><p>Alternatively, if the set of images you are using is well delimited, you can simply pull them manually and push them to a simple, local, private registry.</p><p>Furthermore, if your images are all built in-house, not using the Hub at all and relying entirely on your local registry is the simplest scenario.</p><h5><strong>Gotcha</strong></h5><p>It&#x27;s currently not possible to mirror another private registry. Only the central Hub can be mirrored.</p><h5><strong>Solution</strong></h5><p>The Registry can be configured as a pull through cache. In this mode a Registry responds to all normal docker pull requests but stores all content locally.</p><h4>How does it work?</h4><p>The first time you request an image from your local registry mirror, it pulls the image from the public Docker registry and stores it locally before handing it back to you. On subsequent requests, the local registry mirror is able to serve the image from its own storage.</p><h5><strong>What if the content changes on the Hub?</strong></h5><p>When a pull is attempted with a tag, the Registry checks the remote to ensure if it has the latest version of the requested content. Otherwise, it fetches and caches the latest content.</p><h5><strong>What about my disk?</strong></h5><p>In environments with high churn rates, stale data can build up in the cache. When running as a pull through cache the Registry periodically removes old content to save disk space. Subsequent requests for removed content causes a remote fetch and local re-caching.</p><p>To ensure best performance and guarantee correctness the Registry cache should be configured to use the filesystem driver for storage.</p><h4>Run a Registry as a pull-through cache</h4><p>The easiest way to run a registry as a pull through cache is to run the official Registry image. At least, you need to specify proxy.remoteurl within /etc/docker/registry/config.yml as described in the following subsection.</p><p>Multiple registry caches can be deployed over the same back-end. A single registry cache ensures that concurrent requests do not pull duplicate data, but this property does not hold true for a registry cache cluster.</p><h5><strong>Configure the cache</strong></h5><p>To configure a Registry to run as a pull through cache, the addition of a proxy section is required to the config file.</p><p>To access private images on the Docker Hub, a username and password can be supplied.</p><p>proxy:</p><p>remoteurl: <a href="https://registry-1.docker.io">https://registry-1.docker.io</a></p><p>username: <!-- -->[username]</p><p>password: <!-- -->[password]</p><p><strong>Warning</strong>: If you specify a username and password, it&#x27;s very important to understand that private resources that this user has access to Docker Hub is made available on your mirror. <strong>You must secure your mirror</strong> by implementing authentication if you expect these resources to stay private!</p><p><strong>Warning</strong>: For the scheduler to clean up old entries, delete must be enabled in the registry configuration. See <a href="https://docs.docker.com/registry/configuration/">Registry Configuration</a> for more details.</p><h5><strong>Configure the Docker daemon</strong></h5><p>Either pass the --registry-mirror option when starting dockerd manually, or edit <a href="https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-configuration-file">/etc/docker/daemon.json</a> and add the registry-mirrors key and value, to make the change persistent.</p><p>{</p><p>&quot;registry-mirrors&quot;: <!-- -->[&quot;https://<code style="background-color:lightgray">&lt;my-docker-mirror-host&gt;</code>&quot;]</p><p>}</p><p>Save the file and reload Docker for the change to take effect.</p><p><strong>Some log messages that appear to be errors are actually informational messages.</strong></p><p>Check the level field to determine whether the message is warning you about an error or is giving you information. For example, this log message is informational:</p><p>time=&quot;2017-06-02T15:47:37Z&quot; level=info msg=&quot;error statting local store, serving from upstream: unknown blob&quot; go.version=go1.7.4</p><p>It&#x27;s telling you that the file doesn&#x27;t exist yet in the local cache and is being pulled from upstream.</p><h4>Use case: the China registry mirror</h4><p>The URL of the registry mirror for China is registry.docker-cn.com. You can pull images from this mirror just like you do for other registries by specifying the full path, including the registry, in your docker pull command, for example:</p><p>$ docker pull registry.docker-cn.com/library/ubuntu</p><p>You can add &quot;<a href="https://registry.docker-cn.com%22">https://registry.docker-cn.com&quot;</a> to the registry-mirrors array in <a href="https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-configuration-file">/etc/docker/daemon.json</a> to pull from the China registry mirror by default.</p><p>{</p><p>&quot;registry-mirrors&quot;: <!-- -->[&quot;https://registry.docker-cn.com&quot;]</p><p>}</p><p>Save the file and reload Docker for the change to take effect.</p><p>Or, you can configure the Docker daemon with the --registry-mirror startup parameter:</p><p>$ dockerd --registry-mirror=<a href="https://registry.docker-cn.com">https://registry.docker-cn.com</a></p><h3>Work with external tools</h3><h4>Use PowerShell DSC</h4><p><em>Estimated reading time: 4 minutes</em></p><p>Windows PowerShell Desired State Configuration (DSC) is a configuration management tool that extends the existing functionality of Windows PowerShell. DSC uses a declarative syntax to define the state in which a target should be configured. More information about PowerShell DSC can be found at <code style="background-color:lightgray">&lt;http://technet.microsoft.com/en-us/library/dn249912.aspx&gt;</code>.</p><h5><strong>Requirements</strong></h5><p>To use this guide you need a Windows host with PowerShell v4.0 or newer.</p><p>The included DSC configuration script also uses the official PPA so only an Ubuntu target is supported. The Ubuntu target must already have the required OMI Server and PowerShell DSC for Linux providers installed. More information can be found at <code style="background-color:lightgray">&lt;https://github.com/MSFTOSSMgmt/WPSDSCLinux&gt;</code>. The source repository listed below also includes PowerShell DSC for Linux installation and init scripts along with more detailed installation information.</p><h5><strong>Installation</strong></h5><p>The DSC configuration example source is available in the following repository:<code style="background-color:lightgray">&lt;https://github.com/anweiss/DockerClientDSC&gt;</code>. It can be cloned with:</p><p>$ git clone <a href="https://github.com/anweiss/DockerClientDSC.git">https://github.com/anweiss/DockerClientDSC.git</a></p><h5><strong>Usage</strong></h5><p>The DSC configuration utilizes a set of shell scripts to determine whether or not the specified Docker components are configured on the target node(s). The source repository also includes a script (RunDockerClientConfig.ps1) that can be used to establish the required CIM session(s) and execute the Set-DscConfiguration cmdlet.</p><p>More detailed usage information can be found at <code style="background-color:lightgray">&lt;https://github.com/anweiss/DockerClientDSC&gt;</code>.</p><h6><strong>Install Docker</strong></h6><p>The Docker installation configuration is equivalent to running:</p><p>apt-key adv --keyserver hkp://p80.pool.sks-keyservers.net:80 --recv-keys\</p><p>36A1D7869245C8950F966E92D8576A8BA88D21E9</p><p>sh -c &quot;echo deb <a href="https://apt.dockerproject.org/repo">https://apt.dockerproject.org/repo</a> ubuntu-trusty main\</p><blockquote><p>/etc/apt/sources.list.d/docker.list&quot;</p></blockquote><p>apt-get update</p><p>apt-get install docker-engine</p><p>Ensure that your current working directory is set to the DockerClientDSC source and load the DockerClient configuration into the current PowerShell session</p><p>. .\DockerClient.ps1</p><p>Generate the required DSC configuration .mof file for the targeted node</p><p>DockerClient -Hostname &quot;myhost&quot;</p><p>A sample DSC configuration data file has also been included and can be modified and used in conjunction with or in place of the Hostname parameter:</p><p>DockerClient -ConfigurationData .\DockerConfigData.psd1</p><p>Start the configuration application process on the targeted node</p><p>.\RunDockerClientConfig.ps1 -Hostname &quot;myhost&quot;</p><p>The RunDockerClientConfig.ps1 script can also parse a DSC configuration data file and execute configurations against multiple nodes as such:</p><p>.\RunDockerClientConfig.ps1 -ConfigurationData .\DockerConfigData.psd1</p><h6><strong>Images</strong></h6><p>Image configuration is equivalent to running: docker pull <!-- -->[image]<!-- --> ordocker image rm -f <!-- -->[IMAGE]<!-- -->.</p><p>Using the same steps defined above, execute DockerClient with the Image parameter and apply the configuration:</p><p>DockerClient -Hostname &quot;myhost&quot; -Image &quot;node&quot;</p><p>.\RunDockerClientConfig.ps1 -Hostname &quot;myhost&quot;</p><p>You can also configure the host to pull multiple images:</p><p>DockerClient -Hostname &quot;myhost&quot; -Image &quot;node&quot;,&quot;mongo&quot;</p><p>.\RunDockerClientConfig.ps1 -Hostname &quot;myhost&quot;</p><p>To remove images, use a hashtable as follows:</p><p>DockerClient -Hostname &quot;myhost&quot; -Image @{Name=&quot;node&quot;; Remove=$true}</p><p>.\RunDockerClientConfig.ps1 -Hostname $hostname</p><h6><strong>Containers</strong></h6><p>Container configuration is equivalent to running:</p><p>docker run -d --name=&quot;<!-- -->[containername]<!-- -->&quot; -p \&#x27;<!-- -->[port]<!-- -->\&#x27; -e \&#x27;<!-- -->[env]<!-- -->\&#x27; --link \&#x27;<!-- -->[link]<!-- -->\&#x27;\</p><p>\&#x27;<!-- -->[image]<!-- -->\&#x27; \&#x27;<!-- -->[command]<!-- -->\&#x27;</p><p>or</p><p>docker container rm -f <!-- -->[containername]</p><p>To create or remove containers, you can use the Container parameter with one or more hashtables. The hashtable(s) passed to this parameter can have the following properties:</p><ul><li>Name (required)</li><li>Image (required unless Remove property is set to $true)</li><li>Port</li><li>Env</li><li>Link</li><li>Command</li><li>Remove</li></ul><p>For example, create a hashtable with the settings for your container:</p><p>$webContainer = @{Name=&quot;web&quot;; Image=&quot;anweiss/docker-platynem&quot;; Port=&quot;80:80&quot;}</p><p>Then, using the same steps defined above, execute DockerClient with the -Image and -Container parameters:</p><p>DockerClient -Hostname &quot;myhost&quot; -Image node -Container $webContainer</p><p>.\RunDockerClientConfig.ps1 -Hostname &quot;myhost&quot;</p><p>Existing containers can also be removed as follows:</p><p>$containerToRemove = @{Name=&quot;web&quot;; Remove=$true}</p><p>DockerClient -Hostname &quot;myhost&quot; -Container $containerToRemove</p><p>.\RunDockerClientConfig.ps1 -Hostname &quot;myhost&quot;</p><p>Here is a hashtable with all of the properties that can be used to create a container:</p><p>$containerProps = @{Name=&quot;web&quot;; Image=&quot;node:latest&quot;; Port=&quot;80:80&quot;; `</p><p>Env=&quot;PORT=80&quot;; Link=&quot;db:db&quot;; Command=&quot;grunt&quot;}</p><h4>Chef</h4><h5><strong>Docker Cookbook</strong></h5><p>The Docker Cookbook provides resources for installing docker as well as managing and running docker containers.</p><h6><strong>Scope</strong></h6><p>This cookbook is concerned with the <a href="http://docker.io/">Docker</a> container engine as distributed by Docker, Inc. It does not address Docker ecosystem tooling or prerequisite technology such as cgroups or aufs.</p><h6><strong>Requirements</strong></h6><ul><li>Chef 12.15 or later</li><li>Network accessible web server hosting the docker binary.</li><li>SELinux permissive/disabled if CentOS <a href="https://github.com/docker/docker/issues/15498">Docker Issue #15498</a></li></ul><h6><strong>Platform Support</strong></h6><ul><li>Amazon Linux</li><li>Debian 8/9</li><li>Fedora</li><li>Ubuntu 14.04/16.04</li><li>CentOS 7</li></ul><h6><strong>Cookbook Dependencies</strong></h6><p>This cookbook automatically sets up the upstream Docker package repositories. If you would like to use your own repositories this functionality can be disabled and you can instead setup the repos yourself with yum_repository/apt_repository resources or the <a href="https://supermarket.chef.io/cookbooks/chef-apt-docker">chef-apt-docker</a> / <a href="https://supermarket.chef.io/cookbooks/chef-yum-docker">chef-yum-docker</a> cookbooks.</p><h6><strong>Docker Group</strong></h6><p>If you are not using the official docker repositories you may run into issues with the docker group being different. RHEL is a known issue that defaults to using dockerroot for the service group. Add the groupproperty to the docker_service.</p><p>docker_service \&#x27;default\&#x27; do</p><p>group \&#x27;dockerroot\&#x27;</p><p>action <!-- -->[:create, :start]</p><p>end</p><h6><strong>Usage</strong></h6><ul><li>Add depends \&#x27;docker\&#x27; to your cookbook\&#x27;s metadata.rb</li><li>Use the resources shipped in cookbook in a recipe, the same way you\&#x27;d use core Chef resources (file, template, directory, package, etc).</li></ul><p>docker_service \&#x27;default\&#x27; do</p><p>action <!-- -->[:create, :start]</p><p>end</p><p>docker_image \&#x27;busybox\&#x27; do</p><p>action :pull</p><p>end</p><p>docker_container \&#x27;an-echo-server\&#x27; do</p><p>repo \&#x27;busybox\&#x27;</p><p>port \&#x27;1234:1234\&#x27;</p><p>command &quot;nc -ll -p 1234 -e /bin/cat&quot;</p><p>end</p><h6><strong>Test Cookbooks as Examples</strong></h6><p>The cookbooks ran under test-kitchen make excellent usage examples.</p><p>The test recipes are found at:</p><p>test/cookbooks/docker_test/</p><h6><strong>Resources Overview</strong></h6><ul><li><a href="https://supermarket.chef.io/cookbooks/docker#docker_service">docker_service</a>: composite resource that uses docker_installation and docker_service_manager</li><li><a href="https://supermarket.chef.io/cookbooks/docker#docker_installation">docker_installation</a>: automatically select an installation method</li><li><a href="https://supermarket.chef.io/cookbooks/docker#docker_service_manager">docker_service_manager</a>: automatically selects a service manager</li><li><a href="https://supermarket.chef.io/cookbooks/docker#docker_installation_script">docker_installation_script</a>: curl | bash</li><li><a href="https://supermarket.chef.io/cookbooks/docker#docker_installation_package">docker_installation_package</a>: package \&#x27;docker-ce\&#x27;</li><li><a href="https://supermarket.chef.io/cookbooks/docker#docker_service_manager_execute">docker_service_manager_execute</a>: manage docker daemon with Chef</li><li><a href="https://supermarket.chef.io/cookbooks/docker#docker_service_manager_sysvinit">docker_service_manager_sysvinit</a>: manage docker daemon with a sysvinit script</li><li><a href="https://supermarket.chef.io/cookbooks/docker#docker_service_manager_upstart">docker_service_manager_upstart</a>: manage docker daemon with upstart script</li><li><a href="https://supermarket.chef.io/cookbooks/docker#docker_service_manager_systemd">docker_service_manager_systemd</a>: manage docker daemon with systemd unit files</li><li><a href="https://supermarket.chef.io/cookbooks/docker#docker_image">docker_image</a>: image/repository operations</li><li><a href="https://supermarket.chef.io/cookbooks/docker#docker_container">docker_container</a>: container operations</li><li><a href="https://supermarket.chef.io/cookbooks/docker#docker_tag">docker_tag</a>: image tagging operations</li><li><a href="https://supermarket.chef.io/cookbooks/docker#docker_registry">docker_registry</a>: registry operations</li><li><a href="https://supermarket.chef.io/cookbooks/docker#docker_network">docker_network</a>: network operations</li><li><a href="https://supermarket.chef.io/cookbooks/docker#docker_volume">docker_volume</a>: volume operations</li></ul><h6><strong>Getting Started</strong></h6><p>Here\&#x27;s a quick example of pulling the latest image and running a container with exposed ports.</p><h1>Pull latest image</h1><p>docker_image \&#x27;nginx\&#x27; do</p><p>tag \&#x27;latest\&#x27;</p><p>action :pull</p><p>notifies :redeploy, \&#x27;docker_container<!-- -->[my_nginx]<!-- -->\&#x27;</p><p>end</p><h1>Run container mapping containers port 80 to the host\&#x27;s port 80</h1><p>docker_container \&#x27;my_nginx\&#x27; do</p><p>repo \&#x27;nginx\&#x27;</p><p>tag \&#x27;latest\&#x27;</p><p>port \&#x27;80:80\&#x27;</p><p>host_name \&#x27;www\&#x27;</p><p>domain_name \&#x27;computers.biz\&#x27;</p><p>env \&#x27;FOO=bar\&#x27;</p><p>volumes <!-- -->[ \&#x27;/some/local/files/:/etc/nginx/conf.d\&#x27; ]</p><p>end</p><p>You might run a private registry and multiple Docker hosts.</p><h1>Login to private registry</h1><p>docker_registry \&#x27;<a href="https://registry.computers.biz/%5C&#x27;">https://registry.computers.biz/\&#x27;</a> do</p><p>username \&#x27;shipper\&#x27;</p><p>password \&#x27;iloveshipping\&#x27;</p><p>email \&#x27;shipper\@computers.biz\&#x27;</p><p>end</p><h1>Pull tagged image</h1><p>docker_image \&#x27;registry.computers.biz:443/my_project/my_container\&#x27; do</p><p>tag \&#x27;latest\&#x27;</p><p>action :pull</p><p>host \&#x27;tcp://host-1.computers.biz:2376\&#x27;</p><p>end</p><h1>Run container</h1><p>docker_container \&#x27;crowsnest\&#x27; do</p><p>repo \&#x27;registry.computers.biz:443/my_project/my_container\&#x27;</p><p>tag \&#x27;latest\&#x27;</p><p>host \&#x27;tcp://host-2.computers.biz:2376\&#x27;</p><p>tls_verify true</p><p>tls_ca_cert &quot;/path/to/ca.pem&quot;</p><p>tls_client_cert &quot;/path/to/cert.pem&quot;</p><p>tls_client_key &quot;/path/to/key.pem&quot;</p><p>action :run</p><p>end</p><p>You can manipulate Docker volumes and networks</p><p>docker_network \&#x27;my_network\&#x27; do</p><p>subnet \&#x27;10.9.8.0/24\&#x27;</p><p>gateway \&#x27;10.9.8.1\&#x27;</p><p>end</p><p>docker_volume \&#x27;my_volume\&#x27; do</p><p>action :create</p><p>end</p><p>docker_container \&#x27;my_container\&#x27; do</p><p>repo \&#x27;alpine\&#x27;</p><p>tag \&#x27;3.1\&#x27;</p><p>command &quot;nc -ll -p 1234 -e /bin/cat&quot;</p><p>volumes \&#x27;my_volume:/my_data\&#x27;</p><p>network_mode \&#x27;my_network\&#x27;</p><p>action :run</p><p>end</p><p>See full documentation for each resource and action below for more information.</p><h6><strong>Resources</strong></h6><h6><strong>docker_installation</strong></h6><p>The docker_installation resource auto-selects one of the below resources with the provider resolution system.</p><p><strong>Example</strong></p><p>docker_installation \&#x27;default\&#x27;</p><h6><strong>docker_installation_tarball</strong></h6><p>The docker_installation_tarball resource copies the precompiled Go binary tarball onto the disk. It should not be used in production, especially with devicemapper.</p><p><strong>Example</strong></p><p>docker_installation_tarball \&#x27;default\&#x27; do</p><p>version \&#x27;1.11.0\&#x27;</p><p>source \&#x27;<a href="https://my.computers.biz/dist/docker.tgz%5C&#x27;">https://my.computers.biz/dist/docker.tgz\&#x27;</a></p><p>checksum \&#x27;97a3f5924b0b831a310efa8bf0a4c91956cd6387c4a8667d27e2b2dd3da67e4d\&#x27;</p><p>action :create</p><p>end</p><p><strong>Properties</strong></p><ul><li>version - The desired version of docker to fetch.</li><li>channel - The docker channel to fetch the tarball from. Default: stable</li><li>source - Path to network accessible Docker binary tarball. Ignores version when set.</li><li>checksum - SHA-256 checksum of the tarball file.</li></ul><h6><strong>docker_installation_script</strong></h6><p>The docker_installation_script resource runs the script hosted by Docker, Inc at <a href="http://get.docker.com/">http://get.docker.com</a>. It configures package repositories and installs a dynamically compiled binary.</p><p><strong>Example</strong></p><p>docker_installation_script \&#x27;default\&#x27; do</p><p>repo \&#x27;main\&#x27;</p><p>script_url \&#x27;<a href="https://my.computers.biz/dist/scripts/docker.sh%5C&#x27;">https://my.computers.biz/dist/scripts/docker.sh\&#x27;</a></p><p>action :create</p><p>end</p><p><strong>Properties</strong></p><ul><li>repo - One of \&#x27;main\&#x27;, \&#x27;test\&#x27;, or \&#x27;experimental\&#x27;. Used to calculate script_url in its absence. Defaults to \&#x27;main\&#x27;</li><li>script_url - \&#x27;URL of script to pipe into /bin/sh as root.</li></ul><h6><strong>docker_installation_package</strong></h6><p>The docker_installation_package resource uses the system package manager to install Docker. It relies on the pre-configuration of the system\&#x27;s package repositories. The chef-yum-docker and chef-apt-docker Supermarket cookbooks can be used to use Docker\&#x27;s own repositories.</p><p><strong>This is the recommended production installation method.</strong></p><p><strong>Example</strong></p><p>docker_installation_package \&#x27;default\&#x27; do</p><p>version \&#x27;1.8.3\&#x27;</p><p>action :create</p><p>package_options %q|--force-yes -o Dpkg::Options::=\&#x27;--force-confold\&#x27; -o Dpkg::Options::=\&#x27;--force-all\&#x27;| # if Ubuntu for example</p><p>end</p><p><strong>Properties</strong></p><ul><li>version - Used to calculate package_version string</li><li>package_version - Manually specify the package version string</li><li>package_name - Name of package to install. Defaults to \&#x27;docker-ce\&#x27;</li><li>package_options - Manually specify additional options, like apt-get directives for example</li><li>setup_docker_repo - Setup the download.docker.com repo. If you would like to manage the repo yourself so you can use an internal repo then set this to false. default: true on all platforms except Amazon Linux.</li><li>repo_channel - The channel of docker to setup from download.docker.com. Only used if setup_docker_repo is true. default: \&#x27;stable\&#x27;</li></ul><h6><strong>docker_service_manager</strong></h6><p>The docker<em>service_manager resource auto-selects a strategy from the docker_service_manager</em>*group of resources based on platform and version. The docker_service family share a common set of properties.</p><p><strong>Example</strong></p><p>docker_service_manager \&#x27;default\&#x27; do</p><p>action :start</p><p>end</p><h6><strong>docker_service_manager_execute</strong></h6><p><strong>Example</strong></p><p>docker_service_manager_execute \&#x27;default\&#x27; do</p><p>action :start</p><p>end</p><h6><strong>docker_service_manager_sysvinit</strong></h6><p><strong>Example</strong></p><p>docker_service_manager_sysvinit \&#x27;default\&#x27; do</p><p>host \&#x27;unix:///var/run/docker.sock\&#x27;</p><p>action :stop</p><p>end</p><h6><strong>docker_service_manager_upstart</strong></h6><p><strong>Example</strong></p><p>docker_service_manager_upstart \&#x27;default\&#x27; do</p><p>host <!-- -->[\&#x27;unix:///var/run/docker.sock\&#x27;, \&#x27;tcp://127.0.0.1:2376\&#x27;]</p><p>action :start</p><p>end</p><h6><strong>docker_service_manager_systemd</strong></h6><p><strong>Example</strong></p><p>docker_service_manager_systemd \&#x27;default\&#x27; do</p><p>host <!-- -->[\&#x27;unix:///var/run/docker.sock\&#x27;, \&#x27;tcp://127.0.0.1:2376\&#x27;]</p><p>tls_verify true</p><p>tls_ca_cert &quot;/path/to/ca.pem&quot;</p><p>tls_server_cert &quot;/path/to/server.pem&quot;</p><p>tls_server_key &quot;/path/to/server-key.pem&quot;</p><p>tls_client_cert &quot;/path/to/cert.pem&quot;</p><p>tls_client_key &quot;/path/to/key.pem&quot;</p><p>systemd_opts <!-- -->[&quot;TasksMax=infinity&quot;,&quot;MountFlags=private&quot;]</p><p>action :start</p><p>end</p><h6><strong>docker_service</strong></h6><p>The docker_service: resource is a composite resource that uses docker_installation and docker_service_manager resources.</p><ul><li>The :create action uses a docker_installation</li><li>The :delete action uses a docker_installation</li><li>The :start action uses a docker_service_manager</li><li>The :stop action uses a docker_service_manager</li></ul><p>The service management strategy for the host platform is dynamically chosen based on platform, but can be overridden.</p><p><strong>Example</strong></p><p>docker_service \&#x27;tls_test:2376\&#x27; do</p><p>host [ &quot;tcp://#{node<!-- -->[\&#x27;ipaddress\&#x27;]<!-- -->}:2376&quot;, \&#x27;unix:///var/run/docker.sock\&#x27; ]</p><p>tls_verify true</p><p>tls_ca_cert \&#x27;/path/to/ca.pem\&#x27;</p><p>tls_server_cert \&#x27;/path/to/server.pem\&#x27;</p><p>tls_server_key \&#x27;/path/to/server-key.pem\&#x27;</p><p>tls_client_cert \&#x27;/path/to/client.pem\&#x27;</p><p>tls_client_key \&#x27;/path/to/client-key.pem\&#x27;</p><p>action <!-- -->[:create, :start]</p><p>end</p><p>WARNING - When creating multiple docker_service resources on the same machine, you will need to specify unique data_root properties to avoid unexpected behavior and possible data corruption.</p><p><strong>Properties</strong></p><p>The docker_service resource property list mostly corresponds to the options found in the <a href="https://docs.docker.com/engine/reference/commandline/docker/">Docker Command Line Reference</a></p><ul><li>api_cors_header - Set CORS headers in the remote API</li><li>auto_restart</li><li>exec_opts</li><li>bip - Specify network bridge IP</li><li>bridge - Attach containers to a network bridge</li><li>checksum - sha256 checksum of Docker binary</li><li>cluster_advertise - IP and port that this daemon should advertise to the cluster</li><li>cluster_store_opts - Cluster store options</li><li>cluster_store - Cluster store to use</li><li>daemon - Enable daemon mode</li><li>data_root - Root of the Docker runtime</li><li>debug - Enable debug mode</li><li>default_ulimit - Set default ulimit settings for containers</li><li>disable_legacy_registry - Do not contact legacy registries</li><li>dns_search - DNS search domains to use</li><li>dns - DNS server(s) to use</li><li>exec_driver - Exec driver to use</li><li>fixed_cidr_v6 - IPv6 subnet for fixed IPs</li><li>fixed_cidr - IPv4 subnet for fixed IPs</li><li>group - Posix group for the unix socket. Default to docker</li><li>host - Daemon socket(s) to connect to - tcp://host:port, unix:///path/to/socket, fd://* or fd://socketfd</li><li>http_proxy - ENV variable set before for Docker daemon starts</li><li>https_proxy - ENV variable set before for Docker daemon starts</li><li>icc - Enable inter-container communication</li><li>insecure_registry - Enable insecure registry communication</li><li>install_method - Select script, package, tarball, none, or auto. Defaults to auto.</li><li>instance- Optional property used to override the name provided in the resource.</li><li>ip_forward - Enable ip forwarding</li><li>ip_masq - Enable IP masquerading</li><li>ip - Default IP when binding container ports</li><li>iptables - Enable addition of iptables rules</li><li>ipv4_forward - Enable net.ipv4.ip_forward</li><li>ipv6_forward - Enable net.ipv6.ip_forward</li><li>ipv6 - Enable IPv6 networking</li><li>labels A string or array to set metadata on the daemon in the form <!-- -->[\&#x27;foo:bar\&#x27;, \&#x27;hello:world\&#x27;]<!-- -->`</li><li>log_driver - Container\&#x27;s logging driver (json-file/syslog/journald/gelf/fluentd/awslogs/splunk/etwlogs/gcplogs/none)</li><li>log_level - Set the logging level</li><li>log_opts - Container\&#x27;s logging driver options (driver-specific)</li><li>logfile - Location of Docker daemon log file</li><li>mount_flags - Set the systemd mount propagation flag.</li><li>mtu - Set the containers network MTU</li><li>no_proxy - ENV variable set before for Docker daemon starts</li><li>package_name - Set the package name. Defaults to docker-ce</li><li>pidfile - Path to use for daemon PID file</li><li>registry_mirror - Preferred Docker registry mirror</li><li>selinux_enabled - Enable selinux support</li><li>source - URL to the pre-compiled Docker binary used for installation. Defaults to a calculated URL based on kernel version, Docker version, and platform arch. By default, this will try to get to &quot;<code>&lt;http://get.docker.io/builds/&gt;</code>&quot;.</li><li>storage_driver - Storage driver to use</li><li>storage_opts - Set storage driver options</li><li>tls_ca_cert - Trust certs signed only by this CA. Defaults to ENV<!-- -->[\&#x27;DOCKER_CERT_PATH\&#x27;]<!-- --> if set</li><li>tls_client_cert - Path to TLS certificate file for docker cli. Defaults to ENV<!-- -->[\&#x27;DOCKER_CERT_PATH\&#x27;]<!-- --> if set</li><li>tls_client_key - Path to TLS key file for docker cli. Defaults to ENV<!-- -->[\&#x27;DOCKER_CERT_PATH\&#x27;]<!-- --> if set</li><li>tls_server_cert - Path to TLS certificate file for docker service</li><li>tls_server_key - Path to TLS key file for docker service</li><li>tls_verify - Use TLS and verify the remote. Defaults to ENV<!-- -->[\&#x27;DOCKER_TLS_VERIFY\&#x27;]<!-- --> if set</li><li>tls - Use TLS; implied by --tlsverify. Defaults to ENV<!-- -->[\&#x27;DOCKER_TLS\&#x27;]<!-- --> if set</li><li>tmpdir - ENV variable set before for Docker daemon starts</li><li>userland_proxy- Enables or disables docker-proxy</li><li>userns_remap - Enable user namespace remapping options - default, uid, uid:gid, username, username:groupname (see: <a href="see:%20https://docs.docker.com/v1.10/engine/reference/commandline/daemon/#daemon-user-namespace-options">Docker User Namespaces</a>)</li><li>version - Docker version to install</li></ul><p><strong>Miscellaneous Options</strong></p><ul><li>misc_opts - Pass the docker daemon any other options bypassing flag validation, supplied as --flag=value</li></ul><p><strong>Systemd-specific Options</strong></p><ul><li>systemd_opts - An array of strings that will be included as individual lines in the systemd service unit for Docker. Note: This option is only relevant for systems where systemd is the default service manager or where systemd is specified explicitly as the service manager.</li></ul><p><strong>Actions</strong></p><ul><li>:create - Lays the Docker bits out on disk</li><li>:delete - Removes the Docker bits from the disk</li><li>:start - Makes sure the service provider is set up properly and start it</li><li>:stop - Stops the service</li><li>:restart - Restarts the service</li></ul><p><strong>docker_service implementations</strong></p><ul><li>docker_service_execute - The simplest docker_service. Just starts a process. Fire and forget.</li><li>docker_service_sysvinit - Uses a SystemV init script to manage the service state.</li><li>docker_service_upstart - Uses an Upstart script to manage the service state.</li><li>docker_service_systemd - Uses an Systemd unit file to manage the service state. NOTE: This does NOT enable systemd socket activation.</li></ul><h6><strong>docker_image</strong></h6><p>The docker_image is responsible for managing Docker image pulls, builds, and deletions. It speaks directly to the <a href="https://docs.docker.com/engine/api/v1.35/#tag/Image">Docker Engine API</a>.</p><p><strong>Actions</strong></p><ul><li>:pull - Pulls an image from the registry. Default action.</li><li>:pull_if_missing - Pulls an image from the registry, only if it missing</li><li>:build - Builds an image from a Dockerfile, directory, or tarball</li><li>:build_if_missing - Same build, but only if it is missing</li><li>:save - Exports an image to a tarball at destination</li><li>:import - Imports an image from a tarball at destination</li><li>:remove - Removes (untags) an image</li><li>:push - Pushes an image to the registry</li></ul><p><strong>Properties</strong></p><p>The docker_image resource properties mostly corresponds to the <a href="https://docs.docker.com/engine/api/v1.35/#tag/Image">Docker Engine API</a> as driven by the <a href="https://github.com/swipely/docker-api">docker-api Ruby gem</a></p><p>A docker_image\&#x27;s full identifier is a string in the form &quot;\</p><p><code style="background-color:lightgray">&lt;repo\&gt;:&lt;tag&gt;&quot;. There is some nuance around naming using the public registry vs a private one.&lt;/tag\&gt;&lt;/repo\&gt;</code></p><ul><li>repo - aka image_name - The first half of a Docker image\&#x27;s identity. This is a string in the form: registry:port/owner/image_name. If the registry:port portion is left off, Docker will implicitly use the Docker public registry. &quot;Official Images&quot; omit the owner part. This means a repo id can be as short as busybox, alpine, or centos. These names refer to official images on the public registry. Names can be as long as my.computers.biz:5043/what/ever to refer to custom images on an private registry. Often you\&#x27;ll see something like chef/chef to refer to private images on the public registry. - Defaults to resource name.</li><li>tag - The second half of a Docker image\&#x27;s identity. - Defaults to latest</li><li>source - Path to input for the :import, :build and :build_if_missing actions. For building, this can be a Dockerfile, a tarball containing a Dockerfile in its root, or a directory containing a Dockerfile. For :import, this should be a tarball containing Docker formatted image, as generated with :save.</li><li>destination - Path for output from the :save action.</li><li>force - A force boolean used in various actions - Defaults to false</li><li>nocache - Used in :build operations. - Defaults to false</li><li>noprune - Used in :remove operations - Defaults to false</li><li>rm - Remove intermediate containers after a successful build (default behavior) - Defaults to true</li><li>read_timeout - May need to increase for long image builds/pulls</li><li>write_timeout - May need to increase for long image builds/pulls</li><li>host - A string containing the host the API should communicate with. Defaults to ENV<!-- -->[\&#x27;DOCKER_HOST\&#x27;]<!-- --> if set.</li><li>tls - Use TLS; implied by --tlsverify. Defaults to ENV<!-- -->[\&#x27;DOCKER_TLS\&#x27;]<!-- --> if set.</li><li>tls_verify - Use TLS and verify the remote. Defaults to ENV<!-- -->[\&#x27;DOCKER_TLS_VERIFY\&#x27;]<!-- --> if set</li><li>tls_ca_cert - Trust certs signed only by this CA. Defaults to ENV<!-- -->[\&#x27;DOCKER_CERT_PATH\&#x27;]<!-- --> if set.</li><li>tls_client_cert - Path to TLS certificate file for docker cli. Defaults to ENV<!-- -->[\&#x27;DOCKER_CERT_PATH\&#x27;]<!-- -->if set</li><li>tls_client_key - Path to TLS key file for docker cli. Defaults to ENV<!-- -->[\&#x27;DOCKER_CERT_PATH\&#x27;]<!-- --> if set.</li></ul><p><strong>Examples</strong></p><ul><li>default action, default properties</li></ul><p>docker_image \&#x27;hello-world\&#x27;</p><ul><li>non-default name property</li></ul><p>docker_image &quot;Tom\&#x27;s container&quot; do</p><p>repo \&#x27;tduffield/testcontainerd\&#x27;</p><p>action :pull</p><p>end</p><ul><li>pull every time</li></ul><p>docker_image \&#x27;busybox\&#x27; do</p><p>action :pull</p><p>end</p><ul><li>specify a tag</li></ul><p>docker_image \&#x27;alpine\&#x27; do</p><p>tag \&#x27;3.1\&#x27;</p><p>end</p><ul><li>specify read/write timeouts</li></ul><p>docker_image \&#x27;alpine\&#x27; do</p><p>read_timeout 60</p><p>write_timeout 60</p><p>end</p><p>docker_image \&#x27;vbatts/slackware\&#x27; do</p><p>action :remove</p><p>end</p><ul><li>save</li></ul><p>docker_image \&#x27;save hello-world\&#x27; do</p><p>repo \&#x27;hello-world\&#x27;</p><p>destination \&#x27;/tmp/hello-world.tar\&#x27;</p><p>not_if { ::File.exist?(\&#x27;/tmp/hello-world.tar\&#x27;) }</p><p>action :save</p><p>end</p><ul><li>build from a Dockerfile on every chef-client run</li></ul><p>docker_image \&#x27;image_1\&#x27; do</p><p>tag \&#x27;v0.1.0\&#x27;</p><p>source \&#x27;/src/myproject/container1/Dockerfile\&#x27;</p><p>action :build</p><p>end</p><ul><li>build from a directory, only if image is missing</li></ul><p>docker_image \&#x27;image_2\&#x27; do</p><p>tag \&#x27;v0.1.0\&#x27;</p><p>source \&#x27;/src/myproject/container2\&#x27;</p><p>action :build_if_missing</p><p>end</p><ul><li>build from a tarball NOTE: this is not an &quot;export&quot; tarball generated from an an image save. The contents should be a Dockerfile, and anything it references to COPY or ADD</li></ul><p>docker_image \&#x27;image_3\&#x27; do</p><p>tag \&#x27;v0.1.0\&#x27;</p><p>source \&#x27;/tmp/image_3.tar\&#x27;</p><p>action :build</p><p>end</p><p>docker_image \&#x27;hello-again\&#x27; do</p><p>tag \&#x27;v0.1.0\&#x27;</p><p>source \&#x27;/tmp/hello-world.tar\&#x27;</p><p>action :import</p><p>end</p><ul><li>push</li></ul><p>docker_image \&#x27;my.computers.biz:5043/someara/hello-again\&#x27; do</p><p>action :push</p><p>end</p><ul><li>Connect to an external docker daemon and pull an image</li></ul><p>docker_image \&#x27;alpine\&#x27; do</p><p>host \&#x27;tcp://127.0.0.1:2376\&#x27;</p><p>tag \&#x27;2.7\&#x27;</p><p>end</p><h6><strong>docker_tag</strong></h6><p>Docker tags work very much like hard links in a Unix filesystem. They are just references to an existing image. Therefore, the docker_tag resource has taken inspiration from the Chef link resource.</p><p><strong>Actions</strong></p><ul><li>:tag - Tags the image</li></ul><p><strong>Properties</strong></p><ul><li>target_repo - The repo half of the source image identifier.</li><li>target_tag - The tag half of the source image identifier.</li><li>to_repo - The repo half of the new image identifier</li><li>to_tag- The tag half of the new image identifier</li></ul><p><strong>Examples</strong></p><p>docker_tag \&#x27;private repo tag for hello-again:1.0.1\&#x27; do</p><p>target_repo \&#x27;hello-again\&#x27;</p><p>target_tag \&#x27;v0.1.0\&#x27;</p><p>to_repo \&#x27;localhost:5043/someara/hello-again\&#x27;</p><p>to_tag \&#x27;latest\&#x27;</p><p>action :tag</p><p>end</p><h6><strong>docker_container</strong></h6><p>The docker_container is responsible for managing Docker container actions. It speaks directly to the <a href="https://docs.docker.com/reference/api/docker_remote_api_v1.20/">Docker remote API</a>.</p><p>Containers are process oriented, and move through an event cycle. Thanks to <a href="http://gliderlabs.com/">Glider Labs</a> for this excellent diagram. </p><p><strong>Actions</strong></p><ul><li>:create - Creates the container but does not start it. Useful for Volume containers.</li><li>:start - Starts the container. Useful for containers that run jobs.. command that exit.</li><li>:run - The default action. Both :create and :start the container in one action. Redeploys the container on resource change.</li><li>:run_if_missing - Runs a container only once.</li><li>:stop - Stops the container.</li><li>:restart - Stops and then starts the container.</li><li>:kill - Send a signal to the container process. Defaults to SIGKILL.</li><li>:pause - Pauses the container.</li><li>:unpause - Unpauses the container.</li><li>:delete - Deletes the container.</li><li>:redeploy - Deletes and runs the container.</li><li>:reload - Sends SIGHUP to pid 1 in the container</li></ul><p><strong>Properties</strong></p><p>Most docker_container properties are the snake_case version of the CamelCase keys found in the <a href="https://docs.docker.com/reference/api/docker_remote_api_v1.20/">Docker Remote Api</a></p><ul><li>container_name - The name of the container. Defaults to the name of the docker_containerresource.</li><li>repo - aka image_name. The first half of a the complete identifier for a Docker Image.</li><li>tag - The second half of a Docker image\&#x27;s identity. - Defaults to latest.</li><li>command - The command to run when starting the container.</li><li>autoremove - Boolean - Automatically delete a container when it\&#x27;s command exits. Defaults to false.</li><li>volumes - An array of volume bindings for this container. Each volume binding is a string in one of these forms: container_path to create a new volume for the container. host_path:container_path to bind-mount a host path into the container. host_path:container_path:ro to make the bind-mount read-only inside the container.</li><li>cap_add - An array Linux Capabilities (man 7 capabilities) to add to grant the container beyond what it normally gets.</li><li>cap_drop - An array Linux Capabilities (man 7 capabilities) to revoke that the container normally has.</li><li>cpu_shares - An integer value containing the CPU Shares for the container.</li><li>devices - A Hash of devices to add to the container.</li><li>dns - An array of DNS servers the container will use for name resolution.</li><li>dns_search - An array of domains the container will search for name resolution.</li><li>domain_name - Set\&#x27;s the container\&#x27;s dnsdomainname as returned by the dnsdomainname command.</li><li>entrypoint - Set the entry point for the container as a string or an array of strings.</li><li>env - Set environment variables in the container in the form <!-- -->[\&#x27;FOO=bar\&#x27;, \&#x27;BIZ=baz\&#x27;]</li><li>env_file - Read environment variables from a file and set in the container. Accepts an Array or String to the file location. lazy evaluator must be set if the file passed is created by Chef.</li><li>extra_hosts - An array of hosts to add to the container\&#x27;s /etc/hosts in the form <!-- -->[\&#x27;host_a:10.9.8.7\&#x27;, \&#x27;host_b:10.9.8.6\&#x27;]</li><li>force - A boolean to use in container operations that support a force option. Defaults to false</li><li>host - A string containing the host the API should communicate with. Defaults to ENV<!-- -->[\&#x27;DOCKER_HOST\&#x27;]<!-- --> if set</li><li>host_name - The hostname for the container.</li><li>labels A string, array, or hash to set metadata on the container in the form <!-- -->[\&#x27;foo:bar\&#x27;, \&#x27;hello:world\&#x27;]<!-- -->`</li><li>links - An array of source container/alias pairs to link the container to in the form <!-- -->[container_a:www\&#x27;, container_b:db\&#x27;]</li><li>log_driver - Sets a custom logging driver for the container (json-file/syslog/journald/gelf/fluentd/none).</li><li>log_opts - Configures the above logging driver options (driver-specific).</li><li>init - Run an init inside the container that forwards signals and reaps processes.</li><li>ip_address - Container IPv4 address (e.g. 172.30.100.104)</li><li>mac_address - The mac address for the container to use.</li><li>memory - Memory limit in bytes.</li><li>memory_swap - Total memory limit (memory + swap); set -1 to disable swap limit (unlimited). You must use this with memory and make the swap value larger than memory.</li><li>network_disabled - Boolean to disable networking. Defaults to false.</li><li>network_mode - Sets the networking mode for the container. One of bridge, host, container.</li><li>network_aliases - Adds network-scoped alias for the container in form <!-- -->[\&#x27;alias-1\&#x27;, \&#x27;alias-2\&#x27;]<!-- -->.</li><li>open_stdin - Boolean value, opens stdin. Defaults to false.</li><li>outfile - The path to write the file when using :export action.</li><li>port - The port configuration to use in the container. Matches the syntax used by the docker CLI tool.</li><li>privileged - Boolean to start the container in privileged more. Defaults to false</li><li>publish_all_ports - Allocates a random host port for all of a container\&#x27;s exposed ports.</li><li>remove_volumes - A boolean to clean up &quot;dangling&quot; volumes when removing the last container with a reference to it. Default to false to match the Docker CLI behavior.</li><li>restart_policy - One of no, on-failure, unless-stopped, or always. Use always if you want a service container to survive a Dockerhost reboot. Defaults to no.</li><li>restart_maximum_retry_count - Maximum number of restarts to try when restart_policy is on-failure. Defaults to an ever increasing delay (double the previous delay, starting at 100mS), to prevent flooding the server.</li><li>running_wait_time - Amount of seconds docker_container wait to determine if a process is running.</li><li>runtime - Runtime to use when running container. Defaults to runc.</li><li>security_opt - A list of string values to customize labels for MLS systems, such as SELinux.</li><li>signal - The signal to send when using the :kill action. Defaults to SIGTERM.</li><li>sysctls - A hash of sysctls to set on the container. Defaults to {}.</li><li>tty - Boolean value to allocate a pseudo-TTY. Defaults to false.</li><li>user - A string value specifying the user inside the container.</li><li>volumes - An Array of paths inside the container to expose. Does the same thing as the VOLUMEdirective in a Dockerfile, but works on container creation.</li><li>volumes_from - A list of volumes to inherit from another container. Specified in the form <code>&lt;container name&gt;[:&lt;ro|rw&gt;</code>]</li><li>volume_driver - Driver that this container users to mount volumes.</li><li>working_dir - A string specifying the working directory for commands to run in.</li><li>read_timeout - May need to increase for commits or exports that are slow</li><li>write_timeout - May need to increase for commits or exports that are slow</li><li>kill_after - Number of seconds to wait before killing the container. Defaults to wait indefinitely; eventually will hit read_timeout limit.</li><li>timeout - Seconds to wait for an attached container to return</li><li>tls - Use TLS; implied by --tlsverify. Defaults to ENV<!-- -->[\&#x27;DOCKER_TLS\&#x27;]<!-- --> if set</li><li>tls_verify - Use TLS and verify the remote. Defaults to ENV<!-- -->[\&#x27;DOCKER_TLS_VERIFY\&#x27;]<!-- --> if set</li><li>tls_ca_cert - Trust certs signed only by this CA. Defaults to ENV<!-- -->[\&#x27;DOCKER_CERT_PATH\&#x27;]<!-- --> if set</li><li>tls_client_cert - Path to TLS certificate file for docker cli. Defaults to ENV<!-- -->[\&#x27;DOCKER_CERT_PATH\&#x27;]<!-- --> if set</li><li>tls_client_key - Path to TLS key file for docker cli. Defaults to ENV<!-- -->[\&#x27;DOCKER_CERT_PATH\&#x27;]<!-- --> if set</li><li>userns_mode - Modify the user namespace mode - Defaults to nil, example option: host</li><li>pid_mode - Set the PID (Process) Namespace mode for the container. host: use the host\&#x27;s PID namespace inside the container.</li><li>ipc_mode - Set the IPC mode for the container - Defaults to nil, example option: host</li><li>uts_mode - Set the UTS namespace mode for the container. The UTS namespace is for setting the hostname and the domain that is visible to running processes in that namespace. By default, all containers, including those with --network=host, have their own UTS namespace. The host setting will result in the container using the same UTS namespace as the host. Note that --hostname is invalid in host UTS mode.</li><li>ro_rootfs - Mount the container\&#x27;s root filesystem as read only using the --read-only flag. Defaults to false</li></ul><p><strong>Examples</strong></p><ul><li>Create a container without starting it.</li></ul><p>docker_container \&#x27;hello-world\&#x27; do</p><p>command \&#x27;/hello\&#x27;</p><p>action :create</p><p>end</p><ul><li>This will exit succesfully. It will happen on every chef-client run.</li></ul><p>docker_container \&#x27;busybox_ls\&#x27; do</p><p>repo \&#x27;busybox\&#x27;</p><p>command \&#x27;ls -la /\&#x27;</p><p>action :run</p><p>end</p><ul><li>The :run action contains both :create and :start the container in one action. Redeploys the container on resource change. It is the default action.</li></ul><p>docker_container \&#x27;alpine_ls\&#x27; do</p><p>repo \&#x27;alpine\&#x27;</p><p>tag \&#x27;3.1\&#x27;</p><p>command \&#x27;ls -la /\&#x27;</p><p>action :run</p><p>end</p><ul><li>Set environment variables in a container</li></ul><p>docker_container \&#x27;env\&#x27; do</p><p>repo \&#x27;debian\&#x27;</p><p>env <!-- -->[\&#x27;PATH=/usr/bin\&#x27;, \&#x27;FOO=bar\&#x27;]</p><p>command \&#x27;env\&#x27;</p><p>action :run</p><p>end</p><p>docker_container \&#x27;env_files\&#x27; do</p><p>repo \&#x27;debian\&#x27;</p><p>env_file lazy { <!-- -->[\&#x27;/env_file1\&#x27;, \&#x27;/env_file2\&#x27;]<!-- --> }</p><p>command \&#x27;env\&#x27;</p><p>action :run</p><p>end</p><ul><li>This process remains running between chef-client runs, :run will do nothing on subsequent converges.</li></ul><p>docker_container \&#x27;an_echo_server\&#x27; do</p><p>repo \&#x27;alpine\&#x27;</p><p>tag \&#x27;3.1\&#x27;</p><p>command \&#x27;nc -ll -p 7 -e /bin/cat\&#x27;</p><p>port \&#x27;7:7\&#x27;</p><p>action :run</p><p>end</p><ul><li>Let docker pick the host port</li></ul><p>docker_container \&#x27;another_echo_server\&#x27; do</p><p>repo \&#x27;alpine\&#x27;</p><p>tag \&#x27;3.1\&#x27;</p><p>command \&#x27;nc -ll -p 7 -e /bin/cat\&#x27;</p><p>port \&#x27;7\&#x27;</p><p>action :run</p><p>end</p><ul><li>Specify the udp protocol</li></ul><p>docker_container \&#x27;an_udp_echo_server\&#x27; do</p><p>repo \&#x27;alpine\&#x27;</p><p>tag \&#x27;3.1\&#x27;</p><p>command \&#x27;nc -ul -p 7 -e /bin/cat\&#x27;</p><p>port \&#x27;5007:7/udp\&#x27;</p><p>action :run</p><p>end</p><ul><li>Kill a container</li></ul><p>docker_container \&#x27;bill\&#x27; do</p><p>action :kill</p><p>end</p><ul><li>Stop a container</li></ul><p>docker_container \&#x27;hammer_time\&#x27; do</p><p>action :stop</p><p>end</p><ul><li>Force-stop a container after 30 seconds</li></ul><p>docker_container \&#x27;hammer_time\&#x27; do</p><p>kill_after 30</p><p>action :stop</p><p>end</p><ul><li>Pause a container</li></ul><p>docker_container \&#x27;red_light\&#x27; do</p><p>action :pause</p><p>end</p><ul><li>Unpause a container</li></ul><p>docker_container \&#x27;green_light\&#x27; do</p><p>action :unpause</p><p>end</p><ul><li>Restart a container</li></ul><p>docker_container \&#x27;restarter\&#x27; do</p><p>action :restart</p><p>end</p><ul><li>Delete a container</li></ul><p>docker_container \&#x27;deleteme\&#x27; do</p><p>remove_volumes true</p><p>action :delete</p><p>end</p><ul><li>Redeploy a container</li></ul><p>docker_container \&#x27;redeployer\&#x27; do</p><p>repo \&#x27;alpine\&#x27;</p><p>tag \&#x27;3.1\&#x27;</p><p>command \&#x27;nc -ll -p 7777 -e /bin/cat\&#x27;</p><p>port \&#x27;7\&#x27;</p><p>action :run</p><p>end</p><p>execute \&#x27;redeploy redeployer\&#x27; do</p><p>notifies :redeploy, \&#x27;docker_container<!-- -->[redeployer]<!-- -->\&#x27;, :immediately</p><p>action :run</p><p>end</p><ul><li>Bind mount local directories</li></ul><p>docker_container \&#x27;bind_mounter\&#x27; do</p><p>repo \&#x27;busybox\&#x27;</p><p>command \&#x27;ls -la /bits /more-bits\&#x27;</p><p>volumes <!-- -->[\&#x27;/hostbits:/bits\&#x27;, \&#x27;/more-hostbits:/more-bits\&#x27;]</p><p>action :run_if_missing</p><p>end</p><ul><li>Mount volumes from another container</li></ul><p>docker_container \&#x27;chef_container\&#x27; do</p><p>command \&#x27;true\&#x27;</p><p>volumes \&#x27;/opt/chef\&#x27;</p><p>action :create</p><p>end</p><p>docker_container \&#x27;ohai_debian\&#x27; do</p><p>command \&#x27;/opt/chef/embedded/bin/ohai platform\&#x27;</p><p>repo \&#x27;debian\&#x27;</p><p>volumes_from \&#x27;chef_container\&#x27;</p><p>end</p><ul><li>Set a container\&#x27;s entrypoint</li></ul><p>docker_container \&#x27;ohai_again_debian\&#x27; do</p><p>repo \&#x27;debian\&#x27;</p><p>volumes_from \&#x27;chef_container\&#x27;</p><p>entrypoint \&#x27;/opt/chef/embedded/bin/ohai\&#x27;</p><p>command \&#x27;platform\&#x27;</p><p>action :run_if_missing</p><p>end</p><ul><li>Automatically remove a container after it exits</li></ul><p>docker_container \&#x27;sean_was_here\&#x27; do</p><p>command &quot;touch /opt/chef/sean_was_here-#{Time.new.strftime(\&#x27;%Y%m%d%H%M\&#x27;)}&quot;</p><p>repo \&#x27;debian\&#x27;</p><p>volumes_from \&#x27;chef_container\&#x27;</p><p>autoremove true</p><p>action :run</p><p>end</p><ul><li>Grant NET_ADMIN rights to a container</li></ul><p>docker_container \&#x27;cap_add_net_admin\&#x27; do</p><p>repo \&#x27;debian\&#x27;</p><p>command \&#x27;bash -c &quot;ip addr add 10.9.8.7/24 brd + dev eth0 label eth0:0 ; ip addr list&quot;\&#x27;</p><p>cap_add \&#x27;NET_ADMIN\&#x27;</p><p>action :run_if_missing</p><p>end</p><ul><li>Revoke MKNOD rights to a container</li></ul><p>docker_container \&#x27;cap_drop_mknod\&#x27; do</p><p>repo \&#x27;debian\&#x27;</p><p>command \&#x27;bash -c &quot;mknod -m 444 /dev/urandom2 c 1 9 ; ls -la /dev/urandom2&quot;\&#x27;</p><p>cap_drop \&#x27;MKNOD\&#x27;</p><p>action :run_if_missing</p><p>end</p><ul><li>Set a container\&#x27;s hostname and domainname</li></ul><p>docker_container \&#x27;fqdn\&#x27; do</p><p>repo \&#x27;debian\&#x27;</p><p>command \&#x27;hostname -f\&#x27;</p><p>host_name \&#x27;computers\&#x27;</p><p>domain_name \&#x27;biz\&#x27;</p><p>action :run_if_missing</p><p>end</p><ul><li>Set a container\&#x27;s DNS resolution</li></ul><p>docker_container \&#x27;dns\&#x27; do</p><p>repo \&#x27;debian\&#x27;</p><p>command \&#x27;cat /etc/resolv.conf\&#x27;</p><p>host_name \&#x27;computers\&#x27;</p><p>dns <!-- -->[\&#x27;4.3.2.1\&#x27;, \&#x27;1.2.3.4\&#x27;]</p><p>dns_search <!-- -->[\&#x27;computers.biz\&#x27;, \&#x27;chef.io\&#x27;]</p><p>action :run_if_missing</p><p>end</p><ul><li>Add extra hosts to a container\&#x27;s /etc/hosts</li></ul><p>docker_container \&#x27;extra_hosts\&#x27; do</p><p>repo \&#x27;debian\&#x27;</p><p>command \&#x27;cat /etc/hosts\&#x27;</p><p>extra_hosts <!-- -->[\&#x27;east:4.3.2.1\&#x27;, \&#x27;west:1.2.3.4\&#x27;]</p><p>action :run_if_missing</p><p>end</p><ul><li>Manage container\&#x27;s restart_policy</li></ul><p>docker_container \&#x27;try_try_again\&#x27; do</p><p>repo \&#x27;alpine\&#x27;</p><p>tag \&#x27;3.1\&#x27;</p><p>command \&#x27;grep asdasdasd /etc/passwd\&#x27;</p><p>restart_policy \&#x27;on-failure\&#x27;</p><p>restart_maximum_retry_count 2</p><p>action :run_if_missing</p><p>end</p><p>docker_container \&#x27;reboot_survivor\&#x27; do</p><p>repo \&#x27;alpine\&#x27;</p><p>tag \&#x27;3.1\&#x27;</p><p>command \&#x27;nc -ll -p 123 -e /bin/cat\&#x27;</p><p>port \&#x27;123\&#x27;</p><p>restart_policy \&#x27;always\&#x27;</p><p>action :run_if_missing</p><p>end</p><ul><li>Manage container links</li></ul><p>docker_container \&#x27;link_source\&#x27; do</p><p>repo \&#x27;alpine\&#x27;</p><p>tag \&#x27;3.1\&#x27;</p><p>env <!-- -->[\&#x27;FOO=bar\&#x27;, \&#x27;BIZ=baz\&#x27;]</p><p>command \&#x27;nc -ll -p 321 -e /bin/cat\&#x27;</p><p>port \&#x27;321\&#x27;</p><p>action :run_if_missing</p><p>end</p><p>docker_container \&#x27;link_target_1\&#x27; do</p><p>repo \&#x27;alpine\&#x27;</p><p>tag \&#x27;3.1\&#x27;</p><p>env <!-- -->[\&#x27;ASD=asd\&#x27;]</p><p>command \&#x27;ping -c 1 hello\&#x27;</p><p>links <!-- -->[\&#x27;link_source:hello\&#x27;]</p><p>action :run_if_missing</p><p>end</p><p>docker_container \&#x27;link_target_2\&#x27; do</p><p>repo \&#x27;alpine\&#x27;</p><p>tag \&#x27;3.1\&#x27;</p><p>command \&#x27;env\&#x27;</p><p>links <!-- -->[\&#x27;link_source:hello\&#x27;]</p><p>action :run_if_missing</p><p>end</p><p>execute \&#x27;redeploy_link_source\&#x27; do</p><p>command \&#x27;touch /marker_container_redeploy_link_source\&#x27;</p><p>creates \&#x27;/marker_container_redeploy_link_source\&#x27;</p><p>notifies :redeploy, \&#x27;docker_container<!-- -->[link_source]<!-- -->\&#x27;, :immediately</p><p>notifies :redeploy, \&#x27;docker_container<!-- -->[link_target_1]<!-- -->\&#x27;, :immediately</p><p>notifies :redeploy, \&#x27;docker_container<!-- -->[link_target_2]<!-- -->\&#x27;, :immediately</p><p>action :run</p><p>end</p><ul><li>Mutate a container between chef-client runs</li></ul><p>docker_tag \&#x27;mutator_from_busybox\&#x27; do</p><p>target_repo \&#x27;busybox\&#x27;</p><p>target_tag \&#x27;latest\&#x27;</p><p>to_repo \&#x27;someara/mutator\&#x27;</p><p>target_tag \&#x27;latest\&#x27;</p><p>end</p><p>docker_container \&#x27;mutator\&#x27; do</p><p>repo \&#x27;someara/mutator\&#x27;</p><p>tag \&#x27;latest\&#x27;</p><p>command &quot;sh -c \&#x27;touch /mutator-<code style="background-color:lightgray">date +\&quot;%Y-%m-%d_%H-%M-%S\&quot;</code>\&#x27;&quot;</p><p>outfile \&#x27;/mutator.tar\&#x27;</p><p>force true</p><p>action :run_if_missing</p><p>end</p><p>execute \&#x27;commit mutator\&#x27; do</p><p>command \&#x27;true\&#x27;</p><p>notifies :commit, \&#x27;docker_container<!-- -->[mutator]<!-- -->\&#x27;, :immediately</p><p>notifies :export, \&#x27;docker_container<!-- -->[mutator]<!-- -->\&#x27;, :immediately</p><p>notifies :redeploy, \&#x27;docker_container<!-- -->[mutator]<!-- -->\&#x27;, :immediately</p><p>action :run</p><p>end</p><ul><li>Specify read/write timeouts</li></ul><p>docker_container \&#x27;api_timeouts\&#x27; do</p><p>repo \&#x27;alpine\&#x27;</p><p>read_timeout 60</p><p>write_timeout 60</p><p>end</p><ul><li>Specify a custom logging driver and its options</li></ul><p>docker_container \&#x27;syslogger\&#x27; do</p><p>repo \&#x27;alpine\&#x27;</p><p>tag \&#x27;3.1\&#x27;</p><p>command \&#x27;nc -ll -p 780 -e /bin/cat\&#x27;</p><p>log_driver \&#x27;syslog\&#x27;</p><p>log_opts \&#x27;tag=container-syslogger\&#x27;</p><p>end</p><ul><li>Connect to an external docker daemon and create a container</li></ul><p>docker_container \&#x27;external_daemon\&#x27; do</p><p>repo \&#x27;alpine\&#x27;</p><p>host \&#x27;tcp://1.2.3.4:2376\&#x27;</p><p>action :create</p><p>end</p><h6><strong>docker_registry</strong></h6><p>The docker_registry resource is responsible for managing the connection auth information to a Docker registry.</p><p><strong>Actions</strong></p><ul><li>:login - Login to the Docker Registry</li></ul><p><strong>Properties</strong></p><ul><li>email</li><li>password</li><li>serveraddress</li><li>username</li></ul><p><strong>Examples</strong></p><ul><li>Log into or register with public registry:</li></ul><p>docker_registry \&#x27;<a href="https://index.docker.io/v1/%5C&#x27;">https://index.docker.io/v1/\&#x27;</a> do</p><p>username \&#x27;publicme\&#x27;</p><p>password \&#x27;hope_this_is_in_encrypted_databag\&#x27;</p><p>email \&#x27;publicme\@computers.biz\&#x27;</p><p>end</p><p>Log into private registry with optional port:</p><p>docker_registry \&#x27;my local registry\&#x27; do</p><p>serveraddress \&#x27;<a href="https://registry.computers.biz:8443/%5C&#x27;">https://registry.computers.biz:8443/\&#x27;</a></p><p>username \&#x27;privateme\&#x27;</p><p>password \&#x27;still_hope_this_is_in_encrypted_databag\&#x27;</p><p>email \&#x27;privateme\@computers.biz\&#x27;</p><p>end</p><h6><strong>docker_network</strong></h6><p>The docker_network resource is responsible for managing Docker named networks. Usage of overlaydriver requires the docker_service to be configured to use a distributed key/value store like etcd, consul, or zookeeper.</p><p><strong>Actions</strong></p><ul><li>:create - create a network</li><li>:delete - delete a network</li><li>:connect - connect a container to a network</li><li>:disconnect - disconnect a container from a network</li></ul><p><strong>Properties</strong></p><ul><li>aux_address - Auxiliary addresses for the network. Ex: <!-- -->[\&#x27;a=192.168.1.5\&#x27;, \&#x27;b=192.168.1.6\&#x27;]</li><li>container - Container-id/name to be connected/disconnected to/from the network. Used only by :connect and :disconnect actions</li><li>driver - The network driver to use. Defaults to bridge, other options include overlay.</li><li>enable_ipv6 - Enable IPv6 on the network. Ex: true</li><li>gateway - Specify the gateway(s) for the network. Ex: 192.168.0.1</li><li>ip_range - Specify a range of IPs to allocate for containers. Ex: 192.168.1.0/24</li><li>subnet - Specify the subnet(s) for the network. Ex: 192.168.0.0/16</li></ul><p><strong>Examples</strong></p><p>Create a network and use it in a container</p><p>docker_network \&#x27;network_g\&#x27; do</p><p>driver \&#x27;overlay\&#x27;</p><p>subnet <!-- -->[\&#x27;192.168.0.0/16\&#x27;, \&#x27;192.170.0.0/16\&#x27;]</p><p>gateway <!-- -->[\&#x27;192.168.0.100\&#x27;, \&#x27;192.170.0.100\&#x27;]</p><p>ip_range \&#x27;192.168.1.0/24\&#x27;</p><p>aux_address <!-- -->[\&#x27;a=192.168.1.5\&#x27;, \&#x27;b=192.168.1.6\&#x27;, \&#x27;a=192.170.1.5\&#x27;, \&#x27;b=192.170.1.6\&#x27;]</p><p>end</p><p>docker_container \&#x27;echo-base\&#x27; do</p><p>repo \&#x27;alpine\&#x27;</p><p>tag \&#x27;3.1\&#x27;</p><p>command \&#x27;nc -ll -p 1337 -e /bin/cat\&#x27;</p><p>port \&#x27;1337\&#x27;</p><p>network_mode \&#x27;network_g\&#x27;</p><p>action :run</p><p>end</p><p>Connect to multiple networks</p><p>docker_network \&#x27;network_h1\&#x27; do</p><p>action :create</p><p>end</p><p>docker_network \&#x27;network_h2\&#x27; do</p><p>action :create</p><p>end</p><p>docker_container \&#x27;echo-base-networks_h\&#x27; do</p><p>repo \&#x27;alpine\&#x27;</p><p>tag \&#x27;3.1\&#x27;</p><p>command \&#x27;nc -ll -p 1337 -e /bin/cat\&#x27;</p><p>port \&#x27;1337\&#x27;</p><p>network_mode \&#x27;network_h1\&#x27;</p><p>action :run</p><p>end</p><p>docker_network \&#x27;network_h2\&#x27; do</p><p>container \&#x27;echo-base-networks_h\&#x27;</p><p>action :connect</p><p>end</p><p>IPv6 enabled network</p><p>docker_network \&#x27;network_i1\&#x27; do</p><p>enable_ipv6 true</p><p>subnet \&#x27;fd00:dead:beef::/48\&#x27;</p><p>action :create</p><p>end</p><h6><strong>docker_volume</strong></h6><p>The docker_volume resource is responsible for managing Docker named volumes.</p><p><strong>Actions</strong></p><ul><li>:create - create a volume</li><li>:remove - remove a volume</li></ul><p><strong>Properties</strong></p><ul><li>driver</li><li>host</li><li>opts</li><li>volume</li><li>volume_name</li></ul><p><strong>Examples</strong></p><p>Create a volume named \&#x27;hello\&#x27;</p><p>docker_volume \&#x27;hello\&#x27; do</p><p>action :create</p><p>end</p><p>docker_container \&#x27;file_writer\&#x27; do</p><p>repo \&#x27;alpine\&#x27;</p><p>tag \&#x27;3.1\&#x27;</p><p>volumes \&#x27;hello:/hello\&#x27;</p><p>command \&#x27;touch /hello/sean_was_here\&#x27;</p><p>action :run_if_missing</p><p>end</p><h6><strong>docker_execute</strong></h6><p>The docker_execute resource allows you to execute commands inside of a running container.</p><p><strong>Actions</strong></p><ul><li>:run - Runs the command</li></ul><p><strong>Properties</strong></p><ul><li>host - Daemon socket(s) to connect to - tcp://host:port, unix:///path/to/socket, fd://* or fd://socketfd.</li><li>command - A command structured as an Array similar to CMD in a Dockerfile.</li><li>container - Name of the container to execute the command in.</li><li>timeout- Seconds to wait for an attached container to return. Defaults to 60 seconds.</li><li>container_obj</li></ul><p><strong>Examples</strong></p><p>docker_exec \&#x27;touch_it\&#x27; do</p><p>container \&#x27;busybox_exec\&#x27;</p><p>command <!-- -->[\&#x27;touch\&#x27;, \&#x27;/tmp/onefile\&#x27;]</p><p>end</p><h6><strong>Maintainers</strong></h6><ul><li>Sean OMeara (<code>&lt;sean@sean.io&gt;</code>)</li><li>Brian Flad (<code>&lt;bflad417@gmail.com&gt;</code>)</li><li>Chase Bolt (<code>&lt;chase.bolt@gmail.com&gt;</code>)</li></ul><h6><strong>License</strong></h6><p><strong>Copyright:</strong> 2015-2018, Chef Software, Inc.</p><p>Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</p><p>you may not use this file except in compliance with the License.</p><p>You may obtain a copy of the License at</p><p><a href="http://www.apache.org/licenses/LICENSE-2.0">http://www.apache.org/licenses/LICENSE-2.0</a></p><p>Unless required by applicable law or agreed to in writing, software</p><p>distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</p><p>WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</p><p>See the License for the specific language governing permissions and</p><p>limitations under the License.</p><h3>Security</h3><h4>Docker security</h4><p><em>Estimated reading time: 10 minutes</em></p><p>There are four major areas to consider when reviewing Docker security:</p><ul><li>the intrinsic security of the kernel and its support for namespaces and cgroups;</li><li>the attack surface of the Docker daemon itself;</li><li>loopholes in the container configuration profile, either by default, or when customized by users.</li><li>the &quot;hardening&quot; security features of the kernel and how they interact with containers.</li></ul><h5><strong>Kernel namespaces</strong></h5><p>Docker containers are very similar to LXC containers, and they have similar security features. When you start a container with docker run, behind the scenes Docker creates a set of namespaces and control groups for the container.</p><p><strong>Namespaces provide the first and most straightforward form of isolation</strong>: processes running within a container cannot see, and even less affect, processes running in another container, or in the host system.</p><p><strong>Each container also gets its own network stack</strong>, meaning that a container doesn&#x27;t get privileged access to the sockets or interfaces of another container. Of course, if the host system is setup accordingly, containers can interact with each other through their respective network interfaces --- just like they can interact with external hosts. When you specify public ports for your containers or use <a href="https://docs.docker.com/engine/userguide/networking/default_network/dockerlinks/">links</a> then IP traffic is allowed between containers. They can ping each other, send/receive UDP packets, and establish TCP connections, but that can be restricted if necessary. From a network architecture point of view, all containers on a given Docker host are sitting on bridge interfaces. This means that they are just like physical machines connected through a common Ethernet switch; no more, no less.</p><p>How mature is the code providing kernel namespaces and private networking? Kernel namespaces were introduced <a href="http://man7.org/linux/man-pages/man7/namespaces.7.html">between kernel version 2.6.15 and 2.6.26</a>. This means that since July 2008 (date of the 2.6.26 release ), namespace code has been exercised and scrutinized on a large number of production systems. And there is more: the design and inspiration for the namespaces code are even older. Namespaces are actually an effort to reimplement the features of <a href="http://en.wikipedia.org/wiki/OpenVZ">OpenVZ</a> in such a way that they could be merged within the mainstream kernel. And OpenVZ was initially released in 2005, so both the design and the implementation are pretty mature.</p><h5><strong>Control groups</strong></h5><p>Control Groups are another key component of Linux Containers. They implement resource accounting and limiting. They provide many useful metrics, but they also help ensure that each container gets its fair share of memory, CPU, disk I/O; and, more importantly, that a single container cannot bring the system down by exhausting one of those resources.</p><p>So while they do not play a role in preventing one container from accessing or affecting the data and processes of another container, they are essential to fend off some denial-of-service attacks. They are particularly important on multi-tenant platforms, like public and private PaaS, to guarantee a consistent uptime (and performance) even when some applications start to misbehave.</p><p>Control Groups have been around for a while as well: the code was started in 2006, and initially merged in kernel 2.6.24.</p><h5><strong>Docker daemon attack surface</strong></h5><p>Running containers (and applications) with Docker implies running the Docker daemon. This daemon currently requires root privileges, and you should therefore be aware of some important details.</p><p>First of all, <strong>only trusted users should be allowed to control your Docker daemon</strong>. This is a direct consequence of some powerful Docker features. Specifically, Docker allows you to share a directory between the Docker host and a guest container; and it allows you to do so without limiting the access rights of the container. This means that you can start a container where the /host directory is the / directory on your host; and the container can alter your host filesystem without any restriction. This is similar to how virtualization systems allow filesystem resource sharing. Nothing prevents you from sharing your root filesystem (or even your root block device) with a virtual machine.</p><p>This has a strong security implication: for example, if you instrument Docker from a web server to provision containers through an API, you should be even more careful than usual with parameter checking, to make sure that a malicious user cannot pass crafted parameters causing Docker to create arbitrary containers.</p><p>For this reason, the REST API endpoint (used by the Docker CLI to communicate with the Docker daemon) changed in Docker 0.5.2, and now uses a UNIX socket instead of a TCP socket bound on 127.0.0.1 (the latter being prone to cross-site request forgery attacks if you happen to run Docker directly on your local machine, outside of a VM). You can then use traditional UNIX permission checks to limit access to the control socket.</p><p>You can also expose the REST API over HTTP if you explicitly decide to do so. However, if you do that, be aware of the above mentioned security implications. Ensure that it is reachable only from a trusted network or VPN or protected with a mechanism such as stunnel and client SSL certificates. You can also secure API endpoints with <a href="https://docs.docker.com/engine/security/https/">HTTPS and certificates</a>.</p><p>The daemon is also potentially vulnerable to other inputs, such as image loading from either disk with docker load, or from the network with docker pull. As of Docker 1.3.2, images are now extracted in a chrooted subprocess on Linux/Unix platforms, being the first-step in a wider effort toward privilege separation. As of Docker 1.10.0, all images are stored and accessed by the cryptographic checksums of their contents, limiting the possibility of an attacker causing a collision with an existing image.</p><p>Finally, if you run Docker on a server, it is recommended to run exclusively Docker on the server, and move all other services within containers controlled by Docker. Of course, it is fine to keep your favorite admin tools (probably at least an SSH server), as well as existing monitoring/supervision processes, such as NRPE and collectd.</p><h5><strong>Linux kernel capabilities</strong></h5><p>By default, Docker starts containers with a restricted set of capabilities. What does that mean?</p><p>Capabilities turn the binary &quot;root/non-root&quot; dichotomy into a fine-grained access control system. Processes (like web servers) that just need to bind on a port below 1024 do not need to run as root: they can just be granted the net_bind_service capability instead. And there are many other capabilities, for almost all the specific areas where root privileges are usually needed.</p><p>This means a lot for container security; let&#x27;s see why!</p><p>Typical servers run several processes as root, including the SSH daemon, cron daemon, logging daemons, kernel modules, network configuration tools, and more. A container is different, because almost all of those tasks are handled by the infrastructure around the container:</p><ul><li>SSH access are typically managed by a single server running on the Docker host;</li><li>cron, when necessary, should run as a user process, dedicated and tailored for the app that needs its scheduling service, rather than as a platform-wide facility;</li><li>log management is also typically handed to Docker, or to third-party services like Loggly or Splunk;</li><li>hardware management is irrelevant, meaning that you never need to run udevd or equivalent daemons within containers;</li><li>network management happens outside of the containers, enforcing separation of concerns as much as possible, meaning that a container should never need to perform ifconfig,route, or ip commands (except when a container is specifically engineered to behave like a router or firewall, of course).</li></ul><p>This means that in most cases, containers do not need &quot;real&quot; root privileges at all. And therefore, containers can run with a reduced capability set; meaning that &quot;root&quot; within a container has much less privileges than the real &quot;root&quot;. For instance, it is possible to:</p><ul><li>deny all &quot;mount&quot; operations;</li><li>deny access to raw sockets (to prevent packet spoofing);</li><li>deny access to some filesystem operations, like creating new device nodes, changing the owner of files, or altering attributes (including the immutable flag);</li><li>deny module loading;</li><li>and many others.</li></ul><p>This means that even if an intruder manages to escalate to root within a container, it is much harder to do serious damage, or to escalate to the host.</p><p>This doesn&#x27;t affect regular web apps, but reduces the vectors of attack by malicious users considerably. By default Docker drops all capabilities except <a href="https://github.com/moby/moby/blob/master/oci/defaults.go#L14-L30">those needed</a>, a whitelist instead of a blacklist approach. You can see a full list of available capabilities in <a href="http://man7.org/linux/man-pages/man7/capabilities.7.html">Linux manpages</a>.</p><p>One primary risk with running Docker containers is that the default set of capabilities and mounts given to a container may provide incomplete isolation, either independently, or when used in combination with kernel vulnerabilities.</p><p>Docker supports the addition and removal of capabilities, allowing use of a non-default profile. This may make Docker more secure through capability removal, or less secure through the addition of capabilities. The best practice for users would be to remove all capabilities except those explicitly required for their processes.</p><h5><strong>Other kernel security features</strong></h5><p>Capabilities are just one of the many security features provided by modern Linux kernels. It is also possible to leverage existing, well-known systems like TOMOYO, AppArmor, SELinux, GRSEC, etc. with Docker.</p><p>While Docker currently only enables capabilities, it doesn&#x27;t interfere with the other systems. This means that there are many different ways to harden a Docker host. Here are a few examples.</p><ul><li>You can run a kernel with GRSEC and PAX. This adds many safety checks, both at compile-time and run-time; it also defeats many exploits, thanks to techniques like address randomization. It doesn&#x27;t require Docker-specific configuration, since those security features apply system-wide, independent of containers.</li><li>If your distribution comes with security model templates for Docker containers, you can use them out of the box. For instance, we ship a template that works with AppArmor and Red Hat comes with SELinux policies for Docker. These templates provide an extra safety net (even though it overlaps greatly with capabilities).</li><li>You can define your own policies using your favorite access control mechanism.</li></ul><p>Just as you can use third-party tools to augment Docker containers, including special network topologies or shared filesystems, tools exist to harden Docker containers without the need to modify Docker itself.</p><p>As of Docker 1.10 User Namespaces are supported directly by the docker daemon. This feature allows for the root user in a container to be mapped to a non uid-0 user outside the container, which can help to mitigate the risks of container breakout. This facility is available but not enabled by default.</p><p>Refer to the <a href="https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-user-namespace-options">daemon command</a> in the command line reference for more information on this feature. Additional information on the implementation of User Namespaces in Docker can be found in <a href="https://integratedcode.us/2015/10/13/user-namespaces-have-arrived-in-docker/">this blog post</a>.</p><h5><strong>Conclusions</strong></h5><p>Docker containers are, by default, quite secure; especially if you run your processes as non-privileged users inside the container.</p><p>You can add an extra layer of safety by enabling AppArmor, SELinux, GRSEC, or another appropriate hardening system.</p><p>If you think of ways to make docker more secure, we welcome feature requests, pull requests, or comments on the Docker community forums.</p><h5><strong>Related information</strong></h5><ul><li><a href="https://docs.docker.com/engine/security/trust/">Use trusted images</a></li><li><a href="https://docs.docker.com/engine/security/seccomp/">Seccomp security profiles for Docker</a></li><li><a href="https://docs.docker.com/engine/security/apparmor/">AppArmor security profiles for Docker</a></li><li><a href="https://medium.com/@ewindisch/on-the-security-of-containers-2c60ffe25a9e">On the Security of Containers (2014)</a></li><li><a href="https://docs.docker.com/engine/userguide/networking/overlay-security-model/">Docker swarm mode overlay network security model</a></li></ul><h4>Docker security non-events</h4><p><em>Estimated reading time: 3 minutes</em></p><p>This page lists security vulnerabilities which Docker mitigated, such that processes run in Docker containers were never vulnerable to the bug---even before it was fixed. This assumes containers are run without adding extra capabilities or not run as --privileged.</p><p>The list below is not even remotely complete. Rather, it is a sample of the few bugs we&#x27;ve actually noticed to have attracted security review and publicly disclosed vulnerabilities. In all likelihood, the bugs that haven&#x27;t been reported far outnumber those that have. Luckily, since Docker&#x27;s approach to secure by default through apparmor, seccomp, and dropping capabilities, it likely mitigates unknown bugs just as well as it does known ones.</p><p>Bugs mitigated:</p><ul><li><a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2013-1956">CVE-2013-1956</a>, <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2013-1957">1957</a>, <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2013-1958">1958</a>, <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2013-1959">1959</a>, <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2013-1979">1979</a>, <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-4014">CVE-2014-4014</a>, <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-5206">5206</a>, <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-5207">5207</a>, <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-7970">7970</a>, <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-7975">7975</a>, <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-2925">CVE-2015-2925</a>, <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-8543">8543</a>, <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-3134">CVE-2016-3134</a>, <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-3135">3135</a>, etc.: The introduction of unprivileged user namespaces lead to a huge increase in the attack surface available to unprivileged users by giving such users legitimate access to previously root-only system calls like mount(). All of these CVEs are examples of security vulnerabilities due to introduction of user namespaces. Docker can use user namespaces to set up containers, but then disallows the process inside the container from creating its own nested namespaces through the default seccomp profile, rendering these vulnerabilities unexploitable.</li><li><a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-0181">CVE-2014-0181</a>, <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-3339">CVE-2015-3339</a>: These are bugs that require the presence of a setuid binary. Docker disables setuid binaries inside containers via the NO_NEW_PRIVS process flag and other mechanisms.</li><li><a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-4699">CVE-2014-4699</a>: A bug in ptrace() could allow privilege escalation. Docker disables ptrace() inside the container using apparmor, seccomp and by dropping CAP_PTRACE. Three times the layers of protection there!</li><li><a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-9529">CVE-2014-9529</a>: A series of crafted keyctl() calls could cause kernel DoS / memory corruption. Docker disables keyctl() inside containers using seccomp.</li><li><a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-3214">CVE-2015-3214</a>, <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-4036">4036</a>: These are bugs in common virtualization drivers which could allow a guest OS user to execute code on the host OS. Exploiting them requires access to virtualization devices in the guest. Docker hides direct access to these devices when run without --privileged. Interestingly, these seem to be cases where containers are &quot;more secure&quot; than a VM, going against common wisdom that VMs are &quot;more secure&quot; than containers.</li><li><a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-0728">CVE-2016-0728</a>: Use-after-free caused by crafted keyctl() calls could lead to privilege escalation. Docker disables keyctl() inside containers using the default seccomp profile.</li><li><a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-2383">CVE-2016-2383</a>: A bug in eBPF -- the special in-kernel DSL used to express things like seccomp filters -- allowed arbitrary reads of kernel memory. The bpf() system call is blocked inside Docker containers using (ironically) seccomp.</li><li><a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-3134">CVE-2016-3134</a>, <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-4997">4997</a>, <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-4998">4998</a>: A bug in setsockopt with IPT_SO_SET_REPLACE, ARPT_SO_SET_REPLACE, and ARPT_SO_SET_REPLACE causing memory corruption / local privilege escalation. These arguments are blocked by CAP_NET_ADMIN, which Docker does not allow by default.</li></ul><p>Bugs not mitigated:</p><ul><li><a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-3290">CVE-2015-3290</a>, <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-5157">5157</a>: Bugs in the kernel&#x27;s non-maskable interrupt handling allowed privilege escalation. Can be exploited in Docker containers because the modify_ldt()system call is not currently blocked using seccomp.</li><li><a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-5195">CVE-2016-5195</a>: A race condition was found in the way the Linux kernel&#x27;s memory subsystem handled the copy-on-write (COW) breakage of private read-only memory mappings, which allowed unprivileged local users to gain write access to read-only memory. Also known as &quot;dirty COW.&quot; Partial mitigations: on some operating systems this vulnerability is mitigated by the combination of seccomp filtering of ptrace and the fact that /proc/self/mem is read-only.</li></ul><h4>Protect the Docker daemon socket</h4><p><em>Estimated reading time: 7 minutes</em></p><p>By default, Docker runs via a non-networked Unix socket. It can also optionally communicate using an HTTP socket.</p><p>If you need Docker to be reachable via the network in a safe manner, you can enable TLS by specifying the tlsverify flag and pointing Docker&#x27;s tlscacert flag to a trusted CA certificate.</p><p>In the daemon mode, it only allows connections from clients authenticated by a certificate signed by that CA. In the client mode, it only connects to servers with a certificate signed by that CA.</p><p><strong>Advanced topic</strong></p><p>Using TLS and managing a CA is an advanced topic. Please familiarize yourself with OpenSSL, x509 and TLS before using it in production.</p><h5><strong>Create a CA, server and client keys with OpenSSL</strong></h5><p><strong>Note</strong>: replace all instances of $HOST in the following example with the DNS name of your Docker daemon&#x27;s host.</p><p>First, on the <strong>Docker daemon&#x27;s host machine</strong>, generate CA private and public keys:</p><p>$ openssl genrsa -aes256 -out ca-key.pem 4096</p><p>Generating RSA private key, 4096 bit long modulus</p><p>............................................................................................................................................................................................++</p><p>........++</p><p>e is 65537 (0x10001)</p><p>Enter pass phrase for ca-key.pem:</p><p>Verifying - Enter pass phrase for ca-key.pem:</p><p>$ openssl req -new -x509 -days 365 -key ca-key.pem -sha256 -out ca.pem</p><p>Enter pass phrase for ca-key.pem:</p><p>You are about to be asked to enter information that will be incorporated</p><p>into your certificate request.</p><p>What you are about to enter is what is called a Distinguished Name or a DN.</p><p>There are quite a few fields but you can leave some blank</p><p>For some fields there will be a default value,</p><p>If you enter \&#x27;.\&#x27;, the field will be left blank.</p><hr/><p>Country Name (2 letter code) <!-- -->[AU]<!-- -->:</p><p>State or Province Name (full name) <!-- -->[Some-State]<!-- -->:Queensland</p><p>Locality Name (eg, city) []:Brisbane</p><p>Organization Name (eg, company) <!-- -->[Internet Widgits Pty Ltd]<!-- -->:Docker Inc</p><p>Organizational Unit Name (eg, section) []:Sales</p><p>Common Name (e.g. server FQDN or YOUR name) []:$HOST</p><p>Email Address []:Sven\@home.org.au</p><p>Now that you have a CA, you can create a server key and certificate signing request (CSR). Make sure that &quot;Common Name&quot; matches the hostname you use to connect to Docker:</p><p><strong>Note</strong>: replace all instances of $HOST in the following example with the DNS name of your Docker daemon&#x27;s host.</p><p>$ openssl genrsa -out server-key.pem 4096</p><p>Generating RSA private key, 4096 bit long modulus</p><p>.....................................................................++</p><p>.................................................................................................++</p><p>e is 65537 (0x10001)</p><p>$ openssl req -subj &quot;/CN=$HOST&quot; -sha256 -new -key server-key.pem -out server.csr</p><p>Next, we&#x27;re going to sign the public key with our CA:</p><p>Since TLS connections can be made via IP address as well as DNS name, the IP addresses need to be specified when creating the certificate. For example, to allow connections using 10.10.10.20and 127.0.0.1:</p><p>$ echo subjectAltName = DNS:$HOST,IP:10.10.10.20,IP:127.0.0.1 &gt;&gt; extfile.cnf</p><p>Set the Docker daemon key&#x27;s extended usage attributes to be used only for server authentication:</p><p>$ echo extendedKeyUsage = serverAuth &gt;&gt; extfile.cnf</p><p>Now, generate the signed certificate:</p><p>$ openssl x509 -req -days 365 -sha256 -in server.csr -CA ca.pem -CAkey ca-key.pem \</p><p>-CAcreateserial -out server-cert.pem -extfile extfile.cnf</p><p>Signature ok</p><p>subject=/CN=your.host.com</p><p>Getting CA Private Key</p><p>Enter pass phrase for ca-key.pem:</p><p><a href="https://docs.docker.com/engine/extend/plugins_authorization">Authorization plugins</a> offer more fine-grained control to supplement authentication from mutual TLS. In addition to other information described in the above document, authorization plugins running on a Docker daemon receive the certificate information for connecting Docker clients.</p><p>For client authentication, create a client key and certificate signing request:</p><p><strong>Note:</strong> for simplicity of the next couple of steps, you may perform this step on the Docker daemon&#x27;s host machine as well.</p><p>$ openssl genrsa -out key.pem 4096</p><p>Generating RSA private key, 4096 bit long modulus</p><p>.........................................................++</p><p>................++</p><p>e is 65537 (0x10001)</p><p>$ openssl req -subj \&#x27;/CN=client\&#x27; -new -key key.pem -out client.csr</p><p>To make the key suitable for client authentication, create an extensions config file:</p><p>$ echo extendedKeyUsage = clientAuth &gt;&gt; extfile.cnf</p><p>Now, generate the signed certificate:</p><p>$ openssl x509 -req -days 365 -sha256 -in client.csr -CA ca.pem -CAkey ca-key.pem \</p><p>-CAcreateserial -out cert.pem -extfile extfile.cnf</p><p>Signature ok</p><p>subject=/CN=client</p><p>Getting CA Private Key</p><p>Enter pass phrase for ca-key.pem:</p><p>After generating cert.pem and server-cert.pem you can safely remove the two certificate signing requests:</p><p>$ rm -v client.csr server.csr</p><p>With a default umask of 022, your secret keys are world-readable and writable for you and your group.</p><p>To protect your keys from accidental damage, remove their write permissions. To make them only readable by you, change file modes as follows:</p><p>$ chmod -v 0400 ca-key.pem key.pem server-key.pem</p><p>Certificates can be world-readable, but you might want to remove write access to prevent accidental damage:</p><p>$ chmod -v 0444 ca.pem server-cert.pem cert.pem</p><p>Now you can make the Docker daemon only accept connections from clients providing a certificate trusted by your CA:</p><p>$ dockerd --tlsverify --tlscacert=ca.pem --tlscert=server-cert.pem --tlskey=server-key.pem \</p><p>-H=0.0.0.0:2376</p><p>To connect to Docker and validate its certificate, provide your client keys, certificates and trusted CA:</p><p><strong>Run it on the client machine</strong></p><p>This step should be run on your Docker client machine. As such, you need to copy your CA certificate, your server certificate, and your client certificate to that machine.</p><p><strong>Note</strong>: replace all instances of $HOST in the following example with the DNS name of your Docker daemon&#x27;s host.</p><p>$ docker --tlsverify --tlscacert=ca.pem --tlscert=cert.pem --tlskey=key.pem \</p><p>-H=$HOST:2376 version</p><p><strong>Note</strong>: Docker over TLS should run on TCP port 2376.</p><p><strong>Warning</strong>: As shown in the example above, you don&#x27;t need to run the docker client with sudo or the docker group when you use certificate authentication. That means anyone with the keys can give any instructions to your Docker daemon, giving them root access to the machine hosting the daemon. Guard these keys as you would a root password!</p><h5><strong>Secure by default</strong></h5><p>If you want to secure your Docker client connections by default, you can move the files to the .docker directory in your home directory -- and set the DOCKER_HOST and DOCKER_TLS_VERIFYvariables as well (instead of passing -H=tcp://$HOST:2376 and --tlsverify on every call).</p><p>$ mkdir -pv <!-- -->~<!-- -->/.docker</p><p>$ cp -v {ca,cert,key}.pem <!-- -->~<!-- -->/.docker</p><p>$ export DOCKER_HOST=tcp://$HOST:2376 DOCKER_TLS_VERIFY=1</p><p>Docker now connects securely by default:</p><p>$ docker ps</p><h5><strong>Other modes</strong></h5><p>If you don&#x27;t want to have complete two-way authentication, you can run Docker in various other modes by mixing the flags.</p><h6><strong>Daemon modes</strong></h6><ul><li>tlsverify, tlscacert, tlscert, tlskey set: Authenticate clients</li><li>tls, tlscert, tlskey: Do not authenticate clients</li></ul><h6><strong>Client modes</strong></h6><ul><li>tls: Authenticate server based on public/default CA pool</li><li>tlsverify, tlscacert: Authenticate server based on given CA</li><li>tls, tlscert, tlskey: Authenticate with client certificate, do not authenticate server based on given CA</li><li>tlsverify, tlscacert, tlscert, tlskey: Authenticate with client certificate and authenticate server based on given CA</li></ul><p>If found, the client sends its client certificate, so you just need to drop your keys into <!-- -->~<!-- -->/.docker/{ca,cert,key}.pem. Alternatively, if you want to store your keys in another location, you can specify that location using the environment variable DOCKER_CERT_PATH.</p><p>$ export DOCKER_CERT_PATH=<!-- -->~<!-- -->/.docker/zone1/</p><p>$ docker --tlsverify ps</p><h6><strong>Connecting to the secure Docker port using curl</strong></h6><p>To use curl to make test API requests, you need to use three extra command line flags:</p><p>$ curl https://$HOST:2376/images/json \</p><p>--cert <!-- -->~<!-- -->/.docker/cert.pem \</p><p>--key <!-- -->~<!-- -->/.docker/key.pem \</p><p>--cacert <!-- -->~<!-- -->/.docker/ca.pem</p><h5><strong>Related information</strong></h5><ul><li><a href="https://docs.docker.com/engine/security/certificates/">Using certificates for repository client verification</a></li><li><a href="https://docs.docker.com/engine/security/trust/">Use trusted images</a></li></ul><h4>Verify repository client with certificates</h4><p><em>Estimated reading time: 2 minutes</em></p><p>In <a href="https://docs.docker.com/engine/security/https/">Running Docker with HTTPS</a>, you learned that, by default, Docker runs via a non-networked Unix socket and TLS must be enabled in order to have the Docker client and the daemon communicate securely over HTTPS. TLS ensures authenticity of the registry endpoint and that traffic to/from registry is encrypted.</p><p>This article demonstrates how to ensure the traffic between the Docker registry server and the Docker daemon (a client of the registry server) is encrypted and properly authenticated using certificate-based client-server authentication.</p><p>We show you how to install a Certificate Authority (CA) root certificate for the registry and how to set the client TLS certificate for verification.</p><h5><strong>Understanding the configuration</strong></h5><p>A custom certificate is configured by creating a directory under /etc/docker/certs.d using the same name as the registry&#x27;s hostname, such as localhost. All *.crt files are added to this directory as CA roots.</p><p><strong>Note</strong>: As of Docker 1.13, on Linux any root certificates authorities are merged with the system defaults, including as the host&#x27;s root CA set. On prior versions of Docker, and on Docker Enterprise Edition for Windows Server, the system default certificates are only used when no custom root certificates are configured.</p><p>The presence of one or more <code style="background-color:lightgray">&lt;filename&gt;</code>.key/cert pairs indicates to Docker that there are custom certificates required for access to the desired repository.</p><p><strong>Note</strong>: If multiple certificates exist, each is tried in alphabetical order. If there is a 4xx-level or 5xx-level authentication error, Docker continues to try with the next certificate.</p><p>The following illustrates a configuration with custom certificates:</p><p>/etc/docker/certs.d/ &lt;-- Certificate directory</p><p>└── localhost:5000 &lt;-- Hostname:port</p><p>├── client.cert &lt;-- Client certificate</p><p>├── client.key &lt;-- Client key</p><p>└── ca.crt &lt;-- Certificate authority that signed</p><p>the registry certificate</p><p>The preceding example is operating-system specific and is for illustrative purposes only. You should consult your operating system documentation for creating an os-provided bundled certificate chain.</p><h5><strong>Creating the client certificates</strong></h5><p>Use OpenSSL&#x27;s genrsa and req commands to first generate an RSA key and then use the key to create the certificate.</p><p>$ openssl genrsa -out client.key 4096</p><p>$ openssl req -new -x509 -text -key client.key -out client.cert</p><p><strong>Note</strong>: These TLS commands only generate a working set of certificates on Linux. The version of OpenSSL in macOS is incompatible with the type of certificate Docker requires.</p><h5><strong>Troubleshooting tips</strong></h5><p>The Docker daemon interprets .crt files as CA certificates and .cert files as client certificates. If a CA certificate is accidentally given the extension .cert instead of the correct .crtextension, the Docker daemon logs the following error message:</p><p>Missing key KEY_NAME for client certificate CERT_NAME. CA certificates should use the extension .crt.</p><p>If the Docker registry is accessed without a port number, do not add the port to the directory name. The following shows the configuration for a registry on default port 443 which is accessed with docker login my-https.registry.example.com:</p><p>/etc/docker/certs.d/</p><p>└── my-https.registry.example.com &lt;-- Hostname without port</p><p>├── client.cert</p><p>├── client.key</p><p>└── ca.crt</p><h5><strong>Related Information</strong></h5><ul><li><a href="https://docs.docker.com/engine/security/">Use trusted images</a></li><li><a href="https://docs.docker.com/engine/security/https/">Protect the Docker daemon socket</a></li></ul><h4>Use Trusted Images</h4><h5><strong>Content trust in Docker</strong></h5><p><em>Estimated reading time: 10 minutes</em></p><p>When transferring data among networked systems, trust is a central concern. In particular, when communicating over an untrusted medium such as the internet, it is critical to ensure the integrity and the publisher of all the data a system operates on. You use Docker Engine to push and pull images (data) to a public or private registry. Content trust gives you the ability to verify both the integrity and the publisher of all the data received from a registry over any channel.</p><h6><strong>About trust in Docker</strong></h6><p>Content trust allows operations with a remote Docker registry to enforce client-side signing and verification of image tags. Content trust provides the ability to use digital signatures for data sent to and received from remote Docker registries. These signatures allow client-side verification of the integrity and publisher of specific image tags.</p><p>Currently, content trust is disabled by default. To enable it, set the DOCKER_CONTENT_TRUSTenvironment variable to 1. Refer to the <a href="https://docs.docker.com/engine/reference/commandline/cli/#environment-variables">environment variables</a> and <a href="https://docs.docker.com/engine/reference/commandline/cli/#notary">Notary</a> configuration for the docker client for more options.</p><p>Once content trust is enabled, image publishers can sign their images. Image consumers can ensure that the images they use are signed. Publishers and consumers can be individuals alone or in organizations. Docker&#x27;s content trust supports users and automated processes such as builds.</p><p>When you enable content trust, signing occurs on the client after push and verification happens on the client after pull if you use Docker CE. If you use Docker EE with UCP, and you have configured UCP to require images to be signed before deploying, signing is verified by UCP.</p><p><strong>Image tags and content trust</strong></p><p>An individual image record has the following identifier:</p><p>[REGISTRY_HOST<!-- -->[:REGISTRY_PORT]<!-- -->/]REPOSITORY<!-- -->[:TAG]</p><p>A particular image REPOSITORY can have multiple tags. For example, latest and 3.1.2 are both tags on the mongo image. An image publisher can build an image and tag combination many times changing the image with each build.</p><p>Content trust is associated with the TAG portion of an image. Each image repository has a set of keys that image publishers use to sign an image tag. Image publishers have discretion on which tags they sign.</p><p>An image repository can contain an image with one tag that is signed and another tag that is not. For example, consider <a href="https://hub.docker.com/r/library/mongo/tags/">the Mongo image repository</a>. The latest tag could be unsigned while the 3.1.6 tag could be signed. It is the responsibility of the image publisher to decide if an image tag is signed or not. In this representation, some image tags are signed, others are not:</p><p>Publishers can choose to sign a specific tag or not. As a result, the content of an unsigned tag and that of a signed tag with the same name may not match. For example, a publisher can push a tagged image someimage:latest and sign it. Later, the same publisher can push an unsigned someimage:latest image. This second push replaces the last unsigned tag latest but does not affect the signed latest version. The ability to choose which tags they can sign, allows publishers to iterate over the unsigned version of an image before officially signing it.</p><p>Image consumers can enable content trust to ensure that images they use were signed. If a consumer enables content trust, they can only pull, run, or build with trusted images. Enabling content trust is like wearing a pair of rose-colored glasses. Consumers &quot;see&quot; only signed image tags and the less desirable, unsigned image tags are &quot;invisible&quot; to them.</p><p>To the consumer who has not enabled content trust, nothing about how they work with Docker images changes. Every image is visible regardless of whether it is signed or not.</p><p><strong>Content trust operations and keys</strong></p><p>When content trust is enabled, docker CLI commands that operate on tagged images must either have content signatures or explicit content hashes. The commands that operate with content trust are:</p><ul><li>push</li><li>build</li><li>create</li><li>pull</li><li>run</li></ul><p>For example, with content trust enabled a docker pull someimage:latest only succeeds if someimage:latest is signed. However, an operation with an explicit content hash always succeeds as long as the hash exists:</p><p>$ docker pull someimage\@sha256:d149ab53f8718e987c3a3024bb8aa0e2caadf6c0328f1d9d850b2a2a67f2819a</p><p>Trust for an image tag is managed through the use of signing keys. A key set is created when an operation using content trust is first invoked. A key set consists of the following classes of keys:</p><ul><li>an offline key that is the root of content trust for an image tag</li><li>repository or tagging keys that sign tags</li><li>server-managed keys such as the timestamp key, which provides freshness security guarantees for your repository</li></ul><p>The following image depicts the various signing keys and their relationships:</p><p><strong>WARNING</strong>: Loss of the root key is <strong>very difficult</strong> to recover from. Correcting this loss requires intervention from <a href="https://support.docker.com/">Docker Support</a> to reset the repository state. This loss also requires <strong>manual intervention</strong> from every consumer that used a signed tag from this repository prior to the loss.</p><p>You should backup the root key somewhere safe. Given that it is only required to create new repositories, it is a good idea to store it offline in hardware. For details on securing, and backing up your keys, make sure you read how to <a href="https://docs.docker.com/engine/security/trust/trust_key_mng/">manage keys for content trust</a>.</p><h6><strong>Survey of typical content trust operations</strong></h6><p>This section surveys the typical trusted operations users perform with Docker images. Specifically, we go through the following steps to help us exercise these various trusted operations:</p><ul><li>Build and push an unsigned image</li><li>Pull an unsigned image</li><li>Build and push a signed image</li><li>Pull the signed image pushed above</li><li>Pull unsigned image pushed above</li></ul><p><strong>Enable and disable content trust per-shell or per-invocation</strong></p><p>In a shell, you can enable content trust by setting the DOCKER_CONTENT_TRUST environment variable. Enabling per-shell is useful because you can have one shell configured for trusted operations and another terminal shell for untrusted operations. You can also add this declaration to your shell profile to have it turned on always by default.</p><p>To enable content trust in a bash shell enter the following command:</p><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-bash" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token builtin class-name" style="color:rgb(78, 201, 176)">export</span><span class="token plain"> </span><span class="token assign-left variable" style="color:rgb(156, 220, 254)">DOCKER_CONTENT_TRUST</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token number" style="color:rgb(181, 206, 168)">1</span></div></pre></div><p>Once set, each of the &quot;tag&quot; operations requires a key for a trusted tag.</p><p>In an environment where DOCKER_CONTENT_TRUST is set, you can use the--disable-content-trust flag to run individual operations on tagged images without content trust on an as-needed basis.</p><p>Consider the following Dockerfile that uses an untrusted parent image:</p><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-bash" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">$ </span><span class="token function" style="color:rgb(220, 220, 170)">cat</span><span class="token plain"> Dockerfile</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">FROM docker/trusttest:latest</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">RUN </span><span class="token builtin class-name" style="color:rgb(78, 201, 176)">echo</span></div></pre></div><p>To build a container successfully using this Dockerfile, one can do:</p><div class="MuiContainer-root MuiContainer-maxWidthLg"><pre class="Code__Pre-gy960v-0 UDybk prism-code language-bash" style="color:#9CDCFE;background-color:#1E1E1E"><div class="MuiGrid-root MuiGrid-container MuiGrid-justify-xs-flex-end"><button class="Code__CopyCode-gy960v-1 llUIua">Copy</button></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">$ docker build --disable-content-trust -t </span><span class="token variable" style="color:rgb(156, 220, 254)">`</span><span class="token variable operator" style="color:rgb(212, 212, 212)">&lt;</span><span class="token variable" style="color:rgb(156, 220, 254)">username</span><span class="token variable operator" style="color:rgb(212, 212, 212)">&gt;</span><span class="token variable" style="color:rgb(156, 220, 254)">`</span><span class="token plain">/nottrusttest:latest </span><span class="token builtin class-name" style="color:rgb(78, 201, 176)">.</span><span class="token plain"></span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">Sending build context to Docker daemon </span><span class="token number" style="color:rgb(181, 206, 168)">42.84</span><span class="token plain"> MB</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token punctuation" style="color:rgb(212, 212, 212)">..</span><span class="token plain">.</span></div><div class="token-line" style="color:#9CDCFE"><span class="token plain">Successfully built f21b872447dc</span></div></pre></div><p>The same is true for all the other commands, such as pull and push:</p><p>$ docker pull --disable-content-trust docker/trusttest:latest</p><p>...</p><p>$ docker push --disable-content-trust <code style="background-color:lightgray">&lt;username&gt;</code>/nottrusttest:latest</p><p>...</p><p>To invoke a command with content trust enabled regardless of whether or how the DOCKER_CONTENT_TRUST variable is set:</p><p>$ docker build --disable-content-trust=false -t <code style="background-color:lightgray">&lt;username&gt;</code>/trusttest:testing .</p><p>All of the trusted operations support the --disable-content-trust flag.</p><p><strong>Push trusted content</strong></p><p>To create signed content for a specific image tag, simply enable content trust and push a tagged image. If this is the first time you have pushed an image using content trust on your system, the session looks like this:</p><p>$ docker push <code style="background-color:lightgray">&lt;username&gt;</code>/trusttest:testing</p><p>The push refers to a repository <!-- -->[docker.io/<code style="background-color:lightgray">&lt;username&gt;</code>/trusttest]<!-- --> (len: 1)</p><p>9a61b6b1315e: Image already exists</p><p>902b87aaaec9: Image already exists</p><p>latest: digest: sha256:d02adacee0ac7a5be140adb94fa1dae64f4e71a68696e7f8e7cbf9db8dd49418 size: 3220</p><p>Signing and pushing trust metadata</p><p>You are about to create a new root signing key passphrase. This passphrase</p><p>will be used to protect the most sensitive key in your signing system. Please</p><p>choose a long, complex passphrase and be careful to keep the password and the</p><p>key file itself secure and backed up. It is highly recommended that you use a</p><p>password manager to generate the passphrase and keep it safe. There will be no</p><p>way to recover this key. You can find the key in your config directory.</p><p>Enter passphrase for new root key with id a1d96fb:</p><p>Repeat passphrase for new root key with id a1d96fb:</p><p>Enter passphrase for new repository key with id docker.io/<code style="background-color:lightgray">&lt;username&gt;</code>/trusttest (3a932f1):</p><p>Repeat passphrase for new repository key with id docker.io/<code style="background-color:lightgray">&lt;username&gt;</code>/trusttest (3a932f1):</p><p>Finished initializing &quot;docker.io/<code style="background-color:lightgray">&lt;username&gt;</code>/trusttest&quot;</p><p>When you push your first tagged image with content trust enabled, the docker client recognizes this is your first push and:</p><ul><li>alerts you that it is creating a new root key</li><li>requests a passphrase for the root key</li><li>generates a root key in the <!-- -->~<!-- -->/.docker/trust directory</li><li>requests a passphrase for the repository key</li><li>generates a repository key in the <!-- -->~<!-- -->/.docker/trust directory</li></ul><p>The passphrase you chose for both the root key and your repository key-pair should be randomly generated and stored in a password manager.</p><p><strong>NOTE</strong>: If you omit the testing tag, content trust is skipped. This is true even if content trust is enabled and even if this is your first push.</p><p>$ docker push <code style="background-color:lightgray">&lt;username&gt;</code>/trusttest</p><p>The push refers to a repository <!-- -->[docker.io/<code style="background-color:lightgray">&lt;username&gt;</code>/trusttest]<!-- --> (len: 1)</p><p>9a61b6b1315e: Image successfully pushed</p><p>902b87aaaec9: Image successfully pushed</p><p>latest: digest: sha256:a9a9c4402604b703bed1c847f6d85faac97686e48c579bd9c3b0fa6694a398fc size: 3220</p><p>No tag specified, skipping trust metadata push</p><p>It is skipped because as the message states, you did not supply an image TAG value. In Docker content trust, signatures are associated with tags.</p><p>Once you have a root key on your system, subsequent images repositories you create can use that same root key:</p><p>$ docker push docker.io/<code style="background-color:lightgray">&lt;username&gt;</code>/otherimage:latest</p><p>The push refers to a repository <!-- -->[docker.io/<code style="background-color:lightgray">&lt;username&gt;</code>/otherimage]<!-- --> (len: 1)</p><p>a9539b34a6ab: Image successfully pushed</p><p>b3dbab3810fc: Image successfully pushed</p><p>latest: digest: sha256:d2ba1e603661a59940bfad7072eba698b79a8b20ccbb4e3bfb6f9e367ea43939 size: 3346</p><p>Signing and pushing trust metadata</p><p>Enter key passphrase for root key with id a1d96fb:</p><p>Enter passphrase for new repository key with id docker.io/<code style="background-color:lightgray">&lt;username&gt;</code>/otherimage (bb045e3):</p><p>Repeat passphrase for new repository key with id docker.io/<code style="background-color:lightgray">&lt;username&gt;</code>/otherimage (bb045e3):</p><p>Finished initializing &quot;docker.io/<code style="background-color:lightgray">&lt;username&gt;</code>/otherimage&quot;</p><p>The new image has its own repository key and timestamp key. The latest tag is signed with both of these.</p><p><strong>Pull image content</strong></p><p>A common way to consume an image is to pull it. With content trust enabled, the Docker client only allows docker pull to retrieve signed images. Let&#x27;s try to pull the image you signed and pushed earlier:</p><p>$ docker pull <code style="background-color:lightgray">&lt;username&gt;</code>/trusttest:testing</p><p>Pull (1 of 1): <code style="background-color:lightgray">&lt;username&gt;</code>/trusttest:testing\@sha256:d149ab53f871</p><p>...</p><p>Tagging <code style="background-color:lightgray">&lt;username&gt;</code>/trusttest\@sha256:d149ab53f871 as docker/trusttest:testing</p><p>In the following example, the command does not specify a tag, so the system uses the latesttag by default again and the docker/trusttest:latest tag is not signed.</p><p>$ docker pull docker/trusttest</p><p>Using default tag: latest</p><p>no trust data available</p><p>Because the tag docker/trusttest:latest is not trusted, the pull fails.</p><h6><strong>Related information</strong></h6><ul><li><a href="https://docs.docker.com/engine/security/trust/trust_key_mng/">Manage keys for content trust</a></li><li><a href="https://docs.docker.com/engine/security/trust/trust_automation/">Automation with content trust</a></li><li><a href="https://docs.docker.com/engine/security/trust/trust_delegation/">Delegations for content trust</a></li><li><a href="https://docs.docker.com/engine/security/trust/trust_sandbox/">Play in a content trust sandbox</a></li></ul><h5><strong>Automation with content trust</strong></h5><p><em>Estimated reading time: 2 minutes</em></p><p>Your automation systems that pull or build images can also work with trust. Any automation environment must set DOCKER_CONTENT_TRUST either manually or in a scripted fashion before processing images.</p><h6><strong>Bypass requests for passphrases</strong></h6><p>To allow tools to wrap docker and push trusted content, there are two environment variables that allow you to provide the passphrases without an expect script, or typing them in:</p><ul><li>DOCKER_CONTENT_TRUST_ROOT_PASSPHRASE</li><li>DOCKER_CONTENT_TRUST_REPOSITORY_PASSPHRASE</li></ul><p>Docker attempts to use the contents of these environment variables as passphrase for the keys. For example, an image publisher can export the repository target and snapshot passphrases:</p><p>$ export DOCKER_CONTENT_TRUST_ROOT_PASSPHRASE=&quot;u7pEQcGoebUHm6LHe6&quot;</p><p>$ export DOCKER_CONTENT_TRUST_REPOSITORY_PASSPHRASE=&quot;l7pEQcTKJjUHm6Lpe4&quot;</p><p>Then, when pushing a new tag the Docker client does not request these values but signs automatically:</p><p>$ docker push docker/trusttest:latest</p><p>The push refers to a repository <!-- -->[docker.io/docker/trusttest]<!-- --> (len: 1)</p><p>a9539b34a6ab: Image already exists</p><p>b3dbab3810fc: Image already exists</p><p>latest: digest: sha256:d149ab53f871 size: 3355</p><p>Signing and pushing trust metadata</p><p>When working directly with the Notary client, it uses its <a href="https://docs.docker.com/notary/reference/client-config/#environment-variables-optional">own set of environment variables</a>.</p><h6><strong>Building with content trust</strong></h6><p>You can also build with content trust. Before running the docker build command, you should set the environment variable DOCKER_CONTENT_TRUST either manually or in a scripted fashion. Consider the simple Dockerfile below.</p><p>FROM docker/trusttest:latest</p><p>RUN echo</p><p>The FROM tag is pulling a signed image. You cannot build an image that has a FROM that is not either present locally or signed. Given that content trust data exists for the tag latest, the following build should succeed:</p><p>$ docker build -t docker/trusttest:testing .</p><p>Using default tag: latest</p><p>latest: Pulling from docker/trusttest</p><p>b3dbab3810fc: Pull complete</p><p>a9539b34a6ab: Pull complete</p><p>Digest: sha256:d149ab53f871</p><p>If content trust is enabled, building from a Dockerfile that relies on tag without trust data, causes the build command to fail:</p><p>$ docker build -t docker/trusttest:testing .</p><p>unable to process Dockerfile: No trust data for notrust</p><h6><strong>Related information</strong></h6><ul><li><a href="https://docs.docker.com/engine/security/trust/content_trust/">Content trust in Docker</a></li><li><a href="https://docs.docker.com/engine/security/trust/trust_key_mng/">Manage keys for content trust</a></li><li><a href="https://docs.docker.com/engine/security/trust/trust_delegation/">Delegations for content trust</a></li><li><a href="https://docs.docker.com/engine/security/trust/trust_sandbox/">Play in a content trust sandbox</a></li></ul><h5><strong>Delegations for content trust</strong></h5><p><em>Estimated reading time: 6 minutes</em></p><p>Docker Engine supports the usage of the targets/releases delegation as the canonical source of a trusted image tag.</p><p>Using this delegation allows you to collaborate with other publishers without sharing your repository key, which is a combination of your targets and snapshot keys. See <a href="https://docs.docker.com/engine/security/trust/trust_key_mng/">Manage keys for content trust</a> for more information). Collaborators can keep their own delegation keys private.</p><p>The targets/releases delegation is currently an optional feature - in order to set up delegations, you must use the Notary CLI:</p><ol><li><a href="https://github.com/docker/notary/releases">Download the client</a> and ensure that it is available on your path</li><li>Create a configuration file at <!-- -->~<!-- -->/.notary/config.json with the following content:</li><li>{</li><li>&quot;trust_dir&quot; : &quot;<!-- -->~<!-- -->/.docker/trust&quot;,</li><li>&quot;remote_server&quot;: {</li><li>&quot;url&quot;: &quot;<a href="https://notary.docker.io%22">https://notary.docker.io&quot;</a></li><li>}</li><li>}</li></ol><p>This tells Notary where the Docker Content Trust data is stored, and to use the Notary server used for images in Docker Hub.</p><p>For more detailed information about how to use Notary outside of the default Docker Content Trust use cases, refer to the <a href="https://docs.docker.com/notary/getting_started/">Notary CLI documentation</a>.</p><p>When publishing and listing delegation changes using the Notary client, your Docker Hub credentials are required.</p><h6><strong>Generating delegation keys</strong></h6><p>Your collaborator needs to generate a private key (either RSA or ECDSA) and give you the public key so that you can add it to the targets/releases delegation.</p><p>The easiest way for them to generate these keys is with OpenSSL. Here is an example of how to generate a 2048-bit RSA portion key (all RSA keys must be at least 2048 bits):</p><p>$ openssl genrsa -out delegation.key 2048</p><p>Generating RSA private key, 2048 bit long modulus</p><p>....................................................+++</p><p>............+++</p><p>e is 65537 (0x10001)</p><p>They should keep delegation.key private because it is used to sign tags.</p><p>Then they need to generate an x509 certificate containing the public key, which is what you need from them. Here is the command to generate a CSR (certificate signing request):</p><p>$ openssl req -new -sha256 -key delegation.key -out delegation.csr</p><p>Then they can send it to whichever CA you trust to sign certificates, or they can self-sign the certificate (in this example, creating a certificate that is valid for 1 year):</p><p>$ openssl x509 -req -sha256 -days 365 -in delegation.csr -signkey delegation.key -out delegation.crt</p><p>Then they need to give you delegation.crt, whether it is self-signed or signed by a CA.</p><h6><strong>Adding a delegation key to an existing repository</strong></h6><p>If your repository was created using a version of Docker Engine prior to 1.11, then before adding any delegations, you should rotate the snapshot key to the server so that collaborators don&#x27;t need your snapshot key to sign and publish tags:</p><p>$ notary key rotate docker.io/<code style="background-color:lightgray">&lt;username&gt;/&lt;imagename&gt;</code> snapshot -r</p><p>This tells Notary to rotate a key for your particular image repository. The docker.io/ prefix is required. snapshot -r specifies that you want to rotate the snapshot key and that you want the server to manage it (-r stands for &quot;remote&quot;).</p><p>When adding a delegation, your must acquire <a href="https://docs.docker.com/engine/security/trust/trust_delegation/#generating-delegation-keys">the PEM-encoded x509 certificate with the public key</a> of the collaborator you wish to delegate to.</p><p>Assuming you have the certificate delegation.crt, you can add a delegation for this user and then publish the delegation change:</p><p>$ notary delegation add docker.io/<code style="background-color:lightgray">&lt;username&gt;/&lt;imagename&gt;</code> targets/releases delegation.crt --all-paths</p><p>$ notary publish docker.io/<code style="background-color:lightgray">&lt;username&gt;/&lt;imagename&gt;</code></p><p>The preceding example illustrates a request to add the delegation targets/releases to the image repository, if it doesn&#x27;t exist. Be sure to use targets/releases - Notary supports multiple delegation roles, so if you mistype the delegation name, the Notary CLI does not error. However, Docker Engine supports reading only from targets/releases.</p><p>It also adds the collaborator&#x27;s public key to the delegation, enabling them to sign the targets/releases delegation so long as they have the private key corresponding to this public key. The --all-paths flag tells Notary not to restrict the tag names that can be signed into targets/releases, which we highly recommend for targets/releases.</p><p>Publishing the changes tells the server about the changes to the targets/releases delegation.</p><p>After publishing, view the delegation information to ensure that you correctly added the keys to targets/releases:</p><p>$ notary delegation list docker.io/<code style="background-color:lightgray">&lt;username&gt;/&lt;imagename&gt;</code></p><p>ROLE PATHS KEY IDS THRESHOLD</p><hr/><p>targets/releases &quot;&quot; <code style="background-color:lightgray">&lt;all paths&gt;</code> 729c7094a8210fd1e780e7b17b7bb55c9a28a48b871b07f65d97baf93898523a 1</p><p>You can see the targets/releases with its paths and the key ID you just added.</p><p>Notary currently does not map collaborators names to keys, so we recommend that you add and list delegation keys one at a time, and keep a mapping of the key IDs to collaborators yourself should you need to remove a collaborator.</p><h6><strong>Removing a delegation key from an existing repository</strong></h6><p>To revoke a collaborator&#x27;s ability to sign tags for your image repository, you need to remove their keys from the targets/releases delegation. To do this, you need the IDs of their keys.</p><p>$ notary delegation remove docker.io/<code style="background-color:lightgray">&lt;username&gt;/&lt;imagename&gt;</code> targets/releases 729c7094a8210fd1e780e7b17b7bb55c9a28a48b871b07f65d97baf93898523a</p><p>Removal of delegation role targets/releases with keys <!-- -->[729c7094a8210fd1e780e7b17b7bb55c9a28a48b871b07f65d97baf93898523a]<!-- -->, to repository &quot;docker.io/<code style="background-color:lightgray">&lt;username&gt;/&lt;imagename&gt;</code>&quot; staged for next publish.</p><p>The revocation takes effect as soon as you publish:</p><p>$ notary publish docker.io/<code style="background-color:lightgray">&lt;username&gt;/&lt;imagename&gt;</code></p><p>By removing all the keys from the targets/releases delegation, the delegation (and any tags that are signed into it) is removed. That means that these tags are all deleted, and you may end up with older, legacy tags that were signed directly by the targets key.</p><h6><strong>Removing the targets/releases delegation entirely from a repository</strong></h6><p>If you&#x27;ve decided that delegations aren&#x27;t for you, you can delete the targets/releases delegation entirely. This also removes all the tags that are currently in targets/releases, however, and you may end up with older, legacy tags that were signed directly by the targets key.</p><p>To delete the targets/releases delegation:</p><p>$ notary delegation remove docker.io/<code style="background-color:lightgray">&lt;username&gt;/&lt;imagename&gt;</code> targets/releases</p><p>Are you sure you want to remove all data for this delegation? (yes/no)</p><p>yes</p><p>Forced removal (including all keys and paths) of delegation role targets/releases to repository &quot;docker.io/<code style="background-color:lightgray">&lt;username&gt;/&lt;imagename&gt;</code>&quot; staged for next publish.</p><p>$ notary publish docker.io/<code style="background-color:lightgray">&lt;username&gt;/&lt;imagename&gt;</code></p><h6><strong>Pushing trusted data as a collaborator</strong></h6><p>As a collaborator with a private key that has been added to a repository&#x27;s targets/releasesdelegation, you need to import the private key that you generated into Content Trust.</p><p>To do so, you can run:</p><p>$ notary key import delegation.key --role user</p><p>where delegation.key is the file containing your PEM-encoded private key.</p><p>After you have done so, running docker push on any repository that includes your key in the targets/releases delegation automatically signs tags using this imported key.</p><h6><strong>docker push behavior</strong></h6><p>When running docker push with Docker Content Trust, Docker Engine attempts to sign and push with the targets/releases delegation if it exists. If it does not, the targets key is used to sign the tag, if the key is available.</p><h6><strong>docker pull and docker build behavior</strong></h6><p>When running docker pull or docker build with Docker Content Trust, Docker Engine pulls tags only signed by the targets/releases delegation role or the legacy tags that were signed directly with the targets key.</p><h6><strong>Related information</strong></h6><ul><li><a href="https://docs.docker.com/engine/security/trust/content_trust/">Content trust in Docker</a></li><li><a href="https://docs.docker.com/engine/security/trust/trust_key_mng/">Manage keys for content trust</a></li><li><a href="https://docs.docker.com/engine/security/trust/trust_automation/">Automation with content trust</a></li><li><a href="https://docs.docker.com/engine/security/trust/trust_sandbox/">Play in a content trust sandbox</a></li></ul><h5><strong>Deploy Notary Server with Compose</strong></h5><p><em>Estimated reading time: 1 minute</em></p><p>The easiest way to deploy Notary Server is by using Docker Compose. To follow the procedure on this page, you must have already <a href="https://docs.docker.com/compose/install/">installed Docker Compose</a>.</p><ol><li>Clone the Notary repository.</li><li>git clone git\@github.com:docker/notary.git</li><li>Build and start Notary Server with the sample certificates.</li><li>docker-compose up -d</li></ol><p>For more detailed documentation about how to deploy Notary Server, see the <a href="https://docs.docker.com/notary/running_a_service/">instructions to run a Notary service</a> as well as <a href="https://github.com/docker/notary">the Notary repository</a> for more information.</p><ol><li>Make sure that your Docker or Notary client trusts Notary Server&#x27;s certificate before you try to interact with the Notary server.</li></ol><p>See the instructions for <a href="https://docs.docker.com/engine/reference/commandline/cli/#notary">Docker</a> or for <a href="https://github.com/docker/notary#using-notary">Notary</a> depending on which one you are using.</p><h6><strong>If you want to use Notary in production</strong></h6><p>Check back here for instructions after Notary Server has an official stable release. To get a head start on deploying Notary in production, see <a href="https://github.com/docker/notary">the Notary repository</a>.</p><h5><strong>Manage keys for content trust</strong></h5><p><em>Estimated reading time: 4 minutes</em></p><p>Trust for an image tag is managed through the use of keys. Docker&#x27;s content trust makes use of five different types of keys:</p><p>  <strong>Key</strong>      <strong>Description</strong></p><hr/><p>  root key     Root of content trust for an image tag. When content trust is enabled, you create the root key once. Also known as the offline key, because it should be kept offline.
targets      This key allows you to sign image tags, to manage delegations including delegated keys or permitted delegation paths. Also known as the repository key, since this key determines what tags can be signed into an image repository.
snapshot     This key signs the current collection of image tags, preventing mix and match attacks.
timestamp    This key allows Docker image repositories to have freshness security guarantees without requiring periodic content refreshes on the client&#x27;s side.
delegation   Delegation keys are optional tagging keys and allow you to delegate signing image tags to other publishers without having to share your targets key.</p><p>When doing a docker push with Content Trust enabled for the first time, the root, targets, snapshot, and timestamp keys are generated automatically for the image repository:</p><ul><li>The root and targets key are generated and stored locally client-side.</li><li>The timestamp and snapshot keys are safely generated and stored in a signing server that is deployed alongside the Docker registry. These keys are generated in a backend service that isn&#x27;t directly exposed to the internet and are encrypted at rest.</li></ul><p>Delegation keys are optional, and not generated as part of the normal docker workflow. They need to be <a href="https://docs.docker.com/engine/security/trust/trust_delegation/#generating-delegation-keys">manually generated and added to the repository</a>.</p><p><strong>Note</strong>: Prior to Docker Engine 1.11, the snapshot key was also generated and stored locally client-side. <a href="https://docs.docker.com/notary/advanced_usage/#rotate-keys">Use the Notary CLI to manage your snapshot key locally again</a> for repositories created with newer versions of Docker.</p><h6><strong>Choosing a passphrase</strong></h6><p>The passphrases you chose for both the root key and your repository key should be randomly generated and stored in a password manager. Having the repository key allows users to sign image tags on a repository. Passphrases are used to encrypt your keys at rest and ensure that a lost laptop or an unintended backup doesn&#x27;t put the private key material at risk.</p><h6><strong>Back up your keys</strong></h6><p>All the Docker trust keys are stored encrypted using the passphrase you provide on creation. Even so, you should still take care of the location where you back them up. Good practice is to create two encrypted USB keys.</p><p>It is very important that you back up your keys to a safe, secure location. Loss of the repository key is recoverable; loss of the root key is not.</p><p>The Docker client stores the keys in the <!-- -->~<!-- -->/.docker/trust/private directory. Before backing them up, you should tar them into an archive:</p><p>$ umask 077; tar -zcvf private_keys_backup.tar.gz <!-- -->~<!-- -->/.docker/trust/private; umask 022</p><h6><strong>Hardware storage and signing</strong></h6><p>Docker Content Trust can store and sign with root keys from a Yubikey 4. The Yubikey is prioritized over keys stored in the filesystem. When you initialize a new repository with content trust, Docker Engine looks for a root key locally. If a key is not found and the Yubikey 4 exists, Docker Engine creates a root key in the Yubikey 4. Consult the <a href="https://docs.docker.com/notary/advanced_usage/#use-a-yubikey">Notary documentation</a> for more details.</p><p>Prior to Docker Engine 1.11, this feature was only in the experimental branch.</p><h6><strong>Lost keys</strong></h6><p>If a publisher loses keys it means losing the ability to sign trusted content for your repositories. If you lose a key, contact <a href="https://support.docker.com/">Docker Support</a> (support\@docker.com) to reset the repository state.</p><p>This loss also requires <strong>manual intervention</strong> from every consumer that pulled the tagged image prior to the loss. Image consumers would get an error for content that they already downloaded:</p><p>Warning: potential malicious behavior - trust data has insufficient signatures for remote repository docker.io/my/image: valid signatures did not meet threshold</p><p>To correct this, they need to download a new image tag that is signed with the new key.</p><h6><strong>Related information</strong></h6><ul><li><a href="https://docs.docker.com/engine/security/trust/content_trust/">Content trust in Docker</a></li><li><a href="https://docs.docker.com/engine/security/trust/trust_automation/">Automation with content trust</a></li><li><a href="https://docs.docker.com/engine/security/trust/trust_delegation/">Delegations for content trust</a></li><li><a href="https://docs.docker.com/engine/security/trust/trust_sandbox/">Play in a content trust sandbox</a></li></ul><h5><strong>Play in a content trust sandbox</strong></h5><p><em>Estimated reading time: 8 minutes</em></p><p>This page explains how to set up and use a sandbox for experimenting with trust. The sandbox allows you to configure and try trust operations locally without impacting your production images.</p><p>Before working through this sandbox, you should have read through the <a href="https://docs.docker.com/engine/security/trust/content_trust/">trust overview</a>.</p><p><strong>Prerequisites</strong></p><p>These instructions assume you are running in Linux or macOS. You can run this sandbox on a local machine or on a virtual machine. You need to have privileges to run docker commands on your local machine or in the VM.</p><p>This sandbox requires you to install two Docker tools: Docker Engine &gt;= 1.10.0 and Docker Compose &gt;= 1.6.0. To install the Docker Engine, choose from the <a href="https://docs.docker.com/engine/installation/">list of supported platforms</a>. To install Docker Compose, see the <a href="https://docs.docker.com/compose/install/">detailed instructions here</a>.</p><h6><strong>What is in the sandbox?</strong></h6><p>If you are just using trust out-of-the-box you only need your Docker Engine client and access to the Docker Hub. The sandbox mimics a production trust environment, and sets up these additional components.</p><p>  <strong>Container</strong>     <strong>Description</strong></p><hr/><p>  trustsandbox      A container with the latest version of Docker Engine and with some preconfigured certificates. This is your sandbox where you can use the docker client to test trust operations.
Registry server   A local registry service.
Notary server     The service that does all the heavy-lifting of managing trust</p><p>This means you run your own content trust (Notary) server and registry. If you work exclusively with the Docker Hub, you would not need with these components. They are built into the Docker Hub for you. For the sandbox, however, you build your own entire, mock production environment.</p><p>Within the trustsandbox container, you interact with your local registry rather than the Docker Hub. This means your everyday image repositories are not used. They are protected while you play.</p><p>When you play in the sandbox, you also create root and repository keys. The sandbox is configured to store all the keys and files inside the trustsandbox container. Since the keys you create in the sandbox are for play only, destroying the container destroys them as well.</p><p>By using a docker-in-docker image for the trustsandbox container, you also don&#x27;t pollute your real Docker daemon cache with any images you push and pull. The images are stored in an anonymous volume attached to this container, and can be destroyed after you destroy the container.</p><h6><strong>Build the sandbox</strong></h6><p>In this section, you use Docker Compose to specify how to set up and link together the trustsandbox container, the Notary server, and the Registry server.</p><ol><li>Create a new trustsandbox directory and change into it.</li><li>$ mkdir trustsandbox</li><li>$ cd trustsandbox</li><li>Create a file called docker-compose.yml with your favorite editor. For example, using vim:</li><li>$ touch docker-compose.yml</li><li>$ vim docker-compose.yml</li><li>Add the following to the new file.</li><li>version: &quot;2&quot;</li><li>services:</li><li>notaryserver:</li><li>image: dockersecurity/notary_autobuilds:server-v0.4.2</li><li>volumes:</li><li><ul><li>notarycerts:/go/src/github.com/docker/notary/fixtures</li></ul></li><li>networks:</li><li><ul><li>sandbox</li></ul></li><li>environment:</li><li><ul><li>NOTARY_SERVER_STORAGE_TYPE=memory</li></ul></li><li><ul><li>NOTARY_SERVER_TRUST_SERVICE_TYPE=local</li></ul></li><li>sandboxregistry:</li><li>image: registry:2.4.1</li><li>networks:</li><li><ul><li>sandbox</li></ul></li><li>container_name: sandboxregistry</li><li>trustsandbox:</li><li>image: docker:dind</li><li>networks:</li><li><ul><li>sandbox</li></ul></li><li>volumes:</li><li><ul><li>notarycerts:/notarycerts</li></ul></li><li>privileged: true</li><li>container_name: trustsandbox</li><li>entrypoint: &quot;&quot;</li><li>command: |-</li><li>sh -c \&#x27;</li><li>cp /notarycerts/root-ca.crt /usr/local/share/ca-certificates/root-ca.crt &amp;&amp;</li><li>update-ca-certificates &amp;&amp;</li><li>dockerd-entrypoint.sh --insecure-registry sandboxregistry:5000\&#x27;</li><li>volumes:</li><li>notarycerts:</li><li>external: false</li><li>networks:</li><li>sandbox:</li><li>external: false</li><li>Save and close the file.</li><li>Run the containers on your local system.</li><li>$ docker-compose up -d</li></ol><p>The first time you run this, the docker-in-docker, Notary server, and registry images are downloaded from Docker Hub.</p><h6><strong>Playing in the sandbox</strong></h6><p>Now that everything is setup, you can go into your trustsandbox container and start testing Docker content trust. From your host machine, obtain a shell in the trustsandbox container.</p><p>$ docker container exec -it trustsandbox sh</p><p>/ #</p><p><strong>Test some trust operations</strong></p><p>Now, pull some images from within the trustsandbox container.</p><ol><li>Download a docker image to test with.</li><li>/ # docker pull docker/trusttest</li><li>docker pull docker/trusttest</li><li>Using default tag: latest</li><li>latest: Pulling from docker/trusttest</li><li>b3dbab3810fc: Pull complete</li><li>a9539b34a6ab: Pull complete</li><li>Digest: sha256:d149ab53f8718e987c3a3024bb8aa0e2caadf6c0328f1d9d850b2a2a67f2819a</li><li>Status: Downloaded newer image for docker/trusttest:latest</li><li>Tag it to be pushed to our sandbox registry:</li><li>/ # docker tag docker/trusttest sandboxregistry:5000/test/trusttest:latest</li><li>Enable content trust.</li><li>/ # export DOCKER_CONTENT_TRUST=1</li><li>Identify the trust server.</li><li>/ # export DOCKER_CONTENT_TRUST_SERVER=https://notaryserver:4443</li></ol><p>This step is only necessary because the sandbox is using its own server. Normally, if you are using the Docker Public Hub this step isn&#x27;t necessary.</p><ol><li>Pull the test image.</li><li>/ # docker pull sandboxregistry:5000/test/trusttest</li><li>Using default tag: latest</li><li>Error: remote trust data does not exist for sandboxregistry:5000/test/trusttest: notaryserver:4443 does not have trust data for sandboxregistry:5000/test/trusttest</li></ol><p>You see an error, because this content doesn&#x27;t exist on the notaryserver yet.</p><ol><li>Push and sign the trusted image.</li><li>/ # docker push sandboxregistry:5000/test/trusttest:latest</li><li>The push refers to a repository <!-- -->[sandboxregistry:5000/test/trusttest]</li><li>5f70bf18a086: Pushed</li><li>c22f7bc058a9: Pushed</li><li>latest: digest: sha256:ebf59c538accdf160ef435f1a19938ab8c0d6bd96aef8d4ddd1b379edf15a926 size: 734</li><li>Signing and pushing trust metadata</li><li>You are about to create a new root signing key passphrase. This passphrase</li><li>will be used to protect the most sensitive key in your signing system. Please</li><li>choose a long, complex passphrase and be careful to keep the password and the</li><li>key file itself secure and backed up. It is highly recommended that you use a</li><li>password manager to generate the passphrase and keep it safe. There will be no</li><li>way to recover this key. You can find the key in your config directory.</li><li>Enter passphrase for new root key with ID 27ec255:</li><li>Repeat passphrase for new root key with ID 27ec255:</li><li>Enter passphrase for new repository key with ID 58233f9 (sandboxregistry:5000/test/trusttest):</li><li>Repeat passphrase for new repository key with ID 58233f9 (sandboxregistry:5000/test/trusttest):</li><li>Finished initializing &quot;sandboxregistry:5000/test/trusttest&quot;</li><li>Successfully signed &quot;sandboxregistry:5000/test/trusttest&quot;:latest</li></ol><p>Because you are pushing this repository for the first time, Docker creates new root and repository keys and asks you for passphrases with which to encrypt them. If you push again after this, it only asks you for repository passphrase so it can decrypt the key and sign again.</p><ol><li>Try pulling the image you just pushed:</li><li>/ # docker pull sandboxregistry:5000/test/trusttest</li><li>Using default tag: latest</li><li>Pull (1 of 1): sandboxregistry:5000/test/trusttest:latest\@sha256:ebf59c538accdf160ef435f1a19938ab8c0d6bd96aef8d4ddd1b379edf15a926</li><li>sha256:ebf59c538accdf160ef435f1a19938ab8c0d6bd96aef8d4ddd1b379edf15a926: Pulling from test/trusttest</li><li>Digest: sha256:ebf59c538accdf160ef435f1a19938ab8c0d6bd96aef8d4ddd1b379edf15a926</li><li>Status: Downloaded newer image for sandboxregistry:5000/test/trusttest\@sha256:ebf59c538accdf160ef435f1a19938ab8c0d6bd96aef8d4ddd1b379edf15a926</li><li>Tagging sandboxregistry:5000/test/trusttest\@sha256:ebf59c538accdf160ef435f1a19938ab8c0d6bd96aef8d4ddd1b379edf15a926 as sandboxregistry:5000/test/trusttest:latest</li></ol><p><strong>Test with malicious images</strong></p><p>What happens when data is corrupted and you try to pull it when trust is enabled? In this section, you go into the sandboxregistry and tamper with some data. Then, you try and pull it.</p><ol><li>Leave the trustsandbox shell and container running.</li><li>Open a new interactive terminal from your host, and obtain a shell into thesandboxregistry container.</li><li>$ docker container exec -it sandboxregistry bash</li><li>root\@65084fc6f047:/#</li><li>List the layers for the test/trusttest image you pushed:</li><li>root\@65084fc6f047:/# ls -l /var/lib/registry/docker/registry/v2/repositories/test/trusttest/_layers/sha256</li><li>total 12</li><li>drwxr-xr-x 2 root root 4096 Jun 10 17:26 a3ed95caeb02ffe68cdd9fd84406680ae93d633cb16422d00e8a7c22955b46d4</li><li>drwxr-xr-x 2 root root 4096 Jun 10 17:26 aac0c133338db2b18ff054943cee3267fe50c75cdee969aed88b1992539ed042</li><li>drwxr-xr-x 2 root root 4096 Jun 10 17:26 cc7629d1331a7362b5e5126beb5bf15ca0bf67eb41eab994c719a45de53255cd</li><li>Change into the registry storage for one of those layers (this is in a different directory):</li><li>root\@65084fc6f047:/# cd /var/lib/registry/docker/registry/v2/blobs/sha256/aa/aac0c133338db2b18ff054943cee3267fe50c75cdee969aed88b1992539ed042</li><li>Add malicious data to one of the trusttest layers:</li><li>root\@65084fc6f047:/# echo &quot;Malicious data&quot; &gt; data</li><li>Go back to your trustsandbox terminal.</li><li>List the trusttest image.</li><li>/ # docker image ls | grep trusttest</li><li>REPOSITORY TAG IMAGE ID CREATED SIZE</li><li>docker/trusttest latest cc7629d1331a 11 months ago 5.025 MB</li><li>sandboxregistry:5000/test/trusttest latest cc7629d1331a 11 months ago 5.025 MB</li><li>sandboxregistry:5000/test/trusttest <code>&lt;none&gt;</code> cc7629d1331a 11 months ago 5.025 MB</li><li>Remove the trusttest:latest image from our local cache.</li><li>/ # docker image rm -f cc7629d1331a</li><li>Untagged: docker/trusttest:latest</li><li>Untagged: sandboxregistry:5000/test/trusttest:latest</li><li>Untagged: sandboxregistry:5000/test/trusttest\@sha256:ebf59c538accdf160ef435f1a19938ab8c0d6bd96aef8d4ddd1b379edf15a926</li><li>Deleted: sha256:cc7629d1331a7362b5e5126beb5bf15ca0bf67eb41eab994c719a45de53255cd</li><li>Deleted: sha256:2a1f6535dc6816ffadcdbe20590045e6cbf048d63fd4cc753a684c9bc01abeea</li><li>Deleted: sha256:c22f7bc058a9a8ffeb32989b5d3338787e73855bf224af7aa162823da015d44c</li></ol><p>Docker does not re-download images that it already has cached, but we want Docker to attempt to download the tampered image from the registry and reject it because it is invalid.</p><ol><li>Pull the image again. This downloads the image from the registry, because we don&#x27;t have it cached.</li><li>/ # docker pull sandboxregistry:5000/test/trusttest</li><li>Using default tag: latest</li><li>Pull (1 of 1): sandboxregistry:5000/test/trusttest:latest\@sha256:35d5bc26fd358da8320c137784fe590d8fcf9417263ef261653e8e1c7f15672e</li><li>sha256:35d5bc26fd358da8320c137784fe590d8fcf9417263ef261653e8e1c7f15672e: Pulling from test/trusttest</li><li>aac0c133338d: Retrying in 5 seconds</li><li>a3ed95caeb02: Download complete</li><li>error pulling image configuration: unexpected EOF</li></ol><p>The pull did not complete because the trust system couldn&#x27;t verify the image.</p><h6><strong>More play in the sandbox</strong></h6><p>Now, you have a full Docker content trust sandbox on your local system, feel free to play with it and see how it behaves. If you find any security issues with Docker, feel free to send us an email at <code style="background-color:lightgray">&lt;security@docker.com&gt;</code>.</p><h6><strong>Cleaning up your sandbox</strong></h6><p>When you are done, and want to clean up all the services you&#x27;ve started and any anonymous volumes that have been created, just run the following command in the directory where you&#x27;ve created your Docker Compose file:</p><p>$ docker-compose down -v</p><h4>Antivirus software and Docker</h4><p><em>Estimated reading time: 1 minute</em></p><p>When antivirus software scans files used by Docker, these files may be locked in a way that causes Docker commands to hang.</p><p>One way to reduce these problems is to add the Docker data directory (/var/lib/docker on Linux or $Env:ProgramData on Windows Server) to the antivirus&#x27;s exclusion list. However, this comes with the trade-off that viruses or malware in Docker images, writable layers of containers, or volumes are not detected. If you do choose to exclude Docker&#x27;s data directory from background virus scanning, you may want to schedule a recurring task that stops Docker, scans the data directory, and restarts Docker.</p><h4>AppArmor security profiles for Docker</h4><p><em>Estimated reading time: 6 minutes</em></p><p>AppArmor (Application Armor) is a Linux security module that protects an operating system and its applications from security threats. To use it, a system administrator associates an AppArmor security profile with each program. Docker expects to find an AppArmor policy loaded and enforced.</p><p>Docker automatically generates and loads a default profile for containers nameddocker-default. On Docker versions 1.13.0 and later, the Docker binary generates this profile in tmpfs and then loads it into the kernel. On Docker versions earlier than 1.13.0, this profile is generated in /etc/apparmor.d/docker instead.</p><p><strong>Note</strong>: This profile is used on containers, not on the Docker Daemon.</p><p>A profile for the Docker Engine daemon exists but it is not currently installed with the debpackages. If you are interested in the source for the daemon profile, it is located in<a href="https://github.com/moby/moby/tree/master/contrib/apparmor">contrib/apparmor</a> in the Docker Engine source repository.</p><h5><strong>Understand the policies</strong></h5><p>The docker-default profile is the default for running containers. It is moderately protective while providing wide application compatibility. The profile is generated from the following<a href="https://github.com/moby/moby/blob/master/profiles/apparmor/template.go">template</a>.</p><p>When you run a container, it uses the docker-default policy unless you override it with the security-opt option. For example, the following explicitly specifies the default policy:</p><p>$ docker run --rm -it --security-opt apparmor=docker-default hello-world</p><h5><strong>Load and unload profiles</strong></h5><p>To load a new profile into AppArmor for use with containers:</p><p>$ apparmor_parser -r -W /path/to/your_profile</p><p>Then, run the custom profile with --security-opt like so:</p><p>$ docker run --rm -it --security-opt apparmor=your_profile hello-world</p><p>To unload a profile from AppArmor:</p><h1>stop apparmor</h1><p>$ /etc/init.d/apparmor stop</p><h1>unload the profile</h1><p>$ apparmor_parser -R /path/to/profile</p><h1>start apparmor</h1><p>$ /etc/init.d/apparmor start</p><h6><strong>Resources for writing profiles</strong></h6><p>The syntax for file globbing in AppArmor is a bit different than some other globbing implementations. It is highly suggested you take a look at some of the below resources with regard to AppArmor profile syntax.</p><ul><li><a href="https://gitlab.com/apparmor/apparmor/wikis/QuickProfileLanguage">Quick Profile Language</a></li><li><a href="https://gitlab.com/apparmor/apparmor/wikis/AppArmor_Core_Policy_Reference#AppArmor_globbing_syntax">Globbing Syntax</a></li></ul><h5><strong>Nginx example profile</strong></h5><p>In this example, you create a custom AppArmor profile for Nginx. Below is the custom profile.</p><p>#include <code style="background-color:lightgray">&lt;tunables/global&gt;</code></p><p>profile docker-nginx flags=(attach_disconnected,mediate_deleted) {</p><p>#include <code style="background-color:lightgray">&lt;abstractions/base&gt;</code></p><p>network inet tcp,</p><p>network inet udp,</p><p>network inet icmp,</p><p>deny network raw,</p><p>deny network packet,</p><p>file,</p><p>umount,</p><p>deny /bin/** wl,</p><p>deny /boot/** wl,</p><p>deny /dev/** wl,</p><p>deny /etc/** wl,</p><p>deny /home/** wl,</p><p>deny /lib/** wl,</p><p>deny /lib64/** wl,</p><p>deny /media/** wl,</p><p>deny /mnt/** wl,</p><p>deny /opt/** wl,</p><p>deny /proc/** wl,</p><p>deny /root/** wl,</p><p>deny /sbin/** wl,</p><p>deny /srv/** wl,</p><p>deny /tmp/** wl,</p><p>deny /sys/** wl,</p><p>deny /usr/** wl,</p><p>audit /** w,</p><p>/var/run/nginx.pid w,</p><p>/usr/sbin/nginx ix,</p><p>deny /bin/dash mrwklx,</p><p>deny /bin/sh mrwklx,</p><p>deny /usr/bin/top mrwklx,</p><p>capability chown,</p><p>capability dac_override,</p><p>capability setuid,</p><p>capability setgid,</p><p>capability net_bind_service,</p><p>deny @{PROC}/* w, # deny write for all files directly in /proc (not in a subdir)</p><h1>deny write to files not in /proc/<code>&lt;number&gt;</code>/<strong> or /proc/sys/</strong></h1><p>deny @{PROC}/{<!-- -->[\^1-9]<!-- -->,<!-- -->[\^1-9][\^0-9]<!-- -->,<!-- -->[\^1-9s][\^0-9y]<!-- -->[\^0-9s]<!-- -->,<!-- -->[\^1-9][\^0-9]<!-- -->[\^0-9][\^0-9]<!-- -->*}/** w,</p><p>deny @{PROC}/sys/<!-- -->[\^k]<!-- -->*<em> w, # deny /proc/sys except /proc/sys/k</em> (effectively /proc/sys/kernel)</p><p>deny @{PROC}/sys/kernel/{?,??,<!-- -->[\^s][\^h]<!-- -->[\^m]<!-- -->*<em>} w, # deny everything except shm</em> in /proc/sys/kernel/</p><p>deny @{PROC}/sysrq-trigger rwklx,</p><p>deny @{PROC}/mem rwklx,</p><p>deny @{PROC}/kmem rwklx,</p><p>deny @{PROC}/kcore rwklx,</p><p>deny mount,</p><p>deny /sys/<!-- -->[\^f]<!-- -->*/** wklx,</p><p>deny /sys/f<!-- -->[\^s]<!-- -->*/** wklx,</p><p>deny /sys/fs/<!-- -->[\^c]<!-- -->*/** wklx,</p><p>deny /sys/fs/c<!-- -->[\^g]<!-- -->*/** wklx,</p><p>deny /sys/fs/cg<!-- -->[\^r]<!-- -->*/** wklx,</p><p>deny /sys/firmware/** rwklx,</p><p>deny /sys/kernel/security/** rwklx,</p><p>}</p><ol><li>Save the custom profile to disk in the /etc/apparmor.d/containers/docker-nginx file.</li></ol><p>The file path in this example is not a requirement. In production, you could use another.</p><ol><li>Load the profile.</li><li>$ sudo apparmor_parser -r -W /etc/apparmor.d/containers/docker-nginx</li><li>Run a container with the profile.</li></ol><p>To run nginx in detached mode:</p><p>$ docker run --security-opt &quot;apparmor=docker-nginx&quot; \</p><p>-p 80:80 -d --name apparmor-nginx nginx</p><ol><li>Exec into the running container.</li><li>$ docker container exec -it apparmor-nginx bash</li><li>Try some operations to test the profile.</li><li>root\@6da5a2a930b9:<!-- -->~<!-- --># ping 8.8.8.8</li><li>ping: Lacking privilege for raw socket.</li><li>root\@6da5a2a930b9:/# top</li><li>bash: /usr/bin/top: Permission denied</li><li>root\@6da5a2a930b9:<!-- -->~<!-- --># touch <!-- -->~<!-- -->/thing</li><li>touch: cannot touch \&#x27;thing\&#x27;: Permission denied</li><li>root\@6da5a2a930b9:/# sh</li><li>bash: /bin/sh: Permission denied</li><li>root\@6da5a2a930b9:/# dash</li><li>bash: /bin/dash: Permission denied</li></ol><p>Congrats! You just deployed a container secured with a custom apparmor profile!</p><h5><strong>Debug AppArmor</strong></h5><p>You can use dmesg to debug problems and aa-status check the loaded profiles.</p><h6><strong>Use dmesg</strong></h6><p>Here are some helpful tips for debugging any problems you might be facing with regard to AppArmor.</p><p>AppArmor sends quite verbose messaging to dmesg. Usually an AppArmor line looks like the following:</p><p>[ 5442.864673]<!-- --> audit: type=1400 audit(1453830992.845:37): apparmor=&quot;ALLOWED&quot; operation=&quot;open&quot; profile=&quot;/usr/bin/docker&quot; name=&quot;/home/jessie/docker/man/man1/docker-attach.1&quot; pid=10923 comm=&quot;docker&quot; requested_mask=&quot;r&quot; denied_mask=&quot;r&quot; fsuid=1000 ouid=0</p><p>In the above example, you can see profile=/usr/bin/docker. This means the user has the docker-engine (Docker Engine Daemon) profile loaded.</p><p><strong>Note</strong>: On version of Ubuntu &gt; 14.04 this is all fine and well, but Trusty users might run into some issues when trying to docker container exec.</p><p>Look at another log line:</p><p>[ 3256.689120]<!-- --> type=1400 audit(1405454041.341:73): apparmor=&quot;DENIED&quot; operation=&quot;ptrace&quot; profile=&quot;docker-default&quot; pid=17651 comm=&quot;docker&quot; requested_mask=&quot;receive&quot; denied_mask=&quot;receive&quot;</p><p>This time the profile is docker-default, which is run on containers by default unless in privileged mode. This line shows that apparmor has denied ptrace in the container. This is exactly as expected.</p><h6><strong>Use aa-status</strong></h6><p>If you need to check which profiles are loaded, you can use aa-status. The output looks like:</p><p>$ sudo aa-status</p><p>apparmor module is loaded.</p><p>14 profiles are loaded.</p><p>1 profiles are in enforce mode.</p><p>docker-default</p><p>13 profiles are in complain mode.</p><p>/usr/bin/docker</p><p>/usr/bin/docker///bin/cat</p><p>/usr/bin/docker///bin/ps</p><p>/usr/bin/docker///sbin/apparmor_parser</p><p>/usr/bin/docker///sbin/auplink</p><p>/usr/bin/docker///sbin/blkid</p><p>/usr/bin/docker///sbin/iptables</p><p>/usr/bin/docker///sbin/mke2fs</p><p>/usr/bin/docker///sbin/modprobe</p><p>/usr/bin/docker///sbin/tune2fs</p><p>/usr/bin/docker///sbin/xtables-multi</p><p>/usr/bin/docker///sbin/zfs</p><p>/usr/bin/docker///usr/bin/xz</p><p>38 processes have profiles defined.</p><p>37 processes are in enforce mode.</p><p>docker-default (6044)</p><p>...</p><p>docker-default (31899)</p><p>1 processes are in complain mode.</p><p>/usr/bin/docker (29756)</p><p>0 processes are unconfined but have a profile defined.</p><p>The above output shows that the docker-default profile running on various container PIDs is in enforce mode. This means AppArmor is actively blocking and auditing in dmesg anything outside the bounds of the docker-default profile.</p><p>The output above also shows the /usr/bin/docker (Docker Engine daemon) profile is running in complain mode. This means AppArmor only logs to dmesg activity outside the bounds of the profile. (Except in the case of Ubuntu Trusty, where some interesting behaviors are enforced.)</p><h5><strong>Contribute Docker&#x27;s AppArmor code</strong></h5><p>Advanced users and package managers can find a profile for /usr/bin/docker (Docker Engine Daemon) underneath <a href="https://github.com/moby/moby/tree/master/contrib/apparmor">contrib/apparmor</a> in the Docker Engine source repository.</p><p>The docker-default profile for containers lives in <a href="https://github.com/moby/moby/tree/master/profiles/apparmor">profiles/apparmor</a>.</p><h4>Seccomp security profiles for Docker</h4><p><em>Estimated reading time: 7 minutes</em></p><p>Secure computing mode (seccomp) is a Linux kernel feature. You can use it to restrict the actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. You can use this feature to restrict your application&#x27;s access.</p><p>This feature is available only if Docker has been built with seccomp and the kernel is configured with CONFIG_SECCOMP enabled. To check if your kernel supports seccomp:</p><p>$ cat /boot/config-<code style="background-color:lightgray">uname -r</code> | grep CONFIG_SECCOMP=</p><p>CONFIG_SECCOMP=y</p><p><strong>Note</strong>: seccomp profiles require seccomp 2.2.1 which is not available on Ubuntu 14.04, Debian Wheezy, or Debian Jessie. To use seccomp on these distributions, you must download the <a href="https://docs.docker.com/engine/installation/linux/docker-ce/binaries/">latest static Linux binaries</a> (rather than packages).</p><h5><strong>Pass a profile for a container</strong></h5><p>The default seccomp profile provides a sane default for running containers with seccomp and disables around 44 system calls out of 300+. It is moderately protective while providing wide application compatibility. The default Docker profile can be found <a href="https://github.com/moby/moby/blob/master/profiles/seccomp/default.json">here</a>).</p><p>In effect, the profile is a whitelist which denies access to system calls by default, then whitelists specific system calls. The profile works by defining a defaultAction of SCMP_ACT_ERRNO and overriding that action only for specific system calls. The effect of SCMP_ACT_ERRNO is to cause a Permission Denied error. Next, the profile defines a specific list of system calls which are fully allowed, because their action is overridden to be SCMP_ACT_ALLOW. Finally, some specific rules are for individual system calls such as personality, socket, socketcall, and others, to allow variants of those system calls with specific arguments.</p><p>seccomp is instrumental for running Docker containers with least privilege. It is not recommended to change the default seccomp profile.</p><p>When you run a container, it uses the default profile unless you override it with the --security-opt option. For example, the following explicitly specifies a policy:</p><p>$ docker run --rm \</p><p>-it \</p><p>--security-opt seccomp=/path/to/seccomp/profile.json \</p><p>hello-world</p><h6><strong>Significant syscalls blocked by the default profile</strong></h6><p>Docker&#x27;s default seccomp profile is a whitelist which specifies the calls that are allowed. The table below lists the significant (but not all) syscalls that are effectively blocked because they are not on the whitelist. The table includes the reason each syscall is blocked rather than white-listed.</p><p>  <strong>Syscall</strong>          <strong>Description</strong></p><hr/><p>  acct                 Accounting syscall which could let containers disable their own resource limits or process accounting. Also gated by CAP<em>SYS_PACCT.
add_key              Prevent containers from using the kernel keyring, which is not namespaced.
adjtimex             Similar to clock_settime and settimeofday, time/date is not namespaced. Also gated by CAP_SYS_TIME.
bpf                  Deny loading potentially persistent bpf programs into kernel, already gated by CAP_SYS_ADMIN.
clock_adjtime        Time/date is not namespaced. Also gated by CAP_SYS_TIME.
clock_settime        Time/date is not namespaced. Also gated by CAP_SYS_TIME.
clone                Deny cloning new namespaces. Also gated by CAP_SYS_ADMIN for CLONE</em>* flags, except CLONE_USERNS.
create_module        Deny manipulation and functions on kernel modules. Obsolete. Also gated by CAP_SYS_MODULE.
delete_module        Deny manipulation and functions on kernel modules. Also gated by CAP_SYS_MODULE.
finit_module         Deny manipulation and functions on kernel modules. Also gated by CAP_SYS_MODULE.
get_kernel_syms      Deny retrieval of exported kernel and module symbols. Obsolete.
get_mempolicy        Syscall that modifies kernel memory and NUMA settings. Already gated by CAP_SYS_NICE.
init_module          Deny manipulation and functions on kernel modules. Also gated by CAP_SYS_MODULE.
ioperm               Prevent containers from modifying kernel I/O privilege levels. Already gated by CAP_SYS_RAWIO.
iopl                 Prevent containers from modifying kernel I/O privilege levels. Already gated by CAP_SYS_RAWIO.
kcmp                 Restrict process inspection capabilities, already blocked by dropping CAP_PTRACE.
kexec_file_load      Sister syscall of kexec_load that does the same thing, slightly different arguments. Also gated by CAP_SYS_BOOT.
kexec_load           Deny loading a new kernel for later execution. Also gated by CAP_SYS_BOOT.
keyctl               Prevent containers from using the kernel keyring, which is not namespaced.
lookup_dcookie       Tracing/profiling syscall, which could leak a lot of information on the host. Also gated by CAP_SYS_ADMIN.
mbind                Syscall that modifies kernel memory and NUMA settings. Already gated by CAP_SYS_NICE.
mount                Deny mounting, already gated by CAP_SYS_ADMIN.
move_pages           Syscall that modifies kernel memory and NUMA settings.
name_to_handle_at    Sister syscall to open_by_handle_at. Already gated by CAP_SYS_NICE.
nfsservctl           Deny interaction with the kernel nfs daemon. Obsolete since Linux 3.1.
open_by_handle_at    Cause of an old container breakout. Also gated by CAP_DAC_READ_SEARCH.
perf_event_open      Tracing/profiling syscall, which could leak a lot of information on the host.
personality          Prevent container from enabling BSD emulation. Not inherently dangerous, but poorly tested, potential for a lot of kernel vulns.
pivot_root           Deny pivot_root, should be privileged operation.
process_vm_readv     Restrict process inspection capabilities, already blocked by dropping CAP_PTRACE.
process_vm_writev    Restrict process inspection capabilities, already blocked by dropping CAP_PTRACE.
ptrace               Tracing/profiling syscall, which could leak a lot of information on the host. Already blocked by dropping CAP_PTRACE.
query_module         Deny manipulation and functions on kernel modules. Obsolete.
quotactl             Quota syscall which could let containers disable their own resource limits or process accounting. Also gated by CAP_SYS_ADMIN.
reboot               Don&#x27;t let containers reboot the host. Also gated by CAP_SYS_BOOT.
request_key          Prevent containers from using the kernel keyring, which is not namespaced.
set_mempolicy        Syscall that modifies kernel memory and NUMA settings. Already gated by CAP_SYS_NICE.
setns                Deny associating a thread with a namespace. Also gated by CAP_SYS_ADMIN.
settimeofday         Time/date is not namespaced. Also gated by CAP_SYS_TIME.
socket, socketcall   Used to send or receive packets and for other socket operations. All socket and socketcall calls are blocked except communication domains AF_UNIX, AF_INET, AF_INET6, AF_NETLINK, and AF_PACKET.
stime                Time/date is not namespaced. Also gated by CAP_SYS_TIME.
swapon               Deny start/stop swapping to file/device. Also gated by CAP_SYS_ADMIN.
swapoff              Deny start/stop swapping to file/device. Also gated by CAP_SYS_ADMIN.
sysfs                Obsolete syscall.
_sysctl             Obsolete, replaced by /proc/sys.
umount               Should be a privileged operation. Also gated by CAP_SYS_ADMIN.
umount2              Should be a privileged operation. Also gated by CAP_SYS_ADMIN.
unshare              Deny cloning new namespaces for processes. Also gated by CAP_SYS_ADMIN, with the exception of unshare --user.
uselib               Older syscall related to shared libraries, unused for a long time.
userfaultfd          Userspace page fault handling, largely needed for process migration.
ustat                Obsolete syscall.
vm86                 In kernel x86 real mode virtual machine. Also gated by CAP_SYS_ADMIN.
vm86old              In kernel x86 real mode virtual machine. Also gated by CAP_SYS_ADMIN.</p><h5><strong>Run without the default seccomp profile</strong></h5><p>You can pass unconfined to run a container without the default seccomp profile.</p><p>$ docker run --rm -it --security-opt seccomp=unconfined debian:jessie \</p><p>unshare --map-root-user --user sh -c whoami</p><h4>Isolate containers with a user namespace</h4><p><em>Estimated reading time: 10 minutes</em></p><p>Linux namespaces provide isolation for running processes, limiting their access to system resources without the running process being aware of the limitations. For more information on Linux namespaces, see <a href="https://www.linux.com/news/understanding-and-securing-linux-namespaces">Linux namespaces</a>.</p><p>The best way to prevent privilege-escalation attacks from within a container is to configure your container&#x27;s applications to run as unprivileged users. For containers whose processes must run as the root user within the container, you can re-map this user to a less-privileged user on the Docker host. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself.</p><h5><strong>About remapping and subordinate user and group IDs</strong></h5><p>The remapping itself is handled by two files: /etc/subuid and /etc/subgid. Each file works the same, but one is concerned with the user ID range, and the other with the group ID range. Consider the following entry in /etc/subuid:</p><p>testuser:231072:65536</p><p>This means that testuser is assigned a subordinate user ID range of 231072 and the next 65536 integers in sequence. UID 231072 is mapped within the namespace (within the container, in this case) as UID 0 (root). UID 231073 is mapped as UID 1, and so forth. If a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, which does not even map to a real user. This means the process has no privileges on the host system at all.</p><p><strong>Multiple ranges</strong></p><p>It is possible to assign multiple subordinate ranges for a given user or group by adding multiple non-overlapping mappings for the same user or group in the /etc/subuid or /etc/subgid file. In this case, Docker uses only the first five mappings, in accordance with the kernel&#x27;s limitation of only five entries in /proc/self/uid_map and /proc/self/gid_map.</p><p>When you configure Docker to use the userns-remap feature, you can optionally specify an existing user and/or group, or you can specify default. If you specify default, a user and group dockremap is created and used for this purpose.</p><p><strong>Warning</strong>: Some distributions, such as RHEL and CentOS 7.3, do not automatically add the new group to the /etc/subuid and /etc/subgid files. You are responsible for editing these files and assigning non-overlapping ranges, in this case. This step is covered in <a href="https://docs.docker.com/engine/security/userns-remap/#prerequisites">Prerequisites</a>.</p><p>It is very important that the ranges not overlap, so that a process cannot gain access in a different namespace. On most Linux distributions, system utilities manage the ranges for you when you add or remove users.</p><p>This re-mapping is transparent to the container, but introduces some configuration complexity in situations where the container needs access to resources on the Docker host, such as bind mounts into areas of the filesystem that the system user cannot write to. From a security standpoint, it is best to avoid these situations.</p><h5><strong>Prerequisites</strong></h5><ol><li>The subordinate UID and GID ranges must be associated with an existing user, even though the association is an implementation detail. The user owns the namespaced storage directories under /var/lib/docker/. If you don&#x27;t want to use an existing user, Docker can create one for you and use that. If you want to use an existing username or user ID, it must already exist. Typically, this means that the relevant entries need to be in /etc/passwd and /etc/group, but if you are using a different authentication back-end, this requirement may translate differently.</li></ol><p>To verify this, use the id command:</p><p>$ id testuser</p><p>uid=1001(testuser) gid=1001(testuser) groups=1001(testuser)</p><ol><li>The way the namespace remapping is handled on the host is using two files, /etc/subuidand /etc/subgid. These files are typically managed automatically when you add or remove users or groups, but on a few distributions such as RHEL and CentOS 7.3, you may need to manage these files manually.</li></ol><p>Each file contains three fields: the username or ID of the user, followed by a beginning UID or GID (which is treated as UID or GID 0 within the namespace) and a maximum number of UIDs or GIDs available to the user. For instance, given the following entry:</p><p>testuser:231072:65536</p><p>This means that user-namespaced processes started by testuser are owned by host UID 231072 (which looks like UID 0 inside the namespace) through 296608 (231072 + 65536). These ranges should not overlap, to ensure that namespaced processes cannot access each other&#x27;s namespaces.</p><p>After adding your user, check /etc/subuid and /etc/subgid to see if your user has an entry in each. If not, you need to add it, being careful to avoid overlap.</p><p>If you want to use the dockremap user automatically created by Docker, check for the dockremap entry in these files <strong>after</strong> configuring and restarting Docker.</p><ol><li>If there are any locations on the Docker host where the unprivileged user needs to write, adjust the permissions of those locations accordingly. This is also true if you want to use the dockremap user automatically created by Docker, but you can&#x27;t modify the permissions until after configuring and restarting Docker.</li><li>Enabling userns-remap effectively masks existing image and container layers, as well as other Docker objects within /var/lib/docker/. This is because Docker needs to adjust the ownership of these resources and actually stores them in a subdirectory within /var/lib/docker/. It is best to enable this feature on a new Docker installation rather than an existing one.</li></ol><p>Along the same lines, if you disable userns-remap you can&#x27;t access any of the resources created while it was enabled.</p><ol><li>Check the <a href="https://docs.docker.com/engine/security/userns-remap/#user-namespace-known-restrictions">limitations</a> on user namespaces to be sure your use case is possible.</li></ol><h5><strong>Enable userns-remap on the daemon</strong></h5><p>You can start dockerd with the --userns-remap flag or follow this procedure to configure the daemon using the daemon.json configuration file. The daemon.json method is recommended. If you use the flag, use the following command as a model:</p><p>$ dockerd --userns-remap=&quot;testuser:testuser&quot;</p><ol><li>Edit /etc/docker/daemon.json. Assuming the file was previously empty, the following entry enables userns-remap using user and group called testuser. You can address the user and group by ID or name. You only need to specify the group name or ID if it is different from the user name or ID. If you provide both the user and group name or ID, separate them by a colon (:) character. The following formats all work for the value, assuming the UID and GID of testuser are 1001:<ul><li>testuser</li><li>testuser:testuser</li><li>1001</li><li>1001:1001</li><li>testuser:1001</li><li>1001:testuser</li></ul></li><li>{</li><li>&quot;userns-remap&quot;: &quot;testuser&quot;</li><li>}</li></ol><p><strong>Note</strong>: To use the dockremap user and have Docker create it for you, set the value to default rather than testuser.</p><p>Save the file and restart Docker.</p><ol><li>If you are using the dockremap user, verify that Docker created it using the id command.</li><li>$ id dockremap</li><li>uid=112(dockremap) gid=116(dockremap) groups=116(dockremap)</li></ol><p>Verify that the entry has been added to /etc/subuid and /etc/subgid:</p><p>$ grep dockremap /etc/subuid</p><p>dockremap:231072:65536</p><p>$ grep dockremap /etc/subgid</p><p>dockremap:231072:65536</p><p>If these entries are not present, edit the files as the root user and assign a starting UID and GID that is the highest-assigned one plus the offset (in this case, 65536). Be careful not to allow any overlap in the ranges.</p><ol><li>Verify that previous images are not available using the docker image ls command. The output should be empty.</li><li>Start a container from the hello-world image.</li><li>$ docker run hello-world</li><li>Verify that a namespaced directory exists within /var/lib/docker/ named with the UID and GID of the namespaced user, owned by that UID and GID, and not group-or-world-readable. Some of the subdirectories are still owned by root and have different permissions.</li><li>$ sudo ls -ld /var/lib/docker/231072.231072/</li><li>drwx------ 11 231072 231072 11 Jun 21 21:19 /var/lib/docker/231072.231072/</li><li>$ sudo ls -l /var/lib/docker/231072.231072/</li><li>total 14</li><li>drwx------ 5 231072 231072 5 Jun 21 21:19 aufs</li><li>drwx------ 3 231072 231072 3 Jun 21 21:21 containers</li><li>drwx------ 3 root root 3 Jun 21 21:19 image</li><li>drwxr-x--- 3 root root 3 Jun 21 21:19 network</li><li>drwx------ 4 root root 4 Jun 21 21:19 plugins</li><li>drwx------ 2 root root 2 Jun 21 21:19 swarm</li><li>drwx------ 2 231072 231072 2 Jun 21 21:21 tmp</li><li>drwx------ 2 root root 2 Jun 21 21:19 trust</li><li>drwx------ 2 231072 231072 3 Jun 21 21:19 volumes</li></ol><p>Your directory listing may have some differences, especially if you user a different container storage driver than aufs.</p><p>The directories which are owned by the remapped user are used instead of the same directories directly beneath /var/lib/docker/ and the unused versions (such as /var/lib/docker/tmp/ in the example here) can be removed. Docker does not use them while userns-remap is enabled.</p><h5><strong>Disable namespace remapping for a container</strong></h5><p>If you enable user namespaces on the daemon, all containers are started with user namespaces enabled by default. In some situations, such as privileged containers, you may need to disable user namespaces for a specific container. See <a href="https://docs.docker.com/engine/security/userns-remap/#user-namespace-known-restrictions">user namespace known limitations</a> for some of these limitations.</p><p>To disable user namespaces for a specific container, add the --userns=host flag to the docker container create, docker container run, or docker container exec command.</p><h5><strong>User namespace known limitations</strong></h5><p>The following standard Docker features are incompatible with running a Docker daemon with user namespaces enabled:</p><ul><li>sharing PID or NET namespaces with the host (--pid=host or --network=host).</li><li>external (volume or storage) drivers which are unaware or incapable of using daemon user mappings.</li><li>Using the --privileged mode flag on docker run without also specifying--userns=host.</li></ul><p>User namespaces are an advanced feature and require coordination with other capabilities. For example, if volumes are mounted from the host, file ownership must be pre-arranged need read or write access to the volume contents.</p><p>While the root user inside a user-namespaced container process has many of the expected privileges of the superuser within the container, the Linux kernel imposes restrictions based on internal knowledge that this is a user-namespaced process. One notable restriction is the inability to use the mknod command. Permission is denied for device creation within the container when run by the root user.</p><h3>Scale Your App</h3><h4>Swarm mode overview</h4><p>To use Docker in swarm mode, install Docker. See <a href="https://docs.docker.com/install/">installation instructions</a> for all operating systems and platforms.</p><p>Current versions of Docker include swarm mode for natively managing a cluster of Docker Engines called a swarm. Use the Docker CLI to create a swarm, deploy application services to a swarm, and manage swarm behavior.</p><p>If you are using a Docker version prior to 1.12.0, you can use <a href="https://docs.docker.com/swarm/">standalone swarm</a>, but we recommend updating.</p><h5><strong>Feature highlights</strong></h5><ul><li><strong>Cluster management integrated with Docker Engine:</strong> Use the Docker Engine CLI to create a swarm of Docker Engines where you can deploy application services. You don&#x27;t need additional orchestration software to create or manage a swarm.</li><li><strong>Decentralized design:</strong> Instead of handling differentiation between node roles at deployment time, the Docker Engine handles any specialization at runtime. You can deploy both kinds of nodes, managers and workers, using the Docker Engine. This means you can build an entire swarm from a single disk image.</li><li><strong>Declarative service model:</strong> Docker Engine uses a declarative approach to let you define the desired state of the various services in your application stack. For example, you might describe an application comprised of a web front end service with message queueing services and a database backend.</li><li><strong>Scaling:</strong> For each service, you can declare the number of tasks you want to run. When you scale up or down, the swarm manager automatically adapts by adding or removing tasks to maintain the desired state.</li><li><strong>Desired state reconciliation:</strong> The swarm manager node constantly monitors the cluster state and reconciles any differences between the actual state and your expressed desired state. For example, if you set up a service to run 10 replicas of a container, and a worker machine hosting two of those replicas crashes, the manager creates two new replicas to replace the replicas that crashed. The swarm manager assigns the new replicas to workers that are running and available.</li><li><strong>Multi-host networking:</strong> You can specify an overlay network for your services. The swarm manager automatically assigns addresses to the containers on the overlay network when it initializes or updates the application.</li><li><strong>Service discovery:</strong> Swarm manager nodes assign each service in the swarm a unique DNS name and load balances running containers. You can query every container running in the swarm through a DNS server embedded in the swarm.</li><li><strong>Load balancing:</strong> You can expose the ports for services to an external load balancer. Internally, the swarm lets you specify how to distribute service containers between nodes.</li><li><strong>Secure by default:</strong> Each node in the swarm enforces TLS mutual authentication and encryption to secure communications between itself and all other nodes. You have the option to use self-signed root certificates or certificates from a custom root CA.</li><li><strong>Rolling updates:</strong> At rollout time you can apply service updates to nodes incrementally. The swarm manager lets you control the delay between service deployment to different sets of nodes. If anything goes wrong, you can roll-back a task to a previous version of the service.</li></ul><h5><strong>What&#x27;s next?</strong></h5><h6><strong>Swarm mode key concepts and tutorial</strong></h6><ul><li>Learn swarm mode <a href="https://docs.docker.com/engine/swarm/key-concepts/">key concepts</a>.</li><li>Get started with the <a href="https://docs.docker.com/engine/swarm/swarm-tutorial/">Swarm mode tutorial</a>.</li></ul><h6><strong>Swarm mode CLI commands</strong></h6><p>Explore swarm mode CLI commands</p><ul><li><a href="https://docs.docker.com/engine/reference/commandline/swarm_init/">swarm init</a></li><li><a href="https://docs.docker.com/engine/reference/commandline/swarm_join/">swarm join</a></li><li><a href="https://docs.docker.com/engine/reference/commandline/service_create/">service create</a></li><li><a href="https://docs.docker.com/engine/reference/commandline/service_inspect/">service inspect</a></li><li><a href="https://docs.docker.com/engine/reference/commandline/service_ls/">service ls</a></li><li><a href="https://docs.docker.com/engine/reference/commandline/service_rm/">service rm</a></li><li><a href="https://docs.docker.com/engine/reference/commandline/service_scale/">service scale</a></li><li><a href="https://docs.docker.com/engine/reference/commandline/service_ps/">service ps</a></li><li><a href="https://docs.docker.com/engine/reference/commandline/service_update/">service update</a></li></ul><h4>Swarm mode key concepts</h4><p><em>Estimated reading time: 4 minutes</em></p><p>This topic introduces some of the concepts unique to the cluster management and orchestration features of Docker Engine 1.12.</p><h5><strong>What is a swarm?</strong></h5><p>The cluster management and orchestration features embedded in the Docker Engine are built using <a href="https://github.com/docker/swarmkit/">swarmkit</a>. Swarmkit is a separate project which implements Docker&#x27;s orchestration layer and is used directly within Docker.</p><p>A swarm consists of multiple Docker hosts which run in <strong>swarm mode</strong> and act as managers (to manage membership and delegation) and workers (which run <a href="https://docs.docker.com/engine/swarm/key-concepts/#services-and-tasks">swarm services</a>). A given Docker host can be a manager, a worker, or perform both roles. When you create a service, you define its optimal state (number of replicas, network and storage resources available to it, ports the service exposes to the outside world, and more). Docker works to maintain that desired state. For instance, if a worker node becomes unavailable, Docker schedules that node&#x27;s tasks on other nodes. A task is a running container which is part of a swarm service and managed by a swarm manager, as opposed to a standalone container.</p><p>One of the key advantages of swarm services over standalone containers is that you can modify a service&#x27;s configuration, including the networks and volumes it is connected to, without the need to manually restart the service. Docker will update the configuration, stop the service tasks with the out of date configuration, and create new ones matching the desired configuration.</p><p>When Docker is running in swarm mode, you can still run standalone containers on any of the Docker hosts participating in the swarm, as well as swarm services. A key difference between standalone containers and swarm services is that only swarm managers can manage a swarm, while standalone containers can be started on any daemon. Docker daemons can participate in a swarm as managers, workers, or both.</p><p>In the same way that you can use <a href="https://docs.docker.com/compose/">Docker Compose</a> to define and run containers, you can define and run swarm service <a href="https://docs.docker.com/get-started/part5/">stacks</a>.</p><p>Keep reading for details about concepts relating to Docker swarm services, including nodes, services, tasks, and load balancing.</p><h5><strong>Nodes</strong></h5><p>A <strong>node</strong> is an instance of the Docker engine participating in the swarm. You can also think of this as a Docker node. You can run one or more nodes on a single physical computer or cloud server, but production swarm deployments typically include Docker nodes distributed across multiple physical and cloud machines.</p><p>To deploy your application to a swarm, you submit a service definition to a <strong>manager node</strong>. The manager node dispatches units of work called <a href="https://docs.docker.com/engine/swarm/key-concepts/#services-and-tasks">tasks</a> to worker nodes.</p><p>Manager nodes also perform the orchestration and cluster management functions required to maintain the desired state of the swarm. Manager nodes elect a single leader to conduct orchestration tasks.</p><p><strong>Worker nodes</strong> receive and execute tasks dispatched from manager nodes. By default manager nodes also run services as worker nodes, but you can configure them to run manager tasks exclusively and be manager-only nodes. An agent runs on each worker node and reports on the tasks assigned to it. The worker node notifies the manager node of the current state of its assigned tasks so that the manager can maintain the desired state of each worker.</p><h5><strong>Services and tasks</strong></h5><p>A <strong>service</strong> is the definition of the tasks to execute on the manager or worker nodes. It is the central structure of the swarm system and the primary root of user interaction with the swarm.</p><p>When you create a service, you specify which container image to use and which commands to execute inside running containers.</p><p>In the <strong>replicated services</strong> model, the swarm manager distributes a specific number of replica tasks among the nodes based upon the scale you set in the desired state.</p><p>For <strong>global services</strong>, the swarm runs one task for the service on every available node in the cluster.</p><p>A <strong>task</strong> carries a Docker container and the commands to run inside the container. It is the atomic scheduling unit of swarm. Manager nodes assign tasks to worker nodes according to the number of replicas set in the service scale. Once a task is assigned to a node, it cannot move to another node. It can only run on the assigned node or fail.</p><h5><strong>Load balancing</strong></h5><p>The swarm manager uses <strong>ingress load balancing</strong> to expose the services you want to make available externally to the swarm. The swarm manager can automatically assign the service a <strong>PublishedPort</strong> or you can configure a PublishedPort for the service. You can specify any unused port. If you do not specify a port, the swarm manager assigns the service a port in the 30000-32767 range.</p><p>External components, such as cloud load balancers, can access the service on the PublishedPort of any node in the cluster whether or not the node is currently running the task for the service. All nodes in the swarm route ingress connections to a running task instance.</p><p>Swarm mode has an internal DNS component that automatically assigns each service in the swarm a DNS entry. The swarm manager uses <strong>internal load balancing</strong> to distribute requests among services within the cluster based upon the DNS name of the service.</p><h5><strong>What&#x27;s next?</strong></h5><ul><li>Read the <a href="https://docs.docker.com/engine/swarm/">swarm mode overview</a>.</li><li>Get started with the <a href="https://docs.docker.com/engine/swarm/swarm-tutorial/">swarm mode tutorial</a>.</li></ul><h4>Getting started with swarm mode</h4><p><em>Estimated reading time: 4 minutes</em></p><p>This tutorial introduces you to the features of Docker Engine Swarm mode. You may want to familiarize yourself with the <a href="https://docs.docker.com/engine/swarm/key-concepts/">key concepts</a> before you begin.</p><p>The tutorial guides you through the following activities:</p><ul><li>initializing a cluster of Docker Engines in swarm mode</li><li>adding nodes to the swarm</li><li>deploying application services to the swarm</li><li>managing the swarm once you have everything running</li></ul><p>This tutorial uses Docker Engine CLI commands entered on the command line of a terminal window.</p><p>If you are brand new to Docker, see <a href="https://docs.docker.com/engine/">About Docker Engine</a>.</p><h5><strong>Set up</strong></h5><p>To run this tutorial, you need the following:</p><ul><li><a href="https://docs.docker.com/engine/swarm/swarm-tutorial/#three-networked-host-machines">three Linux hosts which can communicate over a network, with Docker installed</a></li><li><a href="https://docs.docker.com/engine/swarm/swarm-tutorial/#docker-engine-1-12-or-newer">Docker Engine 1.12 or later installed</a></li><li><a href="https://docs.docker.com/engine/swarm/swarm-tutorial/#the-ip-address-of-the-manager-machine">the IP address of the manager machine</a></li><li><a href="https://docs.docker.com/engine/swarm/swarm-tutorial/#open-protocols-and-ports-between-the-hosts">open ports between the hosts</a></li></ul><h6><strong>Three networked host machines</strong></h6><p>This tutorial requires three Linux hosts which have Docker installed and can communicate over a network. These can be physical machines, virtual machines, Amazon EC2 instances, or hosted in some other way. You can even use Docker Machine from a Linux, Mac, or Windows host. Check out <a href="https://docs.docker.com/get-started/part4/#prerequisites">Getting started - Swarms</a> for one possible set-up for the hosts.</p><p>One of these machines is a manager (called manager1) and two of them are workers (worker1and worker2).</p><p><strong>Note</strong>: You can follow many of the tutorial steps to test single-node swarm as well, in which case you need only one host. Multi-node commands do not work, but you can initialize a swarm, create services, and scale them.</p><h6><strong>Docker Engine 1.12 or newer</strong></h6><p>This tutorial requires Docker Engine 1.12 or newer on each of the host machines. Install Docker Engine and verify that the Docker Engine daemon is running on each of the machines. You can get the latest version of Docker Engine as follows:</p><ul><li><a href="https://docs.docker.com/engine/swarm/swarm-tutorial/#install-docker-engine-on-linux-machines">install Docker Engine on Linux machines</a></li><li><a href="https://docs.docker.com/engine/swarm/swarm-tutorial/#use-docker-for-mac-or-docker-for-windows">use Docker for Mac or Docker for Windows</a></li></ul><p><strong>INSTALL DOCKER ENGINE ON LINUX MACHINES</strong></p><p>If you are using Linux based physical computers or cloud-provided computers as hosts, simply follow the <a href="https://docs.docker.com/engine/installation/">Linux install instructions</a> for your platform. Spin up the three machines, and you are ready. You can test both single-node and multi-node swarm scenarios on Linux machines.</p><p><strong>USE DOCKER FOR MAC OR DOCKER FOR WINDOWS</strong></p><p>Alternatively, install the latest <a href="https://docs.docker.com/docker-for-mac/">Docker for Mac</a> or <a href="https://docs.docker.com/docker-for-windows/">Docker for Windows</a> application on one computer. You can test both single-node and multi-node swarm from this computer, but you need to use Docker Machine to test the multi-node scenarios.</p><ul><li>You can use Docker for Mac or Windows to test single-node features of swarm mode, including initializing a swarm with a single node, creating services, and scaling services. Docker &quot;Moby&quot; on Hyperkit (Mac) or Hyper-V (Windows) serve as the single swarm node.</li><li>Currently, you cannot use Docker for Mac or Docker for Windows alone to test a multi-nodeswarm. However, you can use the included version of <a href="https://docs.docker.com/machine/overview/">Docker Machine</a> to create the swarm nodes (see <a href="https://docs.docker.com/machine/get-started/">Get started with Docker Machine and a local VM</a>), then follow the tutorial for all multi-node features. For this scenario, you run commands from a Docker for Mac or Docker for Windows host, but that Docker host itself is not participating in the swarm. After you create the nodes, you can run all swarm commands as shown from the Mac terminal or Windows PowerShell with Docker for Mac or Docker for Windows running.</li></ul><h6><strong>The IP address of the manager machine</strong></h6><p>The IP address must be assigned to a network interface available to the host operating system. All nodes in the swarm need to connect to the manager at the IP address.</p><p>Because other nodes contact the manager node on its IP address, you should use a fixed IP address.</p><p>You can run ifconfig on Linux or macOS to see a list of the available network interfaces.</p><p>If you are using Docker Machine, you can get the manager IP with either docker-machine ls or docker-machine ip <code style="background-color:lightgray">&lt;MACHINE-NAME&gt;</code> --- for example, docker-machine ip manager1.</p><p>The tutorial uses manager1 : 192.168.99.100.</p><h6><strong>Open protocols and ports between the hosts</strong></h6><p>The following ports must be available. On some systems, these ports are open by default.</p><ul><li><strong>TCP port 2377</strong> for cluster management communications</li><li><strong>TCP</strong> and <strong>UDP port 7946</strong> for communication among nodes</li><li><strong>UDP port 4789</strong> for overlay network traffic</li></ul><p>If you plan on creating an overlay network with encryption (--opt encrypted), you also need to ensure <strong>ip protocol 50</strong> (<strong>ESP</strong>) traffic is allowed.</p><h5><strong>What&#x27;s next?</strong></h5><p>After you have set up your environment, you are ready to <a href="https://docs.docker.com/engine/swarm/swarm-tutorial/create-swarm/">create a swarm</a>.</p><h4>Create a swarm</h4><p><em>Estimated reading time: 2 minutes</em></p><p>After you complete the <a href="https://docs.docker.com/engine/swarm/swarm-tutorial/">tutorial setup</a> steps, you&#x27;re ready to create a swarm. Make sure the Docker Engine daemon is started on the host machines.</p><ol><li>Open a terminal and ssh into the machine where you want to run your manager node. This tutorial uses a machine named manager1. If you use Docker Machine, you can connect to it via SSH using the following command:</li><li>$ docker-machine ssh manager1</li><li>Run the following command to create a new swarm:</li><li>docker swarm init --advertise-addr <code>&lt;MANAGER-IP&gt;</code></li></ol><p><strong>Note</strong>: If you are using Docker for Mac or Docker for Windows to test single-node swarm, simply run docker swarm init with no arguments. There is no need to specify --advertise-addr in this case. To learn more, see the topic on how to <a href="https://docs.docker.com/engine/swarm/swarm-tutorial/#use-docker-for-mac-or-docker-for-windows">Use Docker for Mac or Docker for Windows</a> with Swarm.</p><p>In the tutorial, the following command creates a swarm on the manager1 machine:</p><p>$ docker swarm init --advertise-addr 192.168.99.100</p><p>Swarm initialized: current node (dxn1zf6l61qsb1josjja83ngz) is now a manager.</p><p>To add a worker to this swarm, run the following command:</p><p>docker swarm join \</p><p>--token SWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c \</p><p>192.168.99.100:2377</p><p>To add a manager to this swarm, run \&#x27;docker swarm join-token manager\&#x27; and follow the instructions.</p><p>The --advertise-addr flag configures the manager node to publish its address as 192.168.99.100. The other nodes in the swarm must be able to access the manager at the IP address.</p><p>The output includes the commands to join new nodes to the swarm. Nodes will join as managers or workers depending on the value for the --token flag.</p><ol><li>Run docker info to view the current state of the swarm:</li><li>$ docker info</li><li>Containers: 2</li><li>Running: 0</li><li>Paused: 0</li><li>Stopped: 2</li><li>...snip...</li><li>Swarm: active</li><li>NodeID: dxn1zf6l61qsb1josjja83ngz</li><li>Is Manager: true</li><li>Managers: 1</li><li>Nodes: 1</li><li>...snip...</li><li>Run the docker node ls command to view information about nodes:</li><li>$ docker node ls</li><li>ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS</li><li>dxn1zf6l61qsb1josjja83ngz * manager1 Ready Active Leader</li></ol><p>The * next to the node ID indicates that you&#x27;re currently connected on this node.</p><p>Docker Engine swarm mode automatically names the node for the machine host name. The tutorial covers other columns in later steps.</p><h5><strong>What&#x27;s next?</strong></h5><p>In the next section of the tutorial, we <a href="https://docs.docker.com/engine/swarm/swarm-tutorial/add-nodes/">add two more nodes</a> to the cluster.</p><h4>Add nodes to the swarm</h4><p><em>Estimated reading time: 2 minutes</em></p><p>Once you&#x27;ve <a href="https://docs.docker.com/engine/swarm/swarm-tutorial/create-swarm/">created a swarm</a> with a manager node, you&#x27;re ready to add worker nodes.</p><ol><li>Open a terminal and ssh into the machine where you want to run a worker node. This tutorial uses the name worker1.</li><li>Run the command produced by the docker swarm init output from the <a href="https://docs.docker.com/engine/swarm/swarm-tutorial/create-swarm/">Create a swarm</a>tutorial step to create a worker node joined to the existing swarm:</li><li>$ docker swarm join \</li><li>--token SWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c \</li><li>192.168.99.100:2377</li><li>This node joined a swarm as a worker.</li></ol><p>If you don&#x27;t have the command available, you can run the following command on a manager node to retrieve the join command for a worker:</p><p>$ docker swarm join-token worker</p><p>To add a worker to this swarm, run the following command:</p><p>docker swarm join \</p><p>--token SWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c \</p><p>192.168.99.100:2377</p><ol><li>Open a terminal and ssh into the machine where you want to run a second worker node. This tutorial uses the name worker2.</li><li>Run the command produced by the docker swarm init output from the <a href="https://docs.docker.com/engine/swarm/swarm-tutorial/create-swarm/">Create a swarm</a>tutorial step to create a second worker node joined to the existing swarm:</li><li>$ docker swarm join \</li><li>--token SWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c \</li><li>192.168.99.100:2377</li><li>This node joined a swarm as a worker.</li><li>Open a terminal and ssh into the machine where the manager node runs and run the docker node ls command to see the worker nodes:</li><li>ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS</li><li>03g1y59jwfg7cf99w4lt0f662 worker2 Ready Active</li><li>9j68exjopxe7wfl6yuxml7a7j worker1 Ready Active</li><li>dxn1zf6l61qsb1josjja83ngz * manager1 Ready Active Leader</li></ol><p>The MANAGER column identifies the manager nodes in the swarm. The empty status in this column for worker1 and worker2 identifies them as worker nodes.</p><p>Swarm management commands like docker node ls only work on manager nodes.</p><h5><strong>What&#x27;s next?</strong></h5><p>Now your swarm consists of a manager and two worker nodes. In the next step of the tutorial, you <a href="https://docs.docker.com/engine/swarm/swarm-tutorial/deploy-service/">deploy a service</a> to the swarm.</p><h4>Deploy a service to the swarm</h4><p><em>Estimated reading time: 1 minute</em></p><p>After you <a href="https://docs.docker.com/engine/swarm/swarm-tutorial/create-swarm/">create a swarm</a>, you can deploy a service to the swarm. For this tutorial, you also <a href="https://docs.docker.com/engine/swarm/swarm-tutorial/add-nodes/">added worker nodes</a>, but that is not a requirement to deploy a service.</p><ol><li>Open a terminal and ssh into the machine where you run your manager node. For example, the tutorial uses a machine named manager1.</li><li>Run the following command:</li><li>$ docker service create --replicas 1 --name helloworld alpine ping docker.com</li><li>9uk4639qpg7npwf3fn2aasksr<ul><li>The docker service create command creates the service.</li><li>The --name flag names the service helloworld.</li><li>The --replicas flag specifies the desired state of 1 running instance.</li><li>The arguments alpine ping docker.com define the service as an Alpine Linux container that executes the command ping docker.com.</li></ul></li><li>Run docker service ls to see the list of running services:</li><li>$ docker service ls</li><li>ID NAME SCALE IMAGE COMMAND</li><li>9uk4639qpg7n helloworld 1/1 alpine ping docker.com</li></ol><h5><strong>What&#x27;s next?</strong></h5><p>Now you&#x27;ve deployed a service to the swarm, you&#x27;re ready to <a href="https://docs.docker.com/engine/swarm/swarm-tutorial/inspect-service/">inspect the service</a>.</p><h4>Inspect a service on the swarm</h4><p><em>Estimated reading time: 2 minutes</em></p><p>When you have <a href="https://docs.docker.com/engine/swarm/swarm-tutorial/deploy-service/">deployed a service</a> to your swarm, you can use the Docker CLI to see details about the service running in the swarm.</p><ol><li>If you haven&#x27;t already, open a terminal and ssh into the machine where you run your manager node. For example, the tutorial uses a machine named manager1.</li><li>Run docker service inspect --pretty <code>&lt;SERVICE-ID&gt;</code> to display the details about a service in an easily readable format.</li></ol><p>To see the details on the helloworld service:</p><p>[manager1]<!-- -->$ docker service inspect --pretty helloworld</p><p>ID: 9uk4639qpg7npwf3fn2aasksr</p><p>Name: helloworld</p><p>Service Mode: REPLICATED</p><p>Replicas: 1</p><p>Placement:</p><p>UpdateConfig:</p><p>Parallelism: 1</p><p>ContainerSpec:</p><p>Image: alpine</p><p>Args: ping docker.com</p><p>Resources:</p><p>Endpoint Mode: vip</p><p><strong>Tip</strong>: To return the service details in json format, run the same command without the --pretty flag.</p><p>[manager1]<!-- -->$ docker service inspect helloworld</p><p>[</p><p>{</p><p>&quot;ID&quot;: &quot;9uk4639qpg7npwf3fn2aasksr&quot;,</p><p>&quot;Version&quot;: {</p><p>&quot;Index&quot;: 418</p><p>},</p><p>&quot;CreatedAt&quot;: &quot;2016-06-16T21:57:11.622222327Z&quot;,</p><p>&quot;UpdatedAt&quot;: &quot;2016-06-16T21:57:11.622222327Z&quot;,</p><p>&quot;Spec&quot;: {</p><p>&quot;Name&quot;: &quot;helloworld&quot;,</p><p>&quot;TaskTemplate&quot;: {</p><p>&quot;ContainerSpec&quot;: {</p><p>&quot;Image&quot;: &quot;alpine&quot;,</p><p>&quot;Args&quot;: [</p><p>&quot;ping&quot;,</p><p>&quot;docker.com&quot;</p><p>]</p><p>},</p><p>&quot;Resources&quot;: {</p><p>&quot;Limits&quot;: {},</p><p>&quot;Reservations&quot;: {}</p><p>},</p><p>&quot;RestartPolicy&quot;: {</p><p>&quot;Condition&quot;: &quot;any&quot;,</p><p>&quot;MaxAttempts&quot;: 0</p><p>},</p><p>&quot;Placement&quot;: {}</p><p>},</p><p>&quot;Mode&quot;: {</p><p>&quot;Replicated&quot;: {</p><p>&quot;Replicas&quot;: 1</p><p>}</p><p>},</p><p>&quot;UpdateConfig&quot;: {</p><p>&quot;Parallelism&quot;: 1</p><p>},</p><p>&quot;EndpointSpec&quot;: {</p><p>&quot;Mode&quot;: &quot;vip&quot;</p><p>}</p><p>},</p><p>&quot;Endpoint&quot;: {</p><p>&quot;Spec&quot;: {}</p><p>}</p><p>}</p><p>]</p><ol><li>Run docker service ps <code>&lt;SERVICE-ID&gt;</code> to see which nodes are running the service:</li><li>[manager1]<!-- -->$ docker service ps helloworld</li><li>NAME IMAGE NODE DESIRED STATE LAST STATE</li><li>helloworld.1.8p1vev3fq5zm0mi8g0as41w35 alpine worker2 Running Running 3 minutes</li></ol><p>In this case, the one instance of the helloworld service is running on the worker2 node. You may see the service running on your manager node. By default, manager nodes in a swarm can execute tasks just like worker nodes.</p><p>Swarm also shows you the DESIRED STATE and LAST STATE of the service task so you can see if tasks are running according to the service definition.</p><ol><li>Run docker ps on the node where the task is running to see details about the container for the task.</li></ol><p><strong>Tip</strong>: If helloworld is running on a node other than your manager node, you must ssh to that node.</p><p>[worker2]<!-- -->$docker ps</p><p>CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES</p><p>e609dde94e47 alpine:latest &quot;ping docker.com&quot; 3 minutes ago Up 3 minutes helloworld.1.8p1vev3fq5zm0mi8g0as41w35</p><h5><strong>What&#x27;s next?</strong></h5><p>Next, you can <a href="https://docs.docker.com/engine/swarm/swarm-tutorial/scale-service/">change the scale</a> for the service running in the swarm.</p><h4>Scale the service in the swarm</h4><p><em>Estimated reading time: 1 minute</em></p><p>Once you have <a href="https://docs.docker.com/engine/swarm/swarm-tutorial/deploy-service/">deployed a service</a> to a swarm, you are ready to use the Docker CLI to scale the number of containers in the service. Containers running in a service are called &quot;tasks.&quot;</p><ol><li>If you haven&#x27;t already, open a terminal and ssh into the machine where you run your manager node. For example, the tutorial uses a machine named manager1.</li><li>Run the following command to change the desired state of the service running in the swarm:</li><li>$ docker service scale <code>&lt;SERVICE-ID&gt;=&lt;NUMBER-OF-TASKS&gt;</code></li></ol><p>For example:</p><p>$ docker service scale helloworld=5</p><p>helloworld scaled to 5</p><ol><li>Run docker service ps <code>&lt;SERVICE-ID&gt;</code> to see the updated task list:</li><li>$ docker service ps helloworld</li><li>NAME IMAGE NODE DESIRED STATE CURRENT STATE</li><li>helloworld.1.8p1vev3fq5zm0mi8g0as41w35 alpine worker2 Running Running 7 minutes</li><li>helloworld.2.c7a7tcdq5s0uk3qr88mf8xco6 alpine worker1 Running Running 24 seconds</li><li>helloworld.3.6crl09vdcalvtfehfh69ogfb1 alpine worker1 Running Running 24 seconds</li><li>helloworld.4.auky6trawmdlcne8ad8phb0f1 alpine manager1 Running Running 24 seconds</li><li>helloworld.5.ba19kca06l18zujfwxyc5lkyn alpine worker2 Running Running 24 seconds</li></ol><p>You can see that swarm has created 4 new tasks to scale to a total of 5 running instances of Alpine Linux. The tasks are distributed between the three nodes of the swarm. One is running on manager1.</p><ol><li>Run docker ps to see the containers running on the node where you&#x27;re connected. The following example shows the tasks running on manager1:</li><li>$ docker ps</li><li>CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES</li><li>528d68040f95 alpine:latest &quot;ping docker.com&quot; About a minute ago Up About a minute helloworld.4.auky6trawmdlcne8ad8phb0f1</li></ol><p>If you want to see the containers running on other nodes, ssh into those nodes and run the docker ps command.</p><h5><strong>What&#x27;s next?</strong></h5><p>At this point in the tutorial, you&#x27;re finished with the helloworld service. The next step shows how to <a href="https://docs.docker.com/engine/swarm/swarm-tutorial/delete-service/">delete the service</a>.</p><h4>Delete the service running on the swarm</h4><p><em>Estimated reading time: 1 minute</em></p><p>The remaining steps in the tutorial don&#x27;t use the helloworld service, so now you can delete the service from the swarm.</p><ol><li>If you haven&#x27;t already, open a terminal and ssh into the machine where you run your manager node. For example, the tutorial uses a machine named manager1.</li><li>Run docker service rm helloworld to remove the helloworld service.</li><li>$ docker service rm helloworld</li><li>helloworld</li><li>Run docker service inspect <code>&lt;SERVICE-ID&gt;</code> to verify that the swarm manager removed the service. The CLI returns a message that the service is not found:</li><li>$ docker service inspect helloworld</li><li>[]</li><li>Error: no such service: helloworld</li><li>Even though the service no longer exists, the task containers take a few seconds to clean up. You can use docker ps on the nodes to verify when the tasks have been removed.</li><li>$ docker ps</li><li>CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES</li><li>db1651f50347 alpine:latest &quot;ping docker.com&quot; 44 minutes ago Up 46 seconds helloworld.5.9lkmos2beppihw95vdwxy1j3w</li><li>43bf6e532a92 alpine:latest &quot;ping docker.com&quot; 44 minutes ago Up 46 seconds helloworld.3.a71i8rp6fua79ad43ycocl4t2</li><li>5a0fb65d8fa7 alpine:latest &quot;ping docker.com&quot; 44 minutes ago Up 45 seconds helloworld.2.2jpgensh7d935qdc857pxulfr</li><li>afb0ba67076f alpine:latest &quot;ping docker.com&quot; 44 minutes ago Up 46 seconds helloworld.4.1c47o7tluz7drve4vkm2m5olx</li><li>688172d3bfaa alpine:latest &quot;ping docker.com&quot; 45 minutes ago Up About a minute helloworld.1.74nbhb3fhud8jfrhigd7s29we</li><li>$ docker ps</li><li>CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS</li></ol><h5><strong>What&#x27;s next?</strong></h5><p>In the next step of the tutorial, you set up a new service and apply a <a href="https://docs.docker.com/engine/swarm/swarm-tutorial/rolling-update/">rolling update</a>.</p><h4>Apply rolling updates to a service</h4><p><em>Estimated reading time: 4 minutes</em></p><p>In a previous step of the tutorial, you <a href="https://docs.docker.com/engine/swarm/swarm-tutorial/scale-service/">scaled</a> the number of instances of a service. In this part of the tutorial, you deploy a service based on the Redis 3.0.6 container image. Then you upgrade the service to use the Redis 3.0.7 container image using rolling updates.</p><ol><li>If you haven&#x27;t already, open a terminal and ssh into the machine where you run your manager node. For example, the tutorial uses a machine named manager1.</li><li>Deploy Redis 3.0.6 to the swarm and configure the swarm with a 10 second update delay:</li><li>$ docker service create \</li><li>--replicas 3 \</li><li>--name redis \</li><li>--update-delay 10s \</li><li>redis:3.0.6</li><li>0u6a4s31ybk7yw2wyvtikmu50</li></ol><p>You configure the rolling update policy at service deployment time.</p><p>The --update-delay flag configures the time delay between updates to a service task or sets of tasks. You can describe the time T as a combination of the number of seconds Ts, minutes Tm, or hours Th. So 10m30s indicates a 10 minute 30 second delay.</p><p>By default the scheduler updates 1 task at a time. You can pass the --update-parallelismflag to configure the maximum number of service tasks that the scheduler updates simultaneously.</p><p>By default, when an update to an individual task returns a state of RUNNING, the scheduler schedules another task to update until all tasks are updated. If, at any time during an update a task returns FAILED, the scheduler pauses the update. You can control the behavior using the --update-failure-action flag for docker service create ordocker service update.</p><ol><li>Inspect the redis service:</li><li>$ docker service inspect --pretty redis</li><li>ID: 0u6a4s31ybk7yw2wyvtikmu50</li><li>Name: redis</li><li>Service Mode: Replicated</li><li>Replicas: 3</li><li>Placement:</li><li>Strategy: Spread</li><li>UpdateConfig:</li><li>Parallelism: 1</li><li>Delay: 10s</li><li>ContainerSpec:</li><li>Image: redis:3.0.6</li><li>Resources:</li><li>Endpoint Mode: vip</li><li>Now you can update the container image for redis. The swarm manager applies the update to nodes according to the UpdateConfig policy:</li><li>$ docker service update --image redis:3.0.7 redis</li><li>redis</li></ol><p>The scheduler applies rolling updates as follows by default:</p><ul><li><ul><li>Stop the first task.</li><li>Schedule update for the stopped task.</li><li>Start the container for the updated task.</li><li>If the update to a task returns RUNNING, wait for the specified delay period then start the next task.</li><li>If, at any time during the update, a task returns FAILED, pause the update.</li></ul></li></ul><ol><li>Run docker service inspect --pretty redis to see the new image in the desired state:</li><li>$ docker service inspect --pretty redis</li><li>ID: 0u6a4s31ybk7yw2wyvtikmu50</li><li>Name: redis</li><li>Service Mode: Replicated</li><li>Replicas: 3</li><li>Placement:</li><li>Strategy: Spread</li><li>UpdateConfig:</li><li>Parallelism: 1</li><li>Delay: 10s</li><li>ContainerSpec:</li><li>Image: redis:3.0.7</li><li>Resources:</li><li>Endpoint Mode: vip</li></ol><p>The output of service inspect shows if your update paused due to failure:</p><p>$ docker service inspect --pretty redis</p><p>ID: 0u6a4s31ybk7yw2wyvtikmu50</p><p>Name: redis</p><p>...snip...</p><p>Update status:</p><p>State: paused</p><p>Started: 11 seconds ago</p><p>Message: update paused due to failure or early termination of task 9p7ith557h8ndf0ui9s0q951b</p><p>...snip...</p><p>To restart a paused update run docker service update <code style="background-color:lightgray">&lt;SERVICE-ID&gt;</code>. For example:</p><p>docker service update redis</p><p>To avoid repeating certain update failures, you may need to reconfigure the service by passing flags to docker service update.</p><ol><li>Run docker service ps <code>&lt;SERVICE-ID&gt;</code> to watch the rolling update:</li><li>$ docker service ps redis</li><li>NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR</li><li>redis.1.dos1zffgeofhagnve8w864fco redis:3.0.7 worker1 Running Running 37 seconds</li><li>_<!-- --> redis.1.88rdo6pa52ki8oqx6dogf04fh redis:3.0.6 worker2 Shutdown Shutdown 56 seconds ago</li><li>redis.2.9l3i4j85517skba5o7tn5m8g0 redis:3.0.7 worker2 Running Running About a minute</li><li>_<!-- --> redis.2.66k185wilg8ele7ntu8f6nj6i redis:3.0.6 worker1 Shutdown Shutdown 2 minutes ago</li><li>redis.3.egiuiqpzrdbxks3wxgn8qib1g redis:3.0.7 worker1 Running Running 48 seconds</li><li>_<!-- --> redis.3.ctzktfddb2tepkr45qcmqln04 redis:3.0.6 mmanager1 Shutdown Shutdown 2 minutes ago</li></ol><p>Before Swarm updates all of the tasks, you can see that some are running redis:3.0.6while others are running redis:3.0.7. The output above shows the state once the rolling updates are done.</p><h5><strong>What&#x27;s next?</strong></h5><p>Next, learn about how to <a href="https://docs.docker.com/engine/swarm/swarm-tutorial/drain-node/">drain a node</a> in the swarm.</p><h4>Drain a node on the swarm</h4><p><em>Estimated reading time: 3 minutes</em></p><p>In earlier steps of the tutorial, all the nodes have been running with ACTIVE availability. The swarm manager can assign tasks to any ACTIVE node, so up to now all nodes have been available to receive tasks.</p><p>Sometimes, such as planned maintenance times, you need to set a node to DRAIN availability. DRAIN availability prevents a node from receiving new tasks from the swarm manager. It also means the manager stops tasks running on the node and launches replica tasks on a node with ACTIVE availability.</p><p><strong>Important</strong>: Setting a node to DRAIN does not remove standalone containers from that node, such as those created with docker run, docker-compose up, or the Docker Engine API. A node&#x27;s status, including DRAIN, only affects the node&#x27;s ability to schedule swarm service workloads.</p><ol><li>If you haven&#x27;t already, open a terminal and ssh into the machine where you run your manager node. For example, the tutorial uses a machine named manager1.</li><li>Verify that all your nodes are actively available.</li><li>$ docker node ls</li><li>ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS</li><li>1bcef6utixb0l0ca7gxuivsj0 worker2 Ready Active</li><li>38ciaotwjuritcdtn9npbnkuz worker1 Ready Active</li><li>e216jshn25ckzbvmwlnh5jr3g * manager1 Ready Active Leader</li><li>If you aren&#x27;t still running the redis service from the <a href="https://docs.docker.com/engine/swarm/swarm-tutorial/rolling-update/">rolling update</a> tutorial, start it now:</li><li>$ docker service create --replicas 3 --name redis --update-delay 10s redis:3.0.6</li><li>c5uo6kdmzpon37mgj9mwglcfw</li><li>Run docker service ps redis to see how the swarm manager assigned the tasks to different nodes:</li><li>$ docker service ps redis</li><li>NAME IMAGE NODE DESIRED STATE CURRENT STATE</li><li>redis.1.7q92v0nr1hcgts2amcjyqg3pq redis:3.0.6 manager1 Running Running 26 seconds</li><li>redis.2.7h2l8h3q3wqy5f66hlv9ddmi6 redis:3.0.6 worker1 Running Running 26 seconds</li><li>redis.3.9bg7cezvedmkgg6c8yzvbhwsd redis:3.0.6 worker2 Running Running 26 seconds</li></ol><p>In this case the swarm manager distributed one task to each node. You may see the tasks distributed differently among the nodes in your environment.</p><ol><li>Run docker node update --availability drain <code>&lt;NODE-ID&gt;</code> to drain a node that had a task assigned to it:</li><li>docker node update --availability drain worker1</li><li>worker1</li><li>Inspect the node to check its availability:</li><li>$ docker node inspect --pretty worker1</li><li>ID: 38ciaotwjuritcdtn9npbnkuz</li><li>Hostname: worker1</li><li>Status:</li><li>State: Ready</li><li>Availability: Drain</li><li>...snip...</li></ol><p>The drained node shows Drain for AVAILABILITY.</p><ol><li>Run docker service ps redis to see how the swarm manager updated the task assignments for the redis service:</li><li>$ docker service ps redis</li><li>NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR</li><li>redis.1.7q92v0nr1hcgts2amcjyqg3pq redis:3.0.6 manager1 Running Running 4 minutes</li><li>redis.2.b4hovzed7id8irg1to42egue8 redis:3.0.6 worker2 Running Running About a minute</li><li>_<!-- --> redis.2.7h2l8h3q3wqy5f66hlv9ddmi6 redis:3.0.6 worker1 Shutdown Shutdown 2 minutes ago</li><li>redis.3.9bg7cezvedmkgg6c8yzvbhwsd redis:3.0.6 worker2 Running Running 4 minutes</li></ol><p>The swarm manager maintains the desired state by ending the task on a node with Drainavailability and creating a new task on a node with Active availability.</p><ol><li>Run docker node update --availability active <code>&lt;NODE-ID&gt;</code> to return the drained node to an active state:</li><li>$ docker node update --availability active worker1</li><li>worker1</li><li>Inspect the node to see the updated state:</li><li>$ docker node inspect --pretty worker1</li><li>ID: 38ciaotwjuritcdtn9npbnkuz</li><li>Hostname: worker1</li><li>Status:</li><li>State: Ready</li><li>Availability: Active</li><li>...snip...</li></ol><p>When you set the node back to Active availability, it can receive new tasks:</p><ul><li><ul><li>during a service update to scale up</li><li>during a rolling update</li><li>when you set another node to Drain availability</li><li>when a task fails on another active node</li></ul></li></ul><h5><strong>What&#x27;s next?</strong></h5><p>Learn how to <a href="https://docs.docker.com/engine/swarm/ingress/">use a swarm mode routing mesh</a>.</p><h4>Use swarm mode routing mesh</h4><p><em>Estimated reading time: 8 minutes</em></p><p>Docker Engine swarm mode makes it easy to publish ports for services to make them available to resources outside the swarm. All nodes participate in an ingress <strong>routing mesh</strong>. The routing mesh enables each node in the swarm to accept connections on published ports for any service running in the swarm, even if there&#x27;s no task running on the node. The routing mesh routes all incoming requests to published ports on available nodes to an active container.</p><p>To use the ingress network in the swarm, you need to have the following ports open between the swarm nodes before you enable swarm mode:</p><ul><li>Port 7946 TCP/UDP for container network discovery.</li><li>Port 4789 UDP for the container ingress network.</li></ul><p>You must also open the published port between the swarm nodes and any external resources, such as an external load balancer, that require access to the port.</p><p>You can also <a href="https://docs.docker.com/engine/swarm/ingress/#bypass-the-routing-mesh">bypass the routing mesh</a> for a given service.</p><h5><strong>Publish a port for a service</strong></h5><p>Use the --publish flag to publish a port when you create a service. target is used to specify the port inside the container, and published is used to specify the port to bind on the routing mesh. If you leave off the published port, a random high-numbered port is bound for each service task. You need to inspect the task to determine the port.</p><p>$ docker service create \</p><p>--name <code style="background-color:lightgray">&lt;SERVICE-NAME&gt;</code> \</p><p>--publish published=<code style="background-color:lightgray">&lt;PUBLISHED-PORT&gt;,target=&lt;CONTAINER-PORT&gt;</code> \</p><p><code style="background-color:lightgray">&lt;IMAGE&gt;</code></p><p><strong>Note</strong>: The older form of this syntax is a colon-separated string, where the published port is first and the target port is second, such as -p 8080:80. The new syntax is preferred because it is easier to read and allows more flexibility.</p><p>The <code style="background-color:lightgray">&lt;PUBLISHED-PORT&gt; is the port where the swarm makes the service available. If you omit it, a random high-numbered port is bound. The &lt;CONTAINER-PORT&gt;</code> is the port where the container listens. This parameter is required.</p><p>For example, the following command publishes port 80 in the nginx container to port 8080 for any node in the swarm:</p><p>$ docker service create \</p><p>--name my-web \</p><p>--publish published=8080,target=80 \</p><p>--replicas 2 \</p><p>nginx</p><p>When you access port 8080 on any node, Docker routes your request to an active container. On the swarm nodes themselves, port 8080 may not actually be bound, but the routing mesh knows how to route the traffic and prevents any port conflicts from happening.</p><p>The routing mesh listens on the published port for any IP address assigned to the node. For externally routable IP addresses, the port is available from outside the host. For all other IP addresses the access is only available from within the host.</p><p>You can publish a port for an existing service using the following command:</p><p>$ docker service update \</p><p>--publish-add published=<code style="background-color:lightgray">&lt;PUBLISHED-PORT&gt;,target=&lt;CONTAINER-PORT&gt;</code> \</p><p><code style="background-color:lightgray">&lt;SERVICE&gt;</code></p><p>You can use docker service inspect to view the service&#x27;s published port. For instance:</p><p>$ docker service inspect --format=&quot;{{json .Endpoint.Spec.Ports}}&quot; my-web</p><p>[{&quot;Protocol&quot;:&quot;tcp&quot;,&quot;TargetPort&quot;:80,&quot;PublishedPort&quot;:8080}]</p><p>The output shows the <code style="background-color:lightgray">&lt;CONTAINER-PORT&gt; (labeled TargetPort) from the containers and the&lt;PUBLISHED-PORT&gt;</code> (labeled PublishedPort) where nodes listen for requests for the service.</p><h6><strong>Publish a port for TCP only or UDP only</strong></h6><p>By default, when you publish a port, it is a TCP port. You can specifically publish a UDP port instead of or in addition to a TCP port. When you publish both TCP and UDP ports, If you omit the protocol specifier, the port is published as a TCP port. If you use the longer syntax (recommended for Docker 1.13 and higher), set the protocol key to either tcp or udp.</p><p><strong>TCP ONLY</strong></p><p><strong>Long syntax:</strong></p><p>$ docker service create --name dns-cache \</p><p>--publish published=53,target=53 \</p><p>dns-cache</p><p><strong>Short syntax:</strong></p><p>$ docker service create --name dns-cache \</p><p>-p 53:53 \</p><p>dns-cache</p><p><strong>TCP AND UDP</strong></p><p><strong>Long syntax:</strong></p><p>$ docker service create --name dns-cache \</p><p>--publish published=53,target=53 \</p><p>--publish published=53,target=53,protocol=udp \</p><p>dns-cache</p><p><strong>Short syntax:</strong></p><p>$ docker service create --name dns-cache \</p><p>-p 53:53 \</p><p>-p 53:53/udp \</p><p>dns-cache</p><p><strong>UDP ONLY</strong></p><p><strong>Long syntax:</strong></p><p>$ docker service create --name dns-cache \</p><p>--publish published=53,target=53,protocol=udp \</p><p>dns-cache</p><p><strong>Short syntax:</strong></p><p>$ docker service create --name dns-cache \</p><p>-p 53:53/udp \</p><p>dns-cache</p><h5><strong>Bypass the routing mesh</strong></h5><p>You can bypass the routing mesh, so that when you access the bound port on a given node, you are always accessing the instance of the service running on that node. This is referred to as hostmode. There are a few things to keep in mind.</p><ul><li>If you access a node which is not running a service task, the service does not listen on that port. It is possible that nothing is listening, or that a completely different application is listening.</li><li>If you expect to run multiple service tasks on each node (such as when you have 5 nodes but run 10 replicas), you cannot specify a static target port. Either allow Docker to assign a random high-numbered port (by leaving off the target), or ensure that only a single instance of the service runs on a given node, by using a global service rather than a replicated one, or by using placement constraints.</li></ul><p>To bypass the routing mesh, you must use the long --publish service and set mode to host. If you omit the mode key or set it to ingress, the routing mesh is used. The following command creates a global service using host mode and bypassing the routing mesh.</p><p>$ docker service create --name dns-cache \</p><p>--publish published=53,target=53,protocol=udp,mode=host \</p><p>--mode global \</p><p>dns-cache</p><h5><strong>Configure an external load balancer</strong></h5><p>You can configure an external load balancer for swarm services, either in combination with the routing mesh or without using the routing mesh at all.</p><h6><strong>Using the routing mesh</strong></h6><p>You can configure an external load balancer to route requests to a swarm service. For example, you could configure <a href="http://www.haproxy.org/">HAProxy</a> to balance requests to an nginx service published to port 8080.</p><p>In this case, port 8080 must be open between the load balancer and the nodes in the swarm. The swarm nodes can reside on a private network that is accessible to the proxy server, but that is not publicly accessible.</p><p>You can configure the load balancer to balance requests between every node in the swarm even if there are no tasks scheduled on the node. For example, you could have the following HAProxy configuration in /etc/haproxy/haproxy.cfg:</p><p>global</p><p>log /dev/log local0</p><p>log /dev/log local1 notice</p><p>...snip...</p><h1>Configure HAProxy to listen on port 80</h1><p>frontend http_front</p><p>bind *:80</p><p>stats uri /haproxy?stats</p><p>default_backend http_back</p><h1>Configure HAProxy to route requests to swarm nodes on port 8080</h1><p>backend http_back</p><p>balance roundrobin</p><p>server node1 192.168.99.100:8080 check</p><p>server node2 192.168.99.101:8080 check</p><p>server node3 192.168.99.102:8080 check</p><p>When you access the HAProxy load balancer on port 80, it forwards requests to nodes in the swarm. The swarm routing mesh routes the request to an active task. If, for any reason the swarm scheduler dispatches tasks to different nodes, you don&#x27;t need to reconfigure the load balancer.</p><p>You can configure any type of load balancer to route requests to swarm nodes. To learn more about HAProxy, see the <a href="https://cbonte.github.io/haproxy-dconv/">HAProxy documentation</a>.</p><h6><strong>Without the routing mesh</strong></h6><p>To use an external load balancer without the routing mesh, set --endpoint-mode to dnsrrinstead of the default value of vip. In this case, there is not a single virtual IP. Instead, Docker sets up DNS entries for the service such that a DNS query for the service name returns a list of IP addresses, and the client connects directly to one of these. You are responsible for providing the list of IP addresses and ports to your load balancer. See <a href="https://docs.docker.com/engine/swarm/networking/#configure-service-discovery">Configure service discovery</a>.</p><h5><strong>Learn more</strong></h5><ul><li><a href="https://docs.docker.com/engine/swarm/services/">Deploy services to a swarm</a></li></ul><h4>How Swarm Mode Works</h4><h5><strong>How nodes work</strong></h5><p><em>Estimated reading time: 2 minutes</em></p><p>Docker Engine 1.12 introduces swarm mode that enables you to create a cluster of one or more Docker Engines called a swarm. A swarm consists of one or more nodes: physical or virtual machines running Docker Engine 1.12 or later in swarm mode.</p><p>There are two types of nodes: <a href="https://docs.docker.com/engine/swarm/how-swarm-mode-works/nodes/#manager-nodes"><strong>managers</strong></a> and <a href="https://docs.docker.com/engine/swarm/how-swarm-mode-works/nodes/#worker-nodes"><strong>workers</strong></a>.</p><p>If you haven&#x27;t already, read through the <a href="https://docs.docker.com/engine/swarm/">swarm mode overview</a> and <a href="https://docs.docker.com/engine/swarm/key-concepts/">key concepts</a>.</p><h6><strong>Manager nodes</strong></h6><p>Manager nodes handle cluster management tasks:</p><ul><li>maintaining cluster state</li><li>scheduling services</li><li>serving swarm mode <a href="https://docs.docker.com/engine/api/">HTTP API endpoints</a></li></ul><p>Using a <a href="https://raft.github.io/raft.pdf">Raft</a> implementation, the managers maintain a consistent internal state of the entire swarm and all the services running on it. For testing purposes it is OK to run a swarm with a single manager. If the manager in a single-manager swarm fails, your services continue to run, but you need to create a new cluster to recover.</p><p>To take advantage of swarm mode&#x27;s fault-tolerance features, Docker recommends you implement an odd number of nodes according to your organization&#x27;s high-availability requirements. When you have multiple managers you can recover from the failure of a manager node without downtime.</p><ul><li>A three-manager swarm tolerates a maximum loss of one manager.</li><li>A five-manager swarm tolerates a maximum simultaneous loss of two manager nodes.</li><li>An N manager cluster tolerates the loss of at most (N-1)/2 managers.</li><li>Docker recommends a maximum of seven manager nodes for a swarm.</li></ul><p><strong>Important Note</strong>: Adding more managers does NOT mean increased scalability or higher performance. In general, the opposite is true.</p><h6><strong>Worker nodes</strong></h6><p>Worker nodes are also instances of Docker Engine whose sole purpose is to execute containers. Worker nodes don&#x27;t participate in the Raft distributed state, make scheduling decisions, or serve the swarm mode HTTP API.</p><p>You can create a swarm of one manager node, but you cannot have a worker node without at least one manager node. By default, all managers are also workers. In a single manager node cluster, you can run commands like docker service create and the scheduler places all tasks on the local Engine.</p><p>To prevent the scheduler from placing tasks on a manager node in a multi-node swarm, set the availability for the manager node to Drain. The scheduler gracefully stops tasks on nodes in Drain mode and schedules the tasks on an Active node. The scheduler does not assign new tasks to nodes with Drain availability.</p><p>Refer to the <a href="https://docs.docker.com/engine/reference/commandline/node_update/">docker node update</a> command line reference to see how to change node availability.</p><h6><strong>Change roles</strong></h6><p>You can promote a worker node to be a manager by running docker node promote. For example, you may want to promote a worker node when you take a manager node offline for maintenance. See <a href="https://docs.docker.com/engine/reference/commandline/node_promote/">node promote</a>.</p><p>You can also demote a manager node to a worker node. See <a href="https://docs.docker.com/engine/reference/commandline/node_demote/">node demote</a>.</p><h6><strong>Learn more</strong></h6><ul><li>Read about how swarm mode <a href="https://docs.docker.com/engine/swarm/how-swarm-mode-works/services/">services</a> work.</li><li>Learn how <a href="https://docs.docker.com/engine/swarm/how-swarm-mode-works/pki/">PKI</a> works in swarm mode.</li></ul><h5><strong>How services work</strong></h5><p><em>Estimated reading time: 5 minutes</em></p><p>To deploy an application image when Docker Engine is in swarm mode, you create a service. Frequently a service is the image for a microservice within the context of some larger application. Examples of services might include an HTTP server, a database, or any other type of executable program that you wish to run in a distributed environment.</p><p>When you create a service, you specify which container image to use and which commands to execute inside running containers. You also define options for the service including:</p><ul><li>the port where the swarm makes the service available outside the swarm</li><li>an overlay network for the service to connect to other services in the swarm</li><li>CPU and memory limits and reservations</li><li>a rolling update policy</li><li>the number of replicas of the image to run in the swarm</li></ul><h6><strong>Services, tasks, and containers</strong></h6><p>When you deploy the service to the swarm, the swarm manager accepts your service definition as the desired state for the service. Then it schedules the service on nodes in the swarm as one or more replica tasks. The tasks run independently of each other on nodes in the swarm.</p><p>For example, imagine you want to load balance between three instances of an HTTP listener. The diagram below shows an HTTP listener service with three replicas. Each of the three instances of the listener is a task in the swarm.</p><p>A container is an isolated process. In the swarm mode model, each task invokes exactly one container. A task is analogous to a &quot;slot&quot; where the scheduler places a container. Once the container is live, the scheduler recognizes that the task is in a running state. If the container fails health checks or terminates, the task terminates.</p><h6><strong>Tasks and scheduling</strong></h6><p>A task is the atomic unit of scheduling within a swarm. When you declare a desired service state by creating or updating a service, the orchestrator realizes the desired state by scheduling tasks. For instance, you define a service that instructs the orchestrator to keep three instances of an HTTP listener running at all times. The orchestrator responds by creating three tasks. Each task is a slot that the scheduler fills by spawning a container. The container is the instantiation of the task. If an HTTP listener task subsequently fails its health check or crashes, the orchestrator creates a new replica task that spawns a new container.</p><p>A task is a one-directional mechanism. It progresses monotonically through a series of states: assigned, prepared, running, etc. If the task fails the orchestrator removes the task and its container and then creates a new task to replace it according to the desired state specified by the service.</p><p>The underlying logic of Docker swarm mode is a general purpose scheduler and orchestrator. The service and task abstractions themselves are unaware of the containers they implement. Hypothetically, you could implement other types of tasks such as virtual machine tasks or non-containerized process tasks. The scheduler and orchestrator are agnostic about the type of task. However, the current version of Docker only supports container tasks.</p><p>The diagram below shows how swarm mode accepts service create requests and schedules tasks to worker nodes.</p><p><strong>Pending services</strong></p><p>A service may be configured in such a way that no node currently in the swarm can run its tasks. In this case, the service remains in state pending. Here are a few examples of when a service might remain in state pending.</p><p><strong>Note</strong>: If your only intention is to prevent a service from being deployed, scale the service to 0 instead of trying to configure it in such a way that it remains in pending.</p><ul><li>If all nodes are paused or drained, and you create a service, it is pending until a node becomes available. In reality, the first node to become available gets all of the tasks, so this is not a good thing to do in a production environment.</li><li>You can reserve a specific amount of memory for a service. If no node in the swarm has the required amount of memory, the service remains in a pending state until a node is available which can run its tasks. If you specify a very large value, such as 500 GB, the task stays pending forever, unless you really have a node which can satisfy it.</li><li>You can impose placement constraints on the service, and the constraints may not be able to be honored at a given time.</li></ul><p>This behavior illustrates that the requirements and configuration of your tasks are not tightly tied to the current state of the swarm. As the administrator of a swarm, you declare the desired state of your swarm, and the manager works with the nodes in the swarm to create that state. You do not need to micro-manage the tasks on the swarm.</p><h6><strong>Replicated and global services</strong></h6><p>There are two types of service deployments, replicated and global.</p><p>For a replicated service, you specify the number of identical tasks you want to run. For example, you decide to deploy an HTTP service with three replicas, each serving the same content.</p><p>A global service is a service that runs one task on every node. There is no pre-specified number of tasks. Each time you add a node to the swarm, the orchestrator creates a task and the scheduler assigns the task to the new node. Good candidates for global services are monitoring agents, an anti-virus scanners or other types of containers that you want to run on every node in the swarm.</p><p>The diagram below shows a three-service replica in yellow and a global service in gray.</p><h6><strong>Learn more</strong></h6><ul><li>Read about how swarm mode <a href="https://docs.docker.com/engine/swarm/how-swarm-mode-works/nodes/">nodes</a> work.</li><li>Learn how <a href="https://docs.docker.com/engine/swarm/how-swarm-mode-works/pki/">PKI</a> works in swarm mode.</li></ul><h5><strong>Manage swarm security with public key infrastructure (PKI)</strong></h5><p><em>Estimated reading time: 4 minutes</em></p><p>The swarm mode public key infrastructure (PKI) system built into Docker makes it simple to securely deploy a container orchestration system. The nodes in a swarm use mutual Transport Layer Security (TLS) to authenticate, authorize, and encrypt the communications with other nodes in the swarm.</p><p>When you create a swarm by running docker swarm init, Docker designates itself as a manager node. By default, the manager node generates a new root Certificate Authority (CA) along with a key pair, which are used to secure communications with other nodes that join the swarm. If you prefer, you can specify your own externally-generated root CA, using the --external-ca flag of the <a href="https://docs.docker.com/engine/reference/commandline/swarm_init/">docker swarm init</a> command.</p><p>The manager node also generates two tokens to use when you join additional nodes to the swarm: one <strong>worker token</strong> and one <strong>manager token</strong>. Each token includes the digest of the root CA&#x27;s certificate and a randomly generated secret. When a node joins the swarm, the joining node uses the digest to validate the root CA certificate from the remote manager. The remote manager uses the secret to ensure the joining node is an approved node.</p><p>Each time a new node joins the swarm, the manager issues a certificate to the node. The certificate contains a randomly generated node ID to identify the node under the certificate common name (CN) and the role under the organizational unit (OU). The node ID serves as the cryptographically secure node identity for the lifetime of the node in the current swarm.</p><p>The diagram below illustrates how manager nodes and worker nodes encrypt communications using a minimum of TLS 1.2.</p><p>The example below shows the information from a certificate from a worker node:</p><p>Certificate:</p><p>Data:</p><p>Version: 3 (0x2)</p><p>Serial Number:</p><p>3b:1c:06:91:73:fb:16:ff:69:c3:f7:a2:fe:96:c1:73:e2:80:97:3b</p><p>Signature Algorithm: ecdsa-with-SHA256</p><p>Issuer: CN=swarm-ca</p><p>Validity</p><p>Not Before: Aug 30 02:39:00 2016 GMT</p><p>Not After : Nov 28 03:39:00 2016 GMT</p><p>Subject: O=ec2adilxf4ngv7ev8fwsi61i7, OU=swarm-worker, CN=dw02poa4vqvzxi5c10gm4pq2g</p><p>...snip...</p><p>By default, each node in the swarm renews its certificate every three months. You can configure this interval by running the docker swarm update --cert-expiry <code style="background-color:lightgray">&lt;TIME PERIOD&gt;</code> command. The minimum rotation value is 1 hour. Refer to the <a href="https://docs.docker.com/engine/reference/commandline/swarm_update/">docker swarm update</a> CLI reference for details.</p><h6><strong>Rotating the CA certificate</strong></h6><p>In the event that a cluster CA key or a manager node is compromised, you can rotate the swarm root CA so that none of the nodes trust certificates signed by the old root CA anymore.</p><p>Run docker swarm ca --rotate to generate a new CA certificate and key. If you prefer, you can pass the --ca-cert and --external-ca flags to specify the root certificate and and to use a root CA external to the swarm. Alternately, you can pass the --ca-cert and --ca-key flags to specify the exact certificate and key you would like the swarm to use.</p><p>When you issue the docker swarm ca --rotate command, the following things happen in sequence:</p><ol><li>Docker generates a cross-signed certificate. This means that a version of the new root CA certificate is signed with the old root CA certificate. This cross-signed certificate is used as an intermediate certificate for all new node certificates. This ensures that nodes that still trust the old root CA can still validate a certificate signed by the new CA.</li><li>In Docker 17.06 and higher, Docker also tells all nodes to immediately renew their TLS certificates. This process may take several minutes, depending on the number of nodes in the swarm.</li></ol><p><strong>Note: If your swarm has nodes with different Docker versions, the following two things are true:</strong></p><ul><li><ul><li>Only a manager that is running as the leader <strong>and</strong> running Docker 17.06 or higher tells nodes to renew their TLS certificates.</li><li>Only nodes running Docker 17.06 or higher obey this directive.</li></ul></li></ul><p>For the most predictable behavior, ensure that all swarm nodes are running Docker 17.06 or higher.</p><ol><li>After every node in the swarm has a new TLS certificate signed by the new CA, Docker forgets about the old CA certificate and key material, and tells all the nodes to trust the new CA certificate only.</li></ol><p>This also causes a change in the swarm&#x27;s join tokens. The previous join tokens are no longer valid.</p><p>From this point on, all new node certificates issued are signed with the new root CA, and do not contain any intermediates.</p><h6><strong>Learn More</strong></h6><ul><li>Read about how <a href="https://docs.docker.com/engine/swarm/how-swarm-mode-works/nodes/">nodes</a> work.</li><li>Learn how swarm mode <a href="https://docs.docker.com/engine/swarm/how-swarm-mode-works/services/">services</a> work.</li></ul><h5><strong>Swarm task states</strong></h5><p><em>Estimated reading time: 2 minutes</em></p><p>Docker lets you create services, which can start tasks. A service is a description of a desired state, and a task does the work. Work is scheduled on swarm nodes in this sequence:</p><ol><li>Create a service by using docker service create or the UCP web UI or CLI.</li><li>The request goes to a Docker manager node.</li><li>The Docker manager node schedules the service to run on particular nodes.</li><li>Each service can start multiple tasks.</li><li>Each task has a life cycle, with states like NEW, PENDING, and COMPLETE.</li></ol><p>Tasks are execution units that run once to completion. When a task stops, it isn&#x27;t executed again, but a new task may take its place.</p><p>Tasks advance through a number of states until they complete or fail. Tasks are initialized in the NEW state. The task progresses forward through a number of states, and its state doesn&#x27;t go backward. For example, a task never goes from COMPLETE to RUNNING.</p><p>Tasks go through the states in the following order:</p><p>  <strong>Task state</strong>   <strong>Description</strong></p><hr/><p>  NEW              The task was initialized.
PENDING          Resources for the task were allocated.
ASSIGNED         Docker assigned the task to nodes.
ACCEPTED         The task was accepted by a worker node. If a worker node rejects the task, the state changes to REJECTED.
PREPARING        Docker is preparing the task.
STARTING         Docker is starting the task.
RUNNING          The task is executing.
COMPLETE         The task exited without an error code.
FAILED           The task exited with an error code.
SHUTDOWN         Docker requested the task to shut down.
REJECTED         The worker node rejected the task.
ORPHANED         The node was down for too long.</p><h6><strong>View task state</strong></h6><p>Run docker service ps <code style="background-color:lightgray">&lt;service-name&gt;</code> to get the state of a task. The CURRENT STATE field shows the task&#x27;s state and how long it&#x27;s been there.</p><p>$ docker service ps webserver</p><p>ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS</p><p>owsz0yp6z375 webserver.1 nginx UbuntuVM Running Running 44 seconds ago</p><p>j91iahr8s74p <!-- -->_<!-- --> webserver.1 nginx UbuntuVM Shutdown Failed 50 seconds ago &quot;No such container: webserver....&quot;</p><p>7dyaszg13mw2 <!-- -->_<!-- --> webserver.1 nginx UbuntuVM Shutdown Failed 5 hours ago &quot;No such container: webserver....&quot;</p><h6><strong>Where to go next</strong></h6><ul><li><a href="https://github.com/docker/swarmkit/blob/master/design/task_model.md">Learn about swarm tasks</a></li></ul><h4>Run Docker Engine in swarm mode</h4><p><em>Estimated reading time: 5 minutes</em></p><p>When you first install and start working with Docker Engine, swarm mode is disabled by default. When you enable swarm mode, you work with the concept of services managed through the docker service command.</p><p>There are two ways to run the Engine in swarm mode:</p><ul><li>Create a new swarm, covered in this article.</li><li><a href="https://docs.docker.com/engine/swarm/join-nodes/">Join an existing swarm</a>.</li></ul><p>When you run the Engine in swarm mode on your local machine, you can create and test services based upon images you&#x27;ve created or other available images. In your production environment, swarm mode provides a fault-tolerant platform with cluster management features to keep your services running and available.</p><p>These instructions assume you have installed the Docker Engine 1.12 or later on a machine to serve as a manager node in your swarm.</p><p>If you haven&#x27;t already, read through the <a href="https://docs.docker.com/engine/swarm/key-concepts/">swarm mode key concepts</a> and try the <a href="https://docs.docker.com/engine/swarm/swarm-tutorial/">swarm mode tutorial</a>.</p><h5><strong>Create a swarm</strong></h5><p>When you run the command to create a swarm, the Docker Engine starts running in swarm mode.</p><p>Run <a href="https://docs.docker.com/engine/reference/commandline/swarm_init/">docker swarm init</a> to create a single-node swarm on the current node. The Engine sets up the swarm as follows:</p><ul><li>switches the current node into swarm mode.</li><li>creates a swarm named default.</li><li>designates the current node as a leader manager node for the swarm.</li><li>names the node with the machine hostname.</li><li>configures the manager to listen on an active network interface on port 2377.</li><li>sets the current node to Active availability, meaning it can receive tasks from the scheduler.</li><li>starts an internal distributed data store for Engines participating in the swarm to maintain a consistent view of the swarm and all services running on it.</li><li>by default, generates a self-signed root CA for the swarm.</li><li>by default, generates tokens for worker and manager nodes to join the swarm.</li><li>creates an overlay network named ingress for publishing service ports external to the swarm.</li></ul><p>The output for docker swarm init provides the connection command to use when you join new worker nodes to the swarm:</p><p>$ docker swarm init</p><p>Swarm initialized: current node (dxn1zf6l61qsb1josjja83ngz) is now a manager.</p><p>To add a worker to this swarm, run the following command:</p><p>docker swarm join \</p><p>--token SWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c \</p><p>192.168.99.100:2377</p><p>To add a manager to this swarm, run \&#x27;docker swarm join-token manager\&#x27; and follow the instructions.</p><h6><strong>Configure the advertise address</strong></h6><p>Manager nodes use an advertise address to allow other nodes in the swarm access to the Swarmkit API and overlay networking. The other nodes on the swarm must be able to access the manager node on its advertise address.</p><p>If you don&#x27;t specify an advertise address, Docker checks if the system has a single IP address. If so, Docker uses the IP address with the listening port 2377 by default. If the system has multiple IP addresses, you must specify the correct --advertise-addr to enable inter-manager communication and overlay networking:</p><p>$ docker swarm init --advertise-addr <code style="background-color:lightgray">&lt;MANAGER-IP&gt;</code></p><p>You must also specify the --advertise-addr if the address where other nodes reach the first manager node is not the same address the manager sees as its own. For instance, in a cloud setup that spans different regions, hosts have both internal addresses for access within the region and external addresses that you use for access from outside that region. In this case, specify the external address with --advertise-addr so that the node can propagate that information to other nodes that subsequently connect to it.</p><p>Refer to the docker swarm init <a href="https://docs.docker.com/engine/reference/commandline/swarm_init/">CLI reference</a> for more detail on the advertise address.</p><h6><strong>View the join command or update a swarm join token</strong></h6><p>Nodes require a secret token to join the swarm. The token for worker nodes is different from the token for manager nodes. Nodes only use the join-token at the moment they join the swarm. Rotating the join token after a node has already joined a swarm does not affect the node&#x27;s swarm membership. Token rotation ensures an old token cannot be used by any new nodes attempting to join the swarm.</p><p>To retrieve the join command including the join token for worker nodes, run:</p><p>$ docker swarm join-token worker</p><p>To add a worker to this swarm, run the following command:</p><p>docker swarm join \</p><p>--token SWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c \</p><p>192.168.99.100:2377</p><p>This node joined a swarm as a worker.</p><p>To view the join command and token for manager nodes, run:</p><p>$ docker swarm join-token manager</p><p>To add a worker to this swarm, run the following command:</p><p>docker swarm join \</p><p>--token SWMTKN-1-59egwe8qangbzbqb3ryawxzk3jn97ifahlsrw01yar60pmkr90-bdjfnkcflhooyafetgjod97sz \</p><p>192.168.99.100:2377</p><p>Pass the --quiet flag to print only the token:</p><p>$ docker swarm join-token --quiet worker</p><p>SWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c</p><p>Be careful with the join tokens because they are the secrets necessary to join the swarm. In particular, checking a secret into version control is a bad practice because it would allow anyone with access to the application source code to add new nodes to the swarm. Manager tokens are especially sensitive because they allow a new manager node to join and gain control over the whole swarm.</p><p>We recommend that you rotate the join tokens in the following circumstances:</p><ul><li>If a token was checked-in by accident into a version control system, group chat or accidentally printed to your logs.</li><li>If you suspect a node has been compromised.</li><li>If you wish to guarantee that no new nodes can join the swarm.</li></ul><p>Additionally, it is a best practice to implement a regular rotation schedule for any secret including swarm join tokens. We recommend that you rotate your tokens at least every 6 months.</p><p>Run swarm join-token --rotate to invalidate the old token and generate a new token. Specify whether you want to rotate the token for worker or manager nodes:</p><p>$ docker swarm join-token --rotate worker</p><p>To add a worker to this swarm, run the following command:</p><p>docker swarm join \</p><p>--token SWMTKN-1-2kscvs0zuymrsc9t0ocyy1rdns9dhaodvpl639j2bqx55uptag-ebmn5u927reawo27s3azntd44 \</p><p>192.168.99.100:2377</p><h5><strong>Learn more</strong></h5><ul><li><a href="https://docs.docker.com/engine/swarm/join-nodes/">Join nodes to a swarm</a></li><li>swarm init <a href="https://docs.docker.com/engine/reference/commandline/swarm_init/">command line reference</a></li><li><a href="https://docs.docker.com/engine/swarm/swarm-tutorial/">Swarm mode tutorial</a></li></ul><h4>Join nodes to a swarm</h4><p><em>Estimated reading time: 3 minutes</em></p><p>When you first create a swarm, you place a single Docker Engine (Engine) into swarm mode. To take full advantage of swarm mode you can add nodes to the swarm:</p><ul><li>Adding worker nodes increases capacity. When you deploy a service to a swarm, the Engine schedules tasks on available nodes whether they are worker nodes or manager nodes. When you add workers to your swarm, you increase the scale of the swarm to handle tasks without affecting the manager raft consensus.</li><li>Manager nodes increase fault-tolerance. Manager nodes perform the orchestration and cluster management functions for the swarm. Among manager nodes, a single leader node conducts orchestration tasks. If a leader node goes down, the remaining manager nodes elect a new leader and resume orchestration and maintenance of the swarm state. By default, manager nodes also run tasks.</li></ul><p>Before you add nodes to a swarm you must install Docker Engine 1.12 or later on the host machine.</p><p>The Docker Engine joins the swarm depending on the <strong>join-token</strong> you provide to the docker swarm join command. The node only uses the token at join time. If you subsequently rotate the token, it doesn&#x27;t affect existing swarm nodes. Refer to <a href="https://docs.docker.com/engine/swarm/swarm-mode/#view-the-join-command-or-update-a-swarm-join-token">Run Docker Engine in swarm mode</a>.</p><h5><strong>Join as a worker node</strong></h5><p>To retrieve the join command including the join token for worker nodes, run the following command on a manager node:</p><p>$ docker swarm join-token worker</p><p>To add a worker to this swarm, run the following command:</p><p>docker swarm join \</p><p>--token SWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c \</p><p>192.168.99.100:2377</p><p>Run the command from the output on the worker to join the swarm:</p><p>$ docker swarm join \</p><p>--token SWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c \</p><p>192.168.99.100:2377</p><p>This node joined a swarm as a worker.</p><p>The docker swarm join command does the following:</p><ul><li>switches the Docker Engine on the current node into swarm mode.</li><li>requests a TLS certificate from the manager.</li><li>names the node with the machine hostname</li><li>joins the current node to the swarm at the manager listen address based upon the swarm token.</li><li>sets the current node to Active availability, meaning it can receive tasks from the scheduler.</li><li>extends the ingress overlay network to the current node.</li></ul><h5><strong>Join as a manager node</strong></h5><p>When you run docker swarm join and pass the manager token, the Docker Engine switches into swarm mode the same as for workers. Manager nodes also participate in the raft consensus. The new nodes should be Reachable, but the existing manager remains the swarm Leader.</p><p>Docker recommends three or five manager nodes per cluster to implement high availability. Because swarm mode manager nodes share data using Raft, there must be an odd number of managers. The swarm can continue to function after as long as a quorum of more than half of the manager nodes are available.</p><p>For more detail about swarm managers and administering a swarm, see <a href="https://docs.docker.com/engine/swarm/admin_guide/">Administer and maintain a swarm of Docker Engines</a>.</p><p>To retrieve the join command including the join token for manager nodes, run the following command on a manager node:</p><p>$ docker swarm join-token manager</p><p>To add a manager to this swarm, run the following command:</p><p>docker swarm join \</p><p>--token SWMTKN-1-61ztec5kyafptydic6jfc1i33t37flcl4nuipzcusor96k7kby-5vy9t8u35tuqm7vh67lrz9xp6 \</p><p>192.168.99.100:2377</p><p>Run the command from the output on the manager to join the swarm:</p><p>$ docker swarm join \</p><p>--token SWMTKN-1-61ztec5kyafptydic6jfc1i33t37flcl4nuipzcusor96k7kby-5vy9t8u35tuqm7vh67lrz9xp6 \</p><p>192.168.99.100:2377</p><p>This node joined a swarm as a manager.</p><h5><strong>Learn More</strong></h5><ul><li>swarm join <a href="https://docs.docker.com/engine/reference/commandline/swarm_join/">command line reference</a></li><li><a href="https://docs.docker.com/engine/swarm/swarm-tutorial/">Swarm mode tutorial</a></li></ul><h4>Manage nodes in a swarm</h4><p><em>Estimated reading time: 7 minutes</em></p><p>As part of the swarm management lifecycle, you may need to view or update a node as follows:</p><ul><li><a href="https://docs.docker.com/engine/swarm/manage-nodes/#list-nodes">list nodes in the swarm</a></li><li><a href="https://docs.docker.com/engine/swarm/manage-nodes/#inspect-an-individual-node">inspect an individual node</a></li><li><a href="https://docs.docker.com/engine/swarm/manage-nodes/#update-a-node">update a node</a></li><li><a href="https://docs.docker.com/engine/swarm/manage-nodes/#leave-the-swarm">leave the swarm</a></li></ul><h5><strong>List nodes</strong></h5><p>To view a list of nodes in the swarm run docker node ls from a manager node:</p><p>$ docker node ls</p><p>ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS</p><p>46aqrk4e473hjbt745z53cr3t node-5 Ready Active Reachable</p><p>61pi3d91s0w3b90ijw3deeb2q node-4 Ready Active Reachable</p><p>a5b2m3oghd48m8eu391pefq5u node-3 Ready Active</p><p>e7p8btxeu3ioshyuj6lxiv6g0 node-2 Ready Active</p><p>ehkv3bcimagdese79dn78otj5 * node-1 Ready Active Leader</p><p>The AVAILABILITY column shows whether or not the scheduler can assign tasks to the node:</p><ul><li>Active means that the scheduler can assign tasks to the node.</li><li>Pause means the scheduler doesn&#x27;t assign new tasks to the node, but existing tasks remain running.</li><li>Drain means the scheduler doesn&#x27;t assign new tasks to the node. The scheduler shuts down any existing tasks and schedules them on an available node.</li></ul><p>The MANAGER STATUS column shows node participation in the Raft consensus:</p><ul><li>No value indicates a worker node that does not participate in swarm management.</li><li>Leader means the node is the primary manager node that makes all swarm management and orchestration decisions for the swarm.</li><li>Reachable means the node is a manager node participating in the Raft consensus quorum. If the leader node becomes unavailable, the node is eligible for election as the new leader.</li><li>Unavailable means the node is a manager that can&#x27;t communicate with other managers. If a manager node becomes unavailable, you should either join a new manager node to the swarm or promote a worker node to be a manager.</li></ul><p>For more information on swarm administration refer to the <a href="https://docs.docker.com/engine/swarm/admin_guide/">Swarm administration guide</a>.</p><h5><strong>Inspect an individual node</strong></h5><p>You can run docker node inspect <code style="background-color:lightgray">&lt;NODE-ID&gt;</code> on a manager node to view the details for an individual node. The output defaults to JSON format, but you can pass the --pretty flag to print the results in human-readable format. For example:</p><p>$ docker node inspect self --pretty</p><p>ID: ehkv3bcimagdese79dn78otj5</p><p>Hostname: node-1</p><p>Joined at: 2016-06-16 22:52:44.9910662 +0000 utc</p><p>Status:</p><p>State: Ready</p><p>Availability: Active</p><p>Manager Status:</p><p>Address: 172.17.0.2:2377</p><p>Raft Status: Reachable</p><p>Leader: Yes</p><p>Platform:</p><p>Operating System: linux</p><p>Architecture: x86_64</p><p>Resources:</p><p>CPUs: 2</p><p>Memory: 1.954 GiB</p><p>Plugins:</p><p>Network: overlay, host, bridge, overlay, null</p><p>Volume: local</p><p>Engine Version: 1.12.0-dev</p><h5><strong>Update a node</strong></h5><p>You can modify node attributes as follows:</p><ul><li><a href="https://docs.docker.com/engine/swarm/manage-nodes/#change-node-availability">change node availability</a></li><li><a href="https://docs.docker.com/engine/swarm/manage-nodes/#add-or-remove-label-metadata">add or remove label metadata</a></li><li><a href="https://docs.docker.com/engine/swarm/manage-nodes/#promote-or-demote-a-node">change a node role</a></li></ul><h6><strong>Change node availability</strong></h6><p>Changing node availability lets you:</p><ul><li>drain a manager node so that only performs swarm management tasks and is unavailable for task assignment.</li><li>drain a node so you can take it down for maintenance.</li><li>pause a node so it can&#x27;t receive new tasks.</li><li>restore unavailable or paused nodes available status.</li></ul><p>For example, to change a manager node to Drain availability:</p><p>$ docker node update --availability drain node-1</p><p>node-1</p><p>See <a href="https://docs.docker.com/engine/swarm/manage-nodes/#list-nodes">list nodes</a> for descriptions of the different availability options.</p><h6><strong>Add or remove label metadata</strong></h6><p>Node labels provide a flexible method of node organization. You can also use node labels in service constraints. Apply constraints when you create a service to limit the nodes where the scheduler assigns tasks for the service.</p><p>Run docker node update --label-add on a manager node to add label metadata to a node. The --label-add flag supports either a <code style="background-color:lightgray">&lt;key&gt; or a &lt;key&gt;=&lt;value&gt;</code> pair.</p><p>Pass the --label-add flag once for each node label you want to add:</p><p>$ docker node update --label-add foo --label-add bar=baz node-1</p><p>node-1</p><p>The labels you set for nodes using docker node update apply only to the node entity within the swarm. Do not confuse them with the docker daemon labels for <a href="https://docs.docker.com/engine/userguide/labels-custom-metadata/#daemon-labels">dockerd</a>.</p><p>Therefore, node labels can be used to limit critical tasks to nodes that meet certain requirements. For example, schedule only on machines where special workloads should be run, such as machines that meet <a href="https://www.pcisecuritystandards.org/">PCI-SS compliance</a>.</p><p>A compromised worker could not compromise these special workloads because it cannot change node labels.</p><p>Engine labels, however, are still useful because some features that do not affect secure orchestration of containers might be better off set in a decentralized manner. For instance, an engine could have a label to indicate that it has a certain type of disk device, which may not be relevant to security directly. These labels are more easily &quot;trusted&quot; by the swarm orchestrator.</p><p>Refer to the docker service create <a href="https://docs.docker.com/engine/reference/commandline/service_create/">CLI reference</a> for more information about service constraints.</p><h6><strong>Promote or demote a node</strong></h6><p>You can promote a worker node to the manager role. This is useful when a manager node becomes unavailable or if you want to take a manager offline for maintenance. Similarly, you can demote a manager node to the worker role.</p><p><strong>Note</strong>: Regardless of your reason to promote or demote a node, you must always maintain a quorum of manager nodes in the swarm. For more information refer to the <a href="https://docs.docker.com/engine/swarm/admin_guide/">Swarm administration guide</a>.</p><p>To promote a node or set of nodes, run docker node promote from a manager node:</p><p>$ docker node promote node-3 node-2</p><p>Node node-3 promoted to a manager in the swarm.</p><p>Node node-2 promoted to a manager in the swarm.</p><p>To demote a node or set of nodes, run docker node demote from a manager node:</p><p>$ docker node demote node-3 node-2</p><p>Manager node-3 demoted in the swarm.</p><p>Manager node-2 demoted in the swarm.</p><p>docker node promote and docker node demote are convenience commands fordocker node update --role manager and docker node update --role worker respectively.</p><h5><strong>Install plugins on swarm nodes</strong></h5><p><strong>Edge only</strong>: This option is only available in Docker CE Edge versions. See <a href="https://docs.docker.com/edge/">Docker CE Edge</a>.</p><p>If your swarm service relies on one or more <a href="https://docs.docker.com/engine/extend/plugin_api/">plugins</a>, these plugins need to be available on every node where the service could potentially be deployed. You can manually install the plugin on each node or script the installation. In Docker 17.07 and higher, you can also deploy the plugin in a similar way as a global service using the Docker API, by specifying a PluginSpec instead of a ContainerSpec.</p><p><strong>Note</strong>: There is currently no way to deploy a plugin to a swarm using the Docker CLI or Docker Compose. In addition, it is not possible to install plugins from a private repository.</p><p>The <a href="https://docs.docker.com/engine/extend/plugin_api/#json-specification">PluginSpec</a> is defined by the plugin developer. To add the plugin to all Docker nodes, use the <a href="https://docs.docker.com/engine/api/v1.31/#operation/ServiceCreate">service/create</a> API, passing the PluginSpec JSON defined in the TaskTemplate.</p><h5><strong>Leave the swarm</strong></h5><p>Run the docker swarm leave command on a node to remove it from the swarm.</p><p>For example to leave the swarm on a worker node:</p><p>$ docker swarm leave</p><p>Node left the swarm.</p><p>When a node leaves the swarm, the Docker Engine stops running in swarm mode. The orchestrator no longer schedules tasks to the node.</p><p>If the node is a manager node, you receive a warning about maintaining the quorum. To override the warning, pass the --force flag. If the last manager node leaves the swarm, the swarm becomes unavailable requiring you to take disaster recovery measures.</p><p>For information about maintaining a quorum and disaster recovery, refer to the <a href="https://docs.docker.com/engine/swarm/admin_guide/">Swarm administration guide</a>.</p><p>After a node leaves the swarm, you can run the docker node rm command on a manager node to remove the node from the node list.</p><p>For instance:</p><p>$ docker node rm node-2</p><h5><strong>Learn more</strong></h5><ul><li><a href="https://docs.docker.com/engine/swarm/admin_guide/">Swarm administration guide</a></li><li><a href="https://docs.docker.com/engine/reference/commandline/docker/">Docker Engine command line reference</a></li><li><a href="https://docs.docker.com/engine/swarm/swarm-tutorial/">Swarm mode tutorial</a></li></ul><h4>Deploy services to a swarm</h4><p><em>Estimated reading time: 37 minutes</em></p><p>Swarm services use a declarative model, which means that you define the desired state of the service, and rely upon Docker to maintain this state. The state includes information such as (but not limited to):</p><ul><li>the image name and tag the service containers should run</li><li>how many containers participate in the service</li><li>whether any ports are exposed to clients outside the swarm</li><li>whether the service should start automatically when Docker starts</li><li>the specific behavior that happens when the service is restarted (such as whether a rolling restart is used)</li><li>characteristics of the nodes where the service can run (such as resource constraints and placement preferences)</li></ul><p>For an overview of swarm mode, see <a href="https://docs.docker.com/engine/swarm/key-concepts/">Swarm mode key concepts</a>. For an overview of how services work, see <a href="https://docs.docker.com/engine/swarm/how-swarm-mode-works/services/">How services work</a>.</p><h5><strong>Create a service</strong></h5><p>To create a single-replica service with no extra configuration, you only need to supply the image name. This command starts an Nginx service with a randomly-generated name and no published ports. This is a naive example, since you can&#x27;t interact with the Nginx service.</p><p>$ docker service create nginx</p><p>The service is scheduled on an available node. To confirm that the service was created and started successfully, use the docker service ls command:</p><p>$ docker service ls</p><p>ID NAME MODE REPLICAS IMAGE PORTS</p><p>a3iixnklxuem quizzical_lamarr replicated 1/1 docker.io/library/nginx\@sha256:41ad9967ea448d7c2b203c699b429abe1ed5af331cd92533900c6d77490e0268</p><p>Created services do not always run right away. A service can be in a pending state if its image is unavailable, if no node meets the requirements you configure for the service, or other reasons. See <a href="https://docs.docker.com/engine/swarm/how-swarm-mode-works/services/#pending-services">Pending services</a> for more information.</p><p>To provide a name for your service, use the --name flag:</p><p>$ docker service create --name my_web nginx</p><p>Just like with standalone containers, you can specify a command that the service&#x27;s containers should run, by adding it after the image name. This example starts a service called helloworldwhich uses an alpine image and runs the command ping docker.com:</p><p>$ docker service create --name helloworld alpine ping docker.com</p><p>You can also specify an image tag for the service to use. This example modifies the previous one to use the alpine:3.6 tag:</p><p>$ docker service create --name helloworld alpine:3.6 ping docker.com</p><p>For more details about image tag resolution, see <a href="https://docs.docker.com/engine/swarm/services/#specify-the-image-version-the-service-should-use">Specify the image version the service should use</a>.</p><h6><strong>Create a service using an image on a private registry</strong></h6><p>If your image is available on a private registry which requires login, use the--with-registry-auth flag with docker service create, after logging in. If your image is stored on registry.example.com, which is a private registry, use a command like the following:</p><p>$ docker login registry.example.com</p><p>$ docker service create \</p><p>--with-registry-auth \</p><p>--name my_service \</p><p>registry.example.com/acme/my_image:latest</p><p>This passes the login token from your local client to the swarm nodes where the service is deployed, using the encrypted WAL logs. With this information, the nodes are able to log into the registry and pull the image.</p><h5><strong>Update a service</strong></h5><p>You can change almost everything about an existing service using the docker service updatecommand. When you update a service, Docker stops its containers and restarts them with the new configuration.</p><p>Since Nginx is a web service, it works much better if you publish port 80 to clients outside the swarm. You can specify this when you create the service, using the -p or --publish flag. When updating an existing service, the flag is --publish-add. There is also a --publish-rm flag to remove a port that was previously published.</p><p>Assuming that the my_web service from the previous section still exists, use the following command to update it to publish port 80.</p><p>$ docker service update --publish-add 80 my_web</p><p>To verify that it worked, use docker service ls:</p><p>$ docker service ls</p><p>ID NAME MODE REPLICAS IMAGE PORTS</p><p>4nhxl7oxw5vz my_web replicated 1/1 docker.io/library/nginx\@sha256:41ad9967ea448d7c2b203c699b429abe1ed5af331cd92533900c6d77490e0268 *:0-&gt;80/tcp</p><p>For more information on how publishing ports works, see <a href="https://docs.docker.com/engine/swarm/services/#publish-ports">publish ports</a>.</p><p>You can update almost every configuration detail about an existing service, including the image name and tag it runs. See <a href="https://docs.docker.com/engine/swarm/services/#update-a-services-image-after-creation">Update a service&#x27;s image after creation</a>.</p><h5><strong>Remove a service</strong></h5><p>To remove a service, use the docker service remove command. You can remove a service by its ID or name, as shown in the output of the docker service ls command. The following command removes the my_web service.</p><p>$ docker service remove my_web</p><h5><strong>Service configuration details</strong></h5><p>The following sections provide details about service configuration. This topic does not cover every flag or scenario. In almost every instance where you can define a configuration at service creation, you can also update an existing service&#x27;s configuration in a similar way.</p><p>See the command-line references for <a href="https://docs.docker.com/engine/reference/commandline/service_create/">docker service create</a> and <a href="https://docs.docker.com/engine/reference/commandline/service_update/">docker service update</a>, or run one of those commands with the --help flag.</p><h6><strong>Configure the runtime environment</strong></h6><p>You can configure the following options for the runtime environment in the container:</p><ul><li>environment variables using the --env flag</li><li>the working directory inside the container using the --workdir flag</li><li>the username or UID using the --user flag</li></ul><p>The following service&#x27;s containers have an environment variable $MYVAR set to myvalue, run from the /tmp/ directory, and run as the my_user user.</p><p>$ docker service create --name helloworld \</p><p>--env MYVAR=myvalue \</p><p>--workdir /tmp \</p><p>--user my_user \</p><p>alpine ping docker.com</p><h6><strong>Update the command an existing service runs</strong></h6><p>To update the command an existing service runs, you can use the --args flag. The following example updates an existing service called helloworld so that it runs the command ping docker.com instead of whatever command it was running before:</p><p>$ docker service update --args &quot;ping docker.com&quot; helloworld</p><h6><strong>Specify the image version a service should use</strong></h6><p>When you create a service without specifying any details about the version of the image to use, the service uses the version tagged with the latest tag. You can force the service to use a specific version of the image in a few different ways, depending on your desired outcome.</p><p>An image version can be expressed in several different ways:</p><ul><li>If you specify a tag, the manager (or the Docker client, if you use <a href="https://docs.docker.com/engine/swarm/services/#image_resolution_with_trust">content trust</a>) resolves that tag to a digest. When the request to create a container task is received on a worker node, the worker node only sees the digest, not the tag.</li><li>$ docker service create --name=&quot;myservice&quot; ubuntu:16.04</li></ul><p>Some tags represent discrete releases, such as ubuntu:16.04. Tags like this almost always resolve to a stable digest over time. It is recommended that you use this kind of tag when possible.</p><p>Other types of tags, such as latest or nightly, may resolve to a new digest often, depending on how often an image&#x27;s author updates the tag. It is not recommended to run services using a tag which is updated frequently, to prevent different service replica tasks from using different image versions.</p><ul><li>If you don&#x27;t specify a version at all, by convention the image&#x27;s latest tag is resolved to a digest. Workers use the image at this digest when creating the service task.</li></ul><p>Thus, the following two commands are equivalent:</p><p>$ docker service create --name=&quot;myservice&quot; ubuntu</p><p>$ docker service create --name=&quot;myservice&quot; ubuntu:latest</p><ul><li>If you specify a digest directly, that exact version of the image is always used when creating service tasks.</li><li>$ docker service create \</li><li>--name=&quot;myservice&quot; \</li><li>ubuntu:16.04\@sha256:35bc48a1ca97c3971611dc4662d08d131869daa692acb281c7e9e052924e38b1</li></ul><p>When you create a service, the image&#x27;s tag is resolved to the specific digest the tag points to <strong>at the time of service creation</strong>. Worker nodes for that service use that specific digest forever unless the service is explicitly updated. This feature is particularly important if you do use often-changing tags such as latest, because it ensures that all service tasks use the same version of the image.</p><p><strong>Note</strong>: If <a href="https://docs.docker.com/engine/security/trust/content_trust/">content trust</a> is enabled, the client actually resolves the image&#x27;s tag to a digest before contacting the swarm manager, to verify that the image is signed. Thus, if you use content trust, the swarm manager receives the request pre-resolved. In this case, if the client cannot resolve the image to a digest, the request fails.</p><p>If the manager can&#x27;t resolve the tag to a digest, each worker node is responsible for resolving the tag to a digest, and different nodes may use different versions of the image. If this happens, a warning like the following is logged, substituting the placeholders for real information.</p><p>unable to pin image <code style="background-color:lightgray">&lt;IMAGE-NAME&gt; to digest: &lt;REASON&gt;</code></p><p>To see an image&#x27;s current digest, issue the command docker inspect <code style="background-color:lightgray">&lt;IMAGE&gt;:&lt;TAG&gt;</code> and look for the RepoDigests line. The following is the current digest for ubuntu:latest at the time this content was written. The output is truncated for clarity.</p><p>$ docker inspect ubuntu:latest</p><p>&quot;RepoDigests&quot;: [</p><p>&quot;ubuntu\@sha256:35bc48a1ca97c3971611dc4662d08d131869daa692acb281c7e9e052924e38b1&quot;</p><p>],</p><p>After you create a service, its image is never updated unless you explicitly rundocker service update with the --image flag as described below. Other update operations such as scaling the service, adding or removing networks or volumes, renaming the service, or any other type of update operation do not update the service&#x27;s image.</p><h6><strong>Update a service&#x27;s image after creation</strong></h6><p>Each tag represents a digest, similar to a Git hash. Some tags, such as latest, are updated often to point to a new digest. Others, such as ubuntu:16.04, represent a released software version and are not expected to update to point to a new digest often if at all. In Docker 1.13 and higher, when you create a service, it is constrained to create tasks using a specific digest of an image until you update the service using service update with the --image flag. If you use an older version of Docker Engine, you must remove and re-create the service to update its image.</p><p>When you run service update with the --image flag, the swarm manager queries Docker Hub or your private Docker registry for the digest the tag currently points to and updates the service tasks to use that digest.</p><p><strong>Note</strong>: If you use <a href="https://docs.docker.com/engine/swarm/services/#image_resolution_with_trust">content trust</a>, the Docker client resolves image and the swarm manager receives the image and digest, rather than a tag.</p><p>Usually, the manager can resolve the tag to a new digest and the service updates, redeploying each task to use the new image. If the manager can&#x27;t resolve the tag or some other problem occurs, the next two sections outline what to expect.</p><p><strong>IF THE MANAGER RESOLVES THE TAG</strong></p><p>If the swarm manager can resolve the image tag to a digest, it instructs the worker nodes to redeploy the tasks and use the image at that digest.</p><ul><li>If a worker has cached the image at that digest, it uses it.</li><li>If not, it attempts to pull the image from Docker Hub or the private registry.<ul><li>If it succeeds, the task is deployed using the new image.</li><li>If the worker fails to pull the image, the service fails to deploy on that worker node. Docker tries again to deploy the task, possibly on a different worker node.</li></ul></li></ul><p><strong>IF THE MANAGER CANNOT RESOLVE THE TAG</strong></p><p>If the swarm manager cannot resolve the image to a digest, all is not lost:</p><ul><li>The manager instructs the worker nodes to redeploy the tasks using the image at that tag.</li><li>If the worker has a locally cached image that resolves to that tag, it uses that image.</li><li>If the worker does not have a locally cached image that resolves to the tag, the worker tries to connect to Docker Hub or the private registry to pull the image at that tag.<ul><li>If this succeeds, the worker uses that image.</li><li>If this fails, the task fails to deploy and the manager tries again to deploy the task, possibly on a different worker node.</li></ul></li></ul><h6><strong>Publish ports</strong></h6><p>When you create a swarm service, you can publish that service&#x27;s ports to hosts outside the swarm in two ways:</p><ul><li><a href="https://docs.docker.com/engine/swarm/services/#publish-a%20services-ports-using-the-routing-mesh">You can rely on the routing mesh</a>. When you publish a service port, the swarm makes the service accessible at the target port on every node, regardless of whether there is a task for the service running on that node or not. This is less complex and is the right choice for many types of services.</li><li><a href="https://docs.docker.com/engine/swarm/services/#publish-a-services-ports-directly-on-the-swarm-node">You can publish a service task&#x27;s port directly on the swarm node</a> where that service is running. This feature is available in Docker 1.13 and higher. This bypasses the routing mesh and provides the maximum flexibility, including the ability for you to develop your own routing framework. However, you are responsible for keeping track of where each task is running and routing requests to the tasks, and load-balancing across the nodes.</li></ul><p>Keep reading for more information and use cases for each of these methods.</p><p><strong>PUBLISH A SERVICE&#x27;S PORTS USING THE ROUTING MESH</strong></p><p>To publish a service&#x27;s ports externally to the swarm, use the--publish <code style="background-color:lightgray">&lt;PUBLISHED-PORT&gt;:&lt;SERVICE-PORT&gt;</code> flag. The swarm makes the service accessible at the published port <strong>on every swarm node</strong>. If an external host connects to that port on any swarm node, the routing mesh routes it to a task. The external host does not need to know the IP addresses or internally-used ports of the service tasks to interact with the service. When a user or process connects to a service, any worker node running a service task may respond. For more details about swarm service networking, see <a href="https://docs.docker.com/engine/swarm/networking/">Manage swarm service networks</a>.</p><p><strong>Example: Run a three-task Nginx service on 10-node swarm</strong></p><p>Imagine that you have a 10-node swarm, and you deploy an Nginx service running three tasks on a 10-node swarm:</p><p>$ docker service create --name my_web \</p><p>--replicas 3 \</p><p>--publish published=8080,target=80 \</p><p>nginx</p><p>Three tasks run on up to three nodes. You don&#x27;t need to know which nodes are running the tasks; connecting to port 8080 on <strong>any</strong> of the 10 nodes connects you to one of the three nginx tasks. You can test this using curl. The following example assumes that localhost is one of the swarm nodes. If this is not the case, or localhost does not resolve to an IP address on your host, substitute the host&#x27;s IP address or resolvable host name.</p><p>The HTML output is truncated:</p><p>$ curl localhost:8080</p><p><code style="background-color:lightgray">&lt;!DOCTYPE html&gt;</code></p><p><code style="background-color:lightgray">&lt;html&gt;</code></p><p><code style="background-color:lightgray">&lt;head&gt;</code></p><p><code style="background-color:lightgray">&lt;title&gt;Welcome to nginx!&lt;/title&gt;</code></p><p>...truncated...</p><p><code style="background-color:lightgray">&lt;/html&gt;</code></p><p>Subsequent connections may be routed to the same swarm node or a different one.</p><p><strong>PUBLISH A SERVICE&#x27;S PORTS DIRECTLY ON THE SWARM NODE</strong></p><p>Using the routing mesh may not be the right choice for your application if you need to make routing decisions based on application state or you need total control of the process for routing requests to your service&#x27;s tasks. To publish a service&#x27;s port directly on the node where it is running, use the mode=host option to the --publish flag.</p><p><strong>Note: If you publish a service&#x27;s ports directly on the swarm node using mode=host and also set published=<code>&lt;PORT&gt;</code> this creates an implicit limitation that you can only run one task for that service on a given swarm node. You can work around this by specifying published without a port definition, which causes Docker to assign a random port for each task.</strong></p><p>In addition, if you use mode=host and you do not use the --mode=global flag on docker service create, it is difficult to know which nodes are running the service to route work to them.</p><p><strong>Example: Run a nginx web server service on every swarm node</strong></p><p><a href="https://hub.docker.com/_/nginx/">nginx</a> is an open source reverse proxy, load balancer, HTTP cache, and a web server. If you run nginx as a service using the routing mesh, connecting to the nginx port on any swarm node shows you the web page for (effectively) <strong>a random swarm node</strong> running the service.</p><p>The following example runs nginx as a service on each node in your swarm and exposes nginx port locally on each swarm node.</p><p>$ docker service create \</p><p>--mode global \</p><p>--publish mode=host,target=80,published=8080 \</p><p>--name=nginx \</p><p>nginx:latest</p><p>You can reach the nginx server on port 8080 of every swarm node. If you add a node to the swarm, a nginx task is started on it. You cannot start another service or container on any swarm node which binds to port 8080.</p><p><strong>Note</strong>: This is a naive example. Creating an application-layer routing framework for a multi-tiered service is complex and out of scope for this topic.</p><h6><strong>Connect the service to an overlay network</strong></h6><p>You can use overlay networks to connect one or more services within the swarm.</p><p>First, create overlay network on a manager node using the docker network create command with the --driver overlay flag.</p><p>$ docker network create --driver overlay my-network</p><p>After you create an overlay network in swarm mode, all manager nodes have access to the network.</p><p>You can create a new service and pass the --network flag to attach the service to the overlay network:</p><p>$ docker service create \</p><p>--replicas 3 \</p><p>--network my-network \</p><p>--name my-web \</p><p>nginx</p><p>The swarm extends my-network to each node running the service.</p><p>You can also connect an existing service to an overlay network using the --network-add flag.</p><p>$ docker service update --network-add my-network my-web</p><p>To disconnect a running service from a network, use the --network-rm flag.</p><p>$ docker service update --network-rm my-network my-web</p><p>For more information on overlay networking and service discovery, refer to <a href="https://docs.docker.com/engine/swarm/networking/">Attach services to an overlay network</a> and <a href="https://docs.docker.com/engine/userguide/networking/overlay-security-model/">Docker swarm mode overlay network security model</a>.</p><h6><strong>Grant a service access to secrets</strong></h6><p>To create a service with access to Docker-managed secrets, use the --secret flag. For more information, see <a href="https://docs.docker.com/engine/swarm/secrets/">Manage sensitive strings (secrets) for Docker services</a></p><h6><strong>Customize a service&#x27;s isolation mode</strong></h6><p>Docker 17.12 CE and higher allow you to specify a swarm service&#x27;s isolation mode. <strong>This setting applies to Windows hosts only and is ignored for Linux hosts.</strong> The isolation mode can be one of the following:</p><ul><li>default: Use the default isolation mode configured for the Docker host, as configured by the -exec-opt flag or exec-opts array in daemon.json. If the daemon does not specify an isolation technology, process is the default for Windows Server, and hyperv is the default (and only) choice for Windows 10.</li><li>process: Run the service tasks as a separate process on the host.</li></ul><p><strong>Note</strong>: process isolation mode is only supported on Windows Server. Windows 10 only supports hyperv isolation mode.</p><ul><li>hyperv: Run the service tasks as isolated hyperv tasks. This increases overhead but provides more isolation.</li></ul><p>You can specify the isolation mode when creating or updating a new service using the --isolation flag.</p><h6><strong>Control service placement</strong></h6><p>Swarm services provide a few different ways for you to control scale and placement of services on different nodes.</p><ul><li>You can specify whether the service needs to run a specific number of replicas or should run globally on every worker node. See <a href="https://docs.docker.com/engine/swarm/services/#replicated-or-global-services">Replicated or global services</a>.</li><li>You can configure the service&#x27;s <a href="https://docs.docker.com/engine/swarm/services/#reserve-memory-or-cpus-for-a-service">CPU or memory requirements</a>, and the service only runs on nodes which can meet those requirements.</li><li><a href="https://docs.docker.com/engine/swarm/services/#placement-constraints">Placement constraints</a> let you configure the service to run only on nodes with specific (arbitrary) metadata set, and cause the deployment to fail if appropriate nodes do not exist. For instance, you can specify that your service should only run on nodes where an arbitrary label pci_compliant is set to true.</li><li><a href="https://docs.docker.com/engine/swarm/services/#placement-preferences">Placement preferences</a> let you apply an arbitrary label with a range of values to each node, and spread your service&#x27;s tasks across those nodes using an algorithm. Currently, the only supported algorithm is spread, which tries to place them evenly. For instance, if you label each node with a label rack which has a value from 1-10, then specify a placement preference keyed on rack, then service tasks are placed as evenly as possible across all nodes with the label rack, after taking other placement constraints, placement preferences, and other node-specific limitations into account.</li></ul><p>Unlike constraints, placement preferences are best-effort, and a service does not fail to deploy if no nodes can satisfy the preference. If you specify a placement preference for a service, nodes that match that preference are ranked higher when the swarm managers decide which nodes should run the service tasks. Other factors, such as high availability of the service, also factor into which nodes are scheduled to run service tasks. For example, if you have N nodes with the rack label (and then some others), and your service is configured to run N+1 replicas, the +1 is scheduled on a node that doesn&#x27;t already have the service on it if there is one, regardless of whether that node has the rack label or not.</p><p><strong>REPLICATED OR GLOBAL SERVICES</strong></p><p>Swarm mode has two types of services: replicated and global. For replicated services, you specify the number of replica tasks for the swarm manager to schedule onto available nodes. For global services, the scheduler places one task on each available node that meets the service&#x27;s <a href="https://docs.docker.com/engine/swarm/services/#placement-constraints">placement constraints</a> and <a href="https://docs.docker.com/engine/swarm/services/#reserve-cpu-or-memory-for-a-service">resource requirements</a>.</p><p>You control the type of service using the --mode flag. If you don&#x27;t specify a mode, the service defaults to replicated. For replicated services, you specify the number of replica tasks you want to start using the --replicas flag. For example, to start a replicated nginx service with 3 replica tasks:</p><p>$ docker service create \</p><p>--name my_web \</p><p>--replicas 3 \</p><p>nginx</p><p>To start a global service on each available node, pass --mode global to docker service create. Every time a new node becomes available, the scheduler places a task for the global service on the new node. For example to start a service that runs alpine on every node in the swarm:</p><p>$ docker service create \</p><p>--name myservice \</p><p>--mode global \</p><p>alpine top</p><p>Service constraints let you set criteria for a node to meet before the scheduler deploys a service to the node. You can apply constraints to the service based upon node attributes and metadata or engine metadata. For more information on constraints, refer to the docker service create <a href="https://docs.docker.com/engine/reference/commandline/service_create/">CLI reference</a>.</p><p><strong>RESERVE MEMORY OR CPUS FOR A SERVICE</strong></p><p>To reserve a given amount of memory or number of CPUs for a service, use the--reserve-memory or --reserve-cpu flags. If no available nodes can satisfy the requirement (for instance, if you request 4 CPUs and no node in the swarm has 4 CPUs), the service remains in a pending state until an appropriate node is available to run its tasks.</p><p><strong>Out Of Memory Exceptions (OOME)</strong></p><p>If your service attempts to use more memory than the swarm node has available, you may experience an Out Of Memory Exception (OOME) and a container, or the Docker daemon, might be killed by the kernel OOM killer. To prevent this from happening, ensure that your application runs on hosts with adequate memory and see <a href="https://docs.docker.com/engine/admin/resource_constraints/#understand-the-risks-of-running-out-of-memory">Understand the risks of running out of memory</a>.</p><p>Swarm services allow you to use resource constraints, placement preferences, and labels to ensure that your service is deployed to the appropriate swarm nodes.</p><p><strong>PLACEMENT CONSTRAINTS</strong></p><p>Use placement constraints to control the nodes a service can be assigned to. In the following example, the service only runs on nodes with the <a href="https://docs.docker.com/engine/swarm/engine/swarm/manage-nodes/#add-or-remove-label-metadata">label</a> region set to east. If no appropriately-labelled nodes are available, deployment fails. The --constraint flag uses an equality operator (== or !=). For replicated services, it is possible that all services run on the same node, or each node only runs one replica, or that some nodes don&#x27;t run any replicas. For global services, the service runs on every node that meets the placement constraint and any <a href="https://docs.docker.com/engine/swarm/services/#reserve-cpu-or-memory-for-a-service">resource requirements</a>.</p><p>$ docker service create \</p><p>--name my-nginx \</p><p>--replicas 5 \</p><p>--constraint region==east \</p><p>nginx</p><p>You can also use the constraint service-level key in a docker-compose.yml file.</p><p>If you specify multiple placement constraints, the service only deploys onto nodes where they are all met. The following example limits the service to run on all nodes where region is set to east and type is not set to devel:</p><p>$ docker service create \</p><p>--name my-nginx \</p><p>--global \</p><p>--constraint region==east \</p><p>--constraint type!=devel \</p><p>nginx</p><p>You can also use placement constraints in conjunction with placement preferences and CPU/memory constraints. Be careful not to use settings that are not possible to fulfill.</p><p>For more information on constraints, refer to the docker service create <a href="https://docs.docker.com/engine/reference/commandline/service_create/">CLI reference</a>.</p><p><strong>PLACEMENT PREFERENCES</strong></p><p>While <a href="https://docs.docker.com/engine/swarm/services/#placement-constraints">placement constraints</a> limit the nodes a service can run on, placement preferences try to place services on appropriate nodes in an algorithmic way (currently, only spread evenly). For instance, if you assign each node a rack label, you can set a placement preference to spread the service evenly across nodes with the rack label, by value. This way, if you lose a rack, the service is still running on nodes on other racks.</p><p>Placement preferences are not strictly enforced. If no node has the label you specify in your preference, the service is deployed as though the preference were not set.</p><p>Placement preferences are ignored for global services.</p><p>The following example sets a preference to spread the deployment across nodes based on the value of the datacenter label. If some nodes have datacenter=us-east and others have datacenter=us-west, the service is deployed as evenly as possible across the two sets of nodes.</p><p>$ docker service create \</p><p>--replicas 9 \</p><p>--name redis_2 \</p><p>--placement-pref \&#x27;spread=node.labels.datacenter\&#x27; \</p><p>redis:3.0.6</p><p><strong>Missing or null labels</strong></p><p>Nodes which are missing the label used to spread still receive task assignments. As a group, these nodes receive tasks in equal proportion to any of the other groups identified by a specific label value. In a sense, a missing label is the same as having the label with a null value attached to it. If the service should <strong>only</strong> run on nodes with the label being used for the the spread preference, the preference should be combined with a constraint.</p><p>You can specify multiple placement preferences, and they are processed in the order they are encountered. The following example sets up a service with multiple placement preferences. Tasks are spread first over the various datacenters, and then over racks (as indicated by the respective labels):</p><p>$ docker service create \</p><p>--replicas 9 \</p><p>--name redis_2 \</p><p>--placement-pref \&#x27;spread=node.labels.datacenter\&#x27; \</p><p>--placement-pref \&#x27;spread=node.labels.rack\&#x27; \</p><p>redis:3.0.6</p><p>You can also use placement preferences in conjunction with placement constraints or CPU/memory constraints. Be careful not to use settings that are not possible to fulfill.</p><p>This diagram illustrates how placement preferences work:</p><p>When updating a service with docker service update, --placement-pref-add appends a new placement preference after all existing placement preferences. --placement-pref-rm removes an existing placement preference that matches the argument.</p><h6><strong>Configure a service&#x27;s update behavior</strong></h6><p>When you create a service, you can specify a rolling update behavior for how the swarm should apply changes to the service when you run docker service update. You can also specify these flags as part of the update, as arguments to docker service update.</p><p>The --update-delay flag configures the time delay between updates to a service task or sets of tasks. You can describe the time T as a combination of the number of seconds Ts, minutes Tm, or hours Th. So 10m30s indicates a 10 minute 30 second delay.</p><p>By default the scheduler updates 1 task at a time. You can pass the --update-parallelism flag to configure the maximum number of service tasks that the scheduler updates simultaneously.</p><p>When an update to an individual task returns a state of RUNNING, the scheduler continues the update by continuing to another task until all tasks are updated. If, at any time during an update a task returns FAILED, the scheduler pauses the update. You can control the behavior using the --update-failure-action flag for docker service create or docker service update.</p><p>In the example service below, the scheduler applies updates to a maximum of 2 replicas at a time. When an updated task returns either RUNNING or FAILED, the scheduler waits 10 seconds before stopping the next task to update:</p><p>$ docker service create \</p><p>--replicas 10 \</p><p>--name my_web \</p><p>--update-delay 10s \</p><p>--update-parallelism 2 \</p><p>--update-failure-action continue \</p><p>alpine</p><p>The --update-max-failure-ratio flag controls what fraction of tasks can fail during an update before the update as a whole is considered to have failed. For example, with --update-max-failure-ratio 0.1 --update-failure-action pause, after 10% of the tasks being updated fail, the update is paused.</p><p>An individual task update is considered to have failed if the task doesn&#x27;t start up, or if it stops running within the monitoring period specified with the --update-monitor flag. The default value for --update-monitor is 30 seconds, which means that a task failing in the first 30 seconds after its started counts towards the service update failure threshold, and a failure after that is not counted.</p><h6><strong>Roll back to the previous version of a service</strong></h6><p>In case the updated version of a service doesn&#x27;t function as expected, it&#x27;s possible to manually roll back to the previous version of the service using docker service update&#x27;s --rollback flag. This reverts the service to the configuration that was in place before the most recentdocker service update command.</p><p>Other options can be combined with --rollback; for example, --update-delay 0s to execute the rollback without a delay between tasks:</p><p>$ docker service update \</p><p>--rollback \</p><p>--update-delay 0s</p><p>my_web</p><p>In Docker 17.04 and higher, you can configure a service to roll back automatically if a service update fails to deploy. See <a href="https://docs.docker.com/engine/swarm/services/#automatically-roll-back-if-an-update-fails">Automatically roll back if an update fails</a>.</p><p>Related to the new automatic rollback feature, in Docker 17.04 and higher, manual rollback is handled at the server side, rather than the client, if the daemon is running Docker 17.04 or higher. This allows manually-initiated rollbacks to respect the new rollback parameters. The client is version-aware, so it still uses the old method against an older daemon.</p><p>Finally, in Docker 17.04 and higher, --rollback cannot be used in conjunction with other flags to docker service update.</p><h6><strong>Automatically roll back if an update fails</strong></h6><p>You can configure a service in such a way that if an update to the service causes redeployment to fail, the service can automatically roll back to the previous configuration. This helps protect service availability. You can set one or more of the following flags at service creation or update. If you do not set a value, the default is used.</p><p>  <strong>Flag</strong>                        <strong>Default</strong>   <strong>Description</strong></p><hr/><p>  --rollback-delay               0s            Amount of time to wait after rolling back a task before rolling back the next one. A value of 0means to roll back the second task immediately after the first rolled-back task deploys.
--rollback-failure-action      pause         When a task fails to roll back, whether to pauseor continue trying to roll back other tasks.
--rollback-max-failure-ratio   0             The failure rate to tolerate during a rollback, specified as a floating-point number between 0 and 1. For instance, given 5 tasks, a failure ratio of .2 would tolerate one task failing to roll back. A value of 0 means no failure are tolerated, while a value of 1 means any number of failure are tolerated.
--rollback-monitor             5s            Duration after each task rollback to monitor for failure. If a task stops before this time period has elapsed, the rollback is considered to have failed.
--rollback-parallelism         1             The maximum number of tasks to roll back in parallel. By default, one task is rolled back at a time. A value of 0 causes all tasks to be rolled back in parallel.</p><p>The following example configures a redis service to roll back automatically if a docker service update fails to deploy. Two tasks can be rolled back in parallel. Tasks are monitored for 20 seconds after rollback to be sure they do not exit, and a maximum failure ratio of 20% is tolerated. Default values are used for --rollback-delay and --rollback-failure-action.</p><p>$ docker service create --name=my_redis \</p><p>--replicas=5 \</p><p>--rollback-parallelism=2 \</p><p>--rollback-monitor=20s \</p><p>--rollback-max-failure-ratio=.2 \</p><p>redis:latest</p><h6><strong>Give a service access to volumes or bind mounts</strong></h6><p>For best performance and portability, you should avoid writing important data directly into a container&#x27;s writable layer, instead using data volumes or bind mounts. This principle also applies to services.</p><p>You can create two types of mounts for services in a swarm, volume mounts or bind mounts. Regardless of which type of mount you use, configure it using the --mount flag when you create a service, or the --mount-add or --mount-rm flag when updating an existing service.. The default is a data volume if you don&#x27;t specify a type.</p><p><strong>DATA VOLUMES</strong></p><p>Data volumes are storage that remain alive after a container for a task has been removed. The preferred method to mount volumes is to leverage an existing volume:</p><p>$ docker service create \</p><p>--mount src=<code style="background-color:lightgray">&lt;VOLUME-NAME&gt;,dst=&lt;CONTAINER-PATH&gt;</code> \</p><p>--name myservice \</p><p><code style="background-color:lightgray">&lt;IMAGE&gt;</code></p><p>For more information on how to create a volume, see the volume create <a href="https://docs.docker.com/engine/reference/commandline/volume_create/">CLI reference</a>.</p><p>The following method creates the volume at deployment time when the scheduler dispatches a task, just before starting the container:</p><p>$ docker service create \</p><p>--mount type=volume,src=<code style="background-color:lightgray">&lt;VOLUME-NAME&gt;,dst=&lt;CONTAINER-PATH&gt;,volume-driver=&lt;DRIVER&gt;,volume-opt=&lt;KEY0&gt;=&lt;VALUE0&gt;,volume-opt=&lt;KEY1&gt;=&lt;VALUE1&gt;</code></p><p>--name myservice \</p><p><code style="background-color:lightgray">&lt;IMAGE&gt;</code></p><p><strong>Important: If your volume driver accepts a comma-separated list as an option, you must escape the value from the outer CSV parser. To escape a volume-opt, surround it with double quotes (&quot;) and surround the entire mount parameter with single quotes (\&#x27;).</strong></p><p>For example, the local driver accepts mount options as a comma-separated list in the o parameter. This example shows the correct way to escape the list.</p><p>$ docker service create \</p><p>--mount \&#x27;type=volume,src=<code style="background-color:lightgray">&lt;VOLUME-NAME&gt;,dst=&lt;CONTAINER-PATH&gt;,volume-driver=local,volume-opt=type=nfs,volume-opt=device=&lt;nfs-server&gt;:&lt;nfs-path&gt;,&quot;volume-opt=o=addr=&lt;nfs-address&gt;</code>,vers=4,soft,timeo=180,bg,tcp,rw&quot;\&#x27;</p><p>--name myservice \</p><p><code style="background-color:lightgray">&lt;IMAGE&gt;</code></p><p><strong>BIND MOUNTS</strong></p><p>Bind mounts are file system paths from the host where the scheduler deploys the container for the task. Docker mounts the path into the container. The file system path must exist before the swarm initializes the container for the task.</p><p>The following examples show bind mount syntax:</p><ul><li>To mount a read-write bind:</li><li>$ docker service create \</li><li>--mount type=bind,src=<code>&lt;HOST-PATH&gt;,dst=&lt;CONTAINER-PATH&gt;</code> \</li><li>--name myservice \</li><li><code>&lt;IMAGE&gt;</code></li><li>To mount a read-only bind:</li><li>$ docker service create \</li><li>--mount type=bind,src=<code>&lt;HOST-PATH&gt;,dst=&lt;CONTAINER-PATH&gt;</code>,readonly \</li><li>--name myservice \</li><li><code>&lt;IMAGE&gt;</code></li></ul><p><strong>Important: Bind mounts can be useful but they can also cause problems. In most cases, it is recommended that you architect your application such that mounting paths from the host is unnecessary. The main risks include the following:</strong></p><ul><li>If you bind mount a host path into your service&#x27;s containers, the path must exist on every swarm node. The Docker swarm mode scheduler can schedule containers on any machine that meets resource availability requirements and satisfies all constraints and placement preferences you specify.</li><li>The Docker swarm mode scheduler may reschedule your running service containers at any time if they become unhealthy or unreachable.</li><li>Host bind mounts are completely non-portable. When you use bind mounts, there is no guarantee that your application runs the same way in development as it does in production.</li></ul><h6><strong>Create services using templates</strong></h6><p>You can use templates for some flags of service create, using the syntax provided by the Go&#x27;s <a href="http://golang.org/pkg/text/template/">text/template</a> package.</p><p>The following flags are supported:</p><ul><li>--hostname</li><li>--mount</li><li>--env</li></ul><p>Valid placeholders for the Go template are:</p><p>  <strong>Placeholder</strong>   <strong>Description</strong></p><hr/><p>  .Service.ID       Service ID
.Service.Name     Service name
.Service.Labels   Service labels
.Node.ID          Node ID
.Task.Name        Task name
.Task.Slot        Task slot</p><p><strong>TEMPLATE EXAMPLE</strong></p><p>This example sets the template of the created containers based on the service&#x27;s name and the ID of the node where the container is running:</p><p>$ docker service create --name hosttempl \</p><p>--hostname=&quot;{{.Node.ID}}-{{.Service.Name}}&quot;\</p><p>busybox top</p><p>To see the result of using the template, use the docker service ps and docker inspectcommands.</p><p>$ docker service ps va8ew30grofhjoychbr6iot8c</p><p>ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS</p><p>wo41w8hg8qan hosttempl.1 busybox:latest\@sha256:29f5d56d12684887bdfa50dcd29fc31eea4aaf4ad3bec43daf19026a7ce69912 2e7a8a9c4da2 Running Running about a minute ago</p><p>$ docker inspect --format=&quot;{{.Config.Hostname}}&quot; hosttempl.1.wo41w8hg8qanxwjwsg4kxpprj</p><h5><strong>Learn More</strong></h5><ul><li><a href="https://docs.docker.com/engine/swarm/admin_guide/">Swarm administration guide</a></li><li><a href="https://docs.docker.com/engine/reference/commandline/docker/">Docker Engine command line reference</a></li><li><a href="https://docs.docker.com/engine/swarm/swarm-tutorial/">Swarm mode tutorial</a></li></ul><h4>Store configuration data using Docker Configs</h4><p><em>Estimated reading time: 18 minutes</em></p><h5><strong>About configs</strong></h5><p>Docker 17.06 introduces swarm service configs, which allow you to store non-sensitive information, such as configuration files, outside a service&#x27;s image or running containers. This allows you to keep your images as generic as possible, without the need to bind-mount configuration files into the containers or use environment variables.</p><p>Configs operate in a similar way to <a href="https://docs.docker.com/engine/swarm/secrets/">secrets</a>, except that they are not encrypted at rest and are mounted directly into the container&#x27;s filesystem without the use of RAM disks. Configs can be added or removed from a service at any time, and services can share a config. You can even use configs in conjunction with environment variables or labels, for maximum flexibility. Config values can be generic strings or binary content (up to 500 kb in size).</p><p><strong>Note</strong>: Docker configs are only available to swarm services, not to standalone containers. To use this feature, consider adapting your container to run as a service with a scale of 1.</p><p>Configs are supported on both Linux and Windows services.</p><h6><strong>Windows support</strong></h6><p>Docker 17.06 and higher include support for configs on Windows containers. Where there are differences in the implementations, they are called out in the examples below. Keep the following notable differences in mind:</p><ul><li>Config files with custom targets are not directly bind-mounted into Windows containers, since Windows does not support non-directory file bind-mounts. Instead, configs for a container are all mounted in C:\ProgramData\Docker\internal\configs (an implementation detail which should not be relied upon by applications) within the container. Symbolic links are used to point from there to the desired target of the config within the container. The default target is C:\ProgramData\Docker\configs.</li><li>When creating a service which uses Windows containers, the options to specify UID, GID, and mode are not supported for configs. Configs are currently only accessible by administrators and users with system access within the container.</li></ul><h5><strong>How Docker manages configs</strong></h5><p>When you add a config to the swarm, Docker sends the config to the swarm manager over a mutual TLS connection. The config is stored in the Raft log, which is encrypted. The entire Raft log is replicated across the other managers, ensuring the same high availability guarantees for configs as for the rest of the swarm management data.</p><p>When you grant a newly-created or running service access to a config, the config is mounted as a file in the container. The location of the mount point within the container defaults to /<code style="background-color:lightgray">&lt;config-name&gt; in Linux containers. In Windows containers, configs are all mounted into C:\ProgramData\Docker\configs and symbolic links are created to the desired location, which defaults to C:\&lt;config-name&gt;</code>.</p><p>You can set the ownership (uid and gid) or the config, using either the numerical ID or the name of the user or group. You can also specify the file permissions (mode). These settings are ignored for Windows containers.</p><ul><li>If not set, the config is owned by the user and that running the container command (often root) and that user&#x27;s default group (also often root).</li><li>If not set, the config has world-readable permissions (mode 0444), unless a umask is set within the container, in which case the mode is impacted by that umask value.</li></ul><p>You can update a service to grant it access to additional configs or revoke its access to a given config at any time.</p><p>A node only has access to configs if the node is a swarm manager or if it is running service tasks which have been granted access to the config. When a container task stops running, the configs shared to it are unmounted from the in-memory filesystem for that container and flushed from the node&#x27;s memory.</p><p>If a node loses connectivity to the swarm while it is running a task container with access to a config, the task container still has access to its configs, but cannot receive updates until the node reconnects to the swarm.</p><p>You can add or inspect an individual config at any time, or list all configs. You cannot remove a config that a running service is using. See <a href="https://docs.docker.com/engine/swarm/configs/#example-rotate-a-config">Rotate a config</a> for a way to remove a config without disrupting running services.</p><p>To update or roll back configs more easily, consider adding a version number or date to the config name. This is made easier by the ability to control the mount point of the config within a given container.</p><p>To update a stack, make changes to your Compose file, then re-run docker stack deploy -c <code style="background-color:lightgray">&lt;new-compose-file&gt; &lt;stack-name&gt;</code>. If you use a new config in that file, your services start using them. Keep in mind that configurations are immutable, so you can&#x27;t change the file for an existing service. Instead, you create a new config to use a different file</p><p>You can run docker stack rm to stop the app and take down the stack. This removes any config that was created by docker stack deploy with the same stack name. This removes all configs, including those not referenced by services and those remaining after a docker service update --config-rm.</p><h5><strong>Read more about docker config commands</strong></h5><p>Use these links to read about specific commands, or continue to the <a href="https://docs.docker.com/engine/swarm/configs/#example-use-configs-with-a-service">example about using configs with a service</a>.</p><ul><li><a href="https://docs.docker.com/engine/reference/commandline/config_create/">docker config create</a></li><li><a href="https://docs.docker.com/engine/reference/commandline/config_inspect/">docker config inspect</a></li><li><a href="https://docs.docker.com/engine/reference/commandline/config_ls/">docker config ls</a></li><li><a href="https://docs.docker.com/engine/reference/commandline/config_rm/">docker config rm</a></li></ul><h5><strong>Examples</strong></h5><p>This section includes graduated examples which illustrate how to use Docker configs.</p><p><strong>Note</strong>: These examples use a single-Engine swarm and unscaled services for simplicity. The examples use Linux containers, but Windows containers also support configs.</p><h6><strong>Defining and using configs in compose files</strong></h6><p>Both the docker compose and docker stack commands support defining configs in a compose file. See <a href="https://docs.docker.com/compose/compose-file/#configs">the Compose file reference</a> for details.</p><h6><strong>Simple example: Get started with configs</strong></h6><p>This simple example shows how configs work in just a few commands. For a real-world example, continue to <a href="https://docs.docker.com/engine/swarm/configs/#advanced-example-use-configs-with-a-nginx-service">Intermediate example: Use configs with a Nginx service</a>.</p><ol><li>Add a config to Docker. The docker config create command reads standard input because the last argument, which represents the file to read the config from, is set to -.</li><li>$ echo &quot;This is a config&quot; | docker config create my-config -</li><li>Create a redis service and grant it access to the config. By default, the container can access the config at /my-config, but you can customize the file name on the container using the target option.</li><li>$ docker service create --name redis --config my-config redis:alpine</li><li>Verify that the task is running without issues using docker service ps. If everything is working, the output looks similar to this:</li><li>$ docker service ps redis</li><li>ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS</li><li>bkna6bpn8r1a redis.1 redis:alpine ip-172-31-46-109 Running Running 8 seconds ago</li><li>Get the ID of the redis service task container using docker ps, so that you can use docker container exec to connect to the container and read the contents of the config data file, which defaults to being readable by all and has the same name as the name of the config. The first command below illustrates how to find the container ID, and the second and third commands use shell completion to do this automatically.</li><li>$ docker ps --filter name=redis -q</li><li>5cb1c2348a59</li><li>$ docker container exec $(docker ps --filter name=redis -q) ls -l /my-config</li><li>-r--r--r-- 1 root root 12 Jun 5 20:49 my-config</li><li>$ docker container exec $(docker ps --filter name=redis -q) cat /my-config</li><li>This is a config</li><li>Try removing the config. The removal fails because the redis service is running and has access to the config.</li><li>$ docker config ls</li><li>ID NAME CREATED UPDATED</li><li>fzwcfuqjkvo5foqu7ts7ls578 hello 31 minutes ago 31 minutes ago</li><li>$ docker config rm my-config</li><li>Error response from daemon: rpc error: code = 3 desc = config \&#x27;my-config\&#x27; is</li><li>in use by the following service: redis</li><li>Remove access to the config from the running redis service by updating the service.</li><li>$ docker service update --config-rm my-config redis</li><li>Repeat steps 3 and 4 again, verifying that the service no longer has access to the config. The container ID is different, because the service update command redeploys the service.</li><li>$ docker container exec -it $(docker ps --filter name=redis -q) cat /my-config</li><li>cat: can\&#x27;t open \&#x27;/my-config\&#x27;: No such file or directory</li><li>Stop and remove the service, and remove the config from Docker.</li><li>$ docker service rm redis</li><li>$ docker config rm my-config</li></ol><h6><strong>Simple example: Use configs in a Windows service</strong></h6><p>This is a very simple example which shows how to use configs with a Microsoft IIS service running on Docker 17.06 EE on Microsoft Windows Server 2016 or Docker for Windows 17.06 CE on Microsoft Windows 10. It stores the webpage in a config.</p><p>This example assumes that you have PowerShell installed.</p><ol><li>Save the following into a new file index.html.</li><li><code>&lt;html&gt;</code></li><li><code>&lt;head&gt;&lt;title&gt;Hello Docker&lt;/title&gt;&lt;/head&gt;</code></li><li><code>&lt;body&gt;</code></li><li><code>&lt;p&gt;Hello Docker! You have deployed a HTML page.&lt;/p&gt;</code></li><li><code>&lt;/body&gt;</code></li><li><code>&lt;/html&gt;</code></li><li>If you have not already done so, initialize or join the swarm.</li><li>docker swarm init</li><li>Save the index.html file as a swarm config named homepage.</li><li>docker config create homepage index.html</li><li>Create an IIS service and grant it access to the homepage config.</li><li>docker service create</li><li>--name my-iis</li><li>--publish published=8000,target=8000</li><li>--config src=homepage,target=&quot;\inetpub\wwwroot\index.html&quot;</li><li>microsoft/iis:nanoserver</li><li>Access the IIS service at http://localhost:8000/. It should serve the HTML content from the first step.</li><li>Remove the service and the config.</li><li>docker service rm my-iis</li><li>docker config rm homepage</li></ol><h6><strong>Advanced example: Use configs with a Nginx service</strong></h6><p>This example is divided into two parts. <a href="https://docs.docker.com/engine/swarm/configs/#generate-the-site-certificate">The first part</a> is all about generating the site certificate and does not directly involve Docker configs at all, but it sets up <a href="https://docs.docker.com/engine/swarm/configs/#configure-the-nginx-container">the second part</a>, where you store and use the site certificate as a series of secrets and the Nginx configuration as a config. The example shows how to set options on the config, such as the target location within the container and the file permissions (mode).</p><p><strong>GENERATE THE SITE CERTIFICATE</strong></p><p>Generate a root CA and TLS certificate and key for your site. For production sites, you may want to use a service such as Let&#x27;s Encrypt to generate the TLS certificate and key, but this example uses command-line tools. This step is a little complicated, but is only a set-up step so that you have something to store as a Docker secret. If you want to skip these sub-steps, you can <a href="https://letsencrypt.org/getting-started/">use Let&#x27;s Encrypt</a> to generate the site key and certificate, name the files site.key and site.crt, and skip to <a href="https://docs.docker.com/engine/swarm/configs/#configure-the-nginx-container">Configure the Nginx container</a>.</p><ol><li>Generate a root key.</li><li>$ openssl genrsa -out &quot;root-ca.key&quot; 4096</li><li>Generate a CSR using the root key.</li><li>$ openssl req \</li><li>-new -key &quot;root-ca.key&quot; \</li><li>-out &quot;root-ca.csr&quot; -sha256 \</li><li>-subj \&#x27;/C=US/ST=CA/L=San Francisco/O=Docker/CN=Swarm Secret Example CA\&#x27;</li><li>Configure the root CA. Edit a new file called root-ca.cnf and paste the following contents into it. This constrains the root CA to only sign leaf certificates and not intermediate CAs.</li><li>[root_ca]</li><li>basicConstraints = critical,CA:TRUE,pathlen:1</li><li>keyUsage = critical, nonRepudiation, cRLSign, keyCertSign</li><li>subjectKeyIdentifier=hash</li><li>Sign the certificate.</li><li>$ openssl x509 -req -days 3650 -in &quot;root-ca.csr&quot; \</li><li>-signkey &quot;root-ca.key&quot; -sha256 -out &quot;root-ca.crt&quot; \</li><li>-extfile &quot;root-ca.cnf&quot; -extensions \</li><li>root_ca</li><li>Generate the site key.</li><li>$ openssl genrsa -out &quot;site.key&quot; 4096</li><li>Generate the site certificate and sign it with the site key.</li><li>$ openssl req -new -key &quot;site.key&quot; -out &quot;site.csr&quot; -sha256 \</li><li>-subj \&#x27;/C=US/ST=CA/L=San Francisco/O=Docker/CN=localhost\&#x27;</li><li>Configure the site certificate. Edit a new file called site.cnf and paste the following contents into it. This constrains the site certificate so that it can only be used to authenticate a server and can&#x27;t be used to sign certificates.</li><li>[server]</li><li>authorityKeyIdentifier=keyid,issuer</li><li>basicConstraints = critical,CA:FALSE</li><li>extendedKeyUsage=serverAuth</li><li>keyUsage = critical, digitalSignature, keyEncipherment</li><li>subjectAltName = DNS:localhost, IP:127.0.0.1</li><li>subjectKeyIdentifier=hash</li><li>Sign the site certificate.</li><li>$ openssl x509 -req -days 750 -in &quot;site.csr&quot; -sha256 \</li><li>-CA &quot;root-ca.crt&quot; -CAkey &quot;root-ca.key&quot; -CAcreateserial \</li><li>-out &quot;site.crt&quot; -extfile &quot;site.cnf&quot; -extensions server</li><li>The site.csr and site.cnf files are not needed by the Nginx service, but you need them if you want to generate a new site certificate. Protect the root-ca.key file.</li></ol><p><strong>CONFIGURE THE NGINX CONTAINER</strong></p><ol><li>Produce a very basic Nginx configuration that serves static files over HTTPS. The TLS certificate and key are stored as Docker secrets so that they can be rotated easily.</li></ol><p>In the current directory, create a new file called site.conf with the following contents:</p><p>server {</p><p>listen 443 ssl;</p><p>server_name localhost;</p><p>ssl_certificate /run/secrets/site.crt;</p><p>ssl_certificate_key /run/secrets/site.key;</p><p>location / {</p><p>root /usr/share/nginx/html;</p><p>index index.html index.htm;</p><p>}</p><p>}</p><ol><li>Create two secrets, representing the key and the certificate. You can store any file as a secret as long as it is smaller than 500 KB. This allows you to decouple the key and certificate from the services that use them. In these examples, the secret name and the file name are the same.</li><li>$ docker secret create site.key site.key</li><li>$ docker secret create site.crt site.crt</li><li>Save the site.conf file in a Docker config. The first parameter is the name of the config, and the second parameter is the file to read it from.</li><li>$ docker config create site.conf site.conf</li></ol><p>List the configs:</p><p>$ docker config ls</p><p>ID NAME CREATED UPDATED</p><p>4ory233120ccg7biwvy11gl5z site.conf 4 seconds ago 4 seconds ago</p><ol><li>Create a service that runs Nginx and has access to the two secrets and the config. Set the mode to 0440 so that the file is only readable by its owner and that owner&#x27;s group, not the world.</li><li>$ docker service create \</li><li>--name nginx \</li><li>--secret site.key \</li><li>--secret site.crt \</li><li>--config source=site.conf,target=/etc/nginx/conf.d/site.conf,mode=0440 \</li><li>--publish published=3000,target=443 \</li><li>nginx:latest \</li><li>sh -c &quot;exec nginx -g \&#x27;daemon off;\&#x27;&quot;</li></ol><p>Within the running containers, the following three files now exist:</p><ul><li><ul><li>/run/secrets/site.key</li><li>/run/secrets/site.crt</li><li>/etc/nginx/conf.d/site.conf</li></ul></li></ul><ol><li>Verify that the Nginx service is running.</li><li>$ docker service ls</li><li>ID NAME MODE REPLICAS IMAGE</li><li>zeskcec62q24 nginx replicated 1/1 nginx:latest</li><li>$ docker service ps nginx</li><li>NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS</li><li>nginx.1.9ls3yo9ugcls nginx:latest moby Running Running 3 minutes ago</li><li>Verify that the service is operational: you can reach the Nginx server, and that the correct TLS certificate is being used.</li><li>$ curl --cacert root-ca.crt <a href="https://0.0.0.0:3000">https://0.0.0.0:3000</a></li><li><code>&lt;!DOCTYPE html&gt;</code></li><li><code>&lt;html&gt;</code></li><li><code>&lt;head&gt;</code></li><li><code>&lt;title&gt;Welcome to nginx!&lt;/title&gt;</code></li><li><code>&lt;style&gt;</code></li><li>body {</li><li>width: 35em;</li><li>margin: 0 auto;</li><li>font-family: Tahoma, Verdana, Arial, sans-serif;</li><li>}</li><li><code>&lt;/style&gt;</code></li><li><code>&lt;/head&gt;</code></li><li><code>&lt;body&gt;</code></li><li><code>&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;</code></li><li><code>&lt;p&gt;</code>If you see this page, the nginx web server is successfully installed and</li><li>working. Further configuration is required.<code>&lt;/p&gt;</code></li><li><code>&lt;p&gt;</code>For online documentation and support, refer to</li><li><code>&lt;a href=&quot;http://nginx.org/&quot;&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;</code></li><li>Commercial support is available at</li><li><code>&lt;a href=&quot;http://nginx.com/&quot;&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;</code></li><li><code>&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;</code></li><li><code>&lt;/body&gt;</code></li><li><code>&lt;/html&gt;</code></li><li>$ openssl s_client -connect 0.0.0.0:3000 -CAfile root-ca.crt</li><li>CONNECTED(00000003)</li><li>depth=1 /C=US/ST=CA/L=San Francisco/O=Docker/CN=Swarm Secret Example CA</li><li>verify return:1</li><li>depth=0 /C=US/ST=CA/L=San Francisco/O=Docker/CN=localhost</li><li>verify return:1</li><li><hr/></li><li>Certificate chain</li><li>0 s:/C=US/ST=CA/L=San Francisco/O=Docker/CN=localhost</li><li>i:/C=US/ST=CA/L=San Francisco/O=Docker/CN=Swarm Secret Example CA</li><li><hr/></li><li>Server certificate</li><li>-----BEGIN CERTIFICATE-----</li><li>...</li><li>-----END CERTIFICATE-----</li><li>subject=/C=US/ST=CA/L=San Francisco/O=Docker/CN=localhost</li><li>issuer=/C=US/ST=CA/L=San Francisco/O=Docker/CN=Swarm Secret Example CA</li><li><hr/></li><li>No client certificate CA names sent</li><li><hr/></li><li>SSL handshake has read 1663 bytes and written 712 bytes</li><li><hr/></li><li>New, TLSv1/SSLv3, Cipher is AES256-SHA</li><li>Server public key is 4096 bit</li><li>Secure Renegotiation IS supported</li><li>Compression: NONE</li><li>Expansion: NONE</li><li>SSL-Session:</li><li>Protocol : TLSv1</li><li>Cipher : AES256-SHA</li><li>Session-ID: A1A8BF35549C5715648A12FD7B7E3D861539316B03440187D9DA6C2E48822853</li><li>Session-ID-ctx:</li><li>Master-Key: F39D1B12274BA16D3A906F390A61438221E381952E9E1E05D3DD784F0135FB81353DA38C6D5C021CB926E844DFC49FC4</li><li>Key-Arg : None</li><li>Start Time: 1481685096</li><li>Timeout : 300 (sec)</li><li>Verify return code: 0 (ok)</li><li>Unless you are going to continue to the next example, clean up after running this example by removing the nginx service and the stored secrets and config.</li><li>$ docker service rm nginx</li><li>$ docker secret rm site.crt site.key</li><li>$ docker config rm site.conf</li></ol><p>You have now configured a Nginx service with its configuration decoupled from its image. You could run multiple sites with exactly the same image but separate configurations, without the need to build a custom image at all.</p><h6><strong>Example: Rotate a config</strong></h6><p>To rotate a config, you first save a new config with a different name than the one that is currently in use. You then redeploy the service, removing the old config and adding the new config at the same mount point within the container. This example builds upon the previous one by rotating the site.conf configuration file.</p><ol><li>Edit the site.conf file locally. Add index.php to the index line, and save the file.</li><li>server {</li><li>listen 443 ssl;</li><li>server_name localhost;</li><li>ssl_certificate /run/secrets/site.crt;</li><li>ssl_certificate_key /run/secrets/site.key;</li><li>location / {</li><li>root /usr/share/nginx/html;</li><li>index index.html index.htm index.php;</li><li>}</li><li>}</li><li>Create a new Docker config using the new site.conf, called site-v2.conf.</li><li>$ docker config create site-v2.conf site.conf</li><li>Update the nginx service to use the new config instead of the old one.</li><li>$ docker service update \</li><li>--config-rm site.conf \</li><li>--config-add source=site-v2.conf,target=/etc/nginx/conf.d/site.conf,mode=0440 \</li><li>nginx</li><li>Verify that the nginx service is fully re-deployed, using docker service ls nginx. When it is, you can remove the old site.conf config.</li><li>$ docker config rm site.conf</li><li>To clean up, you can remove the nginx service, as well as the secrets and configs.</li><li>$ docker service rm nginx</li><li>$ docker secret rm site.crt site.key</li><li>$ docker config rm site-v2.conf</li></ol><p>You have now updated your nginx service&#x27;s configuration without the need to rebuild its image.</p><h4>Manage sensitive data with Docker secrets</h4><p><em>Estimated reading time: 35 minutes</em></p><h5><strong>About secrets</strong></h5><p>In terms of Docker Swarm services, a secret is a blob of data, such as a password, SSH private key, SSL certificate, or another piece of data that should not be transmitted over a network or stored unencrypted in a Dockerfile or in your application&#x27;s source code. In Docker 1.13 and higher, you can use Docker secrets to centrally manage this data and securely transmit it to only those containers that need access to it. Secrets are encrypted during transit and at rest in a Docker swarm. A given secret is only accessible to those services which have been granted explicit access to it, and only while those service tasks are running.</p><p>You can use secrets to manage any sensitive data which a container needs at runtime but you don&#x27;t want to store in the image or in source control, such as:</p><ul><li>Usernames and passwords</li><li>TLS certificates and keys</li><li>SSH keys</li><li>Other important data such as the name of a database or internal server</li><li>Generic strings or binary content (up to 500 kb in size)</li></ul><p><strong>Note</strong>: Docker secrets are only available to swarm services, not to standalone containers. To use this feature, consider adapting your container to run as a service. Stateful containers can typically run with a scale of 1 without changing the container code.</p><p>Another use case for using secrets is to provide a layer of abstraction between the container and a set of credentials. Consider a scenario where you have separate development, test, and production environments for your application. Each of these environments can have different credentials, stored in the development, test, and production swarms with the same secret name. Your containers only need to know the name of the secret to function in all three environments.</p><p>You can also use secrets to manage non-sensitive data, such as configuration files. However, Docker 17.06 and higher support the use of <a href="https://docs.docker.com/engine/swarm/configs/">configs</a> for storing non-sensitive data. Configs are mounted into the container&#x27;s filesystem directly, without the use of a RAM disk.</p><h6><strong>Windows support</strong></h6><p>Docker 17.06 and higher include support for secrets on Windows containers. Where there are differences in the implementations, they are called out in the examples below. Keep the following notable differences in mind:</p><ul><li>Microsoft Windows has no built-in driver for managing RAM disks, so within running Windows containers, secrets <strong>are</strong> persisted in clear text to the container&#x27;s root disk. However, the secrets are explicitly removed when a container stops. In addition, Windows does not support persisting a running container as an image using docker commit or similar commands.</li><li>On Windows, we recommend enabling <a href="https://technet.microsoft.com/en-us/library/cc732774(v=ws.11).aspx">BitLocker</a> on the volume containing the Docker root directory on the host machine to ensure that secrets for running containers are encrypted at rest.</li><li>Secret files with custom targets are not directly bind-mounted into Windows containers, since Windows does not support non-directory file bind-mounts. Instead, secrets for a container are all mounted in C:\ProgramData\Docker\internal\secrets (an implementation detail which should not be relied upon by applications) within the container. Symbolic links are used to point from there to the desired target of the secret within the container. The default target is C:\ProgramData\Docker\secrets.</li><li>When creating a service which uses Windows containers, the options to specify UID, GID, and mode are not supported for secrets. Secrets are currently only accessible by administrators and users with system access within the container.</li></ul><h5><strong>How Docker manages secrets</strong></h5><p>When you add a secret to the swarm, Docker sends the secret to the swarm manager over a mutual TLS connection. The secret is stored in the Raft log, which is encrypted. The entire Raft log is replicated across the other managers, ensuring the same high availability guarantees for secrets as for the rest of the swarm management data.</p><p><strong>Warning</strong>: Raft data is encrypted in Docker 1.13 and higher. If any of your Swarm managers run an earlier version, and one of those managers becomes the manager of the swarm, the secrets are stored unencrypted in that node&#x27;s Raft logs. Before adding any secrets, update all of your manager nodes to Docker 1.13 or higher to prevent secrets from being written to plain-text Raft logs.</p><p>When you grant a newly-created or running service access to a secret, the decrypted secret is mounted into the container in an in-memory filesystem. The location of the mount point within the container defaults to /run/secrets/<code style="background-color:lightgray">&lt;secret_name&gt;</code> in Linux containers, orC:\ProgramData\Docker\secrets in Windows containers. You can specify a custom location in Docker 17.06 and higher.</p><p>You can update a service to grant it access to additional secrets or revoke its access to a given secret at any time.</p><p>A node only has access to (encrypted) secrets if the node is a swarm manager or if it is running service tasks which have been granted access to the secret. When a container task stops running, the decrypted secrets shared to it are unmounted from the in-memory filesystem for that container and flushed from the node&#x27;s memory.</p><p>If a node loses connectivity to the swarm while it is running a task container with access to a secret, the task container still has access to its secrets, but cannot receive updates until the node reconnects to the swarm.</p><p>You can add or inspect an individual secret at any time, or list all secrets. You cannot remove a secret that a running service is using. See <a href="https://docs.docker.com/engine/swarm/secrets/#example-rotate-a-secret">Rotate a secret</a> for a way to remove a secret without disrupting running services.</p><p>To update or roll back secrets more easily, consider adding a version number or date to the secret name. This is made easier by the ability to control the mount point of the secret within a given container.</p><h5><strong>Read more about docker secret commands</strong></h5><p>Use these links to read about specific commands, or continue to the <a href="https://docs.docker.com/engine/swarm/secrets/#example-use-secrets-with-a-service">example about using secrets with a service</a>.</p><ul><li><a href="https://docs.docker.com/engine/reference/commandline/secret_create/">docker secret create</a></li><li><a href="https://docs.docker.com/engine/reference/commandline/secret_inspect/">docker secret inspect</a></li><li><a href="https://docs.docker.com/engine/reference/commandline/secret_ls/">docker secret ls</a></li><li><a href="https://docs.docker.com/engine/reference/commandline/secret_rm/">docker secret rm</a></li><li><a href="https://docs.docker.com/engine/reference/commandline/service_create/#create-a-service-with-secrets">--secret</a> flag for docker service create</li><li><a href="https://docs.docker.com/engine/reference/commandline/service_update/#adding-and-removing-secrets">--secret-add and --secret-rm</a> flags for docker service update</li></ul><h5><strong>Examples</strong></h5><p>This section includes three graduated examples which illustrate how to use Docker secrets. The images used in these examples have been updated to make it easier to use Docker secrets. To find out how to modify your own images in a similar way, see <a href="https://docs.docker.com/engine/swarm/secrets/#build-support-for-docker-secrets-into-your-images">Build support for Docker Secrets into your images</a>.</p><p><strong>Note</strong>: These examples use a single-Engine swarm and unscaled services for simplicity. The examples use Linux containers, but Windows containers also support secrets in Docker 17.06 and higher. See <a href="https://docs.docker.com/engine/swarm/secrets/#windows-support">Windows support</a>.</p><h6><strong>Defining and using secrets in compose files</strong></h6><p>Both the docker-compose and docker stack commands support defining secrets in a compose file. See <a href="https://docs.docker.com/compose/compose-file/#secrets">the Compose file reference</a> for details.</p><h6><strong>Simple example: Get started with secrets</strong></h6><p>This simple example shows how secrets work in just a few commands. For a real-world example, continue to <a href="https://docs.docker.com/engine/swarm/secrets/#intermediate-example-use-secrets-with-a-nginx-service">Intermediate example: Use secrets with a Nginx service</a>.</p><ol><li>Add a secret to Docker. The docker secret create command reads standard input because the last argument, which represents the file to read the secret from, is set to -.</li><li>$ echo &quot;This is a secret&quot; | docker secret create my_secret_data -</li><li>Create a redis service and grant it access to the secret. By default, the container can access the secret at /run/secrets/<code>&lt;secret_name&gt;</code>, but you can customize the file name on the container using the target option.</li><li>$ docker service create --name redis --secret my_secret_data redis:alpine</li><li>Verify that the task is running without issues using docker service ps. If everything is working, the output looks similar to this:</li><li>$ docker service ps redis</li><li>ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS</li><li>bkna6bpn8r1a redis.1 redis:alpine ip-172-31-46-109 Running Running 8 seconds ago</li></ol><p>If there were an error, and the task were failing and repeatedly restarting, you would see something like this:</p><p>$ docker service ps redis</p><p>NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS</p><p>redis.1.siftice35gla redis:alpine moby Running Running 4 seconds ago</p><p>_<!-- --> redis.1.whum5b7gu13e redis:alpine moby Shutdown Failed 20 seconds ago &quot;task: non-zero exit (1)&quot;</p><p>_<!-- --> redis.1.2s6yorvd9zow redis:alpine moby Shutdown Failed 56 seconds ago &quot;task: non-zero exit (1)&quot;</p><p>_<!-- --> redis.1.ulfzrcyaf6pg redis:alpine moby Shutdown Failed about a minute ago &quot;task: non-zero exit (1)&quot;</p><p>_<!-- --> redis.1.wrny5v4xyps6 redis:alpine moby Shutdown Failed 2 minutes ago &quot;task: non-zero exit (1)&quot;</p><ol><li>Get the ID of the redis service task container using docker ps , so that you can use docker container exec to connect to the container and read the contents of the secret data file, which defaults to being readable by all and has the same name as the name of the secret. The first command below illustrates how to find the container ID, and the second and third commands use shell completion to do this automatically.</li><li>$ docker ps --filter name=redis -q</li><li>5cb1c2348a59</li><li>$ docker container exec $(docker ps --filter name=redis -q) ls -l /run/secrets</li><li>total 4</li><li>-r--r--r-- 1 root root 17 Dec 13 22:48 my_secret_data</li><li>$ docker container exec $(docker ps --filter name=redis -q) cat /run/secrets/my_secret_data</li><li>This is a secret</li><li>Verify that the secret is <strong>not</strong> available if you commit the container.</li><li>$ docker commit $(docker ps --filter name=redis -q) committed_redis</li><li>$ docker run --rm -it committed_redis cat /run/secrets/my_secret_data</li><li>cat: can\&#x27;t open \&#x27;/run/secrets/my_secret_data\&#x27;: No such file or directory</li><li>Try removing the secret. The removal fails because the redis service is running and has access to the secret.</li><li>$ docker secret ls</li><li>ID NAME CREATED UPDATED</li><li>wwwrxza8sxy025bas86593fqs my_secret_data 4 hours ago 4 hours ago</li><li>$ docker secret rm my_secret_data</li><li>Error response from daemon: rpc error: code = 3 desc = secret</li><li>\&#x27;my_secret_data\&#x27; is in use by the following service: redis</li><li>Remove access to the secret from the running redis service by updating the service.</li><li>$ docker service update --secret-rm my_secret_data redis</li><li>Repeat steps 3 and 4 again, verifying that the service no longer has access to the secret. The container ID is different, because the service update command redeploys the service.</li><li>$ docker container exec -it $(docker ps --filter name=redis -q) cat /run/secrets/my_secret_data</li><li>cat: can\&#x27;t open \&#x27;/run/secrets/my_secret_data\&#x27;: No such file or directory</li><li>Stop and remove the service, and remove the secret from Docker.</li><li>$ docker service rm redis</li><li>$ docker secret rm my_secret_data</li></ol><h6><strong>Simple example: Use secrets in a Windows service</strong></h6><p>This is a very simple example which shows how to use secrets with a Microsoft IIS service running on Docker 17.06 EE on Microsoft Windows Server 2016 or Docker for Mac 17.06 on Microsoft Windows 10. It is a naive example that stores the webpage in a secret.</p><p>This example assumes that you have PowerShell installed.</p><ol><li>Save the following into a new file index.html.</li><li><code>&lt;html&gt;</code></li><li><code>&lt;head&gt;&lt;title&gt;Hello Docker&lt;/title&gt;&lt;/head&gt;</code></li><li><code>&lt;body&gt;</code></li><li><code>&lt;p&gt;Hello Docker! You have deployed a HTML page.&lt;/p&gt;</code></li><li><code>&lt;/body&gt;</code></li><li><code>&lt;/html&gt;</code></li><li>If you have not already done so, initialize or join the swarm.</li><li>docker swarm init</li><li>Save the index.html file as a swarm secret named homepage.</li><li>docker secret create homepage index.html</li><li>Create an IIS service and grant it access to the homepage secret.</li><li>docker service create</li><li>--name my-iis</li><li>--publish published=8000,target=8000</li><li>--secret src=homepage,target=&quot;\inetpub\wwwroot\index.html&quot;</li><li>microsoft/iis:nanoserver</li></ol><p><strong>Note</strong>: There is technically no reason to use secrets for this example. With Docker 17.06 and higher, <a href="https://docs.docker.com/engine/swarm/configs/">configs</a> are a better fit. This example is for illustration only.</p><ol><li>Access the IIS service at http://localhost:8000/. It should serve the HTML content from the first step.</li><li>Remove the service and the secret.</li><li>docker service rm my-iis</li><li>docker secret rm homepage</li><li>docker image remove secret-test</li></ol><h6><strong>Intermediate example: Use secrets with a Nginx service</strong></h6><p>This example is divided into two parts. <a href="https://docs.docker.com/engine/swarm/secrets/#generate-the-site-certificate">The first part</a> is all about generating the site certificate and does not directly involve Docker secrets at all, but it sets up <a href="https://docs.docker.com/engine/swarm/secrets/#configure-the-nginx-container">the second part</a>, where you store and use the site certificate and Nginx configuration as secrets.</p><p><strong>GENERATE THE SITE CERTIFICATE</strong></p><p>Generate a root CA and TLS certificate and key for your site. For production sites, you may want to use a service such as Let&#x27;s Encrypt to generate the TLS certificate and key, but this example uses command-line tools. This step is a little complicated, but is only a set-up step so that you have something to store as a Docker secret. If you want to skip these sub-steps, you can <a href="https://letsencrypt.org/getting-started/">use Let&#x27;s Encrypt</a> to generate the site key and certificate, name the files site.key and site.crt, and skip to <a href="https://docs.docker.com/engine/swarm/secrets/#configure-the-nginx-container">Configure the Nginx container</a>.</p><ol><li>Generate a root key.</li><li>$ openssl genrsa -out &quot;root-ca.key&quot; 4096</li><li>Generate a CSR using the root key.</li><li>$ openssl req \</li><li>-new -key &quot;root-ca.key&quot; \</li><li>-out &quot;root-ca.csr&quot; -sha256 \</li><li>-subj \&#x27;/C=US/ST=CA/L=San Francisco/O=Docker/CN=Swarm Secret Example CA\&#x27;</li><li>Configure the root CA. Edit a new file called root-ca.cnf and paste the following contents into it. This constrains the root CA to signing leaf certificates and not intermediate CAs.</li><li>[root_ca]</li><li>basicConstraints = critical,CA:TRUE,pathlen:1</li><li>keyUsage = critical, nonRepudiation, cRLSign, keyCertSign</li><li>subjectKeyIdentifier=hash</li><li>Sign the certificate.</li><li>$ openssl x509 -req -days 3650 -in &quot;root-ca.csr&quot; \</li><li>-signkey &quot;root-ca.key&quot; -sha256 -out &quot;root-ca.crt&quot; \</li><li>-extfile &quot;root-ca.cnf&quot; -extensions \</li><li>root_ca</li><li>Generate the site key.</li><li>$ openssl genrsa -out &quot;site.key&quot; 4096</li><li>Generate the site certificate and sign it with the site key.</li><li>$ openssl req -new -key &quot;site.key&quot; -out &quot;site.csr&quot; -sha256 \</li><li>-subj \&#x27;/C=US/ST=CA/L=San Francisco/O=Docker/CN=localhost\&#x27;</li><li>Configure the site certificate. Edit a new file called site.cnf and paste the following contents into it. This constrains the site certificate so that it can only be used to authenticate a server and can&#x27;t be used to sign certificates.</li><li>[server]</li><li>authorityKeyIdentifier=keyid,issuer</li><li>basicConstraints = critical,CA:FALSE</li><li>extendedKeyUsage=serverAuth</li><li>keyUsage = critical, digitalSignature, keyEncipherment</li><li>subjectAltName = DNS:localhost, IP:127.0.0.1</li><li>subjectKeyIdentifier=hash</li><li>Sign the site certificate.</li><li>$ openssl x509 -req -days 750 -in &quot;site.csr&quot; -sha256 \</li><li>-CA &quot;root-ca.crt&quot; -CAkey &quot;root-ca.key&quot; -CAcreateserial \</li><li>-out &quot;site.crt&quot; -extfile &quot;site.cnf&quot; -extensions server</li><li>The site.csr and site.cnf files are not needed by the Nginx service, but you need them if you want to generate a new site certificate. Protect the root-ca.key file.</li></ol><p><strong>CONFIGURE THE NGINX CONTAINER</strong></p><ol><li>Produce a very basic Nginx configuration that serves static files over HTTPS. The TLS certificate and key are stored as Docker secrets so that they can be rotated easily.</li></ol><p>In the current directory, create a new file called site.conf with the following contents:</p><p>server {</p><p>listen 443 ssl;</p><p>server_name localhost;</p><p>ssl_certificate /run/secrets/site.crt;</p><p>ssl_certificate_key /run/secrets/site.key;</p><p>location / {</p><p>root /usr/share/nginx/html;</p><p>index index.html index.htm;</p><p>}</p><p>}</p><ol><li>Create three secrets, representing the key, the certificate, and the site.conf. You can store any file as a secret as long as it is smaller than 500 KB. This allows you to decouple the key, certificate, and configuration from the services that use them. In each of these commands, the last argument represents the path to the file to read the secret from on the host machine&#x27;s filesystem. In these examples, the secret name and the file name are the same.</li><li>$ docker secret create site.key site.key</li><li>$ docker secret create site.crt site.crt</li><li>$ docker secret create site.conf site.conf</li><li>$ docker secret ls</li><li>ID NAME CREATED UPDATED</li><li>2hvoi9mnnaof7olr3z5g3g7fp site.key 58 seconds ago 58 seconds ago</li><li>aya1dh363719pkiuoldpter4b site.crt 24 seconds ago 24 seconds ago</li><li>zoa5df26f7vpcoz42qf2csth8 site.conf 11 seconds ago 11 seconds ago</li><li>Create a service that runs Nginx and has access to the three secrets. The last part of the docker service create command creates a symbolic link from the location of the site.conf secret to /etc/nginx.conf.d/, where Nginx looks for extra configuration files. This step happens before Nginx actually starts, so you don&#x27;t need to rebuild your image if you change the Nginx configuration.</li></ol><p><strong>Note</strong>: Normally you would create a Dockerfile which copies the site.conf into place, build the image, and run a container using your custom image. This example does not require a custom image. It puts the site.conf into place and runs the container all in one step.</p><p>In Docker 17.05 and earlier, secrets are always located within the /run/secrets/ directory. Docker 17.06 and higher allow you to specify a custom location for a secret within the container. The two examples below illustrate the difference. The older version of this command requires you to create a symbolic link to the true location of the site.conf file so that Nginx can read it, but the newer version does not require this. The older example is preserved so that you can see the difference.</p><ul><li><ul><li><strong>Docker 17.06 and higher</strong>:</li><li>$ docker service create \</li><li>--name nginx \</li><li>--secret site.key \</li><li>--secret site.crt \</li><li>--secret source=site.conf,target=/etc/nginx/conf.d/site.conf \</li><li>--publish published=3000,target=443 \</li><li>nginx:latest \</li><li>sh -c &quot;exec nginx -g \&#x27;daemon off;\&#x27;&quot;</li><li><strong>Docker 17.05 and earlier</strong>:</li><li>$ docker service create \</li><li>--name nginx \</li><li>--secret site.key \</li><li>--secret site.crt \</li><li>--secret site.conf \</li><li>--publish published=3000,target=443 \</li><li>nginx:latest \</li><li>sh -c &quot;ln -s /run/secrets/site.conf /etc/nginx/conf.d/site.conf &amp;&amp; exec nginx -g \&#x27;daemon off;\&#x27;&quot;</li></ul></li></ul><p>The first example shows both the short and long syntax for secrets, and the second example shows only the short syntax. The short syntax creates files in /run/secrets/ with the same name as the secret. Within the running containers, the following three files now exist:</p><ul><li><ul><li>/run/secrets/site.key</li><li>/run/secrets/site.crt</li><li>/etc/nginx/conf.d/site.conf (or /run/secrets/site.conf if you used the second example)</li></ul></li></ul><ol><li>Verify that the Nginx service is running.</li><li>$ docker service ls</li><li>ID NAME MODE REPLICAS IMAGE</li><li>zeskcec62q24 nginx replicated 1/1 nginx:latest</li><li>$ docker service ps nginx</li><li>NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS</li><li>nginx.1.9ls3yo9ugcls nginx:latest moby Running Running 3 minutes ago</li><li>Verify that the service is operational: you can reach the Nginx server, and that the correct TLS certificate is being used.</li><li>$ curl --cacert root-ca.crt https://localhost:3000</li><li><code>&lt;!DOCTYPE html&gt;</code></li><li><code>&lt;html&gt;</code></li><li><code>&lt;head&gt;</code></li><li><code>&lt;title&gt;Welcome to nginx!&lt;/title&gt;</code></li><li><code>&lt;style&gt;</code></li><li>body {</li><li>width: 35em;</li><li>margin: 0 auto;</li><li>font-family: Tahoma, Verdana, Arial, sans-serif;</li><li>}</li><li><code>&lt;/style&gt;</code></li><li><code>&lt;/head&gt;</code></li><li><code>&lt;body&gt;</code></li><li><code>&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;</code></li><li><code>&lt;p&gt;</code>If you see this page, the nginx web server is successfully installed and</li><li>working. Further configuration is required.<code>&lt;/p&gt;</code></li><li><code>&lt;p&gt;</code>For online documentation and support. refer to</li><li><code>&lt;a href=&quot;http://nginx.org/&quot;&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;</code></li><li>Commercial support is available at</li><li><code>&lt;a href=&quot;http://nginx.com/&quot;&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;</code></li><li><code>&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;</code></li><li><code>&lt;/body&gt;</code></li><li><code>&lt;/html&gt;</code></li><li>$ openssl s_client -connect localhost:3000 -CAfile root-ca.crt</li><li>CONNECTED(00000003)</li><li>depth=1 /C=US/ST=CA/L=San Francisco/O=Docker/CN=Swarm Secret Example CA</li><li>verify return:1</li><li>depth=0 /C=US/ST=CA/L=San Francisco/O=Docker/CN=localhost</li><li>verify return:1</li><li><hr/></li><li>Certificate chain</li><li>0 s:/C=US/ST=CA/L=San Francisco/O=Docker/CN=localhost</li><li>i:/C=US/ST=CA/L=San Francisco/O=Docker/CN=Swarm Secret Example CA</li><li><hr/></li><li>Server certificate</li><li>-----BEGIN CERTIFICATE-----</li><li>...</li><li>-----END CERTIFICATE-----</li><li>subject=/C=US/ST=CA/L=San Francisco/O=Docker/CN=localhost</li><li>issuer=/C=US/ST=CA/L=San Francisco/O=Docker/CN=Swarm Secret Example CA</li><li><hr/></li><li>No client certificate CA names sent</li><li><hr/></li><li>SSL handshake has read 1663 bytes and written 712 bytes</li><li><hr/></li><li>New, TLSv1/SSLv3, Cipher is AES256-SHA</li><li>Server public key is 4096 bit</li><li>Secure Renegotiation IS supported</li><li>Compression: NONE</li><li>Expansion: NONE</li><li>SSL-Session:</li><li>Protocol : TLSv1</li><li>Cipher : AES256-SHA</li><li>Session-ID: A1A8BF35549C5715648A12FD7B7E3D861539316B03440187D9DA6C2E48822853</li><li>Session-ID-ctx:</li><li>Master-Key: F39D1B12274BA16D3A906F390A61438221E381952E9E1E05D3DD784F0135FB81353DA38C6D5C021CB926E844DFC49FC4</li><li>Key-Arg : None</li><li>Start Time: 1481685096</li><li>Timeout : 300 (sec)</li><li>Verify return code: 0 (ok)</li><li>To clean up after running this example, remove the nginx service and the stored secrets.</li><li>$ docker service rm nginx</li><li>$ docker secret rm site.crt site.key site.conf</li></ol><h6><strong>Advanced example: Use secrets with a WordPress service</strong></h6><p>In this example, you create a single-node MySQL service with a custom root password, add the credentials as secrets, and create a single-node WordPress service which uses these credentials to connect to MySQL. The <a href="https://docs.docker.com/engine/swarm/secrets/#example-rotate-a-secret">next example</a> builds on this one and shows you how to rotate the MySQL password and update the services so that the WordPress service can still connect to MySQL.</p><p>This example illustrates some techniques to use Docker secrets to avoid saving sensitive credentials within your image or passing them directly on the command line.</p><p><strong>Note: This example uses a single-Engine swarm for simplicity, and uses a single-node MySQL service because a single MySQL server instance cannot be scaled by simply using a replicated service, and setting up a MySQL cluster is beyond the scope of this example.</strong></p><p>Also, changing a MySQL root passphrase isn&#x27;t as simple as changing a file on disk. You must use a query or a mysqladmin command to change the password in MySQL.</p><ol><li>Generate a random alphanumeric password for MySQL and store it as a Docker secret with the name mysql_password using the docker secret create command. To make the password shorter or longer, adjust the last argument of the openssl command. This is just one way to create a relatively random password. You can use another command to generate the password if you choose.</li></ol><p><strong>Note</strong>: After you create a secret, you cannot update it. You can only remove and re-create it, and you cannot remove a secret that a service is using. However, you can grant or revoke a running service&#x27;s access to secrets using docker service update. If you need the ability to update a secret, consider adding a version component to the secret name, so that you can later add a new version, update the service to use it, then remove the old version.</p><p>The last argument is set to -, which indicates that the input is read from standard input.</p><p>$ openssl rand -base64 20 | docker secret create mysql_password -</p><p>l1vinzevzhj4goakjap5ya409</p><p>The value returned is not the password, but the ID of the secret. In the remainder of this tutorial, the ID output is omitted.</p><p>Generate a second secret for the MySQL root user. This secret isn&#x27;t shared with the WordPress service created later. It&#x27;s only needed to bootstrap the mysql service.</p><p>$ openssl rand -base64 20 | docker secret create mysql_root_password -</p><p>List the secrets managed by Docker using docker secret ls:</p><p>$ docker secret ls</p><p>ID NAME CREATED UPDATED</p><p>l1vinzevzhj4goakjap5ya409 mysql_password 41 seconds ago 41 seconds ago</p><p>yvsczlx9votfw3l0nz5rlidig mysql_root_password 12 seconds ago 12 seconds ago</p><p>The secrets are stored in the encrypted Raft logs for the swarm.</p><ol><li>Create a user-defined overlay network which is used for communication between the MySQL and WordPress services. There is no need to expose the MySQL service to any external host or container.</li><li>$ docker network create -d overlay mysql_private</li><li>Create the MySQL service. The MySQL service has the following characteristics:<ul><li>Because the scale is set to 1, only a single MySQL task runs. Load-balancing MySQL is left as an exercise to the reader and involves more than just scaling the service.</li><li>Only reachable by other containers on the mysql_private network.</li><li>Uses the volume mydata to store the MySQL data, so that it persists across restarts to the mysql service.</li><li>The secrets are each mounted in a tmpfs filesystem at/run/secrets/mysql_password and /run/secrets/mysql_root_password. They are never exposed as environment variables, nor can they be committed to an image if the docker commit command is run. The mysql_password secret is the one used by the non-privileged WordPress container to connect to MySQL.</li><li>Sets the environment variables MYSQL_PASSWORD_FILE andMYSQL_ROOT_PASSWORD_FILE to point to the files /run/secrets/mysql_password and /run/secrets/mysql_root_password. The mysql image reads the password strings from those files when initializing the system database for the first time. Afterward, the passwords are stored in the MySQL system database itself.</li><li>Sets environment variables MYSQL_USER and MYSQL_DATABASE. A new database called wordpress is created when the container starts, and the wordpress user has full permissions for this database only. This user cannot create or drop databases or change the MySQL configuration.</li><li>$ docker service create \</li><li>--name mysql \</li><li>--replicas 1 \</li><li>--network mysql_private \</li><li>--mount type=volume,source=mydata,destination=/var/lib/mysql \</li><li>--secret source=mysql_root_password,target=mysql_root_password \</li><li>--secret source=mysql_password,target=mysql_password \</li><li>-e MYSQL_ROOT_PASSWORD_FILE=&quot;/run/secrets/mysql_root_password&quot; \</li><li>-e MYSQL_PASSWORD_FILE=&quot;/run/secrets/mysql_password&quot; \</li><li>-e MYSQL_USER=&quot;wordpress&quot; \</li><li>-e MYSQL_DATABASE=&quot;wordpress&quot; \</li><li>mysql:latest</li></ul></li><li>Verify that the mysql container is running using the docker service ls command.</li><li>$ docker service ls</li><li>ID NAME MODE REPLICAS IMAGE</li><li>wvnh0siktqr3 mysql replicated 1/1 mysql:latest</li></ol><p>At this point, you could actually revoke the mysql service&#x27;s access to the mysql_passwordand mysql_root_password secrets because the passwords have been saved in the MySQL system database. Don&#x27;t do that for now, because we use them later to facilitate rotating the MySQL password.</p><ol><li>Now that MySQL is set up, create a WordPress service that connects to the MySQL service. The WordPress service has the following characteristics:<ul><li>Because the scale is set to 1, only a single WordPress task runs. Load-balancing WordPress is left as an exercise to the reader, because of limitations with storing WordPress session data on the container filesystem.</li><li>Exposes WordPress on port 30000 of the host machine, so that you can access it from external hosts. You can expose port 80 instead if you do not have a web server running on port 80 of the host machine.</li><li>Connects to the mysql_private network so it can communicate with the mysqlcontainer, and also publishes port 80 to port 30000 on all swarm nodes.</li><li>Has access to the mysql_password secret, but specifies a different target file name within the container. The WordPress container uses the mount point /run/secrets/wp_db_password. Also specifies that the secret is not group-or-world-readable, by setting the mode to 0400.</li><li>Sets the environment variable WORDPRESS_DB_PASSWORD_FILE to the file path where the secret is mounted. The WordPress service reads the MySQL password string from that file and add it to the wp-config.php configuration file.</li><li>Connects to the MySQL container using the username wordpress and the password in /run/secrets/wp_db_password and creates the wordpress database if it does not yet exist.</li><li>Stores its data, such as themes and plugins, in a volume called wpdata so these files persist when the service restarts.</li></ul></li><li>$ docker service create \</li><li>--name wordpress \</li><li>--replicas 1 \</li><li>--network mysql_private \</li><li>--publish published=30000,target=80 \</li><li>--mount type=volume,source=wpdata,destination=/var/www/html \</li><li>--secret source=mysql_password,target=wp_db_password,mode=0400 \</li><li>-e WORDPRESS_DB_USER=&quot;wordpress&quot; \</li><li>-e WORDPRESS_DB_PASSWORD_FILE=&quot;/run/secrets/wp_db_password&quot; \</li><li>-e WORDPRESS_DB_HOST=&quot;mysql:3306&quot; \</li><li>-e WORDPRESS_DB_NAME=&quot;wordpress&quot; \</li><li>wordpress:latest</li><li>Verify the service is running using docker service ls and docker service ps commands.</li><li>$ docker service ls</li><li>ID NAME MODE REPLICAS IMAGE</li><li>wvnh0siktqr3 mysql replicated 1/1 mysql:latest</li><li>nzt5xzae4n62 wordpress replicated 1/1 wordpress:latest</li><li>$ docker service ps wordpress</li><li>ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS</li><li>aukx6hgs9gwc wordpress.1 wordpress:latest moby Running Running 52 seconds ago</li></ol><p>At this point, you could actually revoke the WordPress service&#x27;s access to the mysql_password secret, because WordPress has copied the secret to its configuration file wp-config.php. Don&#x27;t do that for now, because we use it later to facilitate rotating the MySQL password.</p><ol><li>Access http://localhost:30000/ from any swarm node and set up WordPress using the web-based wizard. All of these settings are stored in the MySQL wordpress database. WordPress automatically generates a password for your WordPress user, which is completely different from the password WordPress uses to access MySQL. Store this password securely, such as in a password manager. You need it to log into WordPress after<a href="https://docs.docker.com/engine/swarm/secrets/#example-rotate-a-secret">rotating the secret</a>.</li></ol><p>Go ahead and write a blog post or two and install a WordPress plugin or theme to verify that WordPress is fully operational and its state is saved across service restarts.</p><ol><li>Do not clean up any services or secrets if you intend to proceed to the next example, which demonstrates how to rotate the MySQL root password.</li></ol><h6><strong>Example: Rotate a secret</strong></h6><p>This example builds upon the previous one. In this scenario, you create a new secret with a new MySQL password, update the mysql and wordpress services to use it, then remove the old secret.</p><p><strong>Note</strong>: Changing the password on a MySQL database involves running extra queries or commands, as opposed to just changing a single environment variable or a file, since the image only sets the MySQL password if the database doesn&#x27;t already exist, and MySQL stores the password within a MySQL database by default. Rotating passwords or other secrets may involve additional steps outside of Docker.</p><ol><li>Create the new password and store it as a secret named mysql_password_v2.</li><li>$ openssl rand -base64 20 | docker secret create mysql_password_v2 -</li><li>Update the MySQL service to give it access to both the old and new secrets. Remember that you cannot update or rename a secret, but you can revoke a secret and grant access to it using a new target filename.</li><li>$ docker service update \</li><li>--secret-rm mysql_password mysql</li><li>$ docker service update \</li><li>--secret-add source=mysql_password,target=old_mysql_password \</li><li>--secret-add source=mysql_password_v2,target=mysql_password \</li><li>mysql</li></ol><p>Updating a service causes it to restart, and when the MySQL service restarts the second time, it has access to the old secret under /run/secrets/old_mysql_password and the new secret under /run/secrets/mysql_password.</p><p>Even though the MySQL service has access to both the old and new secrets now, the MySQL password for the WordPress user has not yet been changed.</p><p><strong>Note</strong>: This example does not rotate the MySQL root password.</p><ol><li>Now, change the MySQL password for the wordpress user using the mysqladmin CLI. This command reads the old and new password from the files in /run/secrets but does not expose them on the command line or save them in the shell history.</li></ol><p>Do this quickly and move on to the next step, because WordPress loses the ability to connect to MySQL.</p><p>First, find the ID of the mysql container task.</p><p>$ docker ps --filter name=mysql -q</p><p>c7705cf6176f</p><p>Substitute the ID in the command below, or use the second variant which uses shell expansion to do it all in a single step.</p><p>$ docker container exec <code style="background-color:lightgray">&lt;CONTAINER_ID&gt;</code> \</p><p>bash -c \&#x27;mysqladmin --user=wordpress --password=&quot;$(&lt; /run/secrets/old_mysql_password)&quot; password &quot;$(&lt; /run/secrets/mysql_password)&quot;\&#x27;</p><p><strong>or</strong>:</p><p>$ docker container exec $(docker ps --filter name=mysql -q) \</p><p>bash -c \&#x27;mysqladmin --user=wordpress --password=&quot;$(&lt; /run/secrets/old_mysql_password)&quot; password &quot;$(&lt; /run/secrets/mysql_password)&quot;\&#x27;</p><ol><li>Update the wordpress service to use the new password, keeping the target path at /run/secrets/wp_db_secret and keeping the file permissions at 0400. This triggers a rolling restart of the WordPress service and the new secret is used.</li><li>$ docker service update \</li><li>--secret-rm mysql_password \</li><li>--secret-add source=mysql_password_v2,target=wp_db_password,mode=0400 \</li><li>wordpress</li><li>Verify that WordPress works by browsing to http://localhost:30000/ on any swarm node again. Use the WordPress username and password from when you ran through the WordPress wizard in the previous task.</li></ol><p>Verify that the blog post you wrote still exists, and if you changed any configuration values, verify that they are still changed.</p><ol><li>Revoke access to the old secret from the MySQL service and remove the old secret from Docker.</li><li>$ docker service update \</li><li>--secret-rm mysql_password \</li><li>mysql</li><li>$ docker secret rm mysql_password</li><li>If you want to try the running all of these examples again or just want to clean up after running through them, use these commands to remove the WordPress service, the MySQL container, the mydata and wpdata volumes, and the Docker secrets.</li><li>$ docker service rm wordpress mysql</li><li>$ docker volume rm mydata wpdata</li><li>$ docker secret rm mysql_password_v2 mysql_root_password</li></ol><h5><strong>Build support for Docker Secrets into your images</strong></h5><p>If you develop a container that can be deployed as a service and requires sensitive data, such as a credential, as an environment variable, consider adapting your image to take advantage of Docker secrets. One way to do this is to ensure that each parameter you pass to the image when creating the container can also be read from a file.</p><p>Many of the official images in the <a href="https://github.com/docker-library/">Docker library</a>, such as the <a href="https://github.com/docker-library/wordpress/">wordpress</a> image used in the above examples, have been updated in this way.</p><p>When you start a WordPress container, you provide it with the parameters it needs by setting them as environment variables. The WordPress image has been updated so that the environment variables which contain important data for WordPress, such as WORDPRESS_DB_PASSWORD, also have variants which can read their values from a file (WORDPRESS_DB_PASSWORD_FILE). This strategy ensures that backward compatibility is preserved, while allowing your container to read the information from a Docker-managed secret instead of being passed directly.</p><p><strong>Note</strong>: Docker secrets do not set environment variables directly. This was a conscious decision, because environment variables can unintentionally be leaked between containers (for instance, if you use --link).</p><h5><strong>Use Secrets in Compose</strong></h5><p>version: \&#x27;3.1\&#x27;</p><p>services:</p><p>db:</p><p>image: mysql:latest</p><p>volumes:</p><ul><li>db_data:/var/lib/mysql</li></ul><p>environment:</p><p>MYSQL_ROOT_PASSWORD_FILE: /run/secrets/db_root_password</p><p>MYSQL_DATABASE: wordpress</p><p>MYSQL_USER: wordpress</p><p>MYSQL_PASSWORD_FILE: /run/secrets/db_password</p><p>secrets:</p><ul><li><p>db_root_password</p></li><li><p>db_password</p></li></ul><p>wordpress:</p><p>depends_on:</p><ul><li>db</li></ul><p>image: wordpress:latest</p><p>ports:</p><ul><li>&quot;8000:80&quot;</li></ul><p>environment:</p><p>WORDPRESS_DB_HOST: db:3306</p><p>WORDPRESS_DB_USER: wordpress</p><p>WORDPRESS_DB_PASSWORD_FILE: /run/secrets/db_password</p><p>secrets:</p><ul><li>db_password</li></ul><p>secrets:</p><p>db_password:</p><p>file: db_password.txt</p><p>db_root_password:</p><p>file: db_root_password.txt</p><p>volumes:</p><p>db_data:</p><p>This example creates a simple WordPress site using two secrets in a compose file.</p><p>The keyword secrets: defines two secrets db_password: and db_root_password:.</p><p>When deploying, Docker creates these two secrets and populate them with the content from the file specified in the compose file.</p><p>The db service uses both secrets, and the wordpress is using one.</p><p>When you deploy, Docker mounts a file under /run/secrets/<code style="background-color:lightgray">&lt;secret_name&gt;</code> in the services. These files are never persisted in disk, but are managed in memory.</p><p>Each service uses environment variables to specify where the service should look for that secret data.</p><p>More information on short and long syntax for secrets can be found at <a href="https://docs.docker.com/compose/compose-file/#secrets">Compose file version 3 reference</a>.</p><h4>Lock your swarm to protect its encryption key</h4><p><em>Estimated reading time: 5 minutes</em></p><p>In Docker 1.13 and higher, the Raft logs used by swarm managers are encrypted on disk by default. This at-rest encryption protects your service&#x27;s configuration and data from attackers who gain access to the encrypted Raft logs. One of the reasons this feature was introduced was in support of the new <a href="https://docs.docker.com/engine/swarm/secrets/">Docker secrets</a> feature.</p><p>When Docker restarts, both the TLS key used to encrypt communication among swarm nodes, and the key used to encrypt and decrypt Raft logs on disk, are loaded into each manager node&#x27;s memory. Docker 1.13 introduces the ability to protect the mutual TLS encryption key and the key used to encrypt and decrypt Raft logs at rest, by allowing you to take ownership of these keys and to require manual unlocking of your managers. This feature is called autolock.</p><p>When Docker restarts, you must <a href="https://docs.docker.com/engine/swarm/swarm_manager_locking/#unlock-a-swarm">unlock the swarm</a> first, using a key encryption key generated by Docker when the swarm was locked. You can rotate this key encryption key at any time.</p><p><strong>Note</strong>: You don&#x27;t need to unlock the swarm when a new node joins the swarm, because the key is propagated to it over mutual TLS.</p><h5><strong>Initialize a swarm with autolocking enabled</strong></h5><p>When you initialize a new swarm, you can use the --autolock flag to enable autolocking of swarm manager nodes when Docker restarts.</p><p>$ docker swarm init --autolock</p><p>Swarm initialized: current node (k1q27tfyx9rncpixhk69sa61v) is now a manager.</p><p>To add a worker to this swarm, run the following command:</p><p>docker swarm join \</p><p>--token SWMTKN-1-0j52ln6hxjpxk2wgk917abcnxywj3xed0y8vi1e5m9t3uttrtu-7bnxvvlz2mrcpfonjuztmtts9 \</p><p>172.31.46.109:2377</p><p>To add a manager to this swarm, run \&#x27;docker swarm join-token manager\&#x27; and follow the instructions.</p><p>To unlock a swarm manager after it restarts, run the <code style="background-color:lightgray">docker swarm unlock</code></p><p>command and provide the following key:</p><p>SWMKEY-1-WuYH/IX284+lRcXuoVf38viIDK3HJEKY13MIHX+tTt8</p><p>Store the key in a safe place, such as in a password manager.</p><p>When Docker restarts, you need to <a href="https://docs.docker.com/engine/swarm/swarm_manager_locking/#unlock-a-swarm">unlock the swarm</a>. A locked swarm causes an error like the following when you try to start or restart a service:</p><p>$ sudo service docker restart</p><p>$ docker service ls</p><p>Error response from daemon: Swarm is encrypted and needs to be unlocked before it can be used. Use &quot;docker swarm unlock&quot; to unlock it.</p><h5><strong>Enable or disable autolock on an existing swarm</strong></h5><p>To enable autolock on an existing swarm, set the autolock flag to true.</p><p>$ docker swarm update --autolock=true</p><p>Swarm updated.</p><p>To unlock a swarm manager after it restarts, run the <code style="background-color:lightgray">docker swarm unlock</code></p><p>command and provide the following key:</p><p>SWMKEY-1-+MrE8NgAyKj5r3NcR4FiQMdgu+7W72urH0EZeSmP/0Y</p><p>Please remember to store this key in a password manager, since without it you</p><p>will not be able to restart the manager.</p><p>To disable autolock, set --autolock to false. The mutual TLS key and the encryption key used to read and write Raft logs are stored unencrypted on disk. There is a trade-off between the risk of storing the encryption key unencrypted at rest and the convenience of restarting a swarm without needing to unlock each manager.</p><p>$ docker swarm update --autolock=false</p><p>Keep the unlock key around for a short time after disabling autolocking, in case a manager goes down while it is still configured to lock using the old key.</p><h5><strong>Unlock a swarm</strong></h5><p>To unlock a locked swarm, use docker swarm unlock.</p><p>$ docker swarm unlock</p><p>Please enter unlock key:</p><p>Enter the encryption key that was generated and shown in the command output when you locked the swarm or rotated the key, and the swarm unlocks.</p><h5><strong>View the current unlock key for a running swarm</strong></h5><p>Consider a situation where your swarm is running as expected, then a manager node becomes unavailable. You troubleshoot the problem and bring the physical node back online, but you need to unlock the manager by providing the unlock key to read the encrypted credentials and Raft logs.</p><p>If the key has not been rotated since the node left the swarm, and you have a quorum of functional manager nodes in the swarm, you can view the current unlock key using docker swarm unlock-key without any arguments.</p><p>$ docker swarm unlock-key</p><p>To unlock a swarm manager after it restarts, run the <code style="background-color:lightgray">docker swarm unlock</code></p><p>command and provide the following key:</p><p>SWMKEY-1-8jDgbUNlJtUe5P/lcr9IXGVxqZpZUXPzd+qzcGp4ZYA</p><p>Please remember to store this key in a password manager, since without it you</p><p>will not be able to restart the manager.</p><p>If the key was rotated after the swarm node became unavailable and you do not have a record of the previous key, you may need to force the manager to leave the swarm and join it back to the swarm as a new manager.</p><h5><strong>Rotate the unlock key</strong></h5><p>You should rotate the locked swarm&#x27;s unlock key on a regular schedule.</p><p>$ docker swarm unlock-key --rotate</p><p>Successfully rotated manager unlock key.</p><p>To unlock a swarm manager after it restarts, run the <code style="background-color:lightgray">docker swarm unlock</code></p><p>command and provide the following key:</p><p>SWMKEY-1-8jDgbUNlJtUe5P/lcr9IXGVxqZpZUXPzd+qzcGp4ZYA</p><p>Please remember to store this key in a password manager, since without it you</p><p>will not be able to restart the manager.</p><p><strong>Warning</strong>: When you rotate the unlock key, keep a record of the old key around for a few minutes, so that if a manager goes down before it gets the new key, it may still be unlocked with the old one.</p><h4>Administer and maintain a swarm of Docker Engines</h4><p><em>Estimated reading time: 16 minutes</em></p><p>When you run a swarm of Docker Engines, <strong>manager nodes</strong> are the key components for managing the swarm and storing the swarm state. It is important to understand some key features of manager nodes to properly deploy and maintain the swarm.</p><p>Refer to <a href="https://docs.docker.com/engine/swarm/how-swarm-mode-works/nodes/">How nodes work</a> for a brief overview of Docker Swarm mode and the difference between manager and worker nodes.</p><h5><strong>Operate manager nodes in a swarm</strong></h5><p>Swarm manager nodes use the <a href="https://docs.docker.com/engine/swarm/raft/">Raft Consensus Algorithm</a> to manage the swarm state. You only need to understand some general concepts of Raft in order to manage a swarm.</p><p>There is no limit on the number of manager nodes. The decision about how many manager nodes to implement is a trade-off between performance and fault-tolerance. Adding manager nodes to a swarm makes the swarm more fault-tolerant. However, additional manager nodes reduce write performance because more nodes must acknowledge proposals to update the swarm state. This means more network round-trip traffic.</p><p>Raft requires a majority of managers, also called the quorum, to agree on proposed updates to the swarm, such as node additions or removals. Membership operations are subject to the same constraints as state replication.</p><h6><strong>Maintain the quorum of managers</strong></h6><p>If the swarm loses the quorum of managers, the swarm cannot perform management tasks. If your swarm has multiple managers, always have more than two. To maintain quorum, a majority of managers must be available. An odd number of managers is recommended, because the next even number does not make the quorum easier to keep. For instance, whether you have 3 or 4 managers, you can still only lose 1 manager and maintain the quorum. If you have 5 or 6 managers, you can still only lose two.</p><p>Even if a swarm loses the quorum of managers, swarm tasks on existing worker nodes continue to run. However, swarm nodes cannot be added, updated, or removed, and new or existing tasks cannot be started, stopped, moved, or updated.</p><p>See <a href="https://docs.docker.com/engine/swarm/admin_guide/#recovering-from-losing-the-quorum">Recovering from losing the quorum</a> for troubleshooting steps if you do lose the quorum of managers.</p><h5><strong>Configure the manager to advertise on a static IP address</strong></h5><p>When initiating a swarm, you must specify the --advertise-addr flag to advertise your address to other manager nodes in the swarm. For more information, see <a href="https://docs.docker.com/engine/swarm/swarm-mode/#configure-the-advertise-address">Run Docker Engine in swarm mode</a>. Because manager nodes are meant to be a stable component of the infrastructure, you should use a fixed IP address for the advertise address to prevent the swarm from becoming unstable on machine reboot.</p><p>If the whole swarm restarts and every manager node subsequently gets a new IP address, there is no way for any node to contact an existing manager. Therefore the swarm is hung while nodes try to contact one another at their old IP addresses.</p><p>Dynamic IP addresses are OK for worker nodes.</p><h5><strong>Add manager nodes for fault tolerance</strong></h5><p>You should maintain an odd number of managers in the swarm to support manager node failures. Having an odd number of managers ensures that during a network partition, there is a higher chance that the quorum remains available to process requests if the network is partitioned into two sets. Keeping the quorum is not guaranteed if you encounter more than two network partitions.</p><p>  <strong>Swarm Size</strong>   <strong>Majority</strong>   <strong>Fault Tolerance</strong></p><hr/><p>  1                1              0
2                2              0
<strong>3</strong>            2              <strong>1</strong>
4                3              1
<strong>5</strong>            3              <strong>2</strong>
6                4              2
<strong>7</strong>            4              <strong>3</strong>
8                5              3
<strong>9</strong>            5              <strong>4</strong></p><p>For example, in a swarm with 5 nodes, if you lose 3 nodes, you don&#x27;t have a quorum. Therefore you can&#x27;t add or remove nodes until you recover one of the unavailable manager nodes or recover the swarm with disaster recovery commands. See <a href="https://docs.docker.com/engine/swarm/admin_guide/#recover-from-disaster">Recover from disaster</a>.</p><p>While it is possible to scale a swarm down to a single manager node, it is impossible to demote the last manager node. This ensures you maintain access to the swarm and that the swarm can still process requests. Scaling down to a single manager is an unsafe operation and is not recommended. If the last node leaves the swarm unexpectedly during the demote operation, the swarm becomes unavailable until you reboot the node or restart with --force-new-cluster.</p><p>You manage swarm membership with the docker swarm and docker node subsystems. Refer to <a href="https://docs.docker.com/engine/swarm/join-nodes/">Add nodes to a swarm</a> for more information on how to add worker nodes and promote a worker node to be a manager.</p><h6><strong>Distribute manager nodes</strong></h6><p>In addition to maintaining an odd number of manager nodes, pay attention to datacenter topology when placing managers. For optimal fault-tolerance, distribute manager nodes across a minimum of 3 availability-zones to support failures of an entire set of machines or common maintenance scenarios. If you suffer a failure in any of those zones, the swarm should maintain the quorum of manager nodes available to process requests and rebalance workloads.</p><p>  <strong>Swarm manager nodes</strong>   <strong>Repartition (on 3 Availability zones)</strong></p><hr/><p>  3                         1-1-1
5                         2-2-1
7                         3-2-2
9                         3-3-3</p><h6><strong>Run manager-only nodes</strong></h6><p>By default manager nodes also act as a worker nodes. This means the scheduler can assign tasks to a manager node. For small and non-critical swarms assigning tasks to managers is relatively low-risk as long as you schedule services using <strong>resource constraints</strong> for cpu and memory.</p><p>However, because manager nodes use the Raft consensus algorithm to replicate data in a consistent way, they are sensitive to resource starvation. You should isolate managers in your swarm from processes that might block swarm operations like swarm heartbeat or leader elections.</p><p>To avoid interference with manager node operation, you can drain manager nodes to make them unavailable as worker nodes:</p><p>docker node update --availability drain <code style="background-color:lightgray">&lt;NODE&gt;</code></p><p>When you drain a node, the scheduler reassigns any tasks running on the node to other available worker nodes in the swarm. It also prevents the scheduler from assigning tasks to the node.</p><h5><strong>Add worker nodes for load balancing</strong></h5><p><a href="https://docs.docker.com/engine/swarm/join-nodes/">Add nodes to the swarm</a> to balance your swarm&#x27;s load. Replicated service tasks are distributed across the swarm as evenly as possible over time, as long as the worker nodes are matched to the requirements of the services. When limiting a service to run on only specific types of nodes, such as nodes with a specific number of CPUs or amount of memory, remember that worker nodes that do not meet these requirements cannot run these tasks.</p><h5><strong>Monitor swarm health</strong></h5><p>You can monitor the health of manager nodes by querying the docker nodes API in JSON format through the /nodes HTTP endpoint. Refer to the <a href="https://docs.docker.com/engine/api/v1.25/#tag/Node">nodes API documentation</a> for more information.</p><p>From the command line, run docker node inspect <code style="background-color:lightgray">&lt;id-node&gt;</code> to query the nodes. For instance, to query the reachability of the node as a manager:</p><p>docker node inspect manager1 --format &quot;{{ .ManagerStatus.Reachability }}&quot;</p><p>reachable</p><p>To query the status of the node as a worker that accept tasks:</p><p>docker node inspect manager1 --format &quot;{{ .Status.State }}&quot;</p><p>ready</p><p>From those commands, we can see that manager1 is both at the status reachable as a manager and ready as a worker.</p><p>An unreachable health status means that this particular manager node is unreachable from other manager nodes. In this case you need to take action to restore the unreachable manager:</p><ul><li>Restart the daemon and see if the manager comes back as reachable.</li><li>Reboot the machine.</li><li>If neither restarting or rebooting work, you should add another manager node or promote a worker to be a manager node. You also need to cleanly remove the failed node entry from the manager set with docker node demote <code>&lt;NODE&gt; and docker node rm &lt;id-node&gt;</code>.</li></ul><p>Alternatively you can also get an overview of the swarm health from a manager node with docker node ls:</p><p>docker node ls</p><p>ID HOSTNAME MEMBERSHIP STATUS AVAILABILITY MANAGER STATUS</p><p>1mhtdwhvsgr3c26xxbnzdc3yp node05 Accepted Ready Active</p><p>516pacagkqp2xc3fk9t1dhjor node02 Accepted Ready Active Reachable</p><p>9ifojw8of78kkusuc4a6c23fx * node01 Accepted Ready Active Leader</p><p>ax11wdpwrrb6db3mfjydscgk7 node04 Accepted Ready Active</p><p>bb1nrq2cswhtbg4mrsqnlx1ck node03 Accepted Ready Active Reachable</p><p>di9wxgz8dtuh9d2hn089ecqkf node06 Accepted Ready Active</p><h5><strong>Troubleshoot a manager node</strong></h5><p>You should never restart a manager node by copying the raft directory from another node. The data directory is unique to a node ID. A node can only use a node ID once to join the swarm. The node ID space should be globally unique.</p><p>To cleanly re-join a manager node to a cluster:</p><ol><li>To demote the node to a worker, run docker node demote <code>&lt;NODE&gt;</code>.</li><li>To remove the node from the swarm, run docker node rm <code>&lt;NODE&gt;</code>.</li><li>Re-join the node to the swarm with a fresh state using docker swarm join.</li></ol><p>For more information on joining a manager node to a swarm, refer to <a href="https://docs.docker.com/engine/swarm/join-nodes/">Join nodes to a swarm</a>.</p><h5><strong>Forcibly remove a node</strong></h5><p>In most cases, you should shut down a node before removing it from a swarm with the docker node rm command. If a node becomes unreachable, unresponsive, or compromised you can forcefully remove the node without shutting it down by passing the --force flag. For instance, if node9 becomes compromised:</p><p>$ docker node rm node9</p><p>Error response from daemon: rpc error: code = 9 desc = node node9 is not down and can\&#x27;t be removed</p><p>$ docker node rm --force node9</p><p>Node node9 removed from swarm</p><p>Before you forcefully remove a manager node, you must first demote it to the worker role. Make sure that you always have an odd number of manager nodes if you demote or remove a manager.</p><h5><strong>Back up the swarm</strong></h5><p>Docker manager nodes store the swarm state and manager logs in the /var/lib/docker/swarm/directory. In 1.13 and higher, this data includes the keys used to encrypt the Raft logs. Without these keys, you cannot restore the swarm.</p><p>You can back up the swarm using any manager. Use the following procedure.</p><ol><li>If the swarm has auto-lock enabled, you need the unlock key to restore the swarm from backup. Retrieve the unlock key if necessary and store it in a safe location. If you are unsure, read <a href="https://docs.docker.com/engine/swarm/swarm_manager_locking/">Lock your swarm to protect its encryption key</a>.</li><li>Stop Docker on the manager before backing up the data, so that no data is being changed during the backup. It is possible to take a backup while the manager is running (a &quot;hot&quot; backup), but this is not recommended and your results are less predictable when restoring. While the manager is down, other nodes continue generating swarm data that is not part of this backup.</li></ol><p><strong>Note</strong>: Be sure to maintain the quorum of swarm managers. During the time that a manager is shut down, your swarm is more vulnerable to losing the quorum if further nodes are lost. The number of managers you run is a trade-off. If you regularly take down managers to do backups, consider running a 5-manager swarm, so that you can lose an additional manager while the backup is running, without disrupting your services.</p><ol><li>Back up the entire /var/lib/docker/swarm directory.</li><li>Restart the manager.</li></ol><p>To restore, see <a href="https://docs.docker.com/engine/swarm/admin_guide/#restore-from-a-backup">Restore from a backup</a>.</p><h5><strong>Recover from disaster</strong></h5><h6><strong>Restore from a backup</strong></h6><p>After backing up the swarm as described in <a href="https://docs.docker.com/engine/swarm/admin_guide/#back-up-the-swarm">Back up the swarm</a>, use the following procedure to restore the data to a new swarm.</p><ol><li>Shut down Docker on the target host machine for the restored swarm.</li><li>Remove the contents of the /var/lib/docker/swarm directory on the new swarm.</li><li>Restore the /var/lib/docker/swarm directory with the contents of the backup.</li></ol><p><strong>Note: The new node uses the same encryption key for on-disk storage as the old one. It is not possible to change the on-disk storage encryption keys at this time.</strong></p><p>In the case of a swarm with auto-lock enabled, the unlock key is also the same as on the old swarm, and the unlock key is needed to restore the swarm.</p><ol><li>Start Docker on the new node. Unlock the swarm if necessary. Re-initialize the swarm using the following command, so that this node does not attempt to connect to nodes that were part of the old swarm, and presumably no longer exist.</li><li>$ docker swarm init --force-new-cluster</li><li>Verify that the state of the swarm is as expected. This may include application-specific tests or simply checking the output of docker service ls to be sure that all expected services are present.</li><li>If you use auto-lock, <a href="https://docs.docker.com/engine/swarm/swarm_manager_locking/#rotate-the-unlock-key">rotate the unlock key</a>.</li><li>Add manager and worker nodes to bring your new swarm up to operating capacity.</li><li>Reinstate your previous backup regimen on the new swarm.</li></ol><h6><strong>Recover from losing the quorum</strong></h6><p>Swarm is resilient to failures and the swarm can recover from any number of temporary node failures (machine reboots or crash with restart) or other transient errors. However, a swarm cannot automatically recover if it loses a quorum. Tasks on existing worker nodes continue to run, but administrative tasks are not possible, including scaling or updating services and joining or removing nodes from the swarm. The best way to recover is to bring the missing manager nodes back online. If that is not possible, continue reading for some options for recovering your swarm.</p><p>In a swarm of N managers, a quorum (a majority) of manager nodes must always be available. For example, in a swarm with 5 managers, a minimum of 3 must be operational and in communication with each other. In other words, the swarm can tolerate up to (N-1)/2permanent failures beyond which requests involving swarm management cannot be processed. These types of failures include data corruption or hardware failures.</p><p>If you lose the quorum of managers, you cannot administer the swarm. If you have lost the quorum and you attempt to perform any management operation on the swarm, an error occurs:</p><p>Error response from daemon: rpc error: code = 4 desc = context deadline exceeded</p><p>The best way to recover from losing the quorum is to bring the failed nodes back online. If you can&#x27;t do that, the only way to recover from this state is to use the --force-new-cluster action from a manager node. This removes all managers except the manager the command was run from. The quorum is achieved because there is now only one manager. Promote nodes to be managers until you have the desired number of managers.</p><h1>From the node to recover</h1><p>docker swarm init --force-new-cluster --advertise-addr node01:2377</p><p>When you run the docker swarm init command with the --force-new-cluster flag, the Docker Engine where you run the command becomes the manager node of a single-node swarm which is capable of managing and running services. The manager has all the previous information about services and tasks, worker nodes are still part of the swarm, and services are still running. You need to add or re-add manager nodes to achieve your previous task distribution and ensure that you have enough managers to maintain high availability and prevent losing the quorum.</p><h5><strong>Force the swarm to rebalance</strong></h5><p>Generally, you do not need to force the swarm to rebalance its tasks. When you add a new node to a swarm, or a node reconnects to the swarm after a period of unavailability, the swarm does not automatically give a workload to the idle node. This is a design decision. If the swarm periodically shifted tasks to different nodes for the sake of balance, the clients using those tasks would be disrupted. The goal is to avoid disrupting running services for the sake of balance across the swarm. When new tasks start, or when a node with running tasks becomes unavailable, those tasks are given to less busy nodes. The goal is eventual balance, with minimal disruption to the end user.</p><p>In Docker 1.13 and higher, you can use the --force or -f flag with thedocker service update command to force the service to redistribute its tasks across the available worker nodes. This causes the service tasks to restart. Client applications may be disrupted. If you have configured it, your service uses a <a href="https://docs.docker.com/engine/swarm/swarm-tutorial/#rolling-update">rolling update</a>.</p><p>If you use an earlier version and you want to achieve an even balance of load across workers and don&#x27;t mind disrupting running tasks, you can force your swarm to re-balance by temporarily scaling the service upward. Use docker service inspect --pretty <code style="background-color:lightgray">&lt;servicename&gt;</code> to see the configured scale of a service. When you use docker service scale, the nodes with the lowest number of tasks are targeted to receive the new workloads. There may be multiple under-loaded nodes in your swarm. You may need to scale the service up by modest increments a few times to achieve the balance you want across all the nodes.</p><p>When the load is balanced to your satisfaction, you can scale the service back down to the original scale. You can use docker service ps to assess the current balance of your service across nodes.</p><p>See also <a href="https://docs.docker.com/engine/reference/commandline/service_scale/">docker service scale</a> and <a href="https://docs.docker.com/engine/reference/commandline/service_ps/">docker service ps</a>.</p><h4>Raft consensus in swarm mode</h4><p><em>Estimated reading time: 1 minute</em></p><p>When the Docker Engine runs in swarm mode, manager nodes implement the <a href="http://thesecretlivesofdata.com/raft/">Raft Consensus Algorithm</a> to manage the global cluster state.</p><p>The reason why Docker swarm mode is using a consensus algorithm is to make sure that all the manager nodes that are in charge of managing and scheduling tasks in the cluster, are storing the same consistent state.</p><p>Having the same consistent state across the cluster means that in case of a failure, any Manager node can pick up the tasks and restore the services to a stable state. For example, if the Leader Manager which is responsible for scheduling tasks in the cluster dies unexpectedly, any other Manager can pick up the task of scheduling and re-balance tasks to match the desired state.</p><p>Systems using consensus algorithms to replicate logs in a distributed systems do require special care. They ensure that the cluster state stays consistent in the presence of failures by requiring a majority of nodes to agree on values.</p><p>Raft tolerates up to (N-1)/2 failures and requires a majority or quorum of (N/2)+1 members to agree on values proposed to the cluster. This means that in a cluster of 5 Managers running Raft, if 3 nodes are unavailable, the system cannot process any more requests to schedule additional tasks. The existing tasks keep running but the scheduler cannot rebalance tasks to cope with failures if the manager set is not healthy.</p><p>The implementation of the consensus algorithm in swarm mode means it features the properties inherent to distributed systems:</p><ul><li>agreement on values in a fault tolerant system. (Refer to <a href="http://the-paper-trail.org/blog/a-brief-tour-of-flp-impossibility/">FLP impossibility theorem</a> and the <a href="https://www.usenix.org/system/files/conference/atc14/atc14-paper-ongaro.pdf">Raft Consensus Algorithm paper</a>)</li><li>mutual exclusion through the leader election process</li><li>cluster membership management</li><li>globally consistent object sequencing and CAS (compare-and-swap) primitives</li></ul><h3>Extended Docker</h3><h4>Docker Engine managed plugin system</h4><ul><li><a href="https://docs.docker.com/engine/extend/#installing-and-using-a-plugin">Installing and using a plugin</a></li><li><a href="https://docs.docker.com/engine/extend/#developing-a-plugin">Developing a plugin</a></li><li><a href="https://docs.docker.com/engine/extend/#debugging-plugins">Debugging plugins</a></li></ul><p>Docker Engine&#x27;s plugin system allows you to install, start, stop, and remove plugins using Docker Engine.</p><p>For information about the legacy plugin system available in Docker Engine 1.12 and earlier, see <a href="https://docs.docker.com/engine/extend/legacy_plugins/">Understand legacy Docker Engine plugins</a>.</p><p><strong>Note</strong>: Docker Engine managed plugins are currently not supported on Windows daemons.</p><h5><strong>Installing and using a plugin</strong></h5><p>Plugins are distributed as Docker images and can be hosted on Docker Hub or on a private registry.</p><p>To install a plugin, use the docker plugin install command, which pulls the plugin from Docker Hub or your private registry, prompts you to grant permissions or capabilities if necessary, and enables the plugin.</p><p>To check the status of installed plugins, use the docker plugin ls command. Plugins that start successfully are listed as enabled in the output.</p><p>After a plugin is installed, you can use it as an option for another Docker operation, such as creating a volume.</p><p>In the following example, you install the sshfs plugin, verify that it is enabled, and use it to create a volume.</p><p><strong>Note</strong>: This example is intended for instructional purposes only. Once the volume is created, your SSH password to the remote host will be exposed as plaintext when inspecting the volume. You should delete the volume as soon as you are done with the example.</p><ol><li>Install the sshfs plugin.</li><li>$ docker plugin install vieux/sshfs</li><li>Plugin &quot;vieux/sshfs&quot; is requesting the following privileges:</li><li><ul><li>network: <!-- -->[host]</li></ul></li><li><ul><li>capabilities: <!-- -->[CAP_SYS_ADMIN]</li></ul></li><li>Do you grant the above permissions? <!-- -->[y/N]<!-- --> y</li><li>vieux/sshfs</li></ol><p>The plugin requests 2 privileges:</p><ul><li><ul><li>It needs access to the host network.</li><li>It needs the CAP_SYS_ADMIN capability, which allows the plugin to run the mountcommand.</li></ul></li></ul><ol><li>Check that the plugin is enabled in the output of docker plugin ls.</li><li>$ docker plugin ls</li><li>ID NAME TAG DESCRIPTION ENABLED</li><li>69553ca1d789 vieux/sshfs latest the <code>sshfs</code> plugin true</li><li>Create a volume using the plugin. This example mounts the /remote directory on host 1.2.3.4 into a volume named sshvolume.</li></ol><p>This volume can now be mounted into containers.</p><p>$ docker volume create \</p><p>-d vieux/sshfs \</p><p>--name sshvolume \</p><p>-o sshcmd=user\@1.2.3.4:/remote \</p><p>-o password=$(cat file_containing_password_for_remote_host)</p><p>sshvolume</p><ol><li>Verify that the volume was created successfully.</li><li>$ docker volume ls</li><li>DRIVER NAME</li><li>vieux/sshfs sshvolume</li><li>Start a container that uses the volume sshvolume.</li><li>$ docker run --rm -v sshvolume:/data busybox ls /data</li><li><code>&lt;content of /remote on machine 1.2.3.4&gt;</code></li><li>Remove the volume sshvolume</li><li>docker volume rm sshvolume</li><li>sshvolume</li></ol><p>To disable a plugin, use the docker plugin disable command. To completely remove it, use the docker plugin remove command. For other available commands and options, see the <a href="https://docs.docker.com/engine/reference/commandline/">command line reference</a>.</p><h5><strong>Developing a plugin</strong></h5><p><strong>THE ROOTFS DIRECTORY</strong></p><p>The rootfs directory represents the root filesystem of the plugin. In this example, it was created from a Dockerfile:</p><p><strong>Note:</strong> The /run/docker/plugins directory is mandatory inside of the plugin&#x27;s filesystem for docker to communicate with the plugin.</p><p>$ git clone <a href="https://github.com/vieux/docker-volume-sshfs">https://github.com/vieux/docker-volume-sshfs</a></p><p>$ cd docker-volume-sshfs</p><p>$ docker build -t rootfsimage .</p><p>$ id=$(docker create rootfsimage true) # id was cd851ce43a403 when the image was created</p><p>$ sudo mkdir -p myplugin/rootfs</p><p>$ sudo docker export &quot;$id&quot; | sudo tar -x -C myplugin/rootfs</p><p>$ docker rm -vf &quot;$id&quot;</p><p>$ docker rmi rootfsimage</p><p><strong>THE CONFIG.JSON FILE</strong></p><p>The config.json file describes the plugin. See the <a href="https://docs.docker.com/engine/extend/config/">plugins config reference</a>.</p><p>Consider the following config.json file.</p><p>{</p><p>&quot;description&quot;: &quot;sshFS plugin for Docker&quot;,</p><p>&quot;documentation&quot;: &quot;<a href="https://docs.docker.com/engine/extend/plugins/%22">https://docs.docker.com/engine/extend/plugins/&quot;</a>,</p><p>&quot;entrypoint&quot;: <!-- -->[&quot;/docker-volume-sshfs&quot;]<!-- -->,</p><p>&quot;network&quot;: {</p><p>&quot;type&quot;: &quot;host&quot;</p><p>},</p><p>&quot;interface&quot; : {</p><p>&quot;types&quot;: <!-- -->[&quot;docker.volumedriver/1.0&quot;]<!-- -->,</p><p>&quot;socket&quot;: &quot;sshfs.sock&quot;</p><p>},</p><p>&quot;linux&quot;: {</p><p>&quot;capabilities&quot;: <!-- -->[&quot;CAP_SYS_ADMIN&quot;]</p><p>}</p><p>}</p><p>This plugin is a volume driver. It requires a host network and the CAP_SYS_ADMIN capability. It depends upon the /docker-volume-sshfs entrypoint and uses the /run/docker/plugins/sshfs.sock socket to communicate with Docker Engine. This plugin has no runtime parameters.</p><p><strong>CREATING THE PLUGIN</strong></p><p>A new plugin can be created by runningdocker plugin create <code style="background-color:lightgray">&lt;plugin-name&gt;</code> ./path/to/plugin/data where the plugin data contains a plugin configuration file config.json and a root filesystem in subdirectory rootfs.</p><p>After that the plugin <code style="background-color:lightgray">&lt;plugin-name&gt; will show up in docker plugin ls. Plugins can be pushed to remote registries with docker plugin push &lt;plugin-name&gt;</code>.</p><h5><strong>Debugging plugins</strong></h5><p>Stdout of a plugin is redirected to dockerd logs. Such entries have a plugin=<code style="background-color:lightgray">&lt;ID&gt;</code> suffix. Here are a few examples of commands for pluginIDf52a3df433b9aceee436eaada0752f5797aab1de47e5485f1690a073b860ff62 and their corresponding log entries in the docker daemon logs.</p><p>$ docker plugin install tiborvass/sample-volume-plugin</p><p>INFO<!-- -->[0036]<!-- --> Starting... Found 0 volumes on startup plugin=f52a3df433b9aceee436eaada0752f5797aab1de47e5485f1690a073b860ff62</p><p>$ docker volume create -d tiborvass/sample-volume-plugin samplevol</p><p>INFO<!-- -->[0193]<!-- --> Create Called... Ensuring directory /data/samplevol exists on host... plugin=f52a3df433b9aceee436eaada0752f5797aab1de47e5485f1690a073b860ff62</p><p>INFO<!-- -->[0193]<!-- --> open /var/lib/docker/plugin-data/local-persist.json: no such file or directory plugin=f52a3df433b9aceee436eaada0752f5797aab1de47e5485f1690a073b860ff62</p><p>INFO<!-- -->[0193]<!-- --> Created volume samplevol with mountpoint /data/samplevol plugin=f52a3df433b9aceee436eaada0752f5797aab1de47e5485f1690a073b860ff62</p><p>INFO<!-- -->[0193]<!-- --> Path Called... Returned path /data/samplevol plugin=f52a3df433b9aceee436eaada0752f5797aab1de47e5485f1690a073b860ff62</p><p>$ docker run -v samplevol:/tmp busybox sh</p><p>INFO<!-- -->[0421]<!-- --> Get Called... Found samplevol plugin=f52a3df433b9aceee436eaada0752f5797aab1de47e5485f1690a073b860ff62</p><p>INFO<!-- -->[0421]<!-- --> Mount Called... Mounted samplevol plugin=f52a3df433b9aceee436eaada0752f5797aab1de47e5485f1690a073b860ff62</p><p>INFO<!-- -->[0421]<!-- --> Path Called... Returned path /data/samplevol plugin=f52a3df433b9aceee436eaada0752f5797aab1de47e5485f1690a073b860ff62</p><p>INFO<!-- -->[0421]<!-- --> Unmount Called... Unmounted samplevol plugin=f52a3df433b9aceee436eaada0752f5797aab1de47e5485f1690a073b860ff62</p><p><strong>USING DOCKER-RUNC TO OBTAIN LOGFILES AND SHELL INTO THE PLUGIN.</strong></p><p>docker-runc, the default docker container runtime can be used for debugging plugins. This is specifically useful to collect plugin logs if they are redirected to a file.</p><p>$ docker-runc list</p><p>ID PID STATUS BUNDLE CREATED</p><p>f52a3df433b9aceee436eaada0752f5797aab1de47e5485f1690a073b860ff62 2679 running /run/docker/libcontainerd/f52a3df433b9aceee436eaada0752f5797aab1de47e5485f1690a073b860ff62 2017-02-06T21:53:03.031537592Z</p><p>r</p><p>$ docker-runc exec f52a3df433b9aceee436eaada0752f5797aab1de47e5485f1690a073b860ff62 cat /var/log/plugin.log</p><p>If the plugin has a built-in shell, then exec into the plugin can be done as follows:</p><p>$ docker-runc exec -t f52a3df433b9aceee436eaada0752f5797aab1de47e5485f1690a073b860ff62 sh</p><p><strong>USING CURL TO DEBUG PLUGIN SOCKET ISSUES.</strong></p><p>To verify if the plugin API socket that the docker daemon communicates with is responsive, use curl. In this example, we will make API calls from the docker host to volume and network plugins using curl 7.47.0 to ensure that the plugin is listening on the said socket. For a well functioning plugin, these basic requests should work. Note that plugin sockets are available on the host under /var/run/docker/plugins/<code style="background-color:lightgray">&lt;pluginID&gt;</code></p><p>curl -H &quot;Content-Type: application/json&quot; -XPOST -d \&#x27;{}\&#x27; --unix-socket /var/run/docker/plugins/e8a37ba56fc879c991f7d7921901723c64df6b42b87e6a0b055771ecf8477a6d/plugin.sock http:/VolumeDriver.List</p><p>{&quot;Mountpoint&quot;:&quot;&quot;,&quot;Err&quot;:&quot;&quot;,&quot;Volumes&quot;:<!-- -->[{&quot;Name&quot;:&quot;myvol1&quot;,&quot;Mountpoint&quot;:&quot;/data/myvol1&quot;},{&quot;Name&quot;:&quot;myvol2&quot;,&quot;Mountpoint&quot;:&quot;/data/myvol2&quot;}]<!-- -->,&quot;Volume&quot;:null}</p><p>curl -H &quot;Content-Type: application/json&quot; -XPOST -d \&#x27;{}\&#x27; --unix-socket /var/run/docker/plugins/45e00a7ce6185d6e365904c8bcf62eb724b1fe307e0d4e7ecc9f6c1eb7bcdb70/plugin.sock http:/NetworkDriver.GetCapabilities</p><p>{&quot;Scope&quot;:&quot;local&quot;}</p><p>When using curl 7.5 and above, the URL should be of the form http://hostname/APICall, where hostname is the valid hostname where the plugin is installed and APICall is the call to the plugin API.</p><p>For example, http://localhost/VolumeDriver.List</p><h4>Access authorization plugin</h4><p>This document describes the Docker Engine plugins generally available in Docker Engine. To view information on plugins managed by Docker Engine, refer to <a href="https://docs.docker.com/engine/extend/">Docker Engine plugin system</a>.</p><p>Docker&#x27;s out-of-the-box authorization model is all or nothing. Any user with permission to access the Docker daemon can run any Docker client command. The same is true for callers using Docker&#x27;s Engine API to contact the daemon. If you require greater access control, you can create authorization plugins and add them to your Docker daemon configuration. Using an authorization plugin, a Docker administrator can configure granular access policies for managing access to the Docker daemon.</p><p>Anyone with the appropriate skills can develop an authorization plugin. These skills, at their most basic, are knowledge of Docker, understanding of REST, and sound programming knowledge. This document describes the architecture, state, and methods information available to an authorization plugin developer.</p><h5><strong>Basic principles</strong></h5><p>Docker&#x27;s <a href="https://docs.docker.com/engine/extend/plugin_api/">plugin infrastructure</a> enables extending Docker by loading, removing and communicating with third-party components using a generic API. The access authorization subsystem was built using this mechanism.</p><p>Using this subsystem, you don&#x27;t need to rebuild the Docker daemon to add an authorization plugin. You can add a plugin to an installed Docker daemon. You do need to restart the Docker daemon to add a new plugin.</p><p>An authorization plugin approves or denies requests to the Docker daemon based on both the current authentication context and the command context. The authentication context contains all user details and the authentication method. The command context contains all the relevant request data.</p><p>Authorization plugins must follow the rules described in <a href="https://docs.docker.com/engine/extend/plugin_api/">Docker Plugin API</a>. Each plugin must reside within directories described under the <a href="https://docs.docker.com/engine/extend/plugin_api/#plugin-discovery">Plugin discovery</a> section.</p><p><strong>Note</strong>: the abbreviations AuthZ and AuthN mean authorization and authentication respectively.</p><h5><strong>Default user authorization mechanism</strong></h5><p>If TLS is enabled in the <a href="https://docs.docker.com/engine/security/https/">Docker daemon</a>, the default user authorization flow extracts the user details from the certificate subject name. That is, the User field is set to the client certificate subject common name, and the AuthenticationMethod field is set to TLS.</p><h5><strong>Basic architecture</strong></h5><p>You are responsible for registering your plugin as part of the Docker daemon startup. You can install multiple plugins and chain them together. This chain can be ordered. Each request to the daemon passes in order through the chain. Only when all the plugins grant access to the resource, is the access granted.</p><p>When an HTTP request is made to the Docker daemon through the CLI or via the Engine API, the authentication subsystem passes the request to the installed authentication plugin(s). The request contains the user (caller) and command context. The plugin is responsible for deciding whether to allow or deny the request.</p><p>The sequence diagrams below depict an allow and deny authorization flow:</p><p>Each request sent to the plugin includes the authenticated user, the HTTP headers, and the request/response body. Only the user name and the authentication method used are passed to the plugin. Most importantly, no user credentials or tokens are passed. Finally, not all request/response bodies are sent to the authorization plugin. Only those request/response bodies where the Content-Type is either text/* or application/json are sent.</p><p>For commands that can potentially hijack the HTTP connection (HTTP Upgrade), such as exec, the authorization plugin is only called for the initial HTTP requests. Once the plugin approves the command, authorization is not applied to the rest of the flow. Specifically, the streaming data is not passed to the authorization plugins. For commands that return chunked HTTP response, such as logs and events, only the HTTP request is sent to the authorization plugins.</p><p>During request/response processing, some authorization flows might need to do additional queries to the Docker daemon. To complete such flows, plugins can call the daemon API similar to a regular user. To enable these additional queries, the plugin must provide the means for an administrator to configure proper authentication and security policies.</p><h5><strong>Docker client flows</strong></h5><p>To enable and configure the authorization plugin, the plugin developer must support the Docker client interactions detailed in this section.</p><h6><strong>Setting up Docker daemon</strong></h6><p>Enable the authorization plugin with a dedicated command line flag in the--authorization-plugin=PLUGIN_ID format. The flag supplies a PLUGIN_ID value. This value can be the plugin&#x27;s socket or a path to a specification file. Authorization plugins can be loaded without restarting the daemon. Refer to the <a href="https://docs.docker.com/engine/reference/commandline/dockerd/#configuration-reloading">dockerd documentation</a> for more information.</p><p>$ dockerd --authorization-plugin=plugin1 --authorization-plugin=plugin2,...</p><p>Docker&#x27;s authorization subsystem supports multiple --authorization-plugin parameters.</p><h6><strong>Calling authorized command (allow)</strong></h6><p>$ docker pull centos</p><p>...</p><p>f1b10cd84249: Pull complete</p><p>...</p><h6><strong>Calling unauthorized command (deny)</strong></h6><p>$ docker pull centos</p><p>...</p><p>docker: Error response from daemon: authorization denied by plugin PLUGIN_NAME: volumes are not allowed.</p><h6><strong>Error from plugins</strong></h6><p>$ docker pull centos</p><p>...</p><p>docker: Error response from daemon: plugin PLUGIN_NAME failed with error: AuthZPlugin.AuthZReq: Cannot connect to the Docker daemon. Is the docker daemon running on this host?.</p><h5><strong>API schema and implementation</strong></h5><p>In addition to Docker&#x27;s standard plugin registration method, each plugin should implement the following two methods:</p><ul><li>/AuthZPlugin.AuthZReq This authorize request method is called before the Docker daemon processes the client request.</li><li>/AuthZPlugin.AuthZRes This authorize response method is called before the response is returned from Docker daemon to the client.</li></ul><p><strong>/AUTHZPLUGIN.AUTHZREQ</strong></p><p><strong>Request</strong>:</p><p>{</p><p>&quot;User&quot;: &quot;The user identification&quot;,</p><p>&quot;UserAuthNMethod&quot;: &quot;The authentication method used&quot;,</p><p>&quot;RequestMethod&quot;: &quot;The HTTP method&quot;,</p><p>&quot;RequestURI&quot;: &quot;The HTTP request URI&quot;,</p><p>&quot;RequestBody&quot;: &quot;Byte array containing the raw HTTP request body&quot;,</p><p>&quot;RequestHeader&quot;: &quot;Byte array containing the raw HTTP request header as a map<!-- -->[string][]<!-- -->string &quot;</p><p>}</p><p><strong>Response</strong>:</p><p>{</p><p>&quot;Allow&quot;: &quot;Determined whether the user is allowed or not&quot;,</p><p>&quot;Msg&quot;: &quot;The authorization message&quot;,</p><p>&quot;Err&quot;: &quot;The error message if things go wrong&quot;</p><p>}</p><p><strong>/AUTHZPLUGIN.AUTHZRES</strong></p><p><strong>Request</strong>:</p><p>{</p><p>&quot;User&quot;: &quot;The user identification&quot;,</p><p>&quot;UserAuthNMethod&quot;: &quot;The authentication method used&quot;,</p><p>&quot;RequestMethod&quot;: &quot;The HTTP method&quot;,</p><p>&quot;RequestURI&quot;: &quot;The HTTP request URI&quot;,</p><p>&quot;RequestBody&quot;: &quot;Byte array containing the raw HTTP request body&quot;,</p><p>&quot;RequestHeader&quot;: &quot;Byte array containing the raw HTTP request header as a map<!-- -->[string][]<!-- -->string&quot;,</p><p>&quot;ResponseBody&quot;: &quot;Byte array containing the raw HTTP response body&quot;,</p><p>&quot;ResponseHeader&quot;: &quot;Byte array containing the raw HTTP response header as a map<!-- -->[string][]<!-- -->string&quot;,</p><p>&quot;ResponseStatusCode&quot;:&quot;Response status code&quot;</p><p>}</p><p><strong>Response</strong>:</p><p>{</p><p>&quot;Allow&quot;: &quot;Determined whether the user is allowed or not&quot;,</p><p>&quot;Msg&quot;: &quot;The authorization message&quot;,</p><p>&quot;Err&quot;: &quot;The error message if things go wrong&quot;</p><p>}</p><h6><strong>Request authorization</strong></h6><p>Each plugin must support two request authorization messages formats, one from the daemon to the plugin and then from the plugin to the daemon. The tables below detail the content expected in each message.</p><p><strong>DAEMON -&gt; PLUGIN</strong></p><p>  <strong>Name</strong>                <strong>Type</strong>              <strong>Description</strong></p><hr/><p>  User                    string                The user identification
Authentication method   string                The authentication method used
Request method          enum                  The HTTP method (GET/DELETE/POST)
Request URI             string                The HTTP request URI including API version (e.g., v.1.17/containers/json)
Request headers         map<!-- -->[string]<!-- -->string   Request headers as key value pairs (without the authorization header)
Request body            []byte              Raw request body</p><p><strong>PLUGIN -&gt; DAEMON</strong></p><p>  <strong>Name</strong>   <strong>Type</strong>   <strong>Description</strong></p><hr/><p>  Allow      bool       Boolean value indicating whether the request is allowed or denied
Msg        string     Authorization message (will be returned to the client in case the access is denied)
Err        string     Error message (will be returned to the client in case the plugin encounter an error. The string value supplied may appear in logs, so should not include confidential information)</p><h6><strong>Response authorization</strong></h6><p>The plugin must support two authorization messages formats, one from the daemon to the plugin and then from the plugin to the daemon. The tables below detail the content expected in each message.</p><p><strong>DAEMON -&gt; PLUGIN</strong></p><p>  <strong>Name</strong>                <strong>Type</strong>              <strong>Description</strong></p><hr/><p>  User                    string                The user identification
Authentication method   string                The authentication method used
Request method          string                The HTTP method (GET/DELETE/POST)
Request URI             string                The HTTP request URI including API version (e.g., v.1.17/containers/json)
Request headers         map<!-- -->[string]<!-- -->string   Request headers as key value pairs (without the authorization header)
Request body            []byte              Raw request body
Response status code    int                   Status code from the docker daemon
Response headers        map<!-- -->[string]<!-- -->string   Response headers as key value pairs
Response body           []byte              Raw docker daemon response body</p><p><strong>PLUGIN -&gt; DAEMON</strong></p><p>  <strong>Name</strong>   <strong>Type</strong>   <strong>Description</strong></p><hr/><p>  Allow      bool       Boolean value indicating whether the response is allowed or denied
Msg        string     Authorization message (will be returned to the client in case the access is denied)
Err        string     Error message (will be returned to the client in case the plugin encounter an error. The string value supplied may appear in logs, so should not include confidential information)</p><h4>Use Docker Engine plugins</h4><p>This document describes the Docker Engine plugins generally available in Docker Engine. To view information on plugins managed by Docker, refer to <a href="https://docs.docker.com/engine/extend/">Docker Engine plugin system</a>.</p><p>You can extend the capabilities of the Docker Engine by loading third-party plugins. This page explains the types of plugins and provides links to several volume and network plugins for Docker.</p><h5><strong>Types of plugins</strong></h5><p>Plugins extend Docker&#x27;s functionality. They come in specific types. For example, a <a href="https://docs.docker.com/engine/extend/plugins_volume/">volume plugin</a>might enable Docker volumes to persist across multiple Docker hosts and a <a href="https://docs.docker.com/engine/extend/plugins_network/">network plugin</a> might provide network plumbing.</p><p>Currently Docker supports authorization, volume and network driver plugins. In the future it will support additional plugin types.</p><h5><strong>Installing a plugin</strong></h5><p>Follow the instructions in the plugin&#x27;s documentation.</p><h5><strong>Finding a plugin</strong></h5><p>The sections below provide an inexhaustive overview of available plugins.</p><h6><strong>Network plugins</strong></h6><p>  <strong>Plugin</strong>                                                                           <strong>Description</strong></p><hr/><p>  <a href="https://github.com/contiv/netplugin">Contiv Networking</a>                             An open source network plugin to provide infrastructure and security policies for a multi-tenant micro services deployment, while providing an integration to physical network for non-container workload. Contiv Networking implements the remote driver and IPAM APIs available in Docker 1.9 onwards.
<a href="https://github.com/openstack/kuryr">Kuryr Network Plugin</a>                           A network plugin is developed as part of the OpenStack Kuryr project and implements the Docker networking (libnetwork) remote driver API by utilizing Neutron, the OpenStack networking service. It includes an IPAM driver as well.
<a href="https://www.weave.works/docs/net/latest/introducing-weave/">Weave Network Plugin</a>   A network plugin that creates a virtual network that connects your Docker containers - across multiple hosts or clouds and enables automatic discovery of applications. Weave networks are resilient, partition tolerant, secure and work in partially connected networks, and other adverse environments - all configured with delightful simplicity.</p><h6><strong>Volume plugins</strong></h6><p>  <strong>Plugin</strong>                                                                                           <strong>Description</strong></p><hr/><p>  <a href="https://github.com/Azure/azurefile-dockervolumedriver">Azure File Storage plugin</a>                   Lets you mount Microsoft <a href="https://azure.microsoft.com/blog/azure-file-storage-now-generally-available/">Azure File Storage</a> shares to Docker containers as volumes using the SMB 3.0 protocol. <a href="https://azure.microsoft.com/blog/persistent-docker-volumes-with-azure-file-storage/">Learn more</a>.
<a href="https://github.com/RedCoolBeans/docker-volume-beegfs">BeeGFS Volume Plugin</a>                         An open source volume plugin to create persistent volumes in a BeeGFS parallel file system.
<a href="https://github.com/blockbridge/blockbridge-docker-volume">Blockbridge plugin</a>                       A volume plugin that provides access to an extensible set of container-based persistent storage options. It supports single and multi-host Docker environments with features that include tenant isolation, automated provisioning, encryption, secure deletion, snapshots and QoS.
<a href="https://github.com/contiv/volplugin">Contiv Volume Plugin</a>                                          An open source volume plugin that provides multi-tenant, persistent, distributed storage with intent based consumption. It has support for Ceph and NFS.
<a href="https://github.com/rancher/convoy">Convoy plugin</a>                                                   A volume plugin for a variety of storage back-ends including device mapper and NFS. It&#x27;s a simple standalone executable written in Go and provides the framework to support vendor-specific extensions such as snapshots, backups and restore.
<a href="https://github.com/omallo/docker-volume-plugin-dostorage">DigitalOcean Block Storage plugin</a>        Integrates DigitalOcean&#x27;s <a href="https://www.digitalocean.com/products/storage/">block storage solution</a> into the Docker ecosystem by automatically attaching a given block storage volume to a DigitalOcean droplet and making the contents of the volume available to Docker containers running on that droplet.
<a href="https://www.drbd.org/en/supported-projects/docker">DRBD plugin</a>                                     A volume plugin that provides highly available storage replicated by <a href="https://www.drbd.org/">DRBD</a>. Data written to the docker volume is replicated in a cluster of DRBD nodes.
<a href="https://github.com/ScatterHQ/flocker">Flocker plugin</a>                                               A volume plugin that provides multi-host portable volumes for Docker, enabling you to run databases and other stateful containers and move them around across a cluster of machines.
<a href="https://github.com/openstack/fuxi">Fuxi Volume Plugin</a>                                              A volume plugin that is developed as part of the OpenStack Kuryr project and implements the Docker volume plugin API by utilizing Cinder, the OpenStack block storage service.
<a href="https://github.com/mcuadros/gce-docker">gce-docker plugin</a>                                          A volume plugin able to attach, format and mount Google Compute <a href="https://cloud.google.com/compute/docs/disks/persistent-disks">persistent-disks</a>.
<a href="https://github.com/calavera/docker-volume-glusterfs">GlusterFS plugin</a>                              A volume plugin that provides multi-host volumes management for Docker using GlusterFS.
<a href="https://github.com/muthu-r/horcrux">Horcrux Volume Plugin</a>                                          A volume plugin that allows on-demand, version controlled access to your data. Horcrux is an open-source plugin, written in Go, and supports SCP, <a href="https://www.minio.io/">Minio</a> and Amazon S3.
<a href="https://github.com/hpe-storage/python-hpedockerplugin/">HPE 3Par Volume Plugin</a>                     A volume plugin that supports HPE 3Par and StoreVirtual iSCSI storage arrays.
<a href="https://infinit.sh/documentation/docker/volume-plugin">Infinit volume plugin</a>                       A volume plugin that makes it easy to mount and manage Infinit volumes using Docker.
<a href="http://github.com/vdemeester/docker-volume-ipfs">IPFS Volume Plugin</a>                                An open source volume plugin that allows using an <a href="https://ipfs.io/">ipfs</a> filesystem as a volume.
<a href="https://github.com/calavera/docker-volume-keywhiz">Keywhiz plugin</a>                                  A plugin that provides credentials and secret management using Keywhiz as a central repository.
<a href="https://github.com/CWSpear/local-persist">Local Persist Plugin</a>                                     A volume plugin that extends the default local driver&#x27;s functionality by allowing you specify a mountpoint anywhere on the host, which enables the files to always persist, even if the volume is removed via docker volume rm.
<a href="https://github.com/NetApp/netappdvp">NetApp Plugin</a>(nDVP)                                           A volume plugin that provides direct integration with the Docker ecosystem for the NetApp storage portfolio. The nDVP package supports the provisioning and management of storage resources from the storage platform to Docker hosts, with a robust framework for adding additional platforms in the future.
<a href="https://github.com/ContainX/docker-volume-netshare">Netshare plugin</a>                                A volume plugin that provides volume management for NFS 3/4, AWS EFS and CIFS file systems.
<a href="https://connect.nimblestorage.com/community/app-integration/docker">Nimble Storage Volume Plugin</a>   A volume plug-in that integrates with Nimble Storage Unified Flash Fabric arrays. The plug-in abstracts array volume capabilities to the Docker administrator to allow self-provisioning of secure multi-tenant volumes and clones.
<a href="https://github.com/libopenstorage/openstorage">OpenStorage Plugin</a>                                  A cluster-aware volume plugin that provides volume management for file and block storage solutions. It implements a vendor neutral specification for implementing extensions such as CoS, encryption, and snapshots. It has example drivers based on FUSE, NFS, NBD and EBS to name a few.
<a href="https://github.com/portworx/px-dev">Portworx Volume Plugin</a>                                         A volume plugin that turns any server into a scale-out converged compute/storage node, providing container granular storage and highly available volumes across any node, using a shared-nothing storage backend that works with any docker scheduler.
<a href="https://github.com/quobyte/docker-volume">Quobyte Volume Plugin</a>                                    A volume plugin that connects Docker to <a href="http://www.quobyte.com/containers">Quobyte</a>&#x27;s data center file system, a general-purpose scalable and fault-tolerant storage platform.
<a href="https://github.com/emccode/rexray">REX-Ray plugin</a>                                                  A volume plugin which is written in Go and provides advanced storage functionality for many platforms including VirtualBox, EC2, Google Compute Engine, OpenStack, and EMC.
<a href="https://github.com/virtuozzo/docker-volume-ploop">Virtuozzo Storage and Ploop plugin</a>               A volume plugin with support for Virtuozzo Storage distributed cloud file system as well as ploop devices.
<a href="https://github.com/vmware/docker-volume-vsphere">VMware vSphere Storage Plugin</a>                     Docker Volume Driver for vSphere enables customers to address persistent storage requirements for Docker containers in vSphere environments.</p><h6><strong>Authorization plugins</strong></h6><p>  <strong>Plugin</strong>                                                             <strong>Description</strong></p><hr/><p>  <a href="https://github.com/casbin/casbin-authz-plugin">Casbin AuthZ Plugin</a>   An authorization plugin based on <a href="https://github.com/casbin/casbin">Casbin</a>, which supports access control models like ACL, RBAC, ABAC. The access control model can be customized. The policy can be persisted into file or DB.
<a href="https://github.com/kassisol/hbm">HBM plugin</a>                          An authorization plugin that prevents from executing commands with certains parameters.
<a href="https://github.com/twistlock/authz">Twistlock AuthZ Broker</a>           A basic extendable authorization plugin that runs directly on the host or inside a container. This plugin allows you to define user policies that it evaluates during authorization. Basic authorization is provided if Docker daemon is started with the --tlsverify flag (username is extracted from the certificate common name).</p><h5><strong>Troubleshooting a plugin</strong></h5><p>If you are having problems with Docker after loading a plugin, ask the authors of the plugin for help. The Docker team may not be able to assist you.</p><h5><strong>Writing a plugin</strong></h5><p>If you are interested in writing a plugin for Docker, or seeing how they work under the hood, see the <a href="https://docs.docker.com/engine/extend/plugin_api/">docker plugins reference</a>.</p><h4>Docker network driver plugins</h4><p>This document describes Docker Engine network driver plugins generally available in Docker Engine. To view information on plugins managed by Docker Engine, refer to <a href="https://docs.docker.com/engine/extend/">Docker Engine plugin system</a>.</p><p>Docker Engine network plugins enable Engine deployments to be extended to support a wide range of networking technologies, such as VXLAN, IPVLAN, MACVLAN or something completely different. Network driver plugins are supported via the LibNetwork project. Each plugin is implemented as a &quot;remote driver&quot; for LibNetwork, which shares plugin infrastructure with Engine. Effectively, network driver plugins are activated in the same way as other plugins, and use the same kind of protocol.</p><h5><strong>Network plugins and swarm mode</strong></h5><p><a href="https://docs.docker.com/engine/extend/legacy_plugins/">Legacy plugins</a> do not work in swarm mode. However, plugins written using the <a href="https://docs.docker.com/engine/extend/">v2 plugin system</a>do work in swarm mode, as long as they are installed on each swarm worker node.</p><h5><strong>Use network driver plugins</strong></h5><p>The means of installing and running a network driver plugin depend on the particular plugin. So, be sure to install your plugin according to the instructions obtained from the plugin developer.</p><p>Once running however, network driver plugins are used just like the built-in network drivers: by being mentioned as a driver in network-oriented Docker commands. For example,</p><p>$ docker network create --driver weave mynet</p><p>Some network driver plugins are listed in <a href="https://docs.docker.com/engine/extend/legacy_plugins/">plugins</a></p><p>The mynet network is now owned by weave, so subsequent commands referring to that network will be sent to the plugin,</p><p>$ docker run --network=mynet busybox top</p><h5><strong>Find network plugins</strong></h5><p>Network plugins are written by third parties, and are published by those third parties, either on<a href="https://store.docker.com/search?category=network&amp;q=&amp;type=plugin">Docker Store</a> or on the third party&#x27;s site.</p><h5><strong>Write a network plugin</strong></h5><p>Network plugins implement the <a href="https://docs.docker.com/engine/extend/plugin_api/">Docker plugin API</a> and the network plugin protocol</p><h5><strong>Network plugin protocol</strong></h5><p>The network driver protocol, in addition to the plugin activation call, is documented as part of libnetwork: <code style="background-color:lightgray">&lt;https://github.com/docker/libnetwork/blob/master/docs/remote.md&gt;</code>.</p><h5><strong>Related Information</strong></h5><p>To interact with the Docker maintainers and other interested users, see the IRC channel #docker-network.</p><ul><li><a href="https://docs.docker.com/engine/userguide/networking/">Docker networks feature overview</a></li><li>The <a href="https://github.com/docker/libnetwork">LibNetwork</a> project</li></ul><h4>Docker volume plugins</h4><p>Docker Engine volume plugins enable Engine deployments to be integrated with external storage systems such as Amazon EBS, and enable data volumes to persist beyond the lifetime of a single Docker host. See the <a href="https://docs.docker.com/engine/extend/legacy_plugins/">plugin documentation</a> for more information.</p><h5><strong>Changelog</strong></h5><h6><strong>1.13.0</strong></h6><ul><li>If used as part of the v2 plugin architecture, mountpoints that are part of paths returned by the plugin must be mounted under the directory specified by PropagatedMount in the plugin configuration (<a href="https://github.com/docker/docker/pull/26398">#26398</a>)</li></ul><h6><strong>1.12.0</strong></h6><ul><li>Add Status field to VolumeDriver.Get response (<a href="https://github.com/docker/docker/pull/21006">#21006</a>)</li><li>Add VolumeDriver.Capabilities to get capabilities of the volume driver (<a href="https://github.com/docker/docker/pull/22077">#22077</a>)</li></ul><h6><strong>1.10.0</strong></h6><ul><li>Add VolumeDriver.Get which gets the details about the volume (<a href="https://github.com/docker/docker/pull/16534">#16534</a>)</li><li>Add VolumeDriver.List which lists all volumes owned by the driver (<a href="https://github.com/docker/docker/pull/16534">#16534</a>)</li></ul><h6><strong>1.8.0</strong></h6><ul><li>Initial support for volume driver plugins (<a href="https://github.com/docker/docker/pull/14659">#14659</a>)</li></ul><h5><strong>Command-line changes</strong></h5><p>To give a container access to a volume, use the --volume and --volume-driver flags on the docker container run command. The --volume (or -v) flag accepts a volume name and path on the host, and the --volume-driver flag accepts a driver type.</p><p>$ docker volume create --driver=flocker volumename</p><p>$ docker container run -it --volume volumename:/data busybox sh</p><h6><strong>--volume</strong></h6><p>The --volume (or -v) flag takes a value that is in the format <code style="background-color:lightgray">&lt;volume_name&gt;:&lt;mountpoint&gt;</code>. The two parts of the value are separated by a colon (:) character.</p><ul><li>The volume name is a human-readable name for the volume, and cannot begin with a /character. It is referred to as volume_name in the rest of this topic.</li><li>The Mountpoint is the path on the host (v1) or in the plugin (v2) where the volume has been made available.</li></ul><h6><strong>volumedriver</strong></h6><p>Specifying a volumedriver in conjunction with a volumename allows you to use plugins such as <a href="https://github.com/ScatterHQ/flocker">Flocker</a> to manage volumes external to a single host, such as those on EBS.</p><h5><strong>Create a VolumeDriver</strong></h5><p>The container creation endpoint (/containers/create) accepts a VolumeDriver field of type string allowing to specify the name of the driver. If not specified, it defaults to &quot;local&quot; (the default driver for local volumes).</p><h5><strong>Volume plugin protocol</strong></h5><p>If a plugin registers itself as a VolumeDriver when activated, it must provide the Docker Daemon with writeable paths on the host filesystem. The Docker daemon provides these paths to containers to consume. The Docker daemon makes the volumes available by bind-mounting the provided paths into the containers.</p><p><strong>Note</strong>: Volume plugins should not write data to the /var/lib/docker/ directory, including /var/lib/docker/volumes. The /var/lib/docker/ directory is reserved for Docker.</p><h6><strong>/VolumeDriver.Create</strong></h6><p><strong>Request</strong>:</p><p>{</p><p>&quot;Name&quot;: &quot;volume_name&quot;,</p><p>&quot;Opts&quot;: {}</p><p>}</p><p>Instruct the plugin that the user wants to create a volume, given a user specified volume name. The plugin does not need to actually manifest the volume on the filesystem yet (until Mount is called). Opts is a map of driver specific options passed through from the user request.</p><p><strong>Response</strong>:</p><p>{</p><p>&quot;Err&quot;: &quot;&quot;</p><p>}</p><p>Respond with a string error if an error occurred.</p><h6><strong>/VolumeDriver.Remove</strong></h6><p><strong>Request</strong>:</p><p>{</p><p>&quot;Name&quot;: &quot;volume_name&quot;</p><p>}</p><p>Delete the specified volume from disk. This request is issued when a user invokes docker rm -vto remove volumes associated with a container.</p><p><strong>Response</strong>:</p><p>{</p><p>&quot;Err&quot;: &quot;&quot;</p><p>}</p><p>Respond with a string error if an error occurred.</p><h6><strong>/VolumeDriver.Mount</strong></h6><p><strong>Request</strong>:</p><p>{</p><p>&quot;Name&quot;: &quot;volume_name&quot;,</p><p>&quot;ID&quot;: &quot;b87d7442095999a92b65b3d9691e697b61713829cc0ffd1bb72e4ccd51aa4d6c&quot;</p><p>}</p><p>Docker requires the plugin to provide a volume, given a user specified volume name. Mount is called once per container start. If the same volume_name is requested more than once, the plugin may need to keep track of each new mount request and provision at the first mount request and deprovision at the last corresponding unmount request.</p><p>ID is a unique ID for the caller that is requesting the mount.</p><p><strong>Response</strong>:</p><ul><li><strong>v1</strong>:</li><li>{</li><li>&quot;Mountpoint&quot;: &quot;/path/to/directory/on/host&quot;,</li><li>&quot;Err&quot;: &quot;&quot;</li><li>}</li><li><strong>v2</strong>:</li><li>{</li><li>&quot;Mountpoint&quot;: &quot;/path/under/PropagatedMount&quot;,</li><li>&quot;Err&quot;: &quot;&quot;</li><li>}</li></ul><p>Mountpoint is the path on the host (v1) or in the plugin (v2) where the volume has been made available.</p><p>Err is either empty or contains an error string.</p><h6><strong>/VolumeDriver.Path</strong></h6><p><strong>Request</strong>:</p><p>{</p><p>&quot;Name&quot;: &quot;volume_name&quot;</p><p>}</p><p>Request the path to the volume with the given volume_name.</p><p><strong>Response</strong>:</p><ul><li><strong>v1</strong>:</li><li>{</li><li>&quot;Mountpoint&quot;: &quot;/path/to/directory/on/host&quot;,</li><li>&quot;Err&quot;: &quot;&quot;</li><li>}</li><li><strong>v2</strong>:</li><li>{</li><li>&quot;Mountpoint&quot;: &quot;/path/under/PropagatedMount&quot;,</li><li>&quot;Err&quot;: &quot;&quot;</li><li>}</li></ul><p>Respond with the path on the host (v1) or inside the plugin (v2) where the volume has been made available, and/or a string error if an error occurred.</p><p>Mountpoint is optional. However, the plugin may be queried again later if one is not provided.</p><h6><strong>/VolumeDriver.Unmount</strong></h6><p><strong>Request</strong>:</p><p>{</p><p>&quot;Name&quot;: &quot;volume_name&quot;,</p><p>&quot;ID&quot;: &quot;b87d7442095999a92b65b3d9691e697b61713829cc0ffd1bb72e4ccd51aa4d6c&quot;</p><p>}</p><p>Docker is no longer using the named volume. Unmount is called once per container stop. Plugin may deduce that it is safe to deprovision the volume at this point.</p><p>ID is a unique ID for the caller that is requesting the mount.</p><p><strong>Response</strong>:</p><p>{</p><p>&quot;Err&quot;: &quot;&quot;</p><p>}</p><p>Respond with a string error if an error occurred.</p><h6><strong>/VolumeDriver.Get</strong></h6><p><strong>Request</strong>:</p><p>{</p><p>&quot;Name&quot;: &quot;volume_name&quot;</p><p>}</p><p>Get info about volume_name.</p><p><strong>Response</strong>:</p><ul><li><strong>v1</strong>:</li><li>{</li><li>&quot;Volume&quot;: {</li><li>&quot;Name&quot;: &quot;volume_name&quot;,</li><li>&quot;Mountpoint&quot;: &quot;/path/to/directory/on/host&quot;,</li><li>&quot;Status&quot;: {}</li><li>},</li><li>&quot;Err&quot;: &quot;&quot;</li><li>}</li><li><strong>v2</strong>:</li><li>{</li><li>&quot;Volume&quot;: {</li><li>&quot;Name&quot;: &quot;volume_name&quot;,</li><li>&quot;Mountpoint&quot;: &quot;/path/under/PropagatedMount&quot;,</li><li>&quot;Status&quot;: {}</li><li>},</li><li>&quot;Err&quot;: &quot;&quot;</li><li>}</li></ul><p>Respond with a string error if an error occurred. Mountpoint and Status are optional.</p><h6><strong>/VolumeDriver.List</strong></h6><p><strong>Request</strong>:</p><p>{}</p><p>Get the list of volumes registered with the plugin.</p><p><strong>Response</strong>:</p><ul><li><strong>v1</strong>:</li><li>{</li><li>&quot;Volumes&quot;: [</li><li>{</li><li>&quot;Name&quot;: &quot;volume_name&quot;,</li><li>&quot;Mountpoint&quot;: &quot;/path/to/directory/on/host&quot;</li><li>}</li><li>],</li><li>&quot;Err&quot;: &quot;&quot;</li><li>}</li><li><strong>v2</strong>:</li><li>{</li><li>&quot;Volumes&quot;: [</li><li>{</li><li>&quot;Name&quot;: &quot;volume_name&quot;,</li><li>&quot;Mountpoint&quot;: &quot;/path/under/PropagatedMount&quot;</li><li>}</li><li>],</li><li>&quot;Err&quot;: &quot;&quot;</li><li>}</li></ul><p>Respond with a string error if an error occurred. Mountpoint is optional.</p><h6><strong>/VolumeDriver.Capabilities</strong></h6><p><strong>Request</strong>:</p><p>{}</p><p>Get the list of capabilities the driver supports.</p><p>The driver is not required to implement Capabilities. If it is not implemented, the default values are used.</p><p><strong>Response</strong>:</p><p>{</p><p>&quot;Capabilities&quot;: {</p><p>&quot;Scope&quot;: &quot;global&quot;</p><p>}</p><p>}</p><p>Supported scopes are global and local. Any other value in Scope will be ignored, and local is used. Scope allows cluster managers to handle the volume in different ways. For instance, a scope of global, signals to the cluster manager that it only needs to create the volume once instead of on each Docker host. More capabilities may be added in the future.</p><h4>Plugin Config Version 1 of Plugin V2</h4><p>This document outlines the format of the V0 plugin configuration. The plugin config described herein was introduced in the Docker daemon in the <a href="https://github.com/docker/docker/commit/f37117045c5398fd3dca8016ea8ca0cb47e7312b">v1.12.0 release</a>.</p><p>Plugin configs describe the various constituents of a docker plugin. Plugin configs can be serialized to JSON format with the following media types:</p><p>  <strong>Config Type</strong>   <strong>Media Type</strong></p><hr/><p>  config            &quot;application/vnd.docker.plugin.v1+json&quot;</p><h5><strong>Config Field Descriptions</strong></h5><p>Config provides the base accessible fields for working with V0 plugin format in the registry.</p><ul><li><strong>description</strong> string</li></ul><p>description of the plugin</p><ul><li><strong>documentation</strong> string</li><li>link to the documentation about the plugin</li><li><strong>interface</strong> PluginInterface</li></ul><p>interface implemented by the plugins, struct consisting of the following fields</p><ul><li><ul><li><strong>types</strong> string array</li></ul></li></ul><p>types indicate what interface(s) the plugin currently implements.</p><p>currently supported:</p><ul><li><ul><li><ul><li><strong>docker.volumedriver/1.0</strong></li><li><strong>docker.networkdriver/1.0</strong></li><li><strong>docker.ipamdriver/1.0</strong></li><li><strong>docker.authz/1.0</strong></li><li><strong>docker.logdriver/1.0</strong></li><li><strong>docker.metricscollector/1.0</strong></li></ul></li><li><p><strong>socket</strong> string</p></li></ul></li></ul><p>socket is the name of the socket the engine should use to communicate with the plugins. the socket will be created in /run/docker/plugins.</p><ul><li><strong>entrypoint</strong> string array</li></ul><p>entrypoint of the plugin, see <a href="https://docs.docker.com/engine/reference/builder/#entrypoint">ENTRYPOINT</a></p><ul><li><strong>workdir</strong> string</li></ul><p>workdir of the plugin, see <a href="https://docs.docker.com/engine/reference/builder/#workdir">WORKDIR</a></p><ul><li><strong>network</strong> PluginNetwork</li></ul><p>network of the plugin, struct consisting of the following fields</p><ul><li><ul><li><strong>type</strong> string</li></ul></li></ul><p>network type.</p><p>currently supported:</p><ul><li><p><strong>bridge</strong></p></li><li><p><strong>host</strong></p></li><li><p><strong>none</strong></p></li><li><p><strong>mounts</strong> PluginMount array</p></li></ul><p>mount of the plugin, struct consisting of the following fields, see <a href="https://github.com/opencontainers/runtime-spec/blob/master/config.md#mounts">MOUNTS</a></p><ul><li><ul><li><strong>name</strong> string</li></ul></li></ul><p>name of the mount.</p><ul><li><ul><li><strong>description</strong> string</li></ul></li></ul><p>description of the mount.</p><ul><li><ul><li><strong>source</strong> string</li></ul></li></ul><p>source of the mount.</p><ul><li><ul><li><strong>destination</strong> string</li></ul></li></ul><p>destination of the mount.</p><ul><li><ul><li><strong>type</strong> string</li></ul></li></ul><p>mount type.</p><ul><li><ul><li><strong>options</strong> string array</li></ul></li></ul><p>options of the mount.</p><ul><li><strong>ipchost</strong> boolean Access to host ipc namespace.</li><li><strong>pidhost</strong> boolean Access to host pid namespace.</li><li><strong>propagatedMount</strong> string</li></ul><p>path to be mounted as rshared, so that mounts under that path are visible to docker. This is useful for volume plugins. This path will be bind-mounted outside of the plugin rootfs so it&#x27;s contents are preserved on upgrade.</p><ul><li><strong>env</strong> PluginEnv array</li></ul><p>env of the plugin, struct consisting of the following fields</p><ul><li><ul><li><strong>name</strong> string</li></ul></li></ul><p>name of the env.</p><ul><li><ul><li><strong>description</strong> string</li></ul></li></ul><p>description of the env.</p><ul><li><ul><li><strong>value</strong> string</li></ul></li></ul><p>value of the env.</p><ul><li><strong>args</strong> PluginArgs</li></ul><p>args of the plugin, struct consisting of the following fields</p><ul><li><ul><li><strong>name</strong> string</li></ul></li></ul><p>name of the args.</p><ul><li><ul><li><strong>description</strong> string</li></ul></li></ul><p>description of the args.</p><ul><li><ul><li><strong>value</strong> string array</li></ul></li></ul><p>values of the args.</p><ul><li><strong>linux</strong> PluginLinux<ul><li><strong>capabilities</strong> string array</li></ul></li></ul><p>capabilities of the plugin (Linux only), see list <a href="https://github.com/opencontainers/runc/blob/master/libcontainer/SPEC.md#security">here</a></p><ul><li><ul><li><strong>allowAllDevices</strong> boolean</li></ul></li></ul><p>If /dev is bind mounted from the host, and allowAllDevices is set to true, the plugin will have rwm access to all devices on the host.</p><ul><li><ul><li><strong>devices</strong> PluginDevice array</li></ul></li></ul><p>device of the plugin, (Linux only), struct consisting of the following fields, see <a href="https://github.com/opencontainers/runtime-spec/blob/master/config-linux.md#devices">DEVICES</a></p><ul><li><ul><li><ul><li><strong>name</strong> string</li></ul></li></ul></li></ul><p>name of the device.</p><ul><li><ul><li><ul><li><strong>description</strong> string</li></ul></li></ul></li></ul><p>description of the device.</p><ul><li><ul><li><ul><li><strong>path</strong> string</li></ul></li></ul></li></ul><p>path of the device.</p><h5><strong>Example Config</strong></h5><p>Example showing the &#x27;tiborvass/sample-volume-plugin&#x27; plugin config.</p><p>{</p><p>&quot;Args&quot;: {</p><p>&quot;Description&quot;: &quot;&quot;,</p><p>&quot;Name&quot;: &quot;&quot;,</p><p>&quot;Settable&quot;: null,</p><p>&quot;Value&quot;: null</p><p>},</p><p>&quot;Description&quot;: &quot;A sample volume plugin for Docker&quot;,</p><p>&quot;Documentation&quot;: &quot;<a href="https://docs.docker.com/engine/extend/plugins/%22">https://docs.docker.com/engine/extend/plugins/&quot;</a>,</p><p>&quot;Entrypoint&quot;: [</p><p>&quot;/usr/bin/sample-volume-plugin&quot;,</p><p>&quot;/data&quot;</p><p>],</p><p>&quot;Env&quot;: [</p><p>{</p><p>&quot;Description&quot;: &quot;&quot;,</p><p>&quot;Name&quot;: &quot;DEBUG&quot;,</p><p>&quot;Settable&quot;: [</p><p>&quot;value&quot;</p><p>],</p><p>&quot;Value&quot;: &quot;0&quot;</p><p>}</p><p>],</p><p>&quot;Interface&quot;: {</p><p>&quot;Socket&quot;: &quot;plugin.sock&quot;,</p><p>&quot;Types&quot;: [</p><p>&quot;docker.volumedriver/1.0&quot;</p><p>]</p><p>},</p><p>&quot;Linux&quot;: {</p><p>&quot;Capabilities&quot;: null,</p><p>&quot;AllowAllDevices&quot;: false,</p><p>&quot;Devices&quot;: null</p><p>},</p><p>&quot;Mounts&quot;: null,</p><p>&quot;Network&quot;: {</p><p>&quot;Type&quot;: &quot;&quot;</p><p>},</p><p>&quot;PropagatedMount&quot;: &quot;/data&quot;,</p><p>&quot;User&quot;: {},</p><p>&quot;Workdir&quot;: &quot;&quot;</p><p>}</p><h4>Docker Plugin API</h4><p>Docker plugins are out-of-process extensions which add capabilities to the Docker Engine.</p><p>This document describes the Docker Engine plugin API. To view information on plugins managed by Docker Engine, refer to <a href="https://docs.docker.com/engine/extend/">Docker Engine plugin system</a>.</p><p>This page is intended for people who want to develop their own Docker plugin. If you just want to learn about or use Docker plugins, look <a href="https://docs.docker.com/engine/extend/legacy_plugins/">here</a>.</p><h5><strong>What plugins are</strong></h5><p>A plugin is a process running on the same or a different host as the docker daemon, which registers itself by placing a file on the same docker host in one of the plugin directories described in <a href="https://docs.docker.com/engine/extend/plugin_api/#plugin-discovery">Plugin discovery</a>.</p><p>Plugins have human-readable names, which are short, lowercase strings. For example, flockeror weave.</p><p>Plugins can run inside or outside containers. Currently running them outside containers is recommended.</p><h5><strong>Plugin discovery</strong></h5><p>Docker discovers plugins by looking for them in the plugin directory whenever a user or container tries to use one by name.</p><p>There are three types of files which can be put in the plugin directory.</p><ul><li>.sock files are UNIX domain sockets.</li><li>.spec files are text files containing a URL, such as unix:///other.sock or tcp://localhost:8080.</li><li>.json files are text files containing a full json specification for the plugin.</li></ul><p>Plugins with UNIX domain socket files must run on the same docker host, whereas plugins with spec or json files can run on a different host if a remote URL is specified.</p><p>UNIX domain socket files must be located under /run/docker/plugins, whereas spec files can be located either under /etc/docker/plugins or /usr/lib/docker/plugins.</p><p>The name of the file (excluding the extension) determines the plugin name.</p><p>For example, the flocker plugin might create a UNIX socket at/run/docker/plugins/flocker.sock.</p><p>You can define each plugin into a separated subdirectory if you want to isolate definitions from each other. For example, you can create the flocker socket under /run/docker/plugins/flocker/flocker.sock and only mount /run/docker/plugins/flockerinside the flocker container.</p><p>Docker always searches for unix sockets in /run/docker/plugins first. It checks for spec or json files under /etc/docker/plugins and /usr/lib/docker/plugins if the socket doesn&#x27;t exist. The directory scan stops as soon as it finds the first plugin definition with the given name.</p><h6><strong>JSON specification</strong></h6><p>This is the JSON format for a plugin:</p><p>{</p><p>&quot;Name&quot;: &quot;plugin-example&quot;,</p><p>&quot;Addr&quot;: &quot;<a href="https://example.com/docker/plugin%22">https://example.com/docker/plugin&quot;</a>,</p><p>&quot;TLSConfig&quot;: {</p><p>&quot;InsecureSkipVerify&quot;: false,</p><p>&quot;CAFile&quot;: &quot;/usr/shared/docker/certs/example-ca.pem&quot;,</p><p>&quot;CertFile&quot;: &quot;/usr/shared/docker/certs/example-cert.pem&quot;,</p><p>&quot;KeyFile&quot;: &quot;/usr/shared/docker/certs/example-key.pem&quot;</p><p>}</p><p>}</p><p>The TLSConfig field is optional and TLS will only be verified if this configuration is present.</p><h5><strong>Plugin lifecycle</strong></h5><p>Plugins should be started before Docker, and stopped after Docker. For example, when packaging a plugin for a platform which supports systemd, you might use <a href="http://www.freedesktop.org/software/systemd/man/systemd.unit.html#Before=">systemd dependencies</a> to manage startup and shutdown order.</p><p>When upgrading a plugin, you should first stop the Docker daemon, upgrade the plugin, then start Docker again.</p><h5><strong>Plugin activation</strong></h5><p>When a plugin is first referred to -- either by a user referring to it by name (e.g.docker run --volume-driver=foo) or a container already configured to use a plugin being started -- Docker looks for the named plugin in the plugin directory and activates it with a handshake. See Handshake API below.</p><p>Plugins are not activated automatically at Docker daemon startup. Rather, they are activated only lazily, or on-demand, when they are needed.</p><h5><strong>Systemd socket activation</strong></h5><p>Plugins may also be socket activated by systemd. The official <a href="https://github.com/docker/go-plugins-helpers">Plugins helpers</a> natively supports socket activation. In order for a plugin to be socket activated it needs a service file and a socket file.</p><p>The service file (for example /lib/systemd/system/your-plugin.service):</p><p>[Unit]</p><p>Description=Your plugin</p><p>Before=docker.service</p><p>After=network.target your-plugin.socket</p><p>Requires=your-plugin.socket docker.service</p><p>[Service]</p><p>ExecStart=/usr/lib/docker/your-plugin</p><p>[Install]</p><p>WantedBy=multi-user.target</p><p>The socket file (for example /lib/systemd/system/your-plugin.socket):</p><p>[Unit]</p><p>Description=Your plugin</p><p>[Socket]</p><p>ListenStream=/run/docker/plugins/your-plugin.sock</p><p>[Install]</p><p>WantedBy=sockets.target</p><p>This will allow plugins to be actually started when the Docker daemon connects to the sockets they&#x27;re listening on (for instance the first time the daemon uses them or if one of the plugin goes down accidentally).</p><h5><strong>API design</strong></h5><p>The Plugin API is RPC-style JSON over HTTP, much like webhooks.</p><p>Requests flow from the Docker daemon to the plugin. So the plugin needs to implement an HTTP server and bind this to the UNIX socket mentioned in the &quot;plugin discovery&quot; section.</p><p>All requests are HTTP POST requests.</p><p>The API is versioned via an Accept header, which currently is always set toapplication/vnd.docker.plugins.v1+json.</p><h5><strong>Handshake API</strong></h5><p>Plugins are activated via the following &quot;handshake&quot; API call.</p><h6><strong>/Plugin.Activate</strong></h6><p><strong>Request:</strong> empty body</p><p><strong>Response:</strong></p><p>{</p><p>&quot;Implements&quot;: <!-- -->[&quot;VolumeDriver&quot;]</p><p>}</p><p>Responds with a list of Docker subsystems which this plugin implements. After activation, the plugin will then be sent events from this subsystem.</p><p>Possible values are:</p><ul><li><a href="https://docs.docker.com/engine/extend/plugins_authorization/">authz</a></li><li><a href="https://docs.docker.com/engine/extend/plugins_network/">NetworkDriver</a></li><li><a href="https://docs.docker.com/engine/extend/plugins_volume/">VolumeDriver</a></li></ul><h5><strong>Plugin retries</strong></h5><p>Attempts to call a method on a plugin are retried with an exponential backoff for up to 30 seconds. This may help when packaging plugins as containers, since it gives plugin containers a chance to start up before failing any user containers which depend on them.</p><h5><strong>Plugins helpers</strong></h5><p>To ease plugins development, we&#x27;re providing an sdk for each kind of plugins currently supported by Docker at <a href="https://github.com/docker/go-plugins-helpers">docker/go-plugins-helpers</a>.</p></div></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/docker/";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"polyfill":["/polyfill-e4ff66ed5ec0b4bd2598.js"],"app":["/app-eeb4193423903187a951.js"],"component---src-pages-404-tsx":["/component---src-pages-404-tsx-5f7f07bdd531e2b5021f.js"],"component---src-pages-index-tsx":["/component---src-pages-index-tsx-e4ae0f7d9ba5aaf1fdc1.js"],"component---src-templates-blog-post-template-tsx":["/component---src-templates-blog-post-template-tsx-a3788de39add0692b44b.js"]};/*]]>*/</script><script src="/personal-blog/polyfill-e4ff66ed5ec0b4bd2598.js" nomodule=""></script><script src="/personal-blog/component---src-templates-blog-post-template-tsx-a3788de39add0692b44b.js" async=""></script><script src="/personal-blog/ce5c1ec6b0c5670e22550a7ef5fd5c2de8a4bdeb-f3cc52c60397f69658d6.js" async=""></script><script src="/personal-blog/app-eeb4193423903187a951.js" async=""></script><script src="/personal-blog/framework-2601ed29d039b1458055.js" async=""></script><script src="/personal-blog/webpack-runtime-500034a3e408444d0cae.js" async=""></script></body></html>