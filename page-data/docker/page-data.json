{"componentChunkName":"component---src-templates-blog-post-template-tsx","path":"/docker/","result":{"data":{"mdx":{"frontmatter":{"title":"Docker","date":"2021 January 19th"},"tableOfContents":{"items":[{"url":"#important-links","title":"Important Links"},{"url":"#code-links","title":"Code Links"},{"url":"#get-started-with-docker","title":"Get Started with Docker","items":[{"url":"#get-docker","title":"Get Docker","items":[{"url":"#supported-platforms","title":"Supported platforms"},{"url":"#time-based-release-schedule","title":"Time-based release schedule"},{"url":"#updates-and-patches","title":"Updates, and patches"},{"url":"#prior-releases","title":"Prior releases"},{"url":"#install","title":"Install","items":[{"url":"#manage-docker-as-a-non-root-user","title":"Manage Docker as a non-root user"},{"url":"#configure-docker-to-start-on-boot","title":"Configure Docker to start on boot"},{"url":"#use-a-different-storage-engine","title":"Use a different storage engine"},{"url":"#configure-where-the-docker-daemon-listens-for-connections","title":"Configure where the Docker daemon listens for connections"},{"url":"#enable-ipv6-on-the-docker-daemon","title":"Enable IPv6 on the Docker daemon"},{"url":"#troubleshooting","title":"Troubleshooting","items":[{"url":"#kernel-compatibility","title":"Kernel compatibility"},{"url":"#ip-forwarding-problems","title":"IP forwarding problems"}]},{"url":"#specify-dns-servers-for-docker","title":"Specify DNS servers for Docker"},{"url":"#allow-access-to-the-remote-api-through-a-firewall","title":"Allow access to the remote API through a firewall"}]}]},{"url":"#docker-ce-edge-documentation","title":"Docker CE Edge documentation","items":[{"items":[{"url":"#docker-ce-edge-resources","title":"Docker CE Edge resources"}]}]},{"url":"#get-docker-compose","title":"Get Docker-Compose","items":[{"url":"#prerequisites","title":"Prerequisites"},{"url":"#install-compose","title":"Install Compose","items":[{"url":"#install-compose-on-linux-systems","title":"Install Compose on Linux systems"}]},{"url":"#master-builds","title":"Master builds"},{"url":"#upgrading","title":"Upgrading"},{"url":"#uninstallation","title":"Uninstallation"}]},{"url":"#docker----get-started","title":"Docker -- Get Started","items":[{"url":"#images-and-containers","title":"Images and containers"},{"url":"#containers-and-virtual-machines","title":"Containers and virtual machines"},{"url":"#orientation-and-setup","title":"Orientation and Setup","items":[{"url":"#test-docker-version","title":"Test Docker version"},{"url":"#build-the-app","title":"Build the app"},{"url":"#run-the-app","title":"Run the app"},{"url":"#share-your-image","title":"Share your image"},{"url":"#log-in-with-your-docker-id","title":"Log in with your Docker ID"},{"url":"#tag-the-image","title":"Tag the image"},{"url":"#publish-the-image","title":"Publish the image"},{"url":"#pull-and-run-the-image-from-the-remote-repository","title":"Pull and run the image from the remote repository"}]}]},{"url":"#docker-compose","title":"Docker Compose","items":[{"url":"#your-first-docker-composeyml-file","title":"Your first docker-compose.yml file"}]}]},{"url":"#replace-usernamerepotag-with-your-name-and-image-details","title":"replace username/repo:tag with your name and image details","items":[{"items":[{"url":"#run-your-new-load-balanced-app","title":"Run your new load-balanced app"},{"url":"#scale-the-app","title":"Scale the app","items":[{"url":"#take-down-the-app-and-the-swarm","title":"Take down the app and the swarm"}]},{"url":"#recap-and-cheat-sheet","title":"Recap and cheat sheet"}]},{"url":"#docker-swarm","title":"Docker Swarm","items":[{"url":"#understanding-swarm-clusters","title":"Understanding Swarm clusters"},{"url":"#set-up-your-swarm","title":"Set up your swarm","items":[{"url":"#create-a-cluster","title":"Create a cluster","items":[{"url":"#vms-on-your-local-machine-mac-linux-windows-7-and-8","title":"VMS ON YOUR LOCAL MACHINE (MAC, LINUX, WINDOWS 7 AND 8)"},{"url":"#list-the-vms-and-get-their-ip-addresses","title":"LIST THE VMS AND GET THEIR IP ADDRESSES"},{"url":"#initialize-the-swarm-and-add-nodes","title":"INITIALIZE THE SWARM AND ADD NODES"}]}]},{"url":"#deploy-your-app-on-the-swarm-cluster","title":"Deploy your app on the swarm cluster","items":[{"url":"#docker-machine-shell-environment-on-mac-or-linux","title":"DOCKER MACHINE SHELL ENVIRONMENT ON MAC OR LINUX"},{"url":"#deploy-the-app-on-the-swarm-manager","title":"Deploy the app on the swarm manager"},{"url":"#accessing-your-cluster","title":"Accessing your cluster"}]},{"url":"#iterating-and-scaling-your-app","title":"Iterating and scaling your app"},{"url":"#cleanup-and-reboot","title":"Cleanup and reboot","items":[{"url":"#stacks-and-swarms","title":"Stacks and swarms"},{"url":"#unsetting-docker-machine-shell-variable-settings","title":"Unsetting docker-machine shell variable settings"},{"url":"#restarting-docker-machines","title":"Restarting Docker machines"}]},{"url":"#recap-and-cheat-sheet-optional","title":"Recap and cheat sheet (optional)"}]},{"url":"#stacks","title":"Stacks","items":[{"url":"#introduction","title":"Introduction"},{"url":"#add-a-new-service-and-redeploy","title":"Add a new service and redeploy"}]}]},{"url":"#replace-usernamerepotag-with-your-name-and-image-details-1","title":"replace username/repo:tag with your name and image details","items":[{"items":[{"url":"#persist-the-data","title":"Persist the data"}]}]},{"url":"#replace-usernamerepotag-with-your-name-and-image-details-2","title":"replace username/repo:tag with your name and image details","items":[{"url":"#docker-overview","title":"Docker overview","items":[{"url":"#the-docker-platform","title":"The Docker platform"},{"url":"#docker-engine","title":"Docker Engine"},{"url":"#what-can-i-use-docker-for","title":"What can I use Docker for?"},{"url":"#docker-architecture","title":"Docker architecture","items":[{"url":"#the-docker-daemon","title":"The Docker daemon"},{"url":"#the-docker-client","title":"The Docker client"},{"url":"#docker-registries","title":"Docker registries"},{"url":"#docker-objects","title":"Docker objects","items":[{"url":"#images","title":"IMAGES"},{"url":"#containers","title":"CONTAINERS","items":[{"url":"#example-docker-run-command","title":"Example docker run command"}]},{"url":"#services","title":"Services"}]}]},{"url":"#the-underlying-technology","title":"The underlying technology","items":[{"url":"#namespaces","title":"Namespaces"},{"url":"#control-groups","title":"Control groups"},{"url":"#union-file-systems","title":"Union file systems"},{"url":"#container-format","title":"Container format"}]}]}]},{"url":"#develop-with-docker","title":"Develop with Docker","items":[{"url":"#develop-new-apps-on-docker","title":"Develop new apps on Docker"},{"url":"#learn-about-language-specific-app-development-with-docker","title":"Learn about language-specific app development with Docker"},{"url":"#advanced-development-with-the-sdk-or-api","title":"Advanced development with the SDK or API"},{"url":"#docker-development-best-practices","title":"Docker development best practices","items":[{"url":"#how-to-keep-your-images-small","title":"How to keep your images small"},{"url":"#where-and-how-to-persist-application-data","title":"Where and how to persist application data"},{"url":"#use-swarm-services-when-possible","title":"Use swarm services when possible"},{"url":"#use-cicd-for-testing-and-deployment","title":"Use CI/CD for testing and deployment"},{"url":"#differences-in-development-and-production-environments","title":"Differences in development and production environments"}]},{"url":"#develop-images","title":"Develop Images","items":[{"url":"#best-practices-for-writing-dockerfiles","title":"Best practices for writing Dockerfiles","items":[{"url":"#general-guidelines-and-recommendations","title":"General guidelines and recommendations","items":[{"url":"#containers-should-be-ephemeral","title":"Containers should be ephemeral","items":[{"url":"#use-a-dockerignore-file","title":"Use a .dockerignore file"}]},{"url":"#use-multi-stage-builds","title":"Use multi-stage builds"}]}]}]}]},{"url":"#install-tools-required-to-build-the-project","title":"Install tools required to build the project"},{"url":"#we-need-to-run-docker-build---no-cache--to-update-those-dependencies","title":"We need to run docker build --no-cache . to update those dependencies"},{"url":"#gopkgtoml-and-gopkglock-lists-project-dependencies","title":"Gopkg.toml and Gopkg.lock lists project dependencies"},{"url":"#these-layers-are-only-re-built-when-gopkg-files-are-updated","title":"These layers are only re-built when Gopkg files are updated"},{"url":"#install-library-dependencies","title":"Install library dependencies"},{"url":"#copy-all-project-and-build-it","title":"Copy all project and build it"},{"url":"#this-layer-is-rebuilt-when-ever-a-file-has-changed-in-the-project-directory","title":"This layer is rebuilt when ever a file has changed in the project directory"},{"url":"#this-results-in-a-single-layer-image","title":"This results in a single layer image","items":[{"items":[{"items":[{"items":[{"url":"#avoid-installing-unnecessary-packages","title":"Avoid installing unnecessary packages"},{"url":"#each-container-should-have-only-one-concern","title":"Each container should have only one concern"},{"url":"#minimize-the-number-of-layers","title":"Minimize the number of layers"},{"url":"#sort-multi-line-arguments","title":"Sort multi-line arguments"},{"url":"#build-cache","title":"Build cache"}]},{"url":"#the-dockerfile-instructions","title":"The Dockerfile instructions","items":[{"url":"#from","title":"FROM"},{"url":"#label","title":"LABEL"}]}]}]}]},{"url":"#set-one-or-more-individual-labels","title":"Set one or more individual labels"},{"url":"#set-multiple-labels-on-one-line","title":"Set multiple labels on one line"},{"url":"#set-multiple-labels-at-once-using-line-continuation-characters-to-break-long-lines","title":"Set multiple labels at once, using line-continuation characters to break long lines","items":[{"items":[{"items":[{"items":[{"url":"#run","title":"RUN","items":[{"url":"#apt-get","title":"APT-GET"},{"url":"#using-pipes","title":"USING PIPES"}]},{"url":"#cmd","title":"CMD"},{"url":"#expose","title":"EXPOSE"},{"url":"#env","title":"ENV"},{"url":"#add-or-copy","title":"ADD or COPY"},{"url":"#entrypoint","title":"ENTRYPOINT"},{"url":"#volume","title":"VOLUME"},{"url":"#user","title":"USER"},{"url":"#workdir","title":"WORKDIR"},{"url":"#onbuild","title":"ONBUILD"}]},{"url":"#examples-for-official-repositories","title":"Examples for Official Repositories"},{"url":"#additional-resources","title":"Additional resources"}]},{"url":"#create-a-base-image","title":"Create a base image","items":[{"url":"#create-a-full-image-using-tar","title":"Create a full image using tar"},{"url":"#create-a-simple-parent-image-using-scratch","title":"Create a simple parent image using scratch"},{"url":"#more-resources","title":"More resources"}]},{"url":"#use-multi-stage-builds-1","title":"Use multi-stage builds","items":[{"url":"#before-multi-stage-builds","title":"Before multi-stage builds"},{"url":"#use-multi-stage-builds-2","title":"Use multi-stage builds"},{"url":"#name-your-build-stages","title":"Name your build stages"},{"url":"#stop-at-a-specific-build-stage","title":"Stop at a specific build stage"},{"url":"#use-an-external-image-as-a-stage","title":"Use an external image as a \"stage\""}]},{"url":"#dockerfile-reference-unread-ref","title":"Dockerfile reference (Unread) (REF)","items":[{"url":"#usage","title":"Usage"},{"url":"#format","title":"Format"}]}]}]},{"url":"#comment","title":"Comment"},{"url":"#comment-1","title":"Comment","items":[{"items":[{"items":[{"url":"#parser-directives","title":"Parser directives"}]}]}]},{"url":"#direc-","title":"direc \\"},{"url":"#directivevalue1","title":"directive=value1"},{"url":"#directivevalue2","title":"directive=value2"},{"url":"#directivevalue","title":"directive=value"},{"url":"#about-my-dockerfile","title":"About my dockerfile"},{"url":"#directivevalue-1","title":"directive=value"},{"url":"#unknowndirectivevalue","title":"unknowndirective=value"},{"url":"#knowndirectivevalue","title":"knowndirective=value"},{"url":"#directive-value","title":"directive =value"},{"url":"#directive-value-1","title":"directive= value"},{"url":"#directive--value","title":"directive = value"},{"url":"#directivevalue-2","title":"dIrEcTiVe=value","items":[{"items":[{"items":[{"url":"#escape","title":"escape"}]}]}]},{"url":"#escape-backslash","title":"escape=\\ (backslash)"},{"url":"#escape-backtick","title":"escape=` (backtick)"},{"url":"#escape-1","title":"escape=`","items":[{"items":[{"items":[{"url":"#environment-replacement","title":"Environment replacement"},{"url":"#dockerignore-file","title":".dockerignore file"}]}]}]},{"url":"#comment-2","title":"comment"},{"url":"#comment-----ignored","title":"comment     Ignored.","items":[{"items":[{"items":[{"url":"#from-1","title":"FROM","items":[{"url":"#understand-how-arg-and-from-interact","title":"Understand how ARG and FROM interact"}]},{"url":"#run-1","title":"RUN","items":[{"url":"#known-issues-run","title":"Known issues (RUN)"}]},{"url":"#cmd-1","title":"CMD"},{"url":"#label-1","title":"LABEL"},{"url":"#maintainer-deprecated","title":"MAINTAINER (deprecated)"},{"url":"#expose-1","title":"EXPOSE"},{"url":"#env-1","title":"ENV"},{"url":"#add","title":"ADD"},{"url":"#copy","title":"COPY"},{"url":"#entrypoint-1","title":"ENTRYPOINT","items":[{"url":"#exec-form-entrypoint-example","title":"Exec form ENTRYPOINT example"},{"url":"#shell-form-entrypoint-example","title":"Shell form ENTRYPOINT example"},{"url":"#understand-how-cmd-and-entrypoint-interact","title":"Understand how CMD and ENTRYPOINT interact"}]},{"url":"#volume-1","title":"VOLUME","items":[{"url":"#notes-about-specifying-volumes","title":"Notes about specifying volumes"}]},{"url":"#user-1","title":"USER"}]}]}]},{"url":"#create-windows-user-in-the-container","title":"Create Windows user in the container"},{"url":"#set-it-for-subsequent-commands","title":"Set it for subsequent commands","items":[{"items":[{"items":[{"url":"#workdir-1","title":"WORKDIR"},{"url":"#arg","title":"ARG","items":[{"url":"#default-values","title":"Default values"},{"url":"#scope","title":"Scope"},{"url":"#using-arg-variables","title":"Using ARG variables"},{"url":"#predefined-args","title":"Predefined ARGs"},{"url":"#impact-on-build-caching","title":"Impact on build caching"}]},{"url":"#onbuild-1","title":"ONBUILD"},{"url":"#stopsignal","title":"STOPSIGNAL"},{"url":"#healthcheck","title":"HEALTHCHECK"},{"url":"#shell","title":"SHELL"}]}]}]},{"url":"#executed-as-cmd-s-c-echo-default","title":"Executed as cmd /S /C echo default"},{"url":"#executed-as-cmd-s-c-powershell--command-write-host-default","title":"Executed as cmd /S /C powershell -command Write-Host default"},{"url":"#executed-as-powershell--command-write-host-hello","title":"Executed as powershell -command Write-Host hello"},{"url":"#executed-as-cmd-s-c-echo-hello","title":"Executed as cmd /S /C echo hello"},{"url":"#escape-2","title":"escape=`","items":[{"items":[{"items":[{"url":"#dockerfile-examples","title":"Dockerfile examples"}]}]}]},{"url":"#nginx","title":"Nginx"},{"url":"#version-001","title":"VERSION 0.0.1"},{"url":"#firefox-over-vnc","title":"Firefox over VNC"},{"url":"#version-03","title":"VERSION 0.3"},{"url":"#install-vnc-xvfb-in-order-to-create-a-fake-display-and-firefox","title":"Install vnc, xvfb in order to create a \\'fake\\' display and firefox"},{"url":"#setup-a-password","title":"Setup a password"},{"url":"#autostart-firefox-might-not-be-the-best-way-but-it-does-the-trick","title":"Autostart firefox (might not be the best way, but it does the trick)"},{"url":"#multiple-images-example","title":"Multiple images example"},{"url":"#version-01","title":"VERSION 0.1"},{"url":"#will-output-something-like--907ad6c2736f","title":"Will output something like ===> 907ad6c2736f"},{"url":"#will-output-something-like--695d7793cbe4","title":"Will output something like ===> 695d7793cbe4"},{"url":"#youll-now-have-two-images-907ad6c2736f-with-bar-and-695d7793cbe4-with","title":"You\\'ll now have two images, 907ad6c2736f with /bar, and 695d7793cbe4 with"},{"url":"#oink","title":"/oink.","items":[{"items":[{"url":"#manage-images","title":"Manage images","items":[{"url":"#docker-hub","title":"Docker Hub"},{"url":"#docker-registry","title":"Docker Registry"},{"url":"#docker-trusted-registry","title":"Docker Trusted Registry"},{"url":"#content-trust","title":"Content Trust"}]},{"url":"#samples-to-be-done","title":"Samples (To Be Done)","items":[{"url":"#tutorial-labs","title":"Tutorial labs"},{"url":"#library-references","title":"Library references"},{"url":"#sample-applications","title":"Sample applications"}]}]},{"url":"#develop-with-docker-engine-sdks-and-api","title":"Develop with Docker Engine SDKs and API","items":[{"url":"#install-the-sdks","title":"Install the SDKs","items":[{"url":"#go-sdk","title":"Go SDK"},{"url":"#python-sdk","title":"Python SDK"}]},{"url":"#view-the-api-reference","title":"View the API reference"},{"url":"#versioned-api-and-sdk","title":"Versioned API and SDK","items":[{"url":"#docker-ee-and-ce-api-mismatch","title":"Docker EE and CE API mismatch"},{"url":"#api-version-matrix","title":"API version matrix"},{"url":"#choose-the-sdk-or-api-version-to-use","title":"Choose the SDK or API version to use"}]},{"url":"#sdk-and-api-quickstart","title":"SDK and API quickstart"},{"url":"#unofficial-libraries","title":"Unofficial libraries"}]},{"url":"#examples-using-the-docker-engine-sdks-and-docker-api","title":"Examples using the Docker Engine SDKs and Docker API"}]},{"url":"#configuring-networks","title":"Configuring Networks","items":[{"url":"#network-overview","title":"Network Overview","items":[{"url":"#scope-of-this-topic","title":"Scope of this topic"},{"url":"#network-drivers","title":"Network drivers","items":[{"url":"#network-driver-summary","title":"Network driver summary"}]},{"url":"#docker-ee-networking-features","title":"Docker EE networking features"},{"url":"#networking-tutorials","title":"Networking tutorials"}]},{"url":"#use-bridge-networks","title":"Use bridge networks","items":[{"url":"#differences-between-user-defined-bridges-and-the-default-bridge","title":"Differences between user-defined bridges and the default bridge"},{"url":"#manage-a-user-defined-bridge","title":"Manage a user-defined bridge"},{"url":"#connect-a-container-to-a-user-defined-bridge","title":"Connect a container to a user-defined bridge"},{"url":"#disconnect-a-container-from-a-user-defined-bridge","title":"Disconnect a container from a user-defined bridge"},{"url":"#use-ipv6","title":"Use IPv6"},{"url":"#enable-forwarding-from-docker-containers-to-the-outside-world","title":"Enable forwarding from Docker containers to the outside world"},{"url":"#use-the-default-bridge-network","title":"Use the default bridge network","items":[{"url":"#connect-a-container-to-the-default-bridge-network","title":"Connect a container to the default bridge network"},{"url":"#configure-the-default-bridge-network","title":"Configure the default bridge network"},{"url":"#use-ipv6-with-the-default-bridge-network","title":"Use IPv6 with the default bridge network"}]},{"url":"#next-steps","title":"Next steps"}]},{"url":"#use-overlay-networks","title":"Use overlay networks","items":[{"url":"#operations-for-all-overlay-networks","title":"Operations for all overlay networks","items":[{"url":"#create-an-overlay-network","title":"Create an overlay network"},{"url":"#encrypt-traffic-on-an-overlay-network","title":"Encrypt traffic on an overlay network","items":[{"url":"#swarm-mode-overlay-networks-and-standalone-containers","title":"SWARM MODE OVERLAY NETWORKS AND STANDALONE CONTAINERS"}]},{"url":"#customize-the-default-ingress-network","title":"Customize the default ingress network"},{"url":"#customize-the-docker_gwbridge-interface","title":"Customize the docker_gwbridge interface"}]},{"url":"#operations-for-swarm-services","title":"Operations for swarm services","items":[{"url":"#publish-ports-on-an-overlay-network","title":"Publish ports on an overlay network"},{"url":"#bypass-the-routing-mesh-for-a-swarm-service","title":"Bypass the routing mesh for a swarm service"},{"url":"#separate-control-and-data-traffic","title":"Separate control and data traffic"}]},{"url":"#operations-for-standalone-containers-on-overlay-networks","title":"Operations for standalone containers on overlay networks","items":[{"url":"#attach-a-standalone-container-to-an-overlay-network","title":"Attach a standalone container to an overlay network"},{"url":"#publish-ports","title":"Publish ports"}]},{"url":"#next-steps-1","title":"Next steps"}]},{"url":"#use-host-networking","title":"Use host networking","items":[{"url":"#next-steps-2","title":"Next steps"}]},{"url":"#use-macvlan-networks","title":"Use Macvlan networks","items":[{"url":"#create-a-macvlan-network","title":"Create a macvlan network","items":[{"url":"#bridge-mode","title":"Bridge mode"},{"url":"#8021q-trunk-bridge-mode","title":"802.1q trunk bridge mode"},{"url":"#use-an-ipvlan-instead-of-macvlan","title":"Use an ipvlan instead of macvlan"}]},{"url":"#use-ipv6-1","title":"Use IPv6"},{"url":"#next-steps-3","title":"Next steps"}]},{"url":"#disable-networking-for-a-container","title":"Disable networking for a container","items":[{"url":"#next-steps-4","title":"Next steps"}]},{"url":"#networing-tutorials","title":"Networing Tutorials","items":[{"url":"#networking-with-standalone-containers","title":"Networking with standalone containers","items":[{"url":"#use-the-default-bridge-network-1","title":"Use the default bridge network"}]}]}]},{"url":"#ip-addr-show","title":"ip addr show"},{"url":"#ping--c-2-alpine2","title":"ping -c 2 alpine2","items":[{"items":[{"items":[{"url":"#use-user-defined-bridge-networks","title":"Use user-defined bridge networks"}]}]}]},{"url":"#ping--c-2-1721702","title":"ping -c 2 172.17.0.2","items":[{"items":[{"items":[{"url":"#other-networking-tutorials","title":"Other networking tutorials"}]},{"url":"#networking-using-the-host-network","title":"Networking using the host network","items":[{"url":"#goal","title":"Goal"},{"url":"#prerequisites-1","title":"Prerequisites"},{"url":"#procedure","title":"Procedure"},{"url":"#other-networking-tutorials-1","title":"Other networking tutorials"}]},{"url":"#networking-with-overlay-networks","title":"Networking with overlay networks","items":[{"url":"#prerequisites-2","title":"Prerequisites"},{"url":"#use-the-default-overlay-network","title":"Use the default overlay network","items":[{"url":"#prerequisites-3","title":"Prerequisites"},{"url":"#walkthrough","title":"Walkthrough","items":[{"url":"#create-the-swarm","title":"CREATE THE SWARM"},{"url":"#create-the-services","title":"CREATE THE SERVICES"}]}]},{"url":"#use-a-user-defined-overlay-network","title":"Use a user-defined overlay network","items":[{"url":"#prerequisites-4","title":"Prerequisites"},{"url":"#walkthrough-1","title":"Walkthrough"}]},{"url":"#use-an-overlay-network-for-standalone-containers","title":"Use an overlay network for standalone containers","items":[{"url":"#prerequisites-5","title":"Prerequisites"},{"url":"#walk-through","title":"Walk-through"}]}]}]}]},{"url":"#ping--c-2-alpine1","title":"ping -c 2 alpine1","items":[{"items":[{"items":[{"url":"#communicate-between-a-container-and-a-swarm-service","title":"Communicate between a container and a swarm service","items":[{"url":"#prerequisites-6","title":"Prerequisites"},{"url":"#walkthrough-2","title":"Walkthrough"}]}]}]}]},{"url":"#ip-addr-show-1","title":"ip addr show"},{"url":"#ping--c-2-alpine2-1","title":"ping -c 2 alpine2","items":[{"items":[{"items":[{"url":"#other-networking-tutorials-2","title":"Other networking tutorials"}]},{"url":"#networking-using-a-macvlan-network","title":"Networking using a macvlan network","items":[{"url":"#goal-1","title":"Goal"},{"url":"#prerequisites-7","title":"Prerequisites"},{"url":"#bridge-example","title":"Bridge example"},{"url":"#8021q-trunked-bridge-example","title":"802.1q trunked bridge example"},{"url":"#other-networking-tutorials-3","title":"Other networking tutorials"}]},{"url":"#configure-the-daemon-and-the-containers","title":"Configure the Daemon and the Containers","items":[{"url":"#enable-ipv6-support","title":"Enable IPv6 support","items":[{"url":"#next-steps-5","title":"Next steps"}]},{"url":"#docker-and-iptables","title":"Docker and iptables","items":[{"url":"#add-iptables-policies-before-dockers-rules","title":"Add iptables policies before Docker's rules","items":[{"url":"#restrict-connections-to-the-docker-daemon","title":"Restrict connections to the Docker daemon"}]},{"url":"#prevent-docker-from-manipulating-iptables","title":"Prevent Docker from manipulating iptables"},{"url":"#next-steps-6","title":"Next steps"}]},{"url":"#container-networking","title":"Container networking","items":[{"url":"#published-ports","title":"Published ports"},{"url":"#ip-address-and-hostname","title":"IP address and hostname"},{"url":"#dns-services","title":"DNS services"},{"url":"#proxy-server","title":"Proxy server"}]},{"url":"#configure-docker-to-use-a-proxy-server","title":"Configure Docker to use a proxy server","items":[{"url":"#configure-the-docker-client","title":"Configure the Docker client"},{"url":"#use-environment-variables","title":"Use environment variables","items":[{"url":"#set-the-environment-variables-manually","title":"Set the environment variables manually"}]}]}]}]},{"url":"#legacy-networing-content","title":"Legacy Networing Content","items":[{"url":"#legacy-container-links","title":"Legacy container links","items":[{"url":"#connect-using-network-port-mapping","title":"Connect using network port mapping"},{"url":"#connect-with-the-linking-system","title":"Connect with the linking system","items":[{"url":"#the-importance-of-naming","title":"The importance of naming"}]},{"url":"#communication-across-links","title":"Communication across links","items":[{"url":"#environment-variables","title":"Environment variables"},{"url":"#important-notes-on-docker-environment-variables","title":"Important notes on Docker environment variables"},{"url":"#updating-the-etchosts-file","title":"Updating the /etc/hosts file"}]}]},{"url":"#multi-host-networking-with-standalone-swarms","title":"Multi-host networking with standalone swarms","items":[{"url":"#standalone-swarm-only","title":"Standalone swarm only!"},{"url":"#overlay-networking-with-an-external-key-value-store","title":"Overlay networking with an external key-value store","items":[{"url":"#prerequisites-8","title":"Prerequisites"},{"url":"#set-up-a-key-value-store","title":"Set up a key-value store"},{"url":"#create-a-swarm-cluster","title":"Create a swarm cluster"},{"url":"#create-the-overlay-network","title":"Create the overlay network"},{"url":"#run-an-application-on-your-network","title":"Run an application on your network"},{"url":"#check-external-connectivity","title":"Check external connectivity"}]},{"url":"#use-docker-compose-with-swarm-classic","title":"Use Docker Compose with swarm classic"},{"url":"#next-steps-7","title":"Next steps"}]}]}]},{"url":"#manage-data-in-docker","title":"Manage data in Docker","items":[{"url":"#choose-the-right-type-of-mount","title":"Choose the right type of mount","items":[{"url":"#more-details-about-mount-types","title":"More details about mount types"},{"url":"#good-use-cases-for-volumes","title":"Good use cases for volumes"},{"url":"#good-use-cases-for-bind-mounts","title":"Good use cases for bind mounts"},{"url":"#good-use-cases-for-tmpfs-mounts","title":"Good use cases for tmpfs mounts"},{"url":"#tips-for-using-bind-mounts-or-volumes","title":"Tips for using bind mounts or volumes"},{"url":"#next-steps-8","title":"Next steps"}]},{"url":"#use-volumes","title":"Use volumes","items":[{"url":"#choose-the--v-or---mount-flag","title":"Choose the -v or --mount flag","items":[{"url":"#differences-between--v-and---mount-behavior","title":"Differences between -v and --mount behavior"}]},{"url":"#create-and-manage-volumes","title":"Create and manage volumes"},{"url":"#start-a-container-with-a-volume","title":"Start a container with a volume","items":[{"url":"#start-a-service-with-volumes","title":"Start a service with volumes","items":[{"url":"#syntax-differences-for-services","title":"SYNTAX DIFFERENCES FOR SERVICES"}]},{"url":"#populate-a-volume-using-a-container","title":"Populate a volume using a container"}]},{"url":"#use-a-read-only-volume","title":"Use a read-only volume"},{"url":"#use-a-volume-driver","title":"Use a volume driver","items":[{"url":"#initial-set-up","title":"Initial set-up"},{"url":"#create-a-volume-using-a-volume-driver","title":"Create a volume using a volume driver"},{"url":"#start-a-container-which-creates-a-volume-using-a-volume-driver","title":"Start a container which creates a volume using a volume driver"}]},{"url":"#next-steps-9","title":"Next steps"}]},{"url":"#use-bind-mounts","title":"Use bind mounts","items":[{"url":"#choosing-the--v-or---mount-flag","title":"Choosing the -v or --mount flag","items":[{"url":"#differences-between--v-and---mount-behavior-1","title":"Differences between -v and --mount behavior"}]},{"url":"#start-a-container-with-a-bind-mount","title":"Start a container with a bind mount","items":[{"url":"#mounting-into-a-non-empty-directory-on-the-container","title":"Mounting into a non-empty directory on the container"}]},{"url":"#use-a-read-only-bind-mount","title":"Use a read-only bind mount"},{"url":"#configure-bind-propagation","title":"Configure bind propagation"},{"url":"#configure-the-selinux-label","title":"Configure the selinux label"},{"url":"#configure-mount-consistency-for-macos","title":"Configure mount consistency for macOS"},{"url":"#next-steps-10","title":"Next steps"}]},{"url":"#use-tmpfs-mounts","title":"Use tmpfs mounts","items":[{"url":"#choosing-the---tmpfs-or---mount-flag","title":"Choosing the --tmpfs or --mount flag","items":[{"url":"#differences-between---tmpfs-and---mount-behavior","title":"Differences between --tmpfs and --mount behavior"}]},{"url":"#limitations-of-tmpfs-containers","title":"Limitations of tmpfs containers"},{"url":"#use-a-tmpfs-mount-in-a-container","title":"Use a tmpfs mount in a container","items":[{"url":"#specify-tmpfs-options","title":"Specify tmpfs options"}]},{"url":"#next-steps-11","title":"Next steps"}]},{"url":"#troubleshoot-volume-errors","title":"Troubleshoot volume errors","items":[{"url":"#error-unable-to-remove-filesystem","title":"Error: Unable to remove filesystem"}]},{"url":"#store-data-within-containers","title":"Store Data within Containers","items":[{"url":"#about-storage-drivers","title":"About storage drivers","items":[{"url":"#images-and-layers","title":"Images and layers"},{"url":"#container-and-layers","title":"Container and layers"},{"url":"#container-size-on-disk","title":"Container size on disk"},{"url":"#the-copy-on-write-cow-strategy","title":"The copy-on-write (CoW) strategy","items":[{"url":"#sharing-promotes-smaller-images","title":"Sharing promotes smaller images"},{"url":"#copying-makes-containers-efficient","title":"Copying makes containers efficient"}]},{"url":"#data-volumes-and-the-storage-driver","title":"Data volumes and the storage driver"},{"url":"#related-information","title":"Related information"}]},{"url":"#docker-storage-drivers","title":"Docker storage drivers","items":[{"url":"#supported-storage-drivers-per-linux-distribution","title":"Supported storage drivers per Linux distribution","items":[{"url":"#docker-ee-and-cs-engine","title":"Docker EE and CS-Engine"},{"url":"#docker-ce","title":"Docker CE"},{"url":"#docker-for-mac-and-docker-for-windows","title":"Docker for Mac and Docker for Windows"}]},{"url":"#supported-backing-filesystems","title":"Supported backing filesystems"},{"url":"#other-considerations","title":"Other considerations","items":[{"url":"#suitability-for-your-workload","title":"Suitability for your workload"},{"url":"#shared-storage-systems-and-the-storage-driver","title":"Shared storage systems and the storage driver"},{"url":"#stability","title":"Stability"},{"url":"#experience-and-expertise","title":"Experience and expertise"},{"url":"#test-with-your-own-workloads","title":"Test with your own workloads"}]},{"url":"#check-your-current-storage-driver","title":"Check your current storage driver"},{"url":"#related-information-1","title":"Related information"}]},{"url":"#use-the-aufs-storage-driver","title":"Use the AUFS storage driver","items":[{"url":"#prerequisites-9","title":"Prerequisites"},{"url":"#configure-docker-with-the-aufs-storage-driver","title":"Configure Docker with the aufs storage driver"},{"url":"#how-the-aufs-storage-driver-works","title":"How the aufs storage driver works","items":[{"url":"#example-image-and-container-on-disk-constructs","title":"Example: Image and container on-disk constructs","items":[{"url":"#the-image-layers","title":"THE IMAGE LAYERS"},{"url":"#the-container-layer","title":"THE CONTAINER LAYER"}]}]},{"url":"#how-container-reads-and-writes-work-with-aufs","title":"How container reads and writes work with aufs","items":[{"url":"#reading-files","title":"Reading files"},{"url":"#modifying-files-or-directories","title":"Modifying files or directories"}]},{"url":"#aufs-and-docker-performance","title":"AUFS and Docker performance","items":[{"url":"#performance-best-practices","title":"Performance best practices"}]},{"url":"#related-information-2","title":"Related information"}]},{"url":"#use-the-btrfs-storage-driver","title":"Use the BTRFS storage driver","items":[{"url":"#prerequisites-10","title":"Prerequisites"},{"url":"#configure-docker-to-use-the-btrfs-storage-driver","title":"Configure Docker to use the btrfs storage driver"},{"url":"#manage-a-btrfs-volume","title":"Manage a Btrfs volume"},{"url":"#how-the-btrfs-storage-driver-works","title":"How the btrfs storage driver works","items":[{"url":"#image-and-container-layers-on-disk","title":"Image and container layers on-disk"}]},{"url":"#how-container-reads-and-writes-work-with-btrfs","title":"How container reads and writes work with btrfs","items":[{"url":"#reading-files-1","title":"Reading files"},{"url":"#writing-files","title":"Writing files"}]},{"url":"#btrfs-and-docker-performance","title":"Btrfs and Docker performance"},{"url":"#related-information-3","title":"Related Information"}]},{"url":"#use-the-device-mapper-storage-driver","title":"Use the Device Mapper storage driver","items":[{"url":"#prerequisites-11","title":"Prerequisites"},{"url":"#configure-docker-with-the-devicemapper-storage-driver","title":"Configure Docker with the devicemapper storage driver","items":[{"url":"#configure-loop-lvm-mode-for-testing","title":"Configure loop-lvm mode for testing"},{"url":"#configure-direct-lvm-mode-for-production","title":"Configure direct-lvm mode for production","items":[{"url":"#allow-docker-to-configure-direct-lvm-mode","title":"ALLOW DOCKER TO CONFIGURE DIRECT-LVM MODE"},{"url":"#configure-direct-lvm-mode-manually","title":"CONFIGURE DIRECT-LVM MODE MANUALLY"}]}]},{"url":"#manage-devicemapper","title":"Manage devicemapper","items":[{"url":"#monitor-the-thin-pool","title":"Monitor the thin pool"},{"url":"#increase-capacity-on-a-running-device","title":"Increase capacity on a running device","items":[{"url":"#resize-a-loop-lvm-thin-pool","title":"RESIZE A LOOP-LVM THIN POOL"},{"url":"#resize-a-direct-lvm-thin-pool","title":"RESIZE A DIRECT-LVM THIN POOL"}]},{"url":"#activate-the-devicemapper-after-reboot","title":"Activate the devicemapper after reboot"}]},{"url":"#how-the-devicemapper-storage-driver-works","title":"How the devicemapper storage driver works","items":[{"url":"#image-and-container-layers-on-disk-1","title":"Image and container layers on-disk"},{"url":"#image-layering-and-sharing","title":"Image layering and sharing","items":[{"url":"#snapshots","title":"SNAPSHOTS"},{"url":"#devicemapper-workflow","title":"DEVICEMAPPER WORKFLOW"}]}]},{"url":"#how-container-reads-and-writes-work-with-devicemapper","title":"How container reads and writes work with devicemapper","items":[{"url":"#reading-files-2","title":"Reading files"},{"url":"#writing-files-1","title":"Writing files"}]},{"url":"#device-mapper-and-docker-performance","title":"Device Mapper and Docker performance","items":[{"url":"#performance-best-practices-1","title":"Performance best practices"}]},{"url":"#related-information-4","title":"Related Information"}]},{"url":"#use-the-overlayfs-storage-driver","title":"Use the OverlayFS storage driver","items":[{"url":"#prerequisites-12","title":"Prerequisites"},{"url":"#configure-docker-with-the-overlay-or-overlay2storage-driver","title":"Configure Docker with the overlay or overlay2storage driver"},{"url":"#how-the-overlay2-driver-works","title":"How the overlay2 driver works","items":[{"url":"#image-and-container-layers-on-disk-2","title":"Image and container layers on-disk"}]},{"url":"#how-the-overlay-driver-works","title":"How the overlay driver works","items":[{"url":"#image-and-container-layers-on-disk-3","title":"Image and container layers on-disk","items":[{"url":"#the-image-layers-1","title":"THE IMAGE LAYERS"},{"url":"#the-container-layer-1","title":"THE CONTAINER LAYER"}]}]},{"url":"#how-container-reads-and-writes-work-with-overlayor-overlay2","title":"How container reads and writes work with overlayor overlay2","items":[{"url":"#reading-files-3","title":"Reading files"},{"url":"#modifying-files-or-directories-1","title":"Modifying files or directories"}]},{"url":"#overlayfs-and-docker-performance","title":"OverlayFS and Docker Performance","items":[{"url":"#performance-best-practices-2","title":"Performance best practices"}]},{"url":"#limitations-on-overlayfs-compatibility","title":"Limitations on OverlayFS compatibility"}]},{"url":"#use-the-zfs-storage-driver","title":"Use the ZFS storage driver","items":[{"url":"#prerequisites-13","title":"Prerequisites"},{"url":"#configure-docker-with-the-zfs-storage-driver","title":"Configure Docker with the zfs storage driver"},{"url":"#manage-zfs","title":"Manage zfs","items":[{"url":"#increase-capacity-on-a-running-device-1","title":"Increase capacity on a running device"},{"url":"#limit-a-containers-writable-storage-quota","title":"Limit a container's writable storage quota"}]},{"url":"#how-the-zfs-storage-driver-works","title":"How the zfs storage driver works","items":[{"url":"#image-and-container-layers-on-disk-4","title":"Image and container layers on-disk"},{"url":"#image-layering-and-sharing-1","title":"Image layering and sharing"}]},{"url":"#how-container-reads-and-writes-work-with-zfs","title":"How container reads and writes work with zfs","items":[{"url":"#reading-files-4","title":"Reading files"},{"url":"#writing-files-2","title":"Writing files"}]},{"url":"#zfs-and-docker-performance","title":"ZFS and Docker performance","items":[{"url":"#performance-best-practices-3","title":"Performance best practices"}]}]},{"url":"#use-the-vfs-storage-driver","title":"Use the VFS storage driver","items":[{"url":"#configure-docker-with-the-vfs-storage-driver","title":"Configure Docker with the vfs storage driver"},{"url":"#how-the-vfs-storage-driver-works","title":"How the vfs storage driver works","items":[{"url":"#example-image-and-container-on-disk-constructs-1","title":"Example: Image and container on-disk constructs"}]},{"url":"#related-information-5","title":"Related information"},{"url":"#run-your-app-in-production","title":"Run Your App in Production"}]}]},{"url":"#configure-all-objects","title":"Configure All Objects","items":[{"url":"#docker-object-labels","title":"Docker object labels","items":[{"url":"#label-keys-and-values","title":"Label keys and values","items":[{"url":"#key-format-recommendations","title":"Key format recommendations"},{"url":"#value-guidelines","title":"Value guidelines"}]},{"url":"#manage-labels-on-objects","title":"Manage labels on objects"}]},{"url":"#prune-unused-docker-objects","title":"Prune unused Docker objects","items":[{"url":"#prune-images","title":"Prune images"},{"url":"#prune-containers","title":"Prune containers"},{"url":"#prune-volumes","title":"Prune volumes"},{"url":"#prune-networks","title":"Prune networks"},{"url":"#prune-everything","title":"Prune everything"}]},{"url":"#format-command-and-log-output","title":"Format command and log output","items":[{"url":"#join","title":"join"},{"url":"#json","title":"json"},{"url":"#lower","title":"lower"},{"url":"#split","title":"split"},{"url":"#title","title":"title"},{"url":"#upper","title":"upper"},{"url":"#println","title":"println"}]}]},{"url":"#configure-the-daemon","title":"Configure the Daemon","items":[{"url":"#configure-and-troubleshoot-the-docker-daemon","title":"Configure and troubleshoot the Docker daemon","items":[{"url":"#start-the-daemon-using-operating-system-utilities","title":"Start the daemon using operating system utilities"},{"url":"#start-the-daemon-manually","title":"Start the daemon manually"},{"url":"#configure-the-docker-daemon","title":"Configure the Docker daemon","items":[{"url":"#troubleshoot-conflicts-between-the-daemonjson-and-startup-scripts","title":"Troubleshoot conflicts between the daemon.json and startup scripts","items":[{"url":"#use-the-hosts-key-in-daemonjson-with-systemd","title":"USE THE HOSTS KEY IN DAEMON.JSON WITH SYSTEMD"}]}]},{"url":"#troubleshoot-the-daemon","title":"Troubleshoot the daemon","items":[{"url":"#out-of-memory-exceptions-oome","title":"Out Of Memory Exceptions (OOME)"},{"url":"#read-the-logs","title":"Read the logs"},{"url":"#enable-debugging","title":"Enable debugging"},{"url":"#force-a-stack-trace-to-be-logged","title":"Force a stack trace to be logged"},{"url":"#view-stack-traces","title":"View stack traces"}]},{"url":"#check-whether-docker-is-running","title":"Check whether Docker is running"}]},{"url":"#control-docker-with-systemd","title":"Control Docker with systemd","items":[{"url":"#start-the-docker-daemon","title":"Start the Docker daemon","items":[{"url":"#start-manually","title":"Start manually"},{"url":"#start-automatically-at-system-boot","title":"Start automatically at system boot"}]},{"url":"#custom-docker-daemon-options","title":"Custom Docker daemon options","items":[{"url":"#runtime-directory-and-storage-driver","title":"Runtime directory and storage driver"},{"url":"#httphttps-proxy","title":"HTTP/HTTPS proxy"}]},{"url":"#configure-where-the-docker-daemon-listens-for-connections-1","title":"Configure where the Docker daemon listens for connections"},{"url":"#manually-create-the-systemd-unit-files","title":"Manually create the systemd unit files"}]},{"url":"#collect-docker-metrics-with-prometheus","title":"Collect Docker metrics with Prometheus","items":[{"url":"#configure-docker","title":"Configure Docker"},{"url":"#configure-and-run-prometheus","title":"Configure and run Prometheus"}]}]}]},{"url":"#my-global-config","title":"my global config"},{"url":"#scrape_timeout-is-set-to-the-global-default-10s","title":"scrape_timeout is set to the global default (10s)."},{"url":"#attach-these-labels-to-any-time-series-or-alerts-when-communicating-with","title":"Attach these labels to any time series or alerts when communicating with"},{"url":"#external-systems-federation-remote-storage-alertmanager","title":"external systems (federation, remote storage, Alertmanager)."},{"url":"#load-rules-once-and-periodically-evaluate-them-according-to-the-global-evaluation_interval","title":"Load rules once and periodically evaluate them according to the global \\'evaluation_interval\\'."},{"url":"#--firstrules","title":"- \"first.rules\""},{"url":"#--secondrules","title":"- \"second.rules\""},{"url":"#a-scrape-configuration-containing-exactly-one-endpoint-to-scrape","title":"A scrape configuration containing exactly one endpoint to scrape:"},{"url":"#here-its-prometheus-itself","title":"Here it\\'s Prometheus itself."},{"url":"#the-job-name-is-added-as-a-label-jobjob_name-to-any-timeseries-scraped-from-this-config","title":"The job name is added as a label job=<job_name>`` to any timeseries scraped from this config."},{"url":"#metrics_path-defaults-to-metrics","title":"metrics_path defaults to \\'/metrics\\'"},{"url":"#scheme-defaults-to-http","title":"scheme defaults to \\'http\\'."},{"url":"#metrics_path-defaults-to-metrics-1","title":"metrics_path defaults to \\'/metrics\\'"},{"url":"#scheme-defaults-to-http-1","title":"scheme defaults to \\'http\\'.","items":[{"items":[{"items":[{"url":"#use-prometheus","title":"Use Prometheus"},{"url":"#next-steps-12","title":"Next steps"}]}]},{"url":"#configure-containers","title":"Configure Containers","items":[{"url":"#start-containers-automatically","title":"Start containers automatically","items":[{"url":"#use-a-restart-policy","title":"Use a restart policy","items":[{"url":"#restart-policy-details","title":"Restart policy details"}]},{"url":"#use-a-process-manager","title":"Use a process manager","items":[{"url":"#using-a-process-manager-inside-containers","title":"Using a process manager inside containers"}]}]},{"url":"#keep-containers-alive-during-daemon-downtime","title":"Keep containers alive during daemon downtime","items":[{"url":"#enable-live-restore","title":"Enable live restore"},{"url":"#live-restore-during-upgrades","title":"Live restore during upgrades"},{"url":"#live-restore-upon-restart","title":"Live restore upon restart"},{"url":"#impact-of-live-restore-on-running-containers","title":"Impact of live restore on running containers"},{"url":"#live-restore-and-swarm-mode","title":"Live restore and swarm mode"}]},{"url":"#run-multiple-services-in-a-container","title":"Run multiple services in a container"},{"url":"#runtime-metrics","title":"Runtime metrics","items":[{"url":"#docker-stats","title":"Docker stats"},{"url":"#control-groups-1","title":"Control groups","items":[{"url":"#enumerate-cgroups","title":"Enumerate cgroups"},{"url":"#find-the-cgroup-for-a-given-container","title":"Find the cgroup for a given container"},{"url":"#metrics-from-cgroups-memory-cpu-block-io","title":"Metrics from cgroups: memory, CPU, block I/O","items":[{"url":"#memory-metrics-memorystat","title":"MEMORY METRICS: MEMORY.STAT"}]},{"url":"#cpu-metrics-cpuacctstat","title":"CPU metrics: cpuacct.stat","items":[{"url":"#block-io-metrics","title":"BLOCK I/O METRICS"}]},{"url":"#network-metrics","title":"Network metrics","items":[{"url":"#iptables","title":"IPTABLES"},{"url":"#interface-level-counters","title":"INTERFACE-LEVEL COUNTERS"}]}]},{"url":"#tips-for-high-performance-metric-collection","title":"Tips for high-performance metric collection"},{"url":"#collect-metrics-when-a-container-exits","title":"Collect metrics when a container exits"}]},{"url":"#limit-a-containers-resources","title":"Limit a container\\'s resources","items":[{"url":"#memory","title":"Memory","items":[{"url":"#understand-the-risks-of-running-out-of-memory","title":"Understand the risks of running out of memory"},{"url":"#limit-a-containers-access-to-memory","title":"Limit a container's access to memory"},{"url":"#--memory-swap-details","title":"--memory-swap details","items":[{"url":"#prevent-a-container-from-using-swap","title":"PREVENT A CONTAINER FROM USING SWAP"}]},{"url":"#--memory-swappiness-details","title":"--memory-swappiness details"},{"url":"#--kernel-memory-details","title":"--kernel-memory details"}]},{"url":"#cpu","title":"CPU","items":[{"url":"#configure-the-default-cfs-scheduler","title":"Configure the default CFS scheduler"},{"url":"#configure-the-realtime-scheduler","title":"Configure the realtime scheduler","items":[{"url":"#configure-the-host-machines-kernel","title":"CONFIGURE THE HOST MACHINE'S KERNEL"},{"url":"#configure-the-docker-daemon-1","title":"CONFIGURE THE DOCKER DAEMON"},{"url":"#configure-individual-containers","title":"CONFIGURE INDIVIDUAL CONTAINERS"}]}]}]},{"url":"#logging","title":"Logging","items":[{"url":"#view-logs-for-a-container-or-service","title":"View logs for a container or service","items":[{"url":"#next-steps-13","title":"Next steps"}]},{"url":"#configure-logging-drivers","title":"Configure logging drivers","items":[{"url":"#configure-the-default-logging-driver","title":"Configure the default logging driver"},{"url":"#configure-the-logging-driver-for-a-container","title":"Configure the logging driver for a container"},{"url":"#configure-the-delivery-mode-of-log-messages-from-container-to-log-driver","title":"Configure the delivery mode of log messages from container to log driver","items":[{"url":"#use-environment-variables-or-labels-with-logging-drivers","title":"Use environment variables or labels with logging drivers"}]},{"url":"#supported-logging-drivers","title":"Supported logging drivers"},{"url":"#limitations-of-logging-drivers","title":"Limitations of logging drivers"}]},{"url":"#use-a-logging-driver-plugin","title":"Use a logging driver plugin","items":[{"url":"#install-the-logging-driver-plugin","title":"Install the logging driver plugin"},{"url":"#configure-the-plugin-as-the-default-logging-driver","title":"Configure the plugin as the default logging driver"},{"url":"#configure-a-container-to-use-the-plugin-as-the-logging-driver","title":"Configure a container to use the plugin as the logging driver"}]},{"url":"#customize-log-driver-output","title":"Customize log driver output"},{"url":"#logging-driver-details","title":"Logging Driver Details","items":[{"url":"#logentries-logging-driver","title":"Logentries logging driver","items":[{"url":"#usage-1","title":"Usage"},{"url":"#options","title":"Options"}]}]},{"url":"#json-file-logging-driver","title":"JSON File logging driver","items":[{"url":"#usage-2","title":"Usage","items":[{"url":"#options-1","title":"Options"},{"url":"#examples","title":"Examples"}]}]},{"url":"#graylog-extended-format-logging-driver","title":"Graylog Extended Format logging driver","items":[{"url":"#usage-3","title":"Usage","items":[{"url":"#gelf-options","title":"GELF options"},{"url":"#examples-1","title":"Examples"}]}]},{"url":"#syslog-logging-driver","title":"Syslog logging driver","items":[{"url":"#usage-4","title":"Usage"},{"url":"#options-2","title":"Options"}]},{"url":"#amazon-cloudwatch-logs-logging-driver","title":"Amazon CloudWatch Logs logging driver","items":[{"url":"#usage-5","title":"Usage"},{"url":"#amazon-cloudwatch-logs-options","title":"Amazon CloudWatch Logs options","items":[{"url":"#awslogs-region","title":"awslogs-region"},{"url":"#awslogs-group","title":"awslogs-group"},{"url":"#awslogs-stream","title":"awslogs-stream"},{"url":"#awslogs-create-group","title":"awslogs-create-group"},{"url":"#awslogs-datetime-format","title":"awslogs-datetime-format"}]}]}]}]}]},{"url":"#first-event","title":"First event"},{"url":"#second-event","title":"Second event"},{"url":"#third-event","title":"Third event","items":[{"items":[{"items":[{"items":[{"items":[{"url":"#awslogs-multiline-pattern","title":"awslogs-multiline-pattern"}]}]}]}]}]},{"url":"#first-event-1","title":"First event"},{"url":"#second-event-1","title":"Second event"},{"url":"#third-event-1","title":"Third event","items":[{"items":[{"items":[{"items":[{"items":[{"url":"#tag","title":"tag"}]},{"url":"#credentials","title":"Credentials"}]},{"url":"#etw-logging-driver","title":"ETW logging driver","items":[{"url":"#usage-6","title":"Usage"}]},{"url":"#fluentd-logging-driver","title":"Fluentd logging driver","items":[{"url":"#usage-7","title":"Usage"},{"url":"#options-3","title":"Options","items":[{"url":"#fluentd-address","title":"fluentd-address"},{"url":"#tag-1","title":"tag"},{"url":"#labels-env-and-env-regex","title":"labels, env, and env-regex"},{"url":"#fluentd-async-connect","title":"fluentd-async-connect"},{"url":"#fluentd-buffer-limit","title":"fluentd-buffer-limit"},{"url":"#fluentd-retry-wait","title":"fluentd-retry-wait"},{"url":"#fluentd-max-retries","title":"fluentd-max-retries"},{"url":"#fluentd-sub-second-precision","title":"fluentd-sub-second-precision"}]},{"url":"#fluentd-daemon-management-with-docker","title":"Fluentd daemon management with Docker","items":[{"url":"#test-container-loggers","title":"Test container loggers"}]}]},{"url":"#google-cloud-logging-driver","title":"Google Cloud Logging driver","items":[{"url":"#usage-8","title":"Usage"},{"url":"#gcplogs-options","title":"gcplogs options"}]},{"url":"#journald-logging-driver","title":"Journald logging driver","items":[{"url":"#usage-9","title":"Usage"},{"url":"#options-4","title":"Options"},{"url":"#note-regarding-container-names","title":"Note regarding container names"},{"url":"#retrieve-log-messages-with-journalctl","title":"Retrieve log messages with journalctl","items":[{"url":"#view-logs-for-a-container-with-a-tty-enabled","title":"View logs for a container with a TTY enabled"}]},{"url":"#retrieve-log-messages-with-the-journal-api","title":"Retrieve log messages with the journal API"}]},{"url":"#splunk-logging-driver","title":"Splunk logging driver","items":[{"url":"#usage-10","title":"Usage"},{"url":"#splunk-options","title":"Splunk options","items":[{"url":"#message-formats","title":"Message formats"}]},{"url":"#advanced-options","title":"Advanced options"}]}]},{"url":"#registry-as-a-pull-through-cache","title":"Registry as a pull through cache","items":[{"url":"#use-case","title":"Use-case","items":[{"url":"#alternatives","title":"Alternatives"},{"url":"#gotcha","title":"Gotcha"},{"url":"#solution","title":"Solution"}]},{"url":"#how-does-it-work","title":"How does it work?","items":[{"url":"#what-if-the-content-changes-on-the-hub","title":"What if the content changes on the Hub?"},{"url":"#what-about-my-disk","title":"What about my disk?"}]},{"url":"#run-a-registry-as-a-pull-through-cache","title":"Run a Registry as a pull-through cache","items":[{"url":"#configure-the-cache","title":"Configure the cache"},{"url":"#configure-the-docker-daemon-2","title":"Configure the Docker daemon"}]},{"url":"#use-case-the-china-registry-mirror","title":"Use case: the China registry mirror"}]},{"url":"#work-with-external-tools","title":"Work with external tools","items":[{"url":"#use-powershell-dsc","title":"Use PowerShell DSC","items":[{"url":"#requirements","title":"Requirements"},{"url":"#installation","title":"Installation"},{"url":"#usage-11","title":"Usage","items":[{"url":"#install-docker","title":"Install Docker"},{"url":"#images-1","title":"Images"},{"url":"#containers-1","title":"Containers"}]}]},{"url":"#chef","title":"Chef","items":[{"url":"#docker-cookbook","title":"Docker Cookbook","items":[{"url":"#scope-1","title":"Scope"},{"url":"#requirements-1","title":"Requirements"},{"url":"#platform-support","title":"Platform Support"},{"url":"#cookbook-dependencies","title":"Cookbook Dependencies"},{"url":"#docker-group","title":"Docker Group"},{"url":"#usage-12","title":"Usage"},{"url":"#test-cookbooks-as-examples","title":"Test Cookbooks as Examples"},{"url":"#resources-overview","title":"Resources Overview"},{"url":"#getting-started","title":"Getting Started"}]}]}]}]}]},{"url":"#pull-latest-image","title":"Pull latest image"},{"url":"#run-container-mapping-containers-port-80-to-the-hosts-port-80","title":"Run container mapping containers port 80 to the host\\'s port 80"},{"url":"#login-to-private-registry","title":"Login to private registry"},{"url":"#pull-tagged-image","title":"Pull tagged image"},{"url":"#run-container","title":"Run container","items":[{"items":[{"items":[{"items":[{"items":[{"url":"#resources","title":"Resources"},{"url":"#docker_installation","title":"docker_installation"},{"url":"#docker_installation_tarball","title":"docker_installation_tarball"},{"url":"#docker_installation_script","title":"docker_installation_script"},{"url":"#docker_installation_package","title":"docker_installation_package"},{"url":"#docker_service_manager","title":"docker_service_manager"},{"url":"#docker_service_manager_execute","title":"docker_service_manager_execute"},{"url":"#docker_service_manager_sysvinit","title":"docker_service_manager_sysvinit"},{"url":"#docker_service_manager_upstart","title":"docker_service_manager_upstart"},{"url":"#docker_service_manager_systemd","title":"docker_service_manager_systemd"},{"url":"#docker_service","title":"docker_service"},{"url":"#docker_image","title":"docker_image"},{"url":"#docker_tag","title":"docker_tag"},{"url":"#docker_container","title":"docker_container"},{"url":"#docker_registry","title":"docker_registry"},{"url":"#docker_network","title":"docker_network"},{"url":"#docker_volume","title":"docker_volume"},{"url":"#docker_execute","title":"docker_execute"},{"url":"#maintainers","title":"Maintainers"},{"url":"#license","title":"License"}]}]}]},{"url":"#security","title":"Security","items":[{"url":"#docker-security","title":"Docker security","items":[{"url":"#kernel-namespaces","title":"Kernel namespaces"},{"url":"#control-groups-2","title":"Control groups"},{"url":"#docker-daemon-attack-surface","title":"Docker daemon attack surface"},{"url":"#linux-kernel-capabilities","title":"Linux kernel capabilities"},{"url":"#other-kernel-security-features","title":"Other kernel security features"},{"url":"#conclusions","title":"Conclusions"},{"url":"#related-information-6","title":"Related information"}]},{"url":"#docker-security-non-events","title":"Docker security non-events"},{"url":"#protect-the-docker-daemon-socket","title":"Protect the Docker daemon socket","items":[{"url":"#create-a-ca-server-and-client-keys-with-openssl","title":"Create a CA, server and client keys with OpenSSL"},{"url":"#secure-by-default","title":"Secure by default"},{"url":"#other-modes","title":"Other modes","items":[{"url":"#daemon-modes","title":"Daemon modes"},{"url":"#client-modes","title":"Client modes"},{"url":"#connecting-to-the-secure-docker-port-using-curl","title":"Connecting to the secure Docker port using curl"}]},{"url":"#related-information-7","title":"Related information"}]},{"url":"#verify-repository-client-with-certificates","title":"Verify repository client with certificates","items":[{"url":"#understanding-the-configuration","title":"Understanding the configuration"},{"url":"#creating-the-client-certificates","title":"Creating the client certificates"},{"url":"#troubleshooting-tips","title":"Troubleshooting tips"},{"url":"#related-information-8","title":"Related Information"}]},{"url":"#use-trusted-images","title":"Use Trusted Images","items":[{"url":"#content-trust-in-docker","title":"Content trust in Docker","items":[{"url":"#about-trust-in-docker","title":"About trust in Docker"},{"url":"#survey-of-typical-content-trust-operations","title":"Survey of typical content trust operations"},{"url":"#related-information-9","title":"Related information"}]},{"url":"#automation-with-content-trust","title":"Automation with content trust","items":[{"url":"#bypass-requests-for-passphrases","title":"Bypass requests for passphrases"},{"url":"#building-with-content-trust","title":"Building with content trust"},{"url":"#related-information-10","title":"Related information"}]},{"url":"#delegations-for-content-trust","title":"Delegations for content trust","items":[{"url":"#generating-delegation-keys","title":"Generating delegation keys"},{"url":"#adding-a-delegation-key-to-an-existing-repository","title":"Adding a delegation key to an existing repository"},{"url":"#removing-a-delegation-key-from-an-existing-repository","title":"Removing a delegation key from an existing repository"},{"url":"#removing-the-targetsreleases-delegation-entirely-from-a-repository","title":"Removing the targets/releases delegation entirely from a repository"},{"url":"#pushing-trusted-data-as-a-collaborator","title":"Pushing trusted data as a collaborator"},{"url":"#docker-push-behavior","title":"docker push behavior"},{"url":"#docker-pull-and-docker-build-behavior","title":"docker pull and docker build behavior"},{"url":"#related-information-11","title":"Related information"}]},{"url":"#deploy-notary-server-with-compose","title":"Deploy Notary Server with Compose","items":[{"url":"#if-you-want-to-use-notary-in-production","title":"If you want to use Notary in production"}]},{"url":"#manage-keys-for-content-trust","title":"Manage keys for content trust","items":[{"url":"#choosing-a-passphrase","title":"Choosing a passphrase"},{"url":"#back-up-your-keys","title":"Back up your keys"},{"url":"#hardware-storage-and-signing","title":"Hardware storage and signing"},{"url":"#lost-keys","title":"Lost keys"},{"url":"#related-information-12","title":"Related information"}]},{"url":"#play-in-a-content-trust-sandbox","title":"Play in a content trust sandbox","items":[{"url":"#what-is-in-the-sandbox","title":"What is in the sandbox?"},{"url":"#build-the-sandbox","title":"Build the sandbox"},{"url":"#playing-in-the-sandbox","title":"Playing in the sandbox"},{"url":"#more-play-in-the-sandbox","title":"More play in the sandbox"},{"url":"#cleaning-up-your-sandbox","title":"Cleaning up your sandbox"}]}]},{"url":"#antivirus-software-and-docker","title":"Antivirus software and Docker"},{"url":"#apparmor-security-profiles-for-docker","title":"AppArmor security profiles for Docker","items":[{"url":"#understand-the-policies","title":"Understand the policies"},{"url":"#load-and-unload-profiles","title":"Load and unload profiles"}]}]}]}]},{"url":"#stop-apparmor","title":"stop apparmor"},{"url":"#unload-the-profile","title":"unload the profile"},{"url":"#start-apparmor","title":"start apparmor","items":[{"items":[{"items":[{"items":[{"items":[{"url":"#resources-for-writing-profiles","title":"Resources for writing profiles"}]},{"url":"#nginx-example-profile","title":"Nginx example profile"}]}]}]}]},{"url":"#deny-write-to-files-not-in-procnumber-or-procsys","title":"deny write to files not in /proc/<number>/ or /proc/sys/","items":[{"items":[{"items":[{"items":[{"url":"#debug-apparmor","title":"Debug AppArmor","items":[{"url":"#use-dmesg","title":"Use dmesg"},{"url":"#use-aa-status","title":"Use aa-status"}]},{"url":"#contribute-dockers-apparmor-code","title":"Contribute Docker's AppArmor code"}]},{"url":"#seccomp-security-profiles-for-docker","title":"Seccomp security profiles for Docker","items":[{"url":"#pass-a-profile-for-a-container","title":"Pass a profile for a container","items":[{"url":"#significant-syscalls-blocked-by-the-default-profile","title":"Significant syscalls blocked by the default profile"}]},{"url":"#run-without-the-default-seccomp-profile","title":"Run without the default seccomp profile"}]},{"url":"#isolate-containers-with-a-user-namespace","title":"Isolate containers with a user namespace","items":[{"url":"#about-remapping-and-subordinate-user-and-group-ids","title":"About remapping and subordinate user and group IDs"},{"url":"#prerequisites-14","title":"Prerequisites"},{"url":"#enable-userns-remap-on-the-daemon","title":"Enable userns-remap on the daemon"},{"url":"#disable-namespace-remapping-for-a-container","title":"Disable namespace remapping for a container"},{"url":"#user-namespace-known-limitations","title":"User namespace known limitations"}]}]},{"url":"#scale-your-app","title":"Scale Your App","items":[{"url":"#swarm-mode-overview","title":"Swarm mode overview","items":[{"url":"#feature-highlights","title":"Feature highlights"},{"url":"#whats-next","title":"What's next?","items":[{"url":"#swarm-mode-key-concepts-and-tutorial","title":"Swarm mode key concepts and tutorial"},{"url":"#swarm-mode-cli-commands","title":"Swarm mode CLI commands"}]}]},{"url":"#swarm-mode-key-concepts","title":"Swarm mode key concepts","items":[{"url":"#what-is-a-swarm","title":"What is a swarm?"},{"url":"#nodes","title":"Nodes"},{"url":"#services-and-tasks","title":"Services and tasks"},{"url":"#load-balancing","title":"Load balancing"},{"url":"#whats-next-1","title":"What's next?"}]},{"url":"#getting-started-with-swarm-mode","title":"Getting started with swarm mode","items":[{"url":"#set-up","title":"Set up","items":[{"url":"#three-networked-host-machines","title":"Three networked host machines"},{"url":"#docker-engine-112-or-newer","title":"Docker Engine 1.12 or newer"},{"url":"#the-ip-address-of-the-manager-machine","title":"The IP address of the manager machine"},{"url":"#open-protocols-and-ports-between-the-hosts","title":"Open protocols and ports between the hosts"}]},{"url":"#whats-next-2","title":"What's next?"}]},{"url":"#create-a-swarm","title":"Create a swarm","items":[{"url":"#whats-next-3","title":"What's next?"}]},{"url":"#add-nodes-to-the-swarm","title":"Add nodes to the swarm","items":[{"url":"#whats-next-4","title":"What's next?"}]},{"url":"#deploy-a-service-to-the-swarm","title":"Deploy a service to the swarm","items":[{"url":"#whats-next-5","title":"What's next?"}]},{"url":"#inspect-a-service-on-the-swarm","title":"Inspect a service on the swarm","items":[{"url":"#whats-next-6","title":"What's next?"}]},{"url":"#scale-the-service-in-the-swarm","title":"Scale the service in the swarm","items":[{"url":"#whats-next-7","title":"What's next?"}]},{"url":"#delete-the-service-running-on-the-swarm","title":"Delete the service running on the swarm","items":[{"url":"#whats-next-8","title":"What's next?"}]},{"url":"#apply-rolling-updates-to-a-service","title":"Apply rolling updates to a service","items":[{"url":"#whats-next-9","title":"What's next?"}]},{"url":"#drain-a-node-on-the-swarm","title":"Drain a node on the swarm","items":[{"url":"#whats-next-10","title":"What's next?"}]},{"url":"#use-swarm-mode-routing-mesh","title":"Use swarm mode routing mesh","items":[{"url":"#publish-a-port-for-a-service","title":"Publish a port for a service","items":[{"url":"#publish-a-port-for-tcp-only-or-udp-only","title":"Publish a port for TCP only or UDP only"}]},{"url":"#bypass-the-routing-mesh","title":"Bypass the routing mesh"},{"url":"#configure-an-external-load-balancer","title":"Configure an external load balancer","items":[{"url":"#using-the-routing-mesh","title":"Using the routing mesh"}]}]}]}]}]},{"url":"#configure-haproxy-to-listen-on-port-80","title":"Configure HAProxy to listen on port 80"},{"url":"#configure-haproxy-to-route-requests-to-swarm-nodes-on-port-8080","title":"Configure HAProxy to route requests to swarm nodes on port 8080","items":[{"items":[{"items":[{"items":[{"items":[{"url":"#without-the-routing-mesh","title":"Without the routing mesh"}]},{"url":"#learn-more","title":"Learn more"}]},{"url":"#how-swarm-mode-works","title":"How Swarm Mode Works","items":[{"url":"#how-nodes-work","title":"How nodes work","items":[{"url":"#manager-nodes","title":"Manager nodes"},{"url":"#worker-nodes","title":"Worker nodes"},{"url":"#change-roles","title":"Change roles"},{"url":"#learn-more-1","title":"Learn more"}]},{"url":"#how-services-work","title":"How services work","items":[{"url":"#services-tasks-and-containers","title":"Services, tasks, and containers"},{"url":"#tasks-and-scheduling","title":"Tasks and scheduling"},{"url":"#replicated-and-global-services","title":"Replicated and global services"},{"url":"#learn-more-2","title":"Learn more"}]},{"url":"#manage-swarm-security-with-public-key-infrastructure-pki","title":"Manage swarm security with public key infrastructure (PKI)","items":[{"url":"#rotating-the-ca-certificate","title":"Rotating the CA certificate"},{"url":"#learn-more-3","title":"Learn More"}]},{"url":"#swarm-task-states","title":"Swarm task states","items":[{"url":"#view-task-state","title":"View task state"},{"url":"#where-to-go-next","title":"Where to go next"}]}]},{"url":"#run-docker-engine-in-swarm-mode","title":"Run Docker Engine in swarm mode","items":[{"url":"#create-a-swarm-1","title":"Create a swarm","items":[{"url":"#configure-the-advertise-address","title":"Configure the advertise address"},{"url":"#view-the-join-command-or-update-a-swarm-join-token","title":"View the join command or update a swarm join token"}]},{"url":"#learn-more-4","title":"Learn more"}]},{"url":"#join-nodes-to-a-swarm","title":"Join nodes to a swarm","items":[{"url":"#join-as-a-worker-node","title":"Join as a worker node"},{"url":"#join-as-a-manager-node","title":"Join as a manager node"},{"url":"#learn-more-5","title":"Learn More"}]},{"url":"#manage-nodes-in-a-swarm","title":"Manage nodes in a swarm","items":[{"url":"#list-nodes","title":"List nodes"},{"url":"#inspect-an-individual-node","title":"Inspect an individual node"},{"url":"#update-a-node","title":"Update a node","items":[{"url":"#change-node-availability","title":"Change node availability"},{"url":"#add-or-remove-label-metadata","title":"Add or remove label metadata"},{"url":"#promote-or-demote-a-node","title":"Promote or demote a node"}]},{"url":"#install-plugins-on-swarm-nodes","title":"Install plugins on swarm nodes"},{"url":"#leave-the-swarm","title":"Leave the swarm"},{"url":"#learn-more-6","title":"Learn more"}]},{"url":"#deploy-services-to-a-swarm","title":"Deploy services to a swarm","items":[{"url":"#create-a-service","title":"Create a service","items":[{"url":"#create-a-service-using-an-image-on-a-private-registry","title":"Create a service using an image on a private registry"}]},{"url":"#update-a-service","title":"Update a service"},{"url":"#remove-a-service","title":"Remove a service"},{"url":"#service-configuration-details","title":"Service configuration details","items":[{"url":"#configure-the-runtime-environment","title":"Configure the runtime environment"},{"url":"#update-the-command-an-existing-service-runs","title":"Update the command an existing service runs"},{"url":"#specify-the-image-version-a-service-should-use","title":"Specify the image version a service should use"},{"url":"#update-a-services-image-after-creation","title":"Update a service's image after creation"},{"url":"#publish-ports-1","title":"Publish ports"},{"url":"#connect-the-service-to-an-overlay-network","title":"Connect the service to an overlay network"},{"url":"#grant-a-service-access-to-secrets","title":"Grant a service access to secrets"},{"url":"#customize-a-services-isolation-mode","title":"Customize a service's isolation mode"},{"url":"#control-service-placement","title":"Control service placement"},{"url":"#configure-a-services-update-behavior","title":"Configure a service's update behavior"},{"url":"#roll-back-to-the-previous-version-of-a-service","title":"Roll back to the previous version of a service"},{"url":"#automatically-roll-back-if-an-update-fails","title":"Automatically roll back if an update fails"},{"url":"#give-a-service-access-to-volumes-or-bind-mounts","title":"Give a service access to volumes or bind mounts"},{"url":"#create-services-using-templates","title":"Create services using templates"}]},{"url":"#learn-more-7","title":"Learn More"}]},{"url":"#store-configuration-data-using-docker-configs","title":"Store configuration data using Docker Configs","items":[{"url":"#about-configs","title":"About configs","items":[{"url":"#windows-support","title":"Windows support"}]},{"url":"#how-docker-manages-configs","title":"How Docker manages configs"},{"url":"#read-more-about-docker-config-commands","title":"Read more about docker config commands"},{"url":"#examples-2","title":"Examples","items":[{"url":"#defining-and-using-configs-in-compose-files","title":"Defining and using configs in compose files"},{"url":"#simple-example-get-started-with-configs","title":"Simple example: Get started with configs"},{"url":"#simple-example-use-configs-in-a-windows-service","title":"Simple example: Use configs in a Windows service"},{"url":"#advanced-example-use-configs-with-a-nginx-service","title":"Advanced example: Use configs with a Nginx service"},{"url":"#example-rotate-a-config","title":"Example: Rotate a config"}]}]},{"url":"#manage-sensitive-data-with-docker-secrets","title":"Manage sensitive data with Docker secrets","items":[{"url":"#about-secrets","title":"About secrets","items":[{"url":"#windows-support-1","title":"Windows support"}]},{"url":"#how-docker-manages-secrets","title":"How Docker manages secrets"},{"url":"#read-more-about-docker-secret-commands","title":"Read more about docker secret commands"},{"url":"#examples-3","title":"Examples","items":[{"url":"#defining-and-using-secrets-in-compose-files","title":"Defining and using secrets in compose files"},{"url":"#simple-example-get-started-with-secrets","title":"Simple example: Get started with secrets"},{"url":"#simple-example-use-secrets-in-a-windows-service","title":"Simple example: Use secrets in a Windows service"},{"url":"#intermediate-example-use-secrets-with-a-nginx-service","title":"Intermediate example: Use secrets with a Nginx service"},{"url":"#advanced-example-use-secrets-with-a-wordpress-service","title":"Advanced example: Use secrets with a WordPress service"},{"url":"#example-rotate-a-secret","title":"Example: Rotate a secret"}]},{"url":"#build-support-for-docker-secrets-into-your-images","title":"Build support for Docker Secrets into your images"},{"url":"#use-secrets-in-compose","title":"Use Secrets in Compose"}]},{"url":"#lock-your-swarm-to-protect-its-encryption-key","title":"Lock your swarm to protect its encryption key","items":[{"url":"#initialize-a-swarm-with-autolocking-enabled","title":"Initialize a swarm with autolocking enabled"},{"url":"#enable-or-disable-autolock-on-an-existing-swarm","title":"Enable or disable autolock on an existing swarm"},{"url":"#unlock-a-swarm","title":"Unlock a swarm"},{"url":"#view-the-current-unlock-key-for-a-running-swarm","title":"View the current unlock key for a running swarm"},{"url":"#rotate-the-unlock-key","title":"Rotate the unlock key"}]},{"url":"#administer-and-maintain-a-swarm-of-docker-engines","title":"Administer and maintain a swarm of Docker Engines","items":[{"url":"#operate-manager-nodes-in-a-swarm","title":"Operate manager nodes in a swarm","items":[{"url":"#maintain-the-quorum-of-managers","title":"Maintain the quorum of managers"}]},{"url":"#configure-the-manager-to-advertise-on-a-static-ip-address","title":"Configure the manager to advertise on a static IP address"},{"url":"#add-manager-nodes-for-fault-tolerance","title":"Add manager nodes for fault tolerance","items":[{"url":"#distribute-manager-nodes","title":"Distribute manager nodes"},{"url":"#run-manager-only-nodes","title":"Run manager-only nodes"}]},{"url":"#add-worker-nodes-for-load-balancing","title":"Add worker nodes for load balancing"},{"url":"#monitor-swarm-health","title":"Monitor swarm health"},{"url":"#troubleshoot-a-manager-node","title":"Troubleshoot a manager node"},{"url":"#forcibly-remove-a-node","title":"Forcibly remove a node"},{"url":"#back-up-the-swarm","title":"Back up the swarm"},{"url":"#recover-from-disaster","title":"Recover from disaster","items":[{"url":"#restore-from-a-backup","title":"Restore from a backup"},{"url":"#recover-from-losing-the-quorum","title":"Recover from losing the quorum"}]}]}]}]}]},{"url":"#from-the-node-to-recover","title":"From the node to recover","items":[{"items":[{"items":[{"items":[{"url":"#force-the-swarm-to-rebalance","title":"Force the swarm to rebalance"}]},{"url":"#raft-consensus-in-swarm-mode","title":"Raft consensus in swarm mode"}]},{"url":"#extended-docker","title":"Extended Docker","items":[{"url":"#docker-engine-managed-plugin-system","title":"Docker Engine managed plugin system","items":[{"url":"#installing-and-using-a-plugin","title":"Installing and using a plugin"},{"url":"#developing-a-plugin","title":"Developing a plugin"},{"url":"#debugging-plugins","title":"Debugging plugins"}]},{"url":"#access-authorization-plugin","title":"Access authorization plugin","items":[{"url":"#basic-principles","title":"Basic principles"},{"url":"#default-user-authorization-mechanism","title":"Default user authorization mechanism"},{"url":"#basic-architecture","title":"Basic architecture"},{"url":"#docker-client-flows","title":"Docker client flows","items":[{"url":"#setting-up-docker-daemon","title":"Setting up Docker daemon"},{"url":"#calling-authorized-command-allow","title":"Calling authorized command (allow)"},{"url":"#calling-unauthorized-command-deny","title":"Calling unauthorized command (deny)"},{"url":"#error-from-plugins","title":"Error from plugins"}]},{"url":"#api-schema-and-implementation","title":"API schema and implementation","items":[{"url":"#request-authorization","title":"Request authorization"},{"url":"#response-authorization","title":"Response authorization"}]}]},{"url":"#use-docker-engine-plugins","title":"Use Docker Engine plugins","items":[{"url":"#types-of-plugins","title":"Types of plugins"},{"url":"#installing-a-plugin","title":"Installing a plugin"},{"url":"#finding-a-plugin","title":"Finding a plugin","items":[{"url":"#network-plugins","title":"Network plugins"},{"url":"#volume-plugins","title":"Volume plugins"},{"url":"#authorization-plugins","title":"Authorization plugins"}]},{"url":"#troubleshooting-a-plugin","title":"Troubleshooting a plugin"},{"url":"#writing-a-plugin","title":"Writing a plugin"}]},{"url":"#docker-network-driver-plugins","title":"Docker network driver plugins","items":[{"url":"#network-plugins-and-swarm-mode","title":"Network plugins and swarm mode"},{"url":"#use-network-driver-plugins","title":"Use network driver plugins"},{"url":"#find-network-plugins","title":"Find network plugins"},{"url":"#write-a-network-plugin","title":"Write a network plugin"},{"url":"#network-plugin-protocol","title":"Network plugin protocol"},{"url":"#related-information-13","title":"Related Information"}]},{"url":"#docker-volume-plugins","title":"Docker volume plugins","items":[{"url":"#changelog","title":"Changelog","items":[{"url":"#1130","title":"1.13.0"},{"url":"#1120","title":"1.12.0"},{"url":"#1100","title":"1.10.0"},{"url":"#180","title":"1.8.0"}]},{"url":"#command-line-changes","title":"Command-line changes","items":[{"url":"#--volume","title":"--volume"},{"url":"#volumedriver","title":"volumedriver"}]},{"url":"#create-a-volumedriver","title":"Create a VolumeDriver"},{"url":"#volume-plugin-protocol","title":"Volume plugin protocol","items":[{"url":"#volumedrivercreate","title":"/VolumeDriver.Create"},{"url":"#volumedriverremove","title":"/VolumeDriver.Remove"},{"url":"#volumedrivermount","title":"/VolumeDriver.Mount"},{"url":"#volumedriverpath","title":"/VolumeDriver.Path"},{"url":"#volumedriverunmount","title":"/VolumeDriver.Unmount"},{"url":"#volumedriverget","title":"/VolumeDriver.Get"},{"url":"#volumedriverlist","title":"/VolumeDriver.List"},{"url":"#volumedrivercapabilities","title":"/VolumeDriver.Capabilities"}]}]},{"url":"#plugin-config-version-1-of-plugin-v2","title":"Plugin Config Version 1 of Plugin V2","items":[{"url":"#config-field-descriptions","title":"Config Field Descriptions"},{"url":"#example-config","title":"Example Config"}]},{"url":"#docker-plugin-api","title":"Docker Plugin API","items":[{"url":"#what-plugins-are","title":"What plugins are"},{"url":"#plugin-discovery","title":"Plugin discovery","items":[{"url":"#json-specification","title":"JSON specification"}]},{"url":"#plugin-lifecycle","title":"Plugin lifecycle"},{"url":"#plugin-activation","title":"Plugin activation"},{"url":"#systemd-socket-activation","title":"Systemd socket activation"},{"url":"#api-design","title":"API design"},{"url":"#handshake-api","title":"Handshake API","items":[{"url":"#pluginactivate","title":"/Plugin.Activate"}]},{"url":"#plugin-retries","title":"Plugin retries"},{"url":"#plugins-helpers","title":"Plugins helpers"}]}]}]}]}]},"body":"function _extends(){_extends=Object.assign||function(target){for(var i=1;i<arguments.length;i++){var source=arguments[i];for(var key in source){if(Object.prototype.hasOwnProperty.call(source,key)){target[key]=source[key];}}}return target;};return _extends.apply(this,arguments);}function _objectWithoutProperties(source,excluded){if(source==null)return{};var target=_objectWithoutPropertiesLoose(source,excluded);var key,i;if(Object.getOwnPropertySymbols){var sourceSymbolKeys=Object.getOwnPropertySymbols(source);for(i=0;i<sourceSymbolKeys.length;i++){key=sourceSymbolKeys[i];if(excluded.indexOf(key)>=0)continue;if(!Object.prototype.propertyIsEnumerable.call(source,key))continue;target[key]=source[key];}}return target;}function _objectWithoutPropertiesLoose(source,excluded){if(source==null)return{};var target={};var sourceKeys=Object.keys(source);var key,i;for(i=0;i<sourceKeys.length;i++){key=sourceKeys[i];if(excluded.indexOf(key)>=0)continue;target[key]=source[key];}return target;}/* @jsxRuntime classic */ /* @jsx mdx */var _frontmatter={\"title\":\"Docker\",\"date\":\"2021-01-19T00:00:00.000Z\",\"published\":true};var layoutProps={_frontmatter:_frontmatter};var MDXLayout=\"wrapper\";return function MDXContent(_ref){var components=_ref.components,props=_objectWithoutProperties(_ref,[\"components\"]);return mdx(MDXLayout,_extends({},layoutProps,props,{components:components,mdxType:\"MDXLayout\"}),mdx(\"div\",{style:{\"fontSize\":\"30px\"}},\"Docker\"),mdx(\"h1\",null,\"Contents\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#important-links\"}),\"Important Links\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#code-links\"}),\"Code Links\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#get-started-with-docker\"}),\"Get Started with Docker\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#get-docker\"}),\"Get Docker\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#supported-platforms\"}),\"Supported platforms\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#time-based-release-schedule\"}),\"Time-based release schedule\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#updates-and-patches\"}),\"Updates, and patches\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#prior-releases\"}),\"Prior releases\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#install\"}),\"Install\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#manage-docker-as-a-non-root-user\"}),\"Manage Docker as a non-root user\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configure-docker-to-start-on-boot\"}),\"Configure Docker to start on boot\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-a-different-storage-engine\"}),\"Use a different storage engine\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configure-where-the-docker-daemon-listens-for-connections\"}),\"Configure where the Docker daemon listens for connections\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#enable-ipv6-on-the-docker-daemon\"}),\"Enable IPv6 on the Docker daemon\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#troubleshooting\"}),\"Troubleshooting\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#kernel-compatibility\"}),\"Kernel compatibility\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#ip-forwarding-problems\"}),\"IP forwarding problems\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#specify-dns-servers-for-docker\"}),\"Specify DNS servers for Docker\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#allow-access-to-the-remote-api-through-a-firewall\"}),\"Allow access to the remote API through a firewall\")))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#docker-ce-edge-documentation\"}),\"Docker CE Edge documentation\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#docker-ce-edge-resources\"}),\"Docker CE Edge resources\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#get-docker-compose\"}),\"Get Docker-Compose\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#prerequisites\"}),\"Prerequisites\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#install-compose\"}),\"Install Compose\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#install-compose-on-linux-systems\"}),\"Install Compose on Linux systems\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#master-builds\"}),\"Master builds\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#upgrading\"}),\"Upgrading\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#uninstallation\"}),\"Uninstallation\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#docker----get-started\"}),\"Docker -- Get Started\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#images-and-containers\"}),\"Images and containers\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#containers-and-virtual-machines\"}),\"Containers and virtual machines\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#orientation-and-setup\"}),\"Orientation and Setup\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#test-docker-version\"}),\"Test Docker version\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#build-the-app\"}),\"Build the app\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#run-the-app\"}),\"Run the app\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#share-your-image\"}),\"Share your image\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#log-in-with-your-docker-id\"}),\"Log in with your Docker ID\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#tag-the-image\"}),\"Tag the image\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#publish-the-image\"}),\"Publish the image\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#pull-and-run-the-image-from-the-remote-repository\"}),\"Pull and run the image from the remote repository\")))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#docker-compose\"}),\"Docker Compose\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#your-firstdocker-composeymlfile\"}),\"Your first\\xA0docker-compose.yml\\xA0file\")))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#replace-usernamerepotag-with-your-name-and-image-details\"}),\"replace username/repo:tag with your name and image details\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#run-your-new-load-balanced-app\"}),\"Run your new load-balanced app\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#scale-the-app\"}),\"Scale the app\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#take-down-the-app-and-the-swarm\"}),\"Take down the app and the swarm\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#recap-and-cheat-sheet\"}),\"Recap and cheat sheet\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#docker-swarm\"}),\"Docker Swarm\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#understanding-swarm-clusters\"}),\"Understanding Swarm clusters\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#set-up-your-swarm\"}),\"Set up your swarm\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#create-a-cluster\"}),\"Create a cluster\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#vms-on-your-local-machine-mac-linux-windows-7-and-8\"}),\"VMS ON YOUR LOCAL MACHINE (MAC, LINUX, WINDOWS 7 AND 8)\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#list-the-vms-and-get-their-ip-addresses\"}),\"LIST THE VMS AND GET THEIR IP ADDRESSES\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#initialize-the-swarm-and-add-nodes\"}),\"INITIALIZE THE SWARM AND ADD NODES\")))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#deploy-your-app-on-the-swarm-cluster\"}),\"Deploy your app on the swarm cluster\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#docker-machine-shell-environment-on-mac-or-linux\"}),\"DOCKER MACHINE SHELL ENVIRONMENT ON MAC OR LINUX\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#deploy-the-app-on-the-swarm-manager\"}),\"Deploy the app on the swarm manager\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#accessing-your-cluster\"}),\"Accessing your cluster\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#iterating-and-scaling-your-app\"}),\"Iterating and scaling your app\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#cleanup-and-reboot\"}),\"Cleanup and reboot\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#stacks-and-swarms\"}),\"Stacks and swarms\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#unsetting-docker-machine-shell-variable-settings\"}),\"Unsetting docker-machine shell variable settings\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#restarting-docker-machines\"}),\"Restarting Docker machines\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#recap-and-cheat-sheet-optional\"}),\"Recap and cheat sheet (optional)\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#stacks\"}),\"Stacks\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#introduction\"}),\"Introduction\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#add-a-new-service-and-redeploy\"}),\"Add a new service and redeploy\")))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#replace-usernamerepotag-with-your-name-and-image-details-1\"}),\"replace username/repo:tag with your name and image details\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#persist-the-data\"}),\"Persist the data\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#replace-usernamerepotag-with-your-name-and-image-details-2\"}),\"replace username/repo:tag with your name and image details\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#docker-overview\"}),\"Docker overview\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#the-docker-platform\"}),\"The Docker platform\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#docker-engine\"}),\"Docker Engine\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#what-can-i-use-docker-for\"}),\"What can I use Docker for?\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#docker-architecture\"}),\"Docker architecture\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#the-docker-daemon\"}),\"The Docker daemon\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#the-docker-client\"}),\"The Docker client\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#docker-registries\"}),\"Docker registries\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#docker-objects\"}),\"Docker objects\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#images\"}),\"IMAGES\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#containers\"}),\"CONTAINERS\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#exampledocker-runcommand\"}),\"Example\\xA0\",mdx(\"strong\",{parentName:\"a\"},\"docker run\"),\"\\xA0command\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#services\"}),\"Services\")))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#the-underlying-technology\"}),\"The underlying technology\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#namespaces\"}),\"Namespaces\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#control-groups\"}),\"Control groups\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#union-file-systems\"}),\"Union file systems\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#container-format\"}),\"Container format\")))))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#develop-with-docker\"}),\"Develop with Docker\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#develop-new-apps-on-docker\"}),\"Develop new apps on Docker\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#learn-about-language-specific-app-development-with-docker\"}),\"Learn about language-specific app development with Docker\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#advanced-development-with-the-sdk-or-api\"}),\"Advanced development with the SDK or API\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#docker-development-best-practices\"}),\"Docker development best practices\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#how-to-keep-your-images-small\"}),\"How to keep your images small\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#where-and-how-to-persist-application-data\"}),\"Where and how to persist application data\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-swarm-services-when-possible\"}),\"Use swarm services when possible\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-cicd-for-testing-and-deployment\"}),\"Use CI/CD for testing and deployment\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#differences-in-development-and-production-environments\"}),\"Differences in development and production environments\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#develop-images\"}),\"Develop Images\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#best-practices-for-writing-dockerfiles\"}),\"Best practices for writing Dockerfiles\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#general-guidelines-and-recommendations\"}),\"General guidelines and recommendations\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#containers-should-be-ephemeral\"}),\"Containers should be ephemeral\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-a-dockerignore-file\"}),\"Use a .dockerignore file\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-multi-stage-builds\"}),\"Use multi-stage builds\")))))))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#install-tools-required-to-build-the-project\"}),\"Install tools required to build the project\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#we-need-to-run-docker-build---no-cache--to-update-those-dependencies\"}),\"We need to run \",mdx(\"inlineCode\",{parentName:\"a\"},\"docker build --no-cache .\"),\" to update those dependencies\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#gopkgtoml-and-gopkglock-lists-project-dependencies\"}),\"Gopkg.toml and Gopkg.lock lists project dependencies\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#these-layers-are-only-re-built-when-gopkg-files-are-updated\"}),\"These layers are only re-built when Gopkg files are updated\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#install-library-dependencies\"}),\"Install library dependencies\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#copy-all-project-and-build-it\"}),\"Copy all project and build it\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#this-layer-is-rebuilt-when-ever-a-file-has-changed-in-the-project-directory\"}),\"This layer is rebuilt when ever a file has changed in the project directory\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#this-results-in-a-single-layer-image\"}),\"This results in a single layer image\"),mdx(\"pre\",{parentName:\"li\"},mdx(\"code\",_extends({parentName:\"pre\"},{}),\"  - [Avoid installing unnecessary packages](#avoid-installing-unnecessary-packages)\\n  - [Each container should have only one concern](#each-container-should-have-only-one-concern)\\n  - [Minimize the number of layers](#minimize-the-number-of-layers)\\n  - [Sort multi-line arguments](#sort-multi-line-arguments)\\n  - [Build cache](#build-cache)\\n- [The Dockerfile instructions](#the-dockerfile-instructions)\\n  - [FROM](#from)\\n  - [LABEL](#label)\\n\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#set-one-or-more-individual-labels\"}),\"Set one or more individual labels\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#set-multiple-labels-on-one-line\"}),\"Set multiple labels on one line\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#set-multiple-labels-at-once-using-line-continuation-characters-to-break-long-lines\"}),\"Set multiple labels at once, using line-continuation characters to break long lines\"),mdx(\"pre\",{parentName:\"li\"},mdx(\"code\",_extends({parentName:\"pre\"},{}),\"  - [RUN](#run)\\n    - [APT-GET](#apt-get)\\n    - [USING PIPES](#using-pipes)\\n  - [CMD](#cmd)\\n  - [EXPOSE](#expose)\\n  - [ENV](#env)\\n  - [ADD or COPY](#add-or-copy)\\n  - [ENTRYPOINT](#entrypoint)\\n  - [VOLUME](#volume)\\n  - [USER](#user)\\n  - [WORKDIR](#workdir)\\n  - [ONBUILD](#onbuild)\\n- [Examples for Official Repositories](#examples-for-official-repositories)\\n- [Additional resources](#additional-resources)\\n\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#create-a-base-image\"}),\"Create a base image\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#create-a-full-image-using-tar\"}),\"Create a full image using tar\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#create-a-simple-parent-image-using-scratch\"}),\"Create a simple parent image using scratch\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#more-resources\"}),\"More resources\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-multi-stage-builds-1\"}),\"Use multi-stage builds\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#before-multi-stage-builds\"}),\"Before multi-stage builds\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-multi-stage-builds-2\"}),\"Use multi-stage builds\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#name-your-build-stages\"}),\"Name your build stages\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#stop-at-a-specific-build-stage\"}),\"Stop at a specific build stage\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-an-external-image-as-a-stage\"}),\"Use an external image as a \\\"stage\\\"\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#dockerfile-reference-unread-ref\"}),\"Dockerfile reference (Unread) (REF)\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#usage\"}),\"Usage\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#format\"}),\"Format\")))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#comment\"}),\"Comment\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#comment-1\"}),\"Comment\"),mdx(\"pre\",{parentName:\"li\"},mdx(\"code\",_extends({parentName:\"pre\"},{}),\"- [Parser directives](#parser-directives)\\n\"))),mdx(\"li\",{parentName:\"ul\"},\"[direc \",\"]\",\"(#direc-)\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#directivevalue1\"}),\"directive=value1\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#directivevalue2\"}),\"directive=value2\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#directivevalue\"}),\"directive=value\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#about-my-dockerfile\"}),\"About my dockerfile\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#directivevalue-1\"}),\"directive=value\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#unknowndirectivevalue\"}),\"unknowndirective=value\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#knowndirectivevalue\"}),\"knowndirective=value\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#directive-value\"}),\"directive =value\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#directive-value-1\"}),\"directive= value\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#directive--value\"}),\"directive = value\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#directivevalue-2\"}),\"dIrEcTiVe=value\"),mdx(\"pre\",{parentName:\"li\"},mdx(\"code\",_extends({parentName:\"pre\"},{}),\"- [escape](#escape)\\n\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#escape-backslash\"}),\"escape=\\\\ (backslash)\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#escape-backtick\"}),\"escape=` (backtick)\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#escape-1\"}),\"escape=`\"),mdx(\"pre\",{parentName:\"li\"},mdx(\"code\",_extends({parentName:\"pre\"},{}),\"- [Environment replacement](#environment-replacement)\\n- [.dockerignore file](#dockerignore-file)\\n\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#comment-2\"}),\"comment\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#comment-----ignored\"}),\"comment     Ignored.\"),mdx(\"pre\",{parentName:\"li\"},mdx(\"code\",_extends({parentName:\"pre\"},{}),\"- [FROM](#from-1)\\n  - [Understand how ARG and FROM interact](#understand-how-arg-and-from-interact)\\n- [RUN](#run-1)\\n  - [Known issues (RUN)](#known-issues-run)\\n- [CMD](#cmd-1)\\n- [LABEL](#label-1)\\n- [MAINTAINER (deprecated)](#maintainer-deprecated)\\n- [EXPOSE](#expose-1)\\n- [ENV](#env-1)\\n- [ADD](#add)\\n- [COPY](#copy)\\n- [ENTRYPOINT](#entrypoint-1)\\n  - [Exec form ENTRYPOINT example](#exec-form-entrypoint-example)\\n  - [Shell form ENTRYPOINT example](#shell-form-entrypoint-example)\\n  - [Understand how CMD and ENTRYPOINT interact](#understand-how-cmd-and-entrypoint-interact)\\n- [VOLUME](#volume-1)\\n  - [Notes about specifying volumes](#notes-about-specifying-volumes)\\n- [USER](#user-1)\\n\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#create-windows-user-in-the-container\"}),\"Create Windows user in the container\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#set-it-for-subsequent-commands\"}),\"Set it for subsequent commands\"),mdx(\"pre\",{parentName:\"li\"},mdx(\"code\",_extends({parentName:\"pre\"},{}),\"- [WORKDIR](#workdir-1)\\n- [ARG](#arg)\\n  - [Default values](#default-values)\\n  - [Scope](#scope)\\n  - [Using ARG variables](#using-arg-variables)\\n  - [Predefined ARGs](#predefined-args)\\n  - [Impact on build caching](#impact-on-build-caching)\\n- [ONBUILD](#onbuild-1)\\n- [STOPSIGNAL](#stopsignal)\\n- [HEALTHCHECK](#healthcheck)\\n- [SHELL](#shell)\\n\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#executed-as-cmd-s-c-echo-default\"}),\"Executed as cmd /S /C echo default\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#executed-as-cmd-s-c-powershell--command-write-host-default\"}),\"Executed as cmd /S /C powershell -command Write-Host default\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#executed-as-powershell--command-write-host-hello\"}),\"Executed as powershell -command Write-Host hello\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#executed-as-cmd-s-c-echo-hello\"}),\"Executed as cmd /S /C echo hello\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#escape-2\"}),\"escape=`\"),mdx(\"pre\",{parentName:\"li\"},mdx(\"code\",_extends({parentName:\"pre\"},{}),\"- [Dockerfile examples](#dockerfile-examples)\\n\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#nginx\"}),\"Nginx\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#version-001\"}),\"VERSION 0.0.1\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#firefox-over-vnc\"}),\"Firefox over VNC\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#version-03\"}),\"VERSION 0.3\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#install-vnc-xvfb-in-order-to-create-a-fake-display-and-firefox\"}),\"Install vnc, xvfb in order to create a \\\\'fake\\\\' display and firefox\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#setup-a-password\"}),\"Setup a password\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#autostart-firefox-might-not-be-the-best-way-but-it-does-the-trick\"}),\"Autostart firefox (might not be the best way, but it does the trick)\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#multiple-images-example\"}),\"Multiple images example\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#version-01\"}),\"VERSION 0.1\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#will-output-something-like--907ad6c2736f\"}),\"Will output something like ===> 907ad6c2736f\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#will-output-something-like--695d7793cbe4\"}),\"Will output something like ===> 695d7793cbe4\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#youll-now-have-two-images-907ad6c2736f-with-bar-and-695d7793cbe4-with\"}),\"You\\\\'ll now have two images, 907ad6c2736f with /bar, and 695d7793cbe4 with\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#oink\"}),\"/oink.\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#manage-images\"}),\"Manage images\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#docker-hub\"}),\"Docker Hub\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#docker-registry\"}),\"Docker Registry\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#docker-trusted-registry\"}),\"Docker Trusted Registry\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#content-trust\"}),\"Content Trust\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#samples-to-be-done\"}),\"Samples (To Be Done)\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#tutorial-labs\"}),\"Tutorial labs\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#library-references\"}),\"Library references\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#sample-applications\"}),\"Sample applications\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#develop-with-docker-engine-sdks-and-api\"}),\"Develop with Docker Engine SDKs and API\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#install-the-sdks\"}),\"Install the SDKs\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#go-sdk\"}),\"Go SDK\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#python-sdk\"}),\"Python SDK\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#view-the-api-reference\"}),\"View the API reference\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#versioned-api-and-sdk\"}),\"Versioned API and SDK\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#docker-ee-and-ce-api-mismatch\"}),\"Docker EE and CE API mismatch\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#api-version-matrix\"}),\"API version matrix\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#choose-the-sdk-or-api-version-to-use\"}),\"Choose the SDK or API version to use\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#sdk-and-api-quickstart\"}),\"SDK and API quickstart\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#unofficial-libraries\"}),\"Unofficial libraries\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#examples-using-the-docker-engine-sdks-and-docker-api\"}),\"Examples using the Docker Engine SDKs and Docker API\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configuring-networks\"}),\"Configuring Networks\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#network-overview\"}),\"Network Overview\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#scope-of-this-topic\"}),\"Scope of this topic\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#network-drivers\"}),\"Network drivers\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#network-driver-summary\"}),\"Network driver summary\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#docker-ee-networking-features\"}),\"Docker EE networking features\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#networking-tutorials\"}),\"Networking tutorials\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-bridge-networks\"}),\"Use bridge networks\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#differences-between-user-defined-bridges-and-the-default-bridge\"}),\"Differences between user-defined bridges and the default bridge\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#manage-a-user-defined-bridge\"}),\"Manage a user-defined bridge\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#connect-a-container-to-a-user-defined-bridge\"}),\"Connect a container to a user-defined bridge\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#disconnect-a-container-from-a-user-defined-bridge\"}),\"Disconnect a container from a user-defined bridge\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-ipv6\"}),\"Use IPv6\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#enable-forwarding-from-docker-containers-to-the-outside-world\"}),\"Enable forwarding from Docker containers to the outside world\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-the-default-bridge-network\"}),\"Use the default bridge network\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#connect-a-container-to-the-default-bridge-network\"}),\"Connect a container to the default bridge network\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configure-the-default-bridge-network\"}),\"Configure the default bridge network\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-ipv6-with-the-default-bridge-network\"}),\"Use IPv6 with the default bridge network\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#next-steps\"}),\"Next steps\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-overlay-networks\"}),\"Use overlay networks\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#operations-for-all-overlay-networks\"}),\"Operations for all overlay networks\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#create-an-overlay-network\"}),\"Create an overlay network\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#encrypt-traffic-on-an-overlay-network\"}),\"Encrypt traffic on an overlay network\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#swarm-mode-overlay-networks-and-standalone-containers\"}),mdx(\"strong\",{parentName:\"a\"},\"SWARM MODE OVERLAY NETWORKS AND STANDALONE CONTAINERS\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#customize-the-default-ingress-network\"}),\"Customize the default ingress network\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#customize-the-docker_gwbridge-interface\"}),\"Customize the docker_gwbridge interface\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#operations-for-swarm-services\"}),\"Operations for swarm services\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#publish-ports-on-an-overlay-network\"}),\"Publish ports on an overlay network\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#bypass-the-routing-mesh-for-a-swarm-service\"}),\"Bypass the routing mesh for a swarm service\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#separate-control-and-data-traffic\"}),\"Separate control and data traffic\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#operations-for-standalone-containers-on-overlay-networks\"}),\"Operations for standalone containers on overlay networks\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#attach-a-standalone-container-to-an-overlay-network\"}),\"Attach a standalone container to an overlay network\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#publish-ports\"}),\"Publish ports\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#next-steps-1\"}),\"Next steps\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-host-networking\"}),\"Use host networking\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#next-steps-2\"}),\"Next steps\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-macvlan-networks\"}),\"Use Macvlan networks\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#create-a-macvlan-network\"}),\"Create a macvlan network\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#bridge-mode\"}),\"Bridge mode\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#8021q-trunk-bridge-mode\"}),\"802.1q trunk bridge mode\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-an-ipvlan-instead-of-macvlan\"}),\"Use an ipvlan instead of macvlan\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-ipv6-1\"}),\"Use IPv6\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#next-steps-3\"}),\"Next steps\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#disable-networking-for-a-container\"}),\"Disable networking for a container\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#next-steps-4\"}),\"Next steps\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#networing-tutorials\"}),\"Networing Tutorials\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#networking-with-standalone-containers\"}),\"Networking with standalone containers\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-the-default-bridge-network-1\"}),\"Use the default bridge network\")))))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#ip-addr-show\"}),\"ip addr show\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#ping--c-2-alpine2\"}),\"ping -c 2 alpine2\"),mdx(\"pre\",{parentName:\"li\"},mdx(\"code\",_extends({parentName:\"pre\"},{}),\"- [Use user-defined bridge networks](#use-user-defined-bridge-networks)\\n\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#ping--c-2-1721702\"}),\"ping -c 2 172.17.0.2\"),mdx(\"pre\",{parentName:\"li\"},mdx(\"code\",_extends({parentName:\"pre\"},{}),\"- [Other networking tutorials](#other-networking-tutorials)\\n\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#networking-using-the-host-network\"}),\"Networking using the host network\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#goal\"}),\"Goal\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#prerequisites-1\"}),\"Prerequisites\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#procedure\"}),\"Procedure\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#other-networking-tutorials-1\"}),\"Other networking tutorials\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#networking-with-overlay-networks\"}),\"Networking with overlay networks\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#prerequisites-2\"}),\"Prerequisites\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-the-default-overlay-network\"}),\"Use the default overlay network\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#prerequisites-3\"}),mdx(\"strong\",{parentName:\"a\"},\"Prerequisites\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#walkthrough\"}),mdx(\"strong\",{parentName:\"a\"},\"Walkthrough\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#create-the-swarm\"}),mdx(\"strong\",{parentName:\"a\"},\"CREATE THE SWARM\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#create-the-services\"}),mdx(\"strong\",{parentName:\"a\"},\"CREATE THE SERVICES\"))))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-a-user-defined-overlay-network\"}),\"Use a user-defined overlay network\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#prerequisites-4\"}),mdx(\"strong\",{parentName:\"a\"},\"Prerequisites\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#walkthrough-1\"}),mdx(\"strong\",{parentName:\"a\"},\"Walkthrough\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-an-overlay-network-for-standalone-containers\"}),\"Use an overlay network for standalone containers\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#prerequisites-5\"}),mdx(\"strong\",{parentName:\"a\"},\"Prerequisites\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#walk-through\"}),mdx(\"strong\",{parentName:\"a\"},\"Walk-through\"))))))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#ping--c-2-alpine1\"}),\"ping -c 2 alpine1\"),mdx(\"pre\",{parentName:\"li\"},mdx(\"code\",_extends({parentName:\"pre\"},{}),\"- [Communicate between a container and a swarm service](#communicate-between-a-container-and-a-swarm-service)\\n  - [**Prerequisites**](#prerequisites-6)\\n  - [**Walkthrough**](#walkthrough-2)\\n\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#ip-addr-show-1\"}),\"ip addr show\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#ping--c-2-alpine2-1\"}),\"ping -c 2 alpine2\"),mdx(\"pre\",{parentName:\"li\"},mdx(\"code\",_extends({parentName:\"pre\"},{}),\"- [Other networking tutorials](#other-networking-tutorials-2)\\n\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#networking-using-a-macvlan-network\"}),\"Networking using a macvlan network\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#goal-1\"}),\"Goal\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#prerequisites-7\"}),\"Prerequisites\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#bridge-example\"}),\"Bridge example\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#8021q-trunked-bridge-example\"}),\"802.1q trunked bridge example\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#other-networking-tutorials-3\"}),\"Other networking tutorials\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configure-the-daemon-and-the-containers\"}),\"Configure the Daemon and the Containers\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#enable-ipv6-support\"}),\"Enable IPv6 support\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#next-steps-5\"}),mdx(\"strong\",{parentName:\"a\"},\"Next steps\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#docker-and-iptables\"}),\"Docker and iptables\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#add-iptables-policies-before-dockers-rules\"}),mdx(\"strong\",{parentName:\"a\"},\"Add iptables policies before Docker's rules\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#restrict-connections-to-the-docker-daemon\"}),mdx(\"strong\",{parentName:\"a\"},\"Restrict connections to the Docker daemon\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#prevent-docker-from-manipulating-iptables\"}),mdx(\"strong\",{parentName:\"a\"},\"Prevent Docker from manipulating iptables\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#next-steps-6\"}),mdx(\"strong\",{parentName:\"a\"},\"Next steps\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#container-networking\"}),\"Container networking\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#published-ports\"}),mdx(\"strong\",{parentName:\"a\"},\"Published ports\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#ip-address-and-hostname\"}),mdx(\"strong\",{parentName:\"a\"},\"IP address and hostname\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#dns-services\"}),mdx(\"strong\",{parentName:\"a\"},\"DNS services\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#proxy-server\"}),mdx(\"strong\",{parentName:\"a\"},\"Proxy server\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configure-docker-to-use-a-proxy-server\"}),\"Configure Docker to use a proxy server\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configure-the-docker-client\"}),mdx(\"strong\",{parentName:\"a\"},\"Configure the Docker client\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-environment-variables\"}),mdx(\"strong\",{parentName:\"a\"},\"Use environment variables\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#set-the-environment-variables-manually\"}),mdx(\"strong\",{parentName:\"a\"},\"Set the environment variables manually\"))))))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#legacy-networing-content\"}),\"Legacy Networing Content\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#legacy-container-links\"}),\"Legacy container links\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#connect-using-network-port-mapping\"}),\"Connect using network port mapping\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#connect-with-the-linking-system\"}),\"Connect with the linking system\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#the-importance-of-naming\"}),mdx(\"strong\",{parentName:\"a\"},\"The importance of naming\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#communication-across-links\"}),\"Communication across links\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#environment-variables\"}),mdx(\"strong\",{parentName:\"a\"},\"Environment variables\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#important-notes-on-docker-environment-variables\"}),mdx(\"strong\",{parentName:\"a\"},\"Important notes on Docker environment variables\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#updating-theetchostsfile\"}),mdx(\"strong\",{parentName:\"a\"},\"Updating the\\xA0/etc/hosts\\xA0file\"))))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#multi-host-networking-with-standalone-swarms\"}),\"Multi-host networking with standalone swarms\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#standalone-swarm-only\"}),\"Standalone swarm only!\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#overlay-networking-with-an-external-key-value-store\"}),\"Overlay networking with an external key-value store\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#prerequisites-8\"}),mdx(\"strong\",{parentName:\"a\"},\"Prerequisites\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#set-up-a-key-value-store\"}),mdx(\"strong\",{parentName:\"a\"},\"Set up a key-value store\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#create-a-swarm-cluster\"}),mdx(\"strong\",{parentName:\"a\"},\"Create a swarm cluster\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#create-the-overlay-network\"}),mdx(\"strong\",{parentName:\"a\"},\"Create the overlay network\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#run-an-application-on-your-network\"}),mdx(\"strong\",{parentName:\"a\"},\"Run an application on your network\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#check-external-connectivity\"}),mdx(\"strong\",{parentName:\"a\"},\"Check external connectivity\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-docker-compose-with-swarm-classic\"}),\"Use Docker Compose with swarm classic\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#next-steps-7\"}),\"Next steps\")))))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#manage-data-in-docker\"}),\"Manage data in Docker\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#choose-the-right-type-of-mount\"}),\"Choose the right type of mount\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#more-details-about-mount-types\"}),\"More details about mount types\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#good-use-cases-for-volumes\"}),\"Good use cases for volumes\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#good-use-cases-for-bind-mounts\"}),\"Good use cases for bind mounts\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#good-use-cases-for-tmpfs-mounts\"}),\"Good use cases for tmpfs mounts\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#tips-for-using-bind-mounts-or-volumes\"}),\"Tips for using bind mounts or volumes\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#next-steps-8\"}),\"Next steps\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-volumes\"}),\"Use volumes\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#choose-the--v-or---mount-flag\"}),\"Choose the -v or --mount flag\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#differences-between-vand--mountbehavior\"}),\"Differences between\\xA0-v\\xA0and\\xA0--mount\\xA0behavior\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#create-and-manage-volumes\"}),\"Create and manage volumes\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#start-a-container-with-a-volume\"}),\"Start a container with a volume\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#start-a-service-with-volumes\"}),\"Start a service with volumes\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#syntax-differences-for-services\"}),mdx(\"strong\",{parentName:\"a\"},\"SYNTAX DIFFERENCES FOR SERVICES\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#populate-a-volume-using-a-container\"}),\"Populate a volume using a container\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-a-read-only-volume\"}),\"Use a read-only volume\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-a-volume-driver\"}),\"Use a volume driver\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#initial-set-up\"}),\"Initial set-up\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#create-a-volume-using-a-volume-driver\"}),\"Create a volume using a volume driver\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#start-a-container-which-creates-a-volume-using-a-volume-driver\"}),\"Start a container which creates a volume using a volume driver\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#next-steps-9\"}),\"Next steps\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-bind-mounts\"}),\"Use bind mounts\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#choosing-the--v-or---mount-flag\"}),\"Choosing the -v or --mount flag\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#differences-between-vand--mountbehavior-1\"}),\"Differences between\\xA0-v\\xA0and\\xA0--mount\\xA0behavior\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#start-a-container-with-a-bind-mount\"}),\"Start a container with a bind mount\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#mounting-into-a-non-empty-directory-on-the-container\"}),\"Mounting into a non-empty directory on the container\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-a-read-only-bind-mount\"}),\"Use a read-only bind mount\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configure-bind-propagation\"}),\"Configure bind propagation\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configure-the-selinux-label\"}),\"Configure the selinux label\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configure-mount-consistency-for-macos\"}),\"Configure mount consistency for macOS\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#next-steps-10\"}),\"Next steps\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-tmpfs-mounts\"}),\"Use tmpfs mounts\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#choosing-the---tmpfs-or---mount-flag\"}),\"Choosing the --tmpfs or --mount flag\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#differences-between--tmpfsand--mountbehavior\"}),\"Differences between\\xA0--tmpfs\\xA0and\\xA0--mount\\xA0behavior\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#limitations-of-tmpfs-containers\"}),\"Limitations of tmpfs containers\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-a-tmpfs-mount-in-a-container\"}),\"Use a tmpfs mount in a container\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#specify-tmpfs-options\"}),\"Specify tmpfs options\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#next-steps-11\"}),\"Next steps\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#troubleshoot-volume-errors\"}),\"Troubleshoot volume errors\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#error-unable-to-remove-filesystem\"}),\"Error: Unable to remove filesystem\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#store-data-within-containers\"}),\"Store Data within Containers\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#about-storage-drivers\"}),\"About storage drivers\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#images-and-layers\"}),\"Images and layers\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#container-and-layers\"}),\"Container and layers\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#container-size-on-disk\"}),\"Container size on disk\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#the-copy-on-write-cow-strategy\"}),\"The copy-on-write (CoW) strategy\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#sharing-promotes-smaller-images\"}),mdx(\"strong\",{parentName:\"a\"},\"Sharing promotes smaller images\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#copying-makes-containers-efficient\"}),mdx(\"strong\",{parentName:\"a\"},\"Copying makes containers efficient\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#data-volumes-and-the-storage-driver\"}),\"Data volumes and the storage driver\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#related-information\"}),\"Related information\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#docker-storage-drivers\"}),\"Docker storage drivers\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#supported-storage-drivers-per-linux-distribution\"}),\"Supported storage drivers per Linux distribution\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#docker-ee-and-cs-engine\"}),mdx(\"strong\",{parentName:\"a\"},\"Docker EE and CS-Engine\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#docker-ce\"}),mdx(\"strong\",{parentName:\"a\"},\"Docker CE\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#docker-for-mac-and-docker-for-windows\"}),mdx(\"strong\",{parentName:\"a\"},\"Docker for Mac and Docker for Windows\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#supported-backing-filesystems\"}),\"Supported backing filesystems\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#other-considerations\"}),\"Other considerations\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#suitability-for-your-workload\"}),mdx(\"strong\",{parentName:\"a\"},\"Suitability for your workload\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#shared-storage-systems-and-the-storage-driver\"}),mdx(\"strong\",{parentName:\"a\"},\"Shared storage systems and the storage driver\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#stability\"}),mdx(\"strong\",{parentName:\"a\"},\"Stability\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#experience-and-expertise\"}),mdx(\"strong\",{parentName:\"a\"},\"Experience and expertise\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#test-with-your-own-workloads\"}),mdx(\"strong\",{parentName:\"a\"},\"Test with your own workloads\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#check-your-current-storage-driver\"}),\"Check your current storage driver\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#related-information-1\"}),\"Related information\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-the-aufs-storage-driver\"}),\"Use the AUFS storage driver\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#prerequisites-9\"}),\"Prerequisites\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configure-docker-with-theaufsstorage-driver\"}),\"Configure Docker with the\\xA0aufs\\xA0storage driver\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#how-theaufsstorage-driver-works\"}),\"How the\\xA0aufs\\xA0storage driver works\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#example-image-and-container-on-disk-constructs\"}),mdx(\"strong\",{parentName:\"a\"},\"Example: Image and container on-disk constructs\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#the-image-layers\"}),mdx(\"strong\",{parentName:\"a\"},\"THE IMAGE LAYERS\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#the-container-layer\"}),mdx(\"strong\",{parentName:\"a\"},\"THE CONTAINER LAYER\"))))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#how-container-reads-and-writes-work-withaufs\"}),\"How container reads and writes work with\\xA0aufs\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#reading-files\"}),mdx(\"strong\",{parentName:\"a\"},\"Reading files\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#modifying-files-or-directories\"}),mdx(\"strong\",{parentName:\"a\"},\"Modifying files or directories\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#aufs-and-docker-performance\"}),\"AUFS and Docker performance\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#performance-best-practices\"}),mdx(\"strong\",{parentName:\"a\"},\"Performance best practices\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#related-information-2\"}),\"Related information\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-the-btrfs-storage-driver\"}),\"Use the BTRFS storage driver\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#prerequisites-10\"}),\"Prerequisites\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configure-docker-to-use-the-btrfs-storage-driver\"}),\"Configure Docker to use the btrfs storage driver\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#manage-a-btrfs-volume\"}),\"Manage a Btrfs volume\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#how-thebtrfsstorage-driver-works\"}),\"How the\\xA0btrfs\\xA0storage driver works\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#image-and-container-layers-on-disk\"}),mdx(\"strong\",{parentName:\"a\"},\"Image and container layers on-disk\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#how-container-reads-and-writes-work-withbtrfs\"}),\"How container reads and writes work with\\xA0btrfs\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#reading-files-1\"}),mdx(\"strong\",{parentName:\"a\"},\"Reading files\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#writing-files\"}),mdx(\"strong\",{parentName:\"a\"},\"Writing files\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#btrfs-and-docker-performance\"}),\"Btrfs and Docker performance\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#related-information-3\"}),\"Related Information\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-the-device-mapper-storage-driver\"}),\"Use the Device Mapper storage driver\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#prerequisites-11\"}),\"Prerequisites\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configure-docker-with-thedevicemapperstorage-driver\"}),\"Configure Docker with the\\xA0devicemapper\\xA0storage driver\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configureloop-lvmmode-for-testing\"}),mdx(\"strong\",{parentName:\"a\"},\"Configure\\xA0loop-lvm\\xA0mode for testing\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configure-direct-lvm-mode-for-production\"}),mdx(\"strong\",{parentName:\"a\"},\"Configure direct-lvm mode for production\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#allow-docker-to-configure-direct-lvm-mode\"}),mdx(\"strong\",{parentName:\"a\"},\"ALLOW DOCKER TO CONFIGURE DIRECT-LVM MODE\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configure-direct-lvm-mode-manually\"}),mdx(\"strong\",{parentName:\"a\"},\"CONFIGURE DIRECT-LVM MODE MANUALLY\"))))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#manage-devicemapper\"}),\"Manage devicemapper\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#monitor-the-thin-pool\"}),mdx(\"strong\",{parentName:\"a\"},\"Monitor the thin pool\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#increase-capacity-on-a-running-device\"}),mdx(\"strong\",{parentName:\"a\"},\"Increase capacity on a running device\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#resize-a-loop-lvm-thin-pool\"}),mdx(\"strong\",{parentName:\"a\"},\"RESIZE A LOOP-LVM THIN POOL\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#resize-a-direct-lvm-thin-pool\"}),mdx(\"strong\",{parentName:\"a\"},\"RESIZE A DIRECT-LVM THIN POOL\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#activate-thedevicemapperafter-reboot\"}),mdx(\"strong\",{parentName:\"a\"},\"Activate the\\xA0devicemapper\\xA0after reboot\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#how-thedevicemapperstorage-driver-works\"}),\"How the\\xA0devicemapper\\xA0storage driver works\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#image-and-container-layers-on-disk-1\"}),mdx(\"strong\",{parentName:\"a\"},\"Image and container layers on-disk\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#image-layering-and-sharing\"}),mdx(\"strong\",{parentName:\"a\"},\"Image layering and sharing\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#snapshots\"}),mdx(\"strong\",{parentName:\"a\"},\"SNAPSHOTS\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#devicemapper-workflow\"}),mdx(\"strong\",{parentName:\"a\"},\"DEVICEMAPPER WORKFLOW\"))))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#how-container-reads-and-writes-work-withdevicemapper\"}),\"How container reads and writes work with\\xA0devicemapper\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#reading-files-2\"}),mdx(\"strong\",{parentName:\"a\"},\"Reading files\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#writing-files-1\"}),mdx(\"strong\",{parentName:\"a\"},\"Writing files\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#device-mapper-and-docker-performance\"}),\"Device Mapper and Docker performance\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#performance-best-practices-1\"}),mdx(\"strong\",{parentName:\"a\"},\"Performance best practices\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#related-information-4\"}),\"Related Information\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-the-overlayfs-storage-driver\"}),\"Use the OverlayFS storage driver\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#prerequisites-12\"}),\"Prerequisites\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configure-docker-with-theoverlayoroverlay2storage-driver\"}),\"Configure Docker with the\\xA0overlay\\xA0or\\xA0overlay2storage driver\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#how-theoverlay2driver-works\"}),\"How the\\xA0overlay2\\xA0driver works\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#image-and-container-layers-on-disk-2\"}),mdx(\"strong\",{parentName:\"a\"},\"Image and container layers on-disk\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#how-theoverlaydriver-works\"}),\"How the\\xA0overlay\\xA0driver works\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#image-and-container-layers-on-disk-3\"}),mdx(\"strong\",{parentName:\"a\"},\"Image and container layers on-disk\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#the-image-layers-1\"}),mdx(\"strong\",{parentName:\"a\"},\"THE IMAGE LAYERS\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#the-container-layer-1\"}),mdx(\"strong\",{parentName:\"a\"},\"THE CONTAINER LAYER\"))))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#how-container-reads-and-writes-work-withoverlayoroverlay2\"}),\"How container reads and writes work with\\xA0overlayor\\xA0overlay2\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#reading-files-3\"}),mdx(\"strong\",{parentName:\"a\"},\"Reading files\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#modifying-files-or-directories-1\"}),mdx(\"strong\",{parentName:\"a\"},\"Modifying files or directories\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#overlayfs-and-docker-performance\"}),\"OverlayFS and Docker Performance\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#performance-best-practices-2\"}),mdx(\"strong\",{parentName:\"a\"},\"Performance best practices\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#limitations-on-overlayfs-compatibility\"}),\"Limitations on OverlayFS compatibility\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-the-zfs-storage-driver\"}),\"Use the ZFS storage driver\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#prerequisites-13\"}),\"Prerequisites\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configure-docker-with-thezfsstorage-driver\"}),\"Configure Docker with the\\xA0zfs\\xA0storage driver\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#managezfs\"}),\"Manage\\xA0zfs\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#increase-capacity-on-a-running-device-1\"}),mdx(\"strong\",{parentName:\"a\"},\"Increase capacity on a running device\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#limit-a-containers-writable-storage-quota\"}),mdx(\"strong\",{parentName:\"a\"},\"Limit a container's writable storage quota\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#how-thezfsstorage-driver-works\"}),\"How the\\xA0zfs\\xA0storage driver works\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#image-and-container-layers-on-disk-4\"}),mdx(\"strong\",{parentName:\"a\"},\"Image and container layers on-disk\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#image-layering-and-sharing-1\"}),mdx(\"strong\",{parentName:\"a\"},\"Image layering and sharing\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#how-container-reads-and-writes-work-withzfs\"}),\"How container reads and writes work with\\xA0zfs\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#reading-files-4\"}),mdx(\"strong\",{parentName:\"a\"},\"Reading files\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#writing-files-2\"}),mdx(\"strong\",{parentName:\"a\"},\"Writing files\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#zfs-and-docker-performance\"}),\"ZFS and Docker performance\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#performance-best-practices-3\"}),mdx(\"strong\",{parentName:\"a\"},\"Performance best practices\"))))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-the-vfs-storage-driver\"}),\"Use the VFS storage driver\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configure-docker-with-thevfsstorage-driver\"}),\"Configure Docker with the\\xA0vfs\\xA0storage driver\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#how-thevfsstorage-driver-works\"}),\"How the\\xA0vfs\\xA0storage driver works\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#example-image-and-container-on-disk-constructs-1\"}),mdx(\"strong\",{parentName:\"a\"},\"Example: Image and container on-disk constructs\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#related-information-5\"}),\"Related information\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#run-your-app-in-production\"}),\"Run Your App in Production\")))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configure-all-objects\"}),\"Configure All Objects\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#docker-object-labels\"}),\"Docker object labels\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#label-keys-and-values\"}),\"Label keys and values\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#key-format-recommendations\"}),mdx(\"strong\",{parentName:\"a\"},\"Key format recommendations\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#value-guidelines\"}),mdx(\"strong\",{parentName:\"a\"},\"Value guidelines\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#manage-labels-on-objects\"}),\"Manage labels on objects\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#prune-unused-docker-objects\"}),\"Prune unused Docker objects\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#prune-images\"}),\"Prune images\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#prune-containers\"}),\"Prune containers\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#prune-volumes\"}),\"Prune volumes\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#prune-networks\"}),\"Prune networks\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#prune-everything\"}),\"Prune everything\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#format-command-and-log-output\"}),\"Format command and log output\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#join\"}),\"join\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#json\"}),\"json\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#lower\"}),\"lower\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#split\"}),\"split\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#title\"}),\"title\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#upper\"}),\"upper\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#println\"}),\"println\")))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configure-the-daemon\"}),\"Configure the Daemon\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configure-and-troubleshoot-the-docker-daemon\"}),\"Configure and troubleshoot the Docker daemon\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#start-the-daemon-using-operating-system-utilities\"}),\"Start the daemon using operating system utilities\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#start-the-daemon-manually\"}),\"Start the daemon manually\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configure-the-docker-daemon\"}),\"Configure the Docker daemon\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#troubleshoot-conflicts-between-thedaemonjsonand-startup-scripts\"}),mdx(\"strong\",{parentName:\"a\"},\"Troubleshoot conflicts between the\\xA0daemon.json\\xA0and startup scripts\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-the-hosts-key-in-daemonjson-with-systemd\"}),mdx(\"strong\",{parentName:\"a\"},\"USE THE HOSTS KEY IN DAEMON.JSON WITH SYSTEMD\"))))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#troubleshoot-the-daemon\"}),\"Troubleshoot the daemon\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#out-of-memory-exceptions-oome\"}),mdx(\"strong\",{parentName:\"a\"},\"Out Of Memory Exceptions (OOME)\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#read-the-logs\"}),mdx(\"strong\",{parentName:\"a\"},\"Read the logs\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#enable-debugging\"}),mdx(\"strong\",{parentName:\"a\"},\"Enable debugging\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#force-a-stack-trace-to-be-logged\"}),mdx(\"strong\",{parentName:\"a\"},\"Force a stack trace to be logged\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#view-stack-traces\"}),mdx(\"strong\",{parentName:\"a\"},\"View stack traces\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#check-whether-docker-is-running\"}),\"Check whether Docker is running\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#control-docker-with-systemd\"}),\"Control Docker with systemd\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#start-the-docker-daemon\"}),\"Start the Docker daemon\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#start-manually\"}),mdx(\"strong\",{parentName:\"a\"},\"Start manually\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#start-automatically-at-system-boot\"}),mdx(\"strong\",{parentName:\"a\"},\"Start automatically at system boot\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#custom-docker-daemon-options\"}),\"Custom Docker daemon options\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#runtime-directory-and-storage-driver\"}),mdx(\"strong\",{parentName:\"a\"},\"Runtime directory and storage driver\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#httphttps-proxy\"}),mdx(\"strong\",{parentName:\"a\"},\"HTTP/HTTPS proxy\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configure-where-the-docker-daemon-listens-for-connections-1\"}),\"Configure where the Docker daemon listens for connections\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#manually-create-the-systemd-unit-files\"}),\"Manually create the systemd unit files\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#collect-docker-metrics-with-prometheus\"}),\"Collect Docker metrics with Prometheus\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configure-docker\"}),\"Configure Docker\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configure-and-run-prometheus\"}),\"Configure and run Prometheus\")))))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#my-global-config\"}),\"my global config\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#scrape_timeout-is-set-to-the-global-default-10s\"}),\"scrape_timeout is set to the global default (10s).\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#attach-these-labels-to-any-time-series-or-alerts-when-communicating-with\"}),\"Attach these labels to any time series or alerts when communicating with\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#external-systems-federation-remote-storage-alertmanager\"}),\"external systems (federation, remote storage, Alertmanager).\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#load-rules-once-and-periodically-evaluate-them-according-to-the-global-evaluation_interval\"}),\"Load rules once and periodically evaluate them according to the global \\\\'evaluation_interval\\\\'.\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#--firstrules\"}),\"- \\\"first.rules\\\"\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#--secondrules\"}),\"- \\\"second.rules\\\"\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#a-scrape-configuration-containing-exactly-one-endpoint-to-scrape\"}),\"A scrape configuration containing exactly one endpoint to scrape:\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#here-its-prometheus-itself\"}),\"Here it\\\\'s Prometheus itself.\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#the-job-name-is-added-as-a-label-jobjob_name-to-any-timeseries-scraped-from-this-config\"}),\"The job name is added as a label \",mdx(\"inlineCode\",{parentName:\"a\"},\"job=\"),\"<job_name>`` to any timeseries scraped from this config.\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#metrics_path-defaults-to-metrics\"}),\"metrics_path defaults to \\\\'/metrics\\\\'\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#scheme-defaults-to-http\"}),\"scheme defaults to \\\\'http\\\\'.\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#metrics_path-defaults-to-metrics-1\"}),\"metrics_path defaults to \\\\'/metrics\\\\'\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#scheme-defaults-to-http-1\"}),\"scheme defaults to \\\\'http\\\\'.\"),mdx(\"pre\",{parentName:\"li\"},mdx(\"code\",_extends({parentName:\"pre\"},{}),\"- [Use Prometheus](#use-prometheus)\\n- [Next steps](#next-steps-12)\\n\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configure-containers\"}),\"Configure Containers\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#start-containers-automatically\"}),\"Start containers automatically\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-a-restart-policy\"}),\"Use a restart policy\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#restart-policy-details\"}),mdx(\"strong\",{parentName:\"a\"},\"Restart policy details\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-a-process-manager\"}),\"Use a process manager\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#using-a-process-manager-inside-containers\"}),mdx(\"strong\",{parentName:\"a\"},\"Using a process manager inside containers\"))))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#keep-containers-alive-during-daemon-downtime\"}),\"Keep containers alive during daemon downtime\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#enable-live-restore\"}),\"Enable live restore\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#live-restore-during-upgrades\"}),\"Live restore during upgrades\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#live-restore-upon-restart\"}),\"Live restore upon restart\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#impact-of-live-restore-on-running-containers\"}),\"Impact of live restore on running containers\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#live-restore-and-swarm-mode\"}),\"Live restore and swarm mode\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#run-multiple-services-in-a-container\"}),\"Run multiple services in a container\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#runtime-metrics\"}),\"Runtime metrics\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#docker-stats\"}),\"Docker stats\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#control-groups-1\"}),\"Control groups\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#enumerate-cgroups\"}),mdx(\"strong\",{parentName:\"a\"},\"Enumerate cgroups\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#find-the-cgroup-for-a-given-container\"}),mdx(\"strong\",{parentName:\"a\"},\"Find the cgroup for a given container\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#metrics-from-cgroups-memory-cpu-block-io\"}),mdx(\"strong\",{parentName:\"a\"},\"Metrics from cgroups: memory, CPU, block I/O\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#memory-metricsmemorystat\"}),mdx(\"strong\",{parentName:\"a\"},\"MEMORY METRICS:\\xA0MEMORY.STAT\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#cpu-metricscpuacctstat\"}),mdx(\"strong\",{parentName:\"a\"},\"CPU metrics:\\xA0cpuacct.stat\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#block-io-metrics\"}),mdx(\"strong\",{parentName:\"a\"},\"BLOCK I/O METRICS\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#network-metrics\"}),mdx(\"strong\",{parentName:\"a\"},\"Network metrics\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#iptables\"}),mdx(\"strong\",{parentName:\"a\"},\"IPTABLES\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#interface-level-counters\"}),mdx(\"strong\",{parentName:\"a\"},\"INTERFACE-LEVEL COUNTERS\"))))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#tips-for-high-performance-metric-collection\"}),\"Tips for high-performance metric collection\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#collect-metrics-when-a-container-exits\"}),\"Collect metrics when a container exits\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#limit-a-containers-resources\"}),\"Limit a container\\\\'s resources\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#memory\"}),\"Memory\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#understand-the-risks-of-running-out-of-memory\"}),mdx(\"strong\",{parentName:\"a\"},\"Understand the risks of running out of memory\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#limit-a-containers-access-to-memory\"}),mdx(\"strong\",{parentName:\"a\"},\"Limit a container's access to memory\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#--memory-swapdetails\"}),mdx(\"strong\",{parentName:\"a\"},\"--memory-swap\\xA0details\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#prevent-a-container-from-using-swap\"}),mdx(\"strong\",{parentName:\"a\"},\"PREVENT A CONTAINER FROM USING SWAP\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#--memory-swappinessdetails\"}),mdx(\"strong\",{parentName:\"a\"},\"--memory-swappiness\\xA0details\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#--kernel-memorydetails\"}),mdx(\"strong\",{parentName:\"a\"},\"--kernel-memory\\xA0details\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#cpu\"}),\"CPU\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configure-the-default-cfs-scheduler\"}),mdx(\"strong\",{parentName:\"a\"},\"Configure the default CFS scheduler\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configure-the-realtime-scheduler\"}),mdx(\"strong\",{parentName:\"a\"},\"Configure the realtime scheduler\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configure-the-host-machines-kernel\"}),mdx(\"strong\",{parentName:\"a\"},\"CONFIGURE THE HOST MACHINE'S KERNEL\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configure-the-docker-daemon-1\"}),mdx(\"strong\",{parentName:\"a\"},\"CONFIGURE THE DOCKER DAEMON\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configure-individual-containers\"}),mdx(\"strong\",{parentName:\"a\"},\"CONFIGURE INDIVIDUAL CONTAINERS\"))))))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#logging\"}),\"Logging\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#view-logs-for-a-container-or-service\"}),\"View logs for a container or service\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#next-steps-13\"}),mdx(\"strong\",{parentName:\"a\"},\"Next steps\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configure-logging-drivers\"}),\"Configure logging drivers\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configure-the-default-logging-driver\"}),mdx(\"strong\",{parentName:\"a\"},\"Configure the default logging driver\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configure-the-logging-driver-for-a-container\"}),mdx(\"strong\",{parentName:\"a\"},\"Configure the logging driver for a container\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configure-the-delivery-mode-of-log-messages-from-container-to-log-driver\"}),mdx(\"strong\",{parentName:\"a\"},\"Configure the delivery mode of log messages from container to log driver\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-environment-variables-or-labels-with-logging-drivers\"}),mdx(\"strong\",{parentName:\"a\"},\"Use environment variables or labels with logging drivers\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#supported-logging-drivers\"}),mdx(\"strong\",{parentName:\"a\"},\"Supported logging drivers\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#limitations-of-logging-drivers\"}),mdx(\"strong\",{parentName:\"a\"},\"Limitations of logging drivers\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-a-logging-driver-plugin\"}),\"Use a logging driver plugin\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#install-the-logging-driver-plugin\"}),mdx(\"strong\",{parentName:\"a\"},\"Install the logging driver plugin\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configure-the-plugin-as-the-default-logging-driver\"}),mdx(\"strong\",{parentName:\"a\"},\"Configure the plugin as the default logging driver\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configure-a-container-to-use-the-plugin-as-the-logging-driver\"}),mdx(\"strong\",{parentName:\"a\"},\"Configure a container to use the plugin as the logging driver\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#customize-log-driver-output\"}),\"Customize log driver output\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#logging-driver-details\"}),\"Logging Driver Details\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#logentries-logging-driver\"}),mdx(\"strong\",{parentName:\"a\"},\"Logentries logging driver\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#usage-1\"}),mdx(\"strong\",{parentName:\"a\"},\"Usage\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#options\"}),mdx(\"strong\",{parentName:\"a\"},\"Options\"))))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#json-file-logging-driver\"}),\"JSON File logging driver\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#usage-2\"}),mdx(\"strong\",{parentName:\"a\"},\"Usage\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#options-1\"}),mdx(\"strong\",{parentName:\"a\"},\"Options\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#examples\"}),mdx(\"strong\",{parentName:\"a\"},\"Examples\"))))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#graylog-extended-format-logging-driver\"}),\"Graylog Extended Format logging driver\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#usage-3\"}),mdx(\"strong\",{parentName:\"a\"},\"Usage\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#gelf-options\"}),mdx(\"strong\",{parentName:\"a\"},\"GELF options\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#examples-1\"}),mdx(\"strong\",{parentName:\"a\"},\"Examples\"))))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#syslog-logging-driver\"}),\"Syslog logging driver\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#usage-4\"}),mdx(\"strong\",{parentName:\"a\"},\"Usage\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#options-2\"}),mdx(\"strong\",{parentName:\"a\"},\"Options\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#amazon-cloudwatch-logs-logging-driver\"}),\"Amazon CloudWatch Logs logging driver\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#usage-5\"}),mdx(\"strong\",{parentName:\"a\"},\"Usage\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#amazon-cloudwatch-logs-options\"}),mdx(\"strong\",{parentName:\"a\"},\"Amazon CloudWatch Logs options\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#awslogs-region\"}),mdx(\"strong\",{parentName:\"a\"},\"awslogs-region\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#awslogs-group\"}),mdx(\"strong\",{parentName:\"a\"},\"awslogs-group\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#awslogs-stream\"}),mdx(\"strong\",{parentName:\"a\"},\"awslogs-stream\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#awslogs-create-group\"}),mdx(\"strong\",{parentName:\"a\"},\"awslogs-create-group\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#awslogs-datetime-format\"}),mdx(\"strong\",{parentName:\"a\"},\"awslogs-datetime-format\"))))))))))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#first-event\"}),\"First event\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#second-event\"}),\"Second event\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#third-event\"}),\"Third event\"),mdx(\"pre\",{parentName:\"li\"},mdx(\"code\",_extends({parentName:\"pre\"},{}),\"    - [**awslogs-multiline-pattern**](#awslogs-multiline-pattern)\\n\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#first-event-1\"}),\"First event\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#second-event-1\"}),\"Second event\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#third-event-1\"}),\"Third event\"),mdx(\"pre\",{parentName:\"li\"},mdx(\"code\",_extends({parentName:\"pre\"},{}),\"    - [**tag**](#tag)\\n  - [**Credentials**](#credentials)\\n- [ETW logging driver](#etw-logging-driver)\\n  - [**Usage**](#usage-6)\\n- [Fluentd logging driver](#fluentd-logging-driver)\\n  - [**Usage**](#usage-7)\\n  - [**Options**](#options-3)\\n    - [**fluentd-address**](#fluentd-address)\\n    - [**tag**](#tag-1)\\n    - [**labels, env, and env-regex**](#labels-env-and-env-regex)\\n    - [**fluentd-async-connect**](#fluentd-async-connect)\\n    - [**fluentd-buffer-limit**](#fluentd-buffer-limit)\\n    - [**fluentd-retry-wait**](#fluentd-retry-wait)\\n    - [**fluentd-max-retries**](#fluentd-max-retries)\\n    - [**fluentd-sub-second-precision**](#fluentd-sub-second-precision)\\n  - [**Fluentd daemon management with Docker**](#fluentd-daemon-management-with-docker)\\n    - [**Test container loggers**](#test-container-loggers)\\n- [Google Cloud Logging driver](#google-cloud-logging-driver)\\n  - [**Usage**](#usage-8)\\n  - [**gcplogs options**](#gcplogs-options)\\n- [Journald logging driver](#journald-logging-driver)\\n  - [**Usage**](#usage-9)\\n  - [**Options**](#options-4)\\n  - [**Note regarding container names**](#note-regarding-container-names)\\n  - [**Retrieve log messages with\\xA0journalctl**](#retrieve-log-messages-withjournalctl)\\n    - [**View logs for a container with a TTY enabled**](#view-logs-for-a-container-with-a-tty-enabled)\\n  - [**Retrieve log messages with the\\xA0journal\\xA0API**](#retrieve-log-messages-with-thejournalapi)\\n- [Splunk logging driver](#splunk-logging-driver)\\n  - [**Usage**](#usage-10)\\n  - [**Splunk options**](#splunk-options)\\n    - [**Message formats**](#message-formats)\\n  - [**Advanced options**](#advanced-options)\\n\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#registry-as-a-pull-through-cache\"}),\"Registry as a pull through cache\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-case\"}),\"Use-case\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#alternatives\"}),mdx(\"strong\",{parentName:\"a\"},\"Alternatives\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#gotcha\"}),mdx(\"strong\",{parentName:\"a\"},\"Gotcha\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#solution\"}),mdx(\"strong\",{parentName:\"a\"},\"Solution\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#how-does-it-work\"}),\"How does it work?\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#what-if-the-content-changes-on-the-hub\"}),mdx(\"strong\",{parentName:\"a\"},\"What if the content changes on the Hub?\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#what-about-my-disk\"}),mdx(\"strong\",{parentName:\"a\"},\"What about my disk?\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#run-a-registry-as-a-pull-through-cache\"}),\"Run a Registry as a pull-through cache\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configure-the-cache\"}),mdx(\"strong\",{parentName:\"a\"},\"Configure the cache\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configure-the-docker-daemon-2\"}),mdx(\"strong\",{parentName:\"a\"},\"Configure the Docker daemon\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-case-the-china-registry-mirror\"}),\"Use case: the China registry mirror\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#work-with-external-tools\"}),\"Work with external tools\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-powershell-dsc\"}),\"Use PowerShell DSC\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#requirements\"}),mdx(\"strong\",{parentName:\"a\"},\"Requirements\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#installation\"}),mdx(\"strong\",{parentName:\"a\"},\"Installation\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#usage-11\"}),mdx(\"strong\",{parentName:\"a\"},\"Usage\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#install-docker\"}),mdx(\"strong\",{parentName:\"a\"},\"Install Docker\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#images-1\"}),mdx(\"strong\",{parentName:\"a\"},\"Images\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#containers-1\"}),mdx(\"strong\",{parentName:\"a\"},\"Containers\"))))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#chef\"}),\"Chef\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#docker-cookbook\"}),mdx(\"strong\",{parentName:\"a\"},\"Docker Cookbook\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#scope-1\"}),mdx(\"strong\",{parentName:\"a\"},\"Scope\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#requirements-1\"}),mdx(\"strong\",{parentName:\"a\"},\"Requirements\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#platform-support\"}),mdx(\"strong\",{parentName:\"a\"},\"Platform Support\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#cookbook-dependencies\"}),mdx(\"strong\",{parentName:\"a\"},\"Cookbook Dependencies\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#docker-group\"}),mdx(\"strong\",{parentName:\"a\"},\"Docker Group\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#usage-12\"}),mdx(\"strong\",{parentName:\"a\"},\"Usage\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#test-cookbooks-as-examples\"}),mdx(\"strong\",{parentName:\"a\"},\"Test Cookbooks as Examples\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#resources-overview\"}),mdx(\"strong\",{parentName:\"a\"},\"Resources Overview\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#getting-started\"}),mdx(\"strong\",{parentName:\"a\"},\"Getting Started\"))))))))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#pull-latest-image\"}),\"Pull latest image\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#run-container-mapping-containers-port-80-to-the-hosts-port-80\"}),\"Run container mapping containers port 80 to the host\\\\'s port 80\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#login-to-private-registry\"}),\"Login to private registry\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#pull-tagged-image\"}),\"Pull tagged image\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#run-container\"}),\"Run container\"),mdx(\"pre\",{parentName:\"li\"},mdx(\"code\",_extends({parentName:\"pre\"},{}),\"    - [**Resources**](#resources)\\n    - [**docker_installation**](#docker_installation)\\n    - [**docker_installation_tarball**](#docker_installation_tarball)\\n    - [**docker_installation_script**](#docker_installation_script)\\n    - [**docker_installation_package**](#docker_installation_package)\\n    - [**docker_service_manager**](#docker_service_manager)\\n    - [**docker_service_manager_execute**](#docker_service_manager_execute)\\n    - [**docker_service_manager_sysvinit**](#docker_service_manager_sysvinit)\\n    - [**docker_service_manager_upstart**](#docker_service_manager_upstart)\\n    - [**docker_service_manager_systemd**](#docker_service_manager_systemd)\\n    - [**docker_service**](#docker_service)\\n    - [**docker_image**](#docker_image)\\n    - [**docker_tag**](#docker_tag)\\n    - [**docker_container**](#docker_container)\\n    - [**docker_registry**](#docker_registry)\\n    - [**docker_network**](#docker_network)\\n    - [**docker_volume**](#docker_volume)\\n    - [**docker_execute**](#docker_execute)\\n    - [**Maintainers**](#maintainers)\\n    - [**License**](#license)\\n\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#security\"}),\"Security\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#docker-security\"}),\"Docker security\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#kernel-namespaces\"}),mdx(\"strong\",{parentName:\"a\"},\"Kernel namespaces\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#control-groups-2\"}),mdx(\"strong\",{parentName:\"a\"},\"Control groups\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#docker-daemon-attack-surface\"}),mdx(\"strong\",{parentName:\"a\"},\"Docker daemon attack surface\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#linux-kernel-capabilities\"}),mdx(\"strong\",{parentName:\"a\"},\"Linux kernel capabilities\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#other-kernel-security-features\"}),mdx(\"strong\",{parentName:\"a\"},\"Other kernel security features\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#conclusions\"}),mdx(\"strong\",{parentName:\"a\"},\"Conclusions\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#related-information-6\"}),mdx(\"strong\",{parentName:\"a\"},\"Related information\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#docker-security-non-events\"}),\"Docker security non-events\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#protect-the-docker-daemon-socket\"}),\"Protect the Docker daemon socket\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#create-a-ca-server-and-client-keys-with-openssl\"}),mdx(\"strong\",{parentName:\"a\"},\"Create a CA, server and client keys with OpenSSL\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#secure-by-default\"}),mdx(\"strong\",{parentName:\"a\"},\"Secure by default\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#other-modes\"}),mdx(\"strong\",{parentName:\"a\"},\"Other modes\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#daemon-modes\"}),mdx(\"strong\",{parentName:\"a\"},\"Daemon modes\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#client-modes\"}),mdx(\"strong\",{parentName:\"a\"},\"Client modes\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#connecting-to-the-secure-docker-port-usingcurl\"}),mdx(\"strong\",{parentName:\"a\"},\"Connecting to the secure Docker port using\\xA0curl\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#related-information-7\"}),mdx(\"strong\",{parentName:\"a\"},\"Related information\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#verify-repository-client-with-certificates\"}),\"Verify repository client with certificates\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#understanding-the-configuration\"}),mdx(\"strong\",{parentName:\"a\"},\"Understanding the configuration\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#creating-the-client-certificates\"}),mdx(\"strong\",{parentName:\"a\"},\"Creating the client certificates\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#troubleshooting-tips\"}),mdx(\"strong\",{parentName:\"a\"},\"Troubleshooting tips\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#related-information-8\"}),mdx(\"strong\",{parentName:\"a\"},\"Related Information\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-trusted-images\"}),\"Use Trusted Images\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#content-trust-in-docker\"}),mdx(\"strong\",{parentName:\"a\"},\"Content trust in Docker\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#about-trust-in-docker\"}),mdx(\"strong\",{parentName:\"a\"},\"About trust in Docker\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#survey-of-typical-content-trust-operations\"}),mdx(\"strong\",{parentName:\"a\"},\"Survey of typical content trust operations\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#related-information-9\"}),mdx(\"strong\",{parentName:\"a\"},\"Related information\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#automation-with-content-trust\"}),mdx(\"strong\",{parentName:\"a\"},\"Automation with content trust\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#bypass-requests-for-passphrases\"}),mdx(\"strong\",{parentName:\"a\"},\"Bypass requests for passphrases\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#building-with-content-trust\"}),mdx(\"strong\",{parentName:\"a\"},\"Building with content trust\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#related-information-10\"}),mdx(\"strong\",{parentName:\"a\"},\"Related information\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#delegations-for-content-trust\"}),mdx(\"strong\",{parentName:\"a\"},\"Delegations for content trust\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#generating-delegation-keys\"}),mdx(\"strong\",{parentName:\"a\"},\"Generating delegation keys\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#adding-a-delegation-key-to-an-existing-repository\"}),mdx(\"strong\",{parentName:\"a\"},\"Adding a delegation key to an existing repository\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#removing-a-delegation-key-from-an-existing-repository\"}),mdx(\"strong\",{parentName:\"a\"},\"Removing a delegation key from an existing repository\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#removing-thetargetsreleasesdelegation-entirely-from-a-repository\"}),mdx(\"strong\",{parentName:\"a\"},\"Removing the\\xA0targets/releases\\xA0delegation entirely from a repository\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#pushing-trusted-data-as-a-collaborator\"}),mdx(\"strong\",{parentName:\"a\"},\"Pushing trusted data as a collaborator\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#docker-pushbehavior\"}),mdx(\"strong\",{parentName:\"a\"},\"docker push\\xA0behavior\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#docker-pullanddocker-buildbehavior\"}),mdx(\"strong\",{parentName:\"a\"},\"docker pull\\xA0and\\xA0docker build\\xA0behavior\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#related-information-11\"}),mdx(\"strong\",{parentName:\"a\"},\"Related information\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#deploy-notary-server-with-compose\"}),mdx(\"strong\",{parentName:\"a\"},\"Deploy Notary Server with Compose\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#if-you-want-to-use-notary-in-production\"}),mdx(\"strong\",{parentName:\"a\"},\"If you want to use Notary in production\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#manage-keys-for-content-trust\"}),mdx(\"strong\",{parentName:\"a\"},\"Manage keys for content trust\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#choosing-a-passphrase\"}),mdx(\"strong\",{parentName:\"a\"},\"Choosing a passphrase\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#back-up-your-keys\"}),mdx(\"strong\",{parentName:\"a\"},\"Back up your keys\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#hardware-storage-and-signing\"}),mdx(\"strong\",{parentName:\"a\"},\"Hardware storage and signing\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#lost-keys\"}),mdx(\"strong\",{parentName:\"a\"},\"Lost keys\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#related-information-12\"}),mdx(\"strong\",{parentName:\"a\"},\"Related information\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#play-in-a-content-trust-sandbox\"}),mdx(\"strong\",{parentName:\"a\"},\"Play in a content trust sandbox\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#what-is-in-the-sandbox\"}),mdx(\"strong\",{parentName:\"a\"},\"What is in the sandbox?\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#build-the-sandbox\"}),mdx(\"strong\",{parentName:\"a\"},\"Build the sandbox\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#playing-in-the-sandbox\"}),mdx(\"strong\",{parentName:\"a\"},\"Playing in the sandbox\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#more-play-in-the-sandbox\"}),mdx(\"strong\",{parentName:\"a\"},\"More play in the sandbox\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#cleaning-up-your-sandbox\"}),mdx(\"strong\",{parentName:\"a\"},\"Cleaning up your sandbox\"))))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#antivirus-software-and-docker\"}),\"Antivirus software and Docker\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#apparmor-security-profiles-for-docker\"}),\"AppArmor security profiles for Docker\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#understand-the-policies\"}),mdx(\"strong\",{parentName:\"a\"},\"Understand the policies\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#load-and-unload-profiles\"}),mdx(\"strong\",{parentName:\"a\"},\"Load and unload profiles\"))))))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#stop-apparmor\"}),\"stop apparmor\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#unload-the-profile\"}),\"unload the profile\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#start-apparmor\"}),\"start apparmor\"),mdx(\"pre\",{parentName:\"li\"},mdx(\"code\",_extends({parentName:\"pre\"},{}),\"    - [**Resources for writing profiles**](#resources-for-writing-profiles)\\n  - [**Nginx example profile**](#nginx-example-profile)\\n\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#deny-write-to-files-not-in-procnumber-or-procsys\"}),\"deny write to files not in /proc/\",mdx(\"inlineCode\",{parentName:\"a\"},\"<number>\"),\"/\",mdx(\"strong\",{parentName:\"a\"},\" or /proc/sys/\")),mdx(\"pre\",{parentName:\"li\"},mdx(\"code\",_extends({parentName:\"pre\"},{}),\"  - [**Debug AppArmor**](#debug-apparmor)\\n    - [**Use dmesg**](#use-dmesg)\\n    - [**Use aa-status**](#use-aa-status)\\n  - [**Contribute Docker's AppArmor code**](#contribute-dockers-apparmor-code)\\n- [Seccomp security profiles for Docker](#seccomp-security-profiles-for-docker)\\n  - [**Pass a profile for a container**](#pass-a-profile-for-a-container)\\n    - [**Significant syscalls blocked by the default profile**](#significant-syscalls-blocked-by-the-default-profile)\\n  - [**Run without the default seccomp profile**](#run-without-the-default-seccomp-profile)\\n- [Isolate containers with a user namespace](#isolate-containers-with-a-user-namespace)\\n  - [**About remapping and subordinate user and group IDs**](#about-remapping-and-subordinate-user-and-group-ids)\\n  - [**Prerequisites**](#prerequisites-14)\\n  - [**Enable userns-remap on the daemon**](#enable-userns-remap-on-the-daemon)\\n  - [**Disable namespace remapping for a container**](#disable-namespace-remapping-for-a-container)\\n  - [**User namespace known limitations**](#user-namespace-known-limitations)\\n\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#scale-your-app\"}),\"Scale Your App\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#swarm-mode-overview\"}),\"Swarm mode overview\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#feature-highlights\"}),mdx(\"strong\",{parentName:\"a\"},\"Feature highlights\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#whats-next\"}),mdx(\"strong\",{parentName:\"a\"},\"What's next?\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#swarm-mode-key-concepts-and-tutorial\"}),mdx(\"strong\",{parentName:\"a\"},\"Swarm mode key concepts and tutorial\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#swarm-mode-cli-commands\"}),mdx(\"strong\",{parentName:\"a\"},\"Swarm mode CLI commands\"))))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#swarm-mode-key-concepts\"}),\"Swarm mode key concepts\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#what-is-a-swarm\"}),mdx(\"strong\",{parentName:\"a\"},\"What is a swarm?\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#nodes\"}),mdx(\"strong\",{parentName:\"a\"},\"Nodes\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#services-and-tasks\"}),mdx(\"strong\",{parentName:\"a\"},\"Services and tasks\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#load-balancing\"}),mdx(\"strong\",{parentName:\"a\"},\"Load balancing\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#whats-next-1\"}),mdx(\"strong\",{parentName:\"a\"},\"What's next?\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#getting-started-with-swarm-mode\"}),\"Getting started with swarm mode\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#set-up\"}),mdx(\"strong\",{parentName:\"a\"},\"Set up\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#three-networked-host-machines\"}),mdx(\"strong\",{parentName:\"a\"},\"Three networked host machines\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#docker-engine-112-or-newer\"}),mdx(\"strong\",{parentName:\"a\"},\"Docker Engine 1.12 or newer\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#the-ip-address-of-the-manager-machine\"}),mdx(\"strong\",{parentName:\"a\"},\"The IP address of the manager machine\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#open-protocols-and-ports-between-the-hosts\"}),mdx(\"strong\",{parentName:\"a\"},\"Open protocols and ports between the hosts\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#whats-next-2\"}),mdx(\"strong\",{parentName:\"a\"},\"What's next?\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#create-a-swarm\"}),\"Create a swarm\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#whats-next-3\"}),mdx(\"strong\",{parentName:\"a\"},\"What's next?\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#add-nodes-to-the-swarm\"}),\"Add nodes to the swarm\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#whats-next-4\"}),mdx(\"strong\",{parentName:\"a\"},\"What's next?\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#deploy-a-service-to-the-swarm\"}),\"Deploy a service to the swarm\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#whats-next-5\"}),mdx(\"strong\",{parentName:\"a\"},\"What's next?\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#inspect-a-service-on-the-swarm\"}),\"Inspect a service on the swarm\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#whats-next-6\"}),mdx(\"strong\",{parentName:\"a\"},\"What's next?\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#scale-the-service-in-the-swarm\"}),\"Scale the service in the swarm\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#whats-next-7\"}),mdx(\"strong\",{parentName:\"a\"},\"What's next?\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#delete-the-service-running-on-the-swarm\"}),\"Delete the service running on the swarm\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#whats-next-8\"}),mdx(\"strong\",{parentName:\"a\"},\"What's next?\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#apply-rolling-updates-to-a-service\"}),\"Apply rolling updates to a service\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#whats-next-9\"}),mdx(\"strong\",{parentName:\"a\"},\"What's next?\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#drain-a-node-on-the-swarm\"}),\"Drain a node on the swarm\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#whats-next-10\"}),mdx(\"strong\",{parentName:\"a\"},\"What's next?\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-swarm-mode-routing-mesh\"}),\"Use swarm mode routing mesh\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#publish-a-port-for-a-service\"}),mdx(\"strong\",{parentName:\"a\"},\"Publish a port for a service\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#publish-a-port-for-tcp-only-or-udp-only\"}),mdx(\"strong\",{parentName:\"a\"},\"Publish a port for TCP only or UDP only\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#bypass-the-routing-mesh\"}),mdx(\"strong\",{parentName:\"a\"},\"Bypass the routing mesh\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configure-an-external-load-balancer\"}),mdx(\"strong\",{parentName:\"a\"},\"Configure an external load balancer\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#using-the-routing-mesh\"}),mdx(\"strong\",{parentName:\"a\"},\"Using the routing mesh\"))))))))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configure-haproxy-to-listen-on-port-80\"}),\"Configure HAProxy to listen on port 80\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configure-haproxy-to-route-requests-to-swarm-nodes-on-port-8080\"}),\"Configure HAProxy to route requests to swarm nodes on port 8080\"),mdx(\"pre\",{parentName:\"li\"},mdx(\"code\",_extends({parentName:\"pre\"},{}),\"    - [**Without the routing mesh**](#without-the-routing-mesh)\\n  - [**Learn more**](#learn-more)\\n- [How Swarm Mode Works](#how-swarm-mode-works)\\n  - [**How nodes work**](#how-nodes-work)\\n    - [**Manager nodes**](#manager-nodes)\\n    - [**Worker nodes**](#worker-nodes)\\n    - [**Change roles**](#change-roles)\\n    - [**Learn more**](#learn-more-1)\\n  - [**How services work**](#how-services-work)\\n    - [**Services, tasks, and containers**](#services-tasks-and-containers)\\n    - [**Tasks and scheduling**](#tasks-and-scheduling)\\n    - [**Replicated and global services**](#replicated-and-global-services)\\n    - [**Learn more**](#learn-more-2)\\n  - [**Manage swarm security with public key infrastructure (PKI)**](#manage-swarm-security-with-public-key-infrastructure-pki)\\n    - [**Rotating the CA certificate**](#rotating-the-ca-certificate)\\n    - [**Learn More**](#learn-more-3)\\n  - [**Swarm task states**](#swarm-task-states)\\n    - [**View task state**](#view-task-state)\\n    - [**Where to go next**](#where-to-go-next)\\n- [Run Docker Engine in swarm mode](#run-docker-engine-in-swarm-mode)\\n  - [**Create a swarm**](#create-a-swarm-1)\\n    - [**Configure the advertise address**](#configure-the-advertise-address)\\n    - [**View the join command or update a swarm join token**](#view-the-join-command-or-update-a-swarm-join-token)\\n  - [**Learn more**](#learn-more-4)\\n- [Join nodes to a swarm](#join-nodes-to-a-swarm)\\n  - [**Join as a worker node**](#join-as-a-worker-node)\\n  - [**Join as a manager node**](#join-as-a-manager-node)\\n  - [**Learn More**](#learn-more-5)\\n- [Manage nodes in a swarm](#manage-nodes-in-a-swarm)\\n  - [**List nodes**](#list-nodes)\\n  - [**Inspect an individual node**](#inspect-an-individual-node)\\n  - [**Update a node**](#update-a-node)\\n    - [**Change node availability**](#change-node-availability)\\n    - [**Add or remove label metadata**](#add-or-remove-label-metadata)\\n    - [**Promote or demote a node**](#promote-or-demote-a-node)\\n  - [**Install plugins on swarm nodes**](#install-plugins-on-swarm-nodes)\\n  - [**Leave the swarm**](#leave-the-swarm)\\n  - [**Learn more**](#learn-more-6)\\n- [Deploy services to a swarm](#deploy-services-to-a-swarm)\\n  - [**Create a service**](#create-a-service)\\n    - [**Create a service using an image on a private registry**](#create-a-service-using-an-image-on-a-private-registry)\\n  - [**Update a service**](#update-a-service)\\n  - [**Remove a service**](#remove-a-service)\\n  - [**Service configuration details**](#service-configuration-details)\\n    - [**Configure the runtime environment**](#configure-the-runtime-environment)\\n    - [**Update the command an existing service runs**](#update-the-command-an-existing-service-runs)\\n    - [**Specify the image version a service should use**](#specify-the-image-version-a-service-should-use)\\n    - [**Update a service's image after creation**](#update-a-services-image-after-creation)\\n    - [**Publish ports**](#publish-ports-1)\\n    - [**Connect the service to an overlay network**](#connect-the-service-to-an-overlay-network)\\n    - [**Grant a service access to secrets**](#grant-a-service-access-to-secrets)\\n    - [**Customize a service's isolation mode**](#customize-a-services-isolation-mode)\\n    - [**Control service placement**](#control-service-placement)\\n    - [**Configure a service's update behavior**](#configure-a-services-update-behavior)\\n    - [**Roll back to the previous version of a service**](#roll-back-to-the-previous-version-of-a-service)\\n    - [**Automatically roll back if an update fails**](#automatically-roll-back-if-an-update-fails)\\n    - [**Give a service access to volumes or bind mounts**](#give-a-service-access-to-volumes-or-bind-mounts)\\n    - [**Create services using templates**](#create-services-using-templates)\\n  - [**Learn More**](#learn-more-7)\\n- [Store configuration data using Docker Configs](#store-configuration-data-using-docker-configs)\\n  - [**About configs**](#about-configs)\\n    - [**Windows support**](#windows-support)\\n  - [**How Docker manages configs**](#how-docker-manages-configs)\\n  - [**Read more about\\xA0docker config\\xA0commands**](#read-more-aboutdocker-configcommands)\\n  - [**Examples**](#examples-2)\\n    - [**Defining and using configs in compose files**](#defining-and-using-configs-in-compose-files)\\n    - [**Simple example: Get started with configs**](#simple-example-get-started-with-configs)\\n    - [**Simple example: Use configs in a Windows service**](#simple-example-use-configs-in-a-windows-service)\\n    - [**Advanced example: Use configs with a Nginx service**](#advanced-example-use-configs-with-a-nginx-service)\\n    - [**Example: Rotate a config**](#example-rotate-a-config)\\n- [Manage sensitive data with Docker secrets](#manage-sensitive-data-with-docker-secrets)\\n  - [**About secrets**](#about-secrets)\\n    - [**Windows support**](#windows-support-1)\\n  - [**How Docker manages secrets**](#how-docker-manages-secrets)\\n  - [**Read more about\\xA0docker secret\\xA0commands**](#read-more-aboutdocker-secretcommands)\\n  - [**Examples**](#examples-3)\\n    - [**Defining and using secrets in compose files**](#defining-and-using-secrets-in-compose-files)\\n    - [**Simple example: Get started with secrets**](#simple-example-get-started-with-secrets)\\n    - [**Simple example: Use secrets in a Windows service**](#simple-example-use-secrets-in-a-windows-service)\\n    - [**Intermediate example: Use secrets with a Nginx service**](#intermediate-example-use-secrets-with-a-nginx-service)\\n    - [**Advanced example: Use secrets with a WordPress service**](#advanced-example-use-secrets-with-a-wordpress-service)\\n    - [**Example: Rotate a secret**](#example-rotate-a-secret)\\n  - [**Build support for Docker Secrets into your images**](#build-support-for-docker-secrets-into-your-images)\\n  - [**Use Secrets in Compose**](#use-secrets-in-compose)\\n- [Lock your swarm to protect its encryption key](#lock-your-swarm-to-protect-its-encryption-key)\\n  - [**Initialize a swarm with autolocking enabled**](#initialize-a-swarm-with-autolocking-enabled)\\n  - [**Enable or disable autolock on an existing swarm**](#enable-or-disable-autolock-on-an-existing-swarm)\\n  - [**Unlock a swarm**](#unlock-a-swarm)\\n  - [**View the current unlock key for a running swarm**](#view-the-current-unlock-key-for-a-running-swarm)\\n  - [**Rotate the unlock key**](#rotate-the-unlock-key)\\n- [Administer and maintain a swarm of Docker Engines](#administer-and-maintain-a-swarm-of-docker-engines)\\n  - [**Operate manager nodes in a swarm**](#operate-manager-nodes-in-a-swarm)\\n    - [**Maintain the quorum of managers**](#maintain-the-quorum-of-managers)\\n  - [**Configure the manager to advertise on a static IP address**](#configure-the-manager-to-advertise-on-a-static-ip-address)\\n  - [**Add manager nodes for fault tolerance**](#add-manager-nodes-for-fault-tolerance)\\n    - [**Distribute manager nodes**](#distribute-manager-nodes)\\n    - [**Run manager-only nodes**](#run-manager-only-nodes)\\n  - [**Add worker nodes for load balancing**](#add-worker-nodes-for-load-balancing)\\n  - [**Monitor swarm health**](#monitor-swarm-health)\\n  - [**Troubleshoot a manager node**](#troubleshoot-a-manager-node)\\n  - [**Forcibly remove a node**](#forcibly-remove-a-node)\\n  - [**Back up the swarm**](#back-up-the-swarm)\\n  - [**Recover from disaster**](#recover-from-disaster)\\n    - [**Restore from a backup**](#restore-from-a-backup)\\n    - [**Recover from losing the quorum**](#recover-from-losing-the-quorum)\\n\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#from-the-node-to-recover\"}),\"From the node to recover\"),mdx(\"pre\",{parentName:\"li\"},mdx(\"code\",_extends({parentName:\"pre\"},{}),\"  - [**Force the swarm to rebalance**](#force-the-swarm-to-rebalance)\\n- [Raft consensus in swarm mode](#raft-consensus-in-swarm-mode)\\n\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#extended-docker\"}),\"Extended Docker\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#docker-engine-managed-plugin-system\"}),\"Docker Engine managed plugin system\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#installing-and-using-a-plugin\"}),mdx(\"strong\",{parentName:\"a\"},\"Installing and using a plugin\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#developing-a-plugin\"}),mdx(\"strong\",{parentName:\"a\"},\"Developing a plugin\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#debugging-plugins\"}),mdx(\"strong\",{parentName:\"a\"},\"Debugging plugins\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#access-authorization-plugin\"}),\"Access authorization plugin\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#basic-principles\"}),mdx(\"strong\",{parentName:\"a\"},\"Basic principles\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#default-user-authorization-mechanism\"}),mdx(\"strong\",{parentName:\"a\"},\"Default user authorization mechanism\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#basic-architecture\"}),mdx(\"strong\",{parentName:\"a\"},\"Basic architecture\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#docker-client-flows\"}),mdx(\"strong\",{parentName:\"a\"},\"Docker client flows\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#setting-up-docker-daemon\"}),mdx(\"strong\",{parentName:\"a\"},\"Setting up Docker daemon\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#calling-authorized-command-allow\"}),mdx(\"strong\",{parentName:\"a\"},\"Calling authorized command (allow)\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#calling-unauthorized-command-deny\"}),mdx(\"strong\",{parentName:\"a\"},\"Calling unauthorized command (deny)\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#error-from-plugins\"}),mdx(\"strong\",{parentName:\"a\"},\"Error from plugins\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#api-schema-and-implementation\"}),mdx(\"strong\",{parentName:\"a\"},\"API schema and implementation\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#request-authorization\"}),mdx(\"strong\",{parentName:\"a\"},\"Request authorization\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#response-authorization\"}),mdx(\"strong\",{parentName:\"a\"},\"Response authorization\"))))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-docker-engine-plugins\"}),\"Use Docker Engine plugins\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#types-of-plugins\"}),mdx(\"strong\",{parentName:\"a\"},\"Types of plugins\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#installing-a-plugin\"}),mdx(\"strong\",{parentName:\"a\"},\"Installing a plugin\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#finding-a-plugin\"}),mdx(\"strong\",{parentName:\"a\"},\"Finding a plugin\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#network-plugins\"}),mdx(\"strong\",{parentName:\"a\"},\"Network plugins\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#volume-plugins\"}),mdx(\"strong\",{parentName:\"a\"},\"Volume plugins\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#authorization-plugins\"}),mdx(\"strong\",{parentName:\"a\"},\"Authorization plugins\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#troubleshooting-a-plugin\"}),mdx(\"strong\",{parentName:\"a\"},\"Troubleshooting a plugin\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#writing-a-plugin\"}),mdx(\"strong\",{parentName:\"a\"},\"Writing a plugin\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#docker-network-driver-plugins\"}),\"Docker network driver plugins\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#network-plugins-and-swarm-mode\"}),mdx(\"strong\",{parentName:\"a\"},\"Network plugins and swarm mode\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#use-network-driver-plugins\"}),mdx(\"strong\",{parentName:\"a\"},\"Use network driver plugins\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#find-network-plugins\"}),mdx(\"strong\",{parentName:\"a\"},\"Find network plugins\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#write-a-network-plugin\"}),mdx(\"strong\",{parentName:\"a\"},\"Write a network plugin\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#network-plugin-protocol\"}),mdx(\"strong\",{parentName:\"a\"},\"Network plugin protocol\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#related-information-13\"}),mdx(\"strong\",{parentName:\"a\"},\"Related Information\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#docker-volume-plugins\"}),\"Docker volume plugins\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#changelog\"}),mdx(\"strong\",{parentName:\"a\"},\"Changelog\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#1130\"}),mdx(\"strong\",{parentName:\"a\"},\"1.13.0\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#1120\"}),mdx(\"strong\",{parentName:\"a\"},\"1.12.0\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#1100\"}),mdx(\"strong\",{parentName:\"a\"},\"1.10.0\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#180\"}),mdx(\"strong\",{parentName:\"a\"},\"1.8.0\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#command-line-changes\"}),mdx(\"strong\",{parentName:\"a\"},\"Command-line changes\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#--volume\"}),mdx(\"strong\",{parentName:\"a\"},\"--volume\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#volumedriver\"}),mdx(\"strong\",{parentName:\"a\"},\"volumedriver\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#create-a-volumedriver\"}),mdx(\"strong\",{parentName:\"a\"},\"Create a VolumeDriver\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#volume-plugin-protocol\"}),mdx(\"strong\",{parentName:\"a\"},\"Volume plugin protocol\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#volumedrivercreate\"}),mdx(\"strong\",{parentName:\"a\"},\"/VolumeDriver.Create\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#volumedriverremove\"}),mdx(\"strong\",{parentName:\"a\"},\"/VolumeDriver.Remove\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#volumedrivermount\"}),mdx(\"strong\",{parentName:\"a\"},\"/VolumeDriver.Mount\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#volumedriverpath\"}),mdx(\"strong\",{parentName:\"a\"},\"/VolumeDriver.Path\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#volumedriverunmount\"}),mdx(\"strong\",{parentName:\"a\"},\"/VolumeDriver.Unmount\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#volumedriverget\"}),mdx(\"strong\",{parentName:\"a\"},\"/VolumeDriver.Get\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#volumedriverlist\"}),mdx(\"strong\",{parentName:\"a\"},\"/VolumeDriver.List\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#volumedrivercapabilities\"}),mdx(\"strong\",{parentName:\"a\"},\"/VolumeDriver.Capabilities\"))))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#plugin-config-version-1-of-plugin-v2\"}),\"Plugin Config Version 1 of Plugin V2\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#configfield-descriptions\"}),mdx(\"strong\",{parentName:\"a\"},\"Config\\xA0Field Descriptions\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#example-config\"}),mdx(\"strong\",{parentName:\"a\"},\"Example Config\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#docker-plugin-api\"}),\"Docker Plugin API\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#what-plugins-are\"}),mdx(\"strong\",{parentName:\"a\"},\"What plugins are\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#plugin-discovery\"}),mdx(\"strong\",{parentName:\"a\"},\"Plugin discovery\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#json-specification\"}),mdx(\"strong\",{parentName:\"a\"},\"JSON specification\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#plugin-lifecycle\"}),mdx(\"strong\",{parentName:\"a\"},\"Plugin lifecycle\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#plugin-activation\"}),mdx(\"strong\",{parentName:\"a\"},\"Plugin activation\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#systemd-socket-activation\"}),mdx(\"strong\",{parentName:\"a\"},\"Systemd socket activation\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#api-design\"}),mdx(\"strong\",{parentName:\"a\"},\"API design\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#handshake-api\"}),mdx(\"strong\",{parentName:\"a\"},\"Handshake API\")),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#pluginactivate\"}),mdx(\"strong\",{parentName:\"a\"},\"/Plugin.Activate\"))))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#plugin-retries\"}),mdx(\"strong\",{parentName:\"a\"},\"Plugin retries\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"#plugins-helpers\"}),mdx(\"strong\",{parentName:\"a\"},\"Plugins helpers\")))))))))),mdx(\"h1\",null,\"Important Links\"),mdx(\"p\",null,mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/get-started/\"}),\"https://docs.docker.com/get-started/\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/samples/\"}),\"Samples\"),\": Our samples include multiple examples of popular software running in containers, and some good labs that teach best practices.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/userguide/\"}),\"User Guide\"),\": The user guide has several examples that explain networking and storage in greater depth than was covered here.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/admin/\"}),\"Admin Guide\"),\": Covers how to manage a Dockerized production environment.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://training.docker.com/\"}),\"Training\"),\": Official Docker courses that offer in-person instruction and virtual classroom environments.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://blog.docker.com/\"}),\"Blog\"),\": Covers what's going on with Docker lately.\")),mdx(\"h1\",null,\"Code Links\"),mdx(\"p\",null,mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/docker/labs\"}),\"https://github.com/docker/labs\")),mdx(\"h1\",null,\"Get Started with Docker\"),mdx(\"h2\",null,mdx(\"a\",_extends({parentName:\"h2\"},{\"href\":\"https://docs.docker.com/install/\"}),\"Get Docker\")),mdx(\"p\",null,\"Docker is available in two editions: Community Edition (CE) and Enterprise Edition (EE).\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Docker Community Edition (CE)\"),\" is ideal for developers and small teams looking to get started with Docker and experimenting with container-based apps. Docker CE has two update channels, stable and edge:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Stable gives you reliable updates every quarter\"),mdx(\"li\",{parentName:\"ul\"},\"Edge gives you new features every month\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Docker Enterprise Edition (EE)\"),\" is designed for enterprise development and IT teams who build, ship, and run business critical applications in production at scale.\"),mdx(\"p\",null,\"Table \\u2011 Capabilities of different Docker editions\"),mdx(\"hr\",null),mdx(\"p\",null,\"  Capabilities                                                        Community Edition   Enterprise Edition Basic   Enterprise Edition Standard   Enterprise Edition Advanced\\nContainer engine and built in orchestration, networking, security   yup                 yup                        yup                           yup\\nCertified infrastructure, plugins and ISV containers                \\xA0                   yup                        yup                           yup\\nImage management                                                    \\xA0                   \\xA0                          yup                           yup\\nContainer app management                                            \\xA0                   \\xA0                          yup                           yup\\nImage security scanning                                             \\xA0                   \\xA0                          \\xA0                             yup\"),mdx(\"hr\",null),mdx(\"h3\",null,\"Supported platforms\"),mdx(\"p\",null,\"Docker CE and EE are available on multiple platforms, on cloud and on-premises. Use the following tables to choose the best installation path for you.\"),mdx(\"p\",null,\"Table \\u2011 Desktop Installations\"),mdx(\"hr\",null),mdx(\"p\",null,\"  Platform                                                                                           Docker CE x86_64   Docker CE ARM   Docker EE\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/docker-for-mac/install/\"}),\"Docker for Mac (macOS)\"),\"                          Yup\",mdx(\"br\",{parentName:\"p\"}),\"\\n\",\"\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/docker-for-windows/install/\"}),\"Docker for Windows (Microsoft Windows 10)\"),\"   yup                                \"),mdx(\"hr\",null),mdx(\"p\",null,\"Table \\u2011 Cloud Installations\"),mdx(\"hr\",null),mdx(\"p\",null,\"  Platform                                                            Docker CE x86_64   Docker CE ARM   Docker EE\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/docker-for-aws/\"}),\"Amazon Web Services\"),\"      Yup                                Yup\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/docker-for-azure/\"}),\"Microsoft Azure\"),\"        yup                                Yup\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/docker-for-ibm-cloud/\"}),\"IBM Cloud (Beta)\"),\"                                      yup\"),mdx(\"hr\",null),mdx(\"h3\",null,\"Time-based release schedule\"),mdx(\"p\",null,\"Starting with Docker 17.03, Docker uses a time-based release schedule.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Docker CE Edge releases generally happen monthly.\"),mdx(\"li\",{parentName:\"ul\"},\"Docker CE Stable releases generally happen quarterly, with patch releases as needed.\"),mdx(\"li\",{parentName:\"ul\"},\"Docker EE releases generally happen twice per year, with patch releases as needed.\")),mdx(\"h3\",null,\"Updates, and patches\"),mdx(\"p\",null,\"A given Docker EE release receives patches and updates for at least\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"one year\"),\"\\xA0after it is released.\"),mdx(\"p\",null,\"A given Docker CE Stable release receives patches and updates for\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"one month after the next Docker CE Stable release\"),\".\"),mdx(\"p\",null,\"A given Docker CE Edge release does not receive any patches or updates after a subsequent Docker CE Edge or Stable release.\"),mdx(\"h3\",null,\"Prior releases\"),mdx(\"p\",null,\"Instructions for installing prior releases of Docker can be found in the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/docsarchive/\"}),\"Docker archives\"),\".\"),mdx(\"h3\",null,\"Install\"),mdx(\"h4\",null,\"Manage Docker as a non-root user\"),mdx(\"p\",null,\"The\\xA0docker\\xA0daemon binds to a Unix socket instead of a TCP port. By default that Unix socket is owned by the user\\xA0root\\xA0and other users can only access it using\\xA0sudo. The\\xA0docker\\xA0daemon always runs as the\\xA0root\\xA0user.\"),mdx(\"p\",null,\"If you don't want to use\\xA0sudo\\xA0when you use the\\xA0docker\\xA0command, create a Unix group called\\xA0docker\\xA0and add users to it. When the\\xA0docker\\xA0daemon starts, it makes the ownership of the Unix socket read/writable by the\\xA0docker\\xA0group.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Warning\"),\": The\\xA0docker\\xA0group grants privileges equivalent to the\\xA0root\\xA0user. For details on how this impacts security in your system, see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/security/security/#docker-daemon-attack-surface\"}),mdx(\"em\",{parentName:\"a\"},\"Docker Daemon Attack Surface\")),\".\"),mdx(\"p\",null,\"To create the\\xA0docker\\xA0group and add your user:\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Create the\\xA0docker\\xA0group.\")),mdx(\"p\",null,\"$ sudo groupadd docker\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Add your user to the\\xA0docker\\xA0group.\")),mdx(\"p\",null,\"$ sudo usermod -aG docker $USER\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Log out and log back in so that your group membership is re-evaluated. If testing on a virtual machine, it may be necessary to restart the virtual machine for changes to take effect.\"),mdx(\"li\",{parentName:\"ol\"},\"On a desktop Linux environment such as X Windows, log out of your session completely and then log back in. Verify that you can run\\xA0docker\\xA0commands without\\xA0sudo.\")),mdx(\"p\",null,\"$ docker run hello-world\"),mdx(\"p\",null,\"This command downloads a test image and runs it in a container. When the container runs, it prints an informational message and exits.\"),mdx(\"p\",null,\"If you initially ran Docker CLI commands using\\xA0sudo\\xA0before adding your user to the\\xA0docker group, you may see the following error, which indicates that your\\xA0\",\"~\",\"/.docker/\\xA0directory was created with incorrect permissions due to the\\xA0sudo\\xA0commands.\"),mdx(\"p\",null,\"WARNING: Error loading config file: /home/user/.docker/config.json -\"),mdx(\"p\",null,\"stat /home/user/.docker/config.json: permission denied\"),mdx(\"p\",null,\"To fix this problem, either remove the\\xA0\",\"~\",\"/.docker/\\xA0directory (it is recreated automatically, but any custom settings are lost), or change its ownership and permissions using the following commands:\"),mdx(\"pre\",null,mdx(\"code\",_extends({parentName:\"pre\"},{\"className\":\"language-bash\"}),\"$ sudo chown \\\"$USER\\\":\\\"$USER\\\" /home/\\\"$USER\\\"/.docker -R\\n$ sudo chmod g+rwx \\\"/home/$USER/.docker\\\" -R\\n\")),mdx(\"h4\",null,\"Configure Docker to start on boot\"),mdx(\"p\",null,\"Most current Linux distributions (RHEL, CentOS, Fedora, Ubuntu 16.04 and higher) use\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/install/linux/linux-postinstall/#systemd\"}),\"systemd\"),\"\\xA0to manage which services start when the system boots. Ubuntu 14.10 and below use\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/install/linux/linux-postinstall/#upstart\"}),\"upstart\"),\".\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"systemd\")),mdx(\"pre\",null,mdx(\"code\",_extends({parentName:\"pre\"},{\"className\":\"language-bash\"}),\"$ sudo systemctl enable docker\\n\")),mdx(\"p\",null,\"To disable this behavior, use\\xA0disable\\xA0instead.\"),mdx(\"pre\",null,mdx(\"code\",_extends({parentName:\"pre\"},{\"className\":\"language-bash\"}),\"$ sudo systemctl disable docker\\n\")),mdx(\"p\",null,\"If you need to add an HTTP Proxy, set a different directory or partition for the Docker runtime files, or make other customizations, see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/admin/systemd/\"}),\"customize your systemd Docker daemon options\"),\".\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"upstart\")),mdx(\"p\",null,\"Docker is automatically configured to start on boot using\\xA0upstart. To disable this behavior, use the following command:\"),mdx(\"p\",null,\"$ echo manual | sudo tee /etc/init/docker.override\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"chkconfig\")),mdx(\"p\",null,\"$ sudo chkconfig docker on\"),mdx(\"h4\",null,\"Use a different storage engine\"),mdx(\"h4\",null,\"Configure where the Docker daemon listens for connections\"),mdx(\"h4\",null,\"Enable IPv6 on the Docker daemon\"),mdx(\"h4\",null,\"Troubleshooting\"),mdx(\"h5\",null,\"Kernel compatibility\"),mdx(\"h5\",null,\"IP forwarding problems\"),mdx(\"h4\",null,\"Specify DNS servers for Docker\"),mdx(\"h4\",null,\"Allow access to the remote API through a firewall\"),mdx(\"h2\",null,\"Docker CE Edge documentation\"),mdx(\"p\",null,\"The current Docker CE Edge release is\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/release-notes/docker-ce/#edge-releases\"}),mdx(\"strong\",{parentName:\"a\"},\"here\")),\".\"),mdx(\"p\",null,\"The Docker CE Edge channel provides monthly releases which allow you to try new features of Docker and verify bug fixes quickly. Each edge release is only supported for one month and does not receive updates after a new Edge release is available.\"),mdx(\"p\",null,\"Stable releases are not published to the Edge channel, so Linux repository users should subscribe to both Edge and Stable channels.\"),mdx(\"p\",null,\"Commercial support is not available for Docker CE. For information about all Docker release channels and expectations about support, see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/install/#docker-channels\"}),\"Docker channels\"),\".\"),mdx(\"p\",null,\"Documentation for API and CLI references is updated with each Edge release as appropriate. However, full documentation for features may not be available until a Docker CE Stable release incorporates the feature.\"),mdx(\"h4\",null,\"Docker CE Edge resources\"),mdx(\"p\",null,\"The\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/edge/engine/reference/commandline/docker/\"}),\"Docker CE Edge CLI reference\"),\"\\xA0includes commands, options, and flags which have not yet been integrated into a Docker CE Stable release.\"),mdx(\"p\",null,\"The\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/edge/engine/reference/commandline/dockerd/\"}),\"Docker CE Edge dockerd reference\"),\"\\xA0includes commands, options, and flags for the Docker daemon which have not yet been integrated into a Docker CE Stable release.\"),mdx(\"h2\",null,mdx(\"a\",_extends({parentName:\"h2\"},{\"href\":\"https://docs.docker.com/compose/install/\"})),\"Get Docker-Compose\"),mdx(\"h3\",null,\"Prerequisites\"),mdx(\"p\",null,\"Docker Compose relies on Docker Engine for any meaningful work, so make sure you have Docker Engine installed either locally or remote, depending on your setup.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"On desktop systems like Docker for Mac and Windows, Docker Compose is included as part of those desktop installs.\"),mdx(\"li\",{parentName:\"ul\"},\"On Linux systems, first install the\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/install/#server\"}),\"Docker\"),\"\\xA0for your OS as described on the Get Docker page, then come back here for instructions on installing Compose on Linux systems.\"),mdx(\"li\",{parentName:\"ul\"},\"To run Compose as a non-root user, see\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/install/linux/linux-postinstall/\"}),\"Manage Docker as a non-root user\"),\".\")),mdx(\"h3\",null,\"Install Compose\"),mdx(\"p\",null,\"Follow the instructions below to install Compose on Mac, Windows, Windows Server 2016, or Linux systems, or find out about alternatives like using the\\xA0pip\\xA0Python package manager or installing Compose as a container.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Mac\"),mdx(\"li\",{parentName:\"ul\"},\"Windows\"),mdx(\"li\",{parentName:\"ul\"},\"Linux\"),mdx(\"li\",{parentName:\"ul\"},\"Alternative Install Options\")),mdx(\"h4\",null,\"Install Compose on Linux systems\"),mdx(\"p\",null,\"On\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"Linux\"),\", you can download the Docker Compose binary from the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/docker/compose/releases\"}),\"Compose repository release page on GitHub\"),\". Follow the instructions from the link, which involve running the\\xA0curl\\xA0command in your terminal to download the binaries. These step by step instructions are also included below.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Run this command to download the latest version of Docker Compose:\")),mdx(\"p\",null,\"sudo curl -L \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/docker/compose/releases/download/1.19.0/docker-compose-%60uname\"}),\"https://github.com/docker/compose/releases/download/1.19.0/docker-compose-`uname\"),\" -s\",mdx(\"inlineCode\",{parentName:\"p\"},\"-\"),\"uname -m` -o /usr/local/bin/docker-compose\"),mdx(\"p\",null,\"Use the latest Compose release number in the download command.\"),mdx(\"p\",null,\"The above command is an\\xA0example, and it may become out-of-date. To ensure you have the latest version, check the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/docker/compose/releases\"}),\"Compose repository release page on GitHub\"),\".\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Apply executable permissions to the binary:\")),mdx(\"p\",null,\"sudo chmod +x /usr/local/bin/docker-compose\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Optionally, install\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/compose/completion/\"}),\"command completion\"),\"\\xA0for the\\xA0bash\\xA0and\\xA0zsh\\xA0shell.\"),mdx(\"li\",{parentName:\"ol\"},\"Test the installation.\")),mdx(\"p\",null,\"$ docker-compose --version\"),mdx(\"p\",null,\"docker-compose version 1.19.0, build 1719ceb\"),mdx(\"h3\",null,\"Master builds\"),mdx(\"p\",null,\"If you're interested in trying out a pre-release build, you can download a binary from\",mdx(\"inlineCode\",{parentName:\"p\"},\"<https://dl.bintray.com/docker-compose/master/>\"),\". Pre-release builds allow you to try out new features before they are released, but may be less stable.\"),mdx(\"h3\",null,\"Upgrading\"),mdx(\"p\",null,\"If you're upgrading from Compose 1.2 or earlier, remove or migrate your existing containers after upgrading Compose. This is because, as of version 1.3, Compose uses Docker labels to keep track of containers, and your containers need to be recreated to add the labels.\"),mdx(\"p\",null,\"If Compose detects containers that were created without labels, it refuses to run so that you don't end up with two sets of them. If you want to keep using your existing containers (for example, because they have data volumes you want to preserve), you can use Compose 1.5.x to migrate them with the following command:\"),mdx(\"p\",null,\"docker-compose migrate-to-labels\"),mdx(\"p\",null,\"Alternatively, if you're not worried about keeping them, you can remove them. Compose just creates new ones.\"),mdx(\"p\",null,\"docker container rm -f -v myapp_web_1 myapp_db_1 ...\"),mdx(\"h3\",null,\"Uninstallation\"),mdx(\"p\",null,\"To uninstall Docker Compose if you installed using\\xA0curl:\"),mdx(\"p\",null,\"sudo rm /usr/local/bin/docker-compose\"),mdx(\"p\",null,\"To uninstall Docker Compose if you installed using\\xA0pip:\"),mdx(\"p\",null,\"pip uninstall docker-compose\"),mdx(\"p\",null,\"Got a \\\"Permission denied\\\" error?\"),mdx(\"p\",null,\"If you get a \\\"Permission denied\\\" error using either of the above methods, you probably do not have the proper permissions to remove\\xA0docker-compose. To force the removal, prepend\\xA0sudoto either of the above commands and run again.\"),mdx(\"h2\",null,\"Docker -- Get Started\"),mdx(\"p\",null,\"Docker is a platform for developers and sysadmins to develop, deploy, and run applications with containers. The use of Linux containers to deploy applications is called containerization. Containers are not new, but their use for easily deploying applications.\"),mdx(\"p\",null,\"Containerization is increasingly popular because containers are:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Flexible: Even the most complex applications can be containerized.\"),mdx(\"li\",{parentName:\"ul\"},\"Lightweight: Containers leverage and share the host kernel.\"),mdx(\"li\",{parentName:\"ul\"},\"Interchangeable: You can deploy updates and upgrades on-the-fly.\"),mdx(\"li\",{parentName:\"ul\"},\"Portable: You can build locally, deploy to the cloud, and run anywhere.\"),mdx(\"li\",{parentName:\"ul\"},\"Scalable: You can increase and automatically distribute container replicas.\"),mdx(\"li\",{parentName:\"ul\"},\"Stackable: You can stack services vertically and on-the-fly.\")),mdx(\"h3\",null,\"Images and containers\"),mdx(\"p\",null,\"A container is launched by running an image. An image is an executable package that includes everything needed to run an application--the code, a runtime, libraries, environment variables, and configuration files.\"),mdx(\"p\",null,\"A container is a runtime instance of an image--what the image becomes in memory when executed (that is, an image with state, or a user process). You can see a list of your running containers with the command, docker ps, just as you would in Linux.\"),mdx(\"h3\",null,\"Containers and virtual machines\"),mdx(\"p\",null,\"A container runs natively on Linux and shares the kernel of the host machine with other containers. It runs a discrete process, taking no more memory than any other executable, making it lightweight.\"),mdx(\"p\",null,\"By contrast, a virtual machine (VM) runs a full-blown \\\"guest\\\" operating system with virtual access to host resources through a hypervisor. In general, VMs provide an environment with more resources than most applications need.\"),mdx(\"h3\",null,\"Orientation and Setup\"),mdx(\"h4\",null,\"Test Docker version\"),mdx(\"p\",null,\"Ensure that you have a supported version of Docker:\"),mdx(\"p\",null,\"$ docker --version\"),mdx(\"p\",null,\"Docker version 17.12.0-ce, build c97c6d6\"),mdx(\"p\",null,\"Run\\xA0docker version (without\\xA0--) or\\xA0docker info\\xA0to view even more details about your docker installation:\"),mdx(\"pre\",null,mdx(\"code\",_extends({parentName:\"pre\"},{\"className\":\"language-bash\"}),\"$ docker info\\nContainers: 0\\nRunning: 0\\nPaused: 0\\nStopped: 0\\nImages: 0\\nServer Version: 17.12.0-ce\\nStorage Driver: overlay2\\n``\\n\\n**Note**: To avoid permission errors (and the use of\\xA0sudo), add your user to the\\xA0docker\\xA0group.\\xA0[Read more](https://docs.docker.com/engine/installation/linux/linux-postinstall/).\\n\\n#### Test Docker installation\\n\\nTest that your installation works by running the simple Docker image,\\xA0[hello-world](https://hub.docker.com/_/hello-world/):\\n\\n$ docker run hello-world\\n\\nUnable to find image \\\\'hello-world:latest\\\\' locally\\n\\nlatest: Pulling from library/hello-world\\n\\nca4f61b1923c: Pull complete\\n\\nDigest: sha256:ca0eeb6fb05351dfc8759c20733c91def84cb8007aa89a5bf606bc8b315b9fc7\\n\\nStatus: Downloaded newer image for hello-world:latest\\n\\nHello from Docker!\\n\\nThis message shows that your installation appears to be working correctly.\\n\\n...\\n\\nList the\\xA0hello-world\\xA0image that was downloaded to your machine:\\n\\n$ docker image ls\\n\\nList the\\xA0hello-world\\xA0container (spawned by the image), which exits after displaying its message. If it were still running, you would\\xA0not\\xA0need the\\xA0--all\\xA0option:\\n\\n$ docker container ls --all\\n\\nCONTAINER ID IMAGE COMMAND CREATED STATUS\\n\\n54f4984ed6a8 hello-world \\\"/hello\\\" 20 seconds ago Exited (0) 19 seconds ago\\n\\n#### Recap and cheat sheet\\n\\n## List Docker CLI commands\\n\\ndocker\\n\\ndocker container --help\\n\\n## Display Docker version and info\\n\\ndocker --version\\n\\ndocker version\\n\\ndocker info\\n\\n## Excecute Docker image\\n\\ndocker run hello-world\\n\\n## List Docker images\\n\\ndocker image ls\\n\\n## List Docker containers (running, all, all in quiet mode)\\n\\ndocker container ls\\n\\ndocker container ls --all\\n\\ndocker container ls -a -q\\n\\nContainerization makes\\xA0[CI/CD](https://www.docker.com/use-cases/cicd)\\xA0seamless. For example:\\n\\n-   applications have no system dependencies\\n-   updates can be pushed to any part of a distributed application\\n-   resource density can be optimized.\\n\\nWith Docker, scaling your application is a matter of spinning up new executables, not running heavy VM hosts.\\n\\n### Containers\\n\\n#### Your new development environment\\n\\nIn the past, if you were to start writing a Python app, your first order of business was to install a Python runtime onto your machine. But, that creates a situation where the environment on your machine needs to be perfect for your app to run as expected, and needs to match your production environment.\\n\\nWith Docker, you can just grab a portable Python runtime as an image, no installation necessary. Then, your build can include the base Python image right alongside your app code, ensuring that your app, its dependencies, and the runtime, all travel together.\\n\\nThese portable images are defined by something called a\\xA0Dockerfile.\\n\\n#### Define a container with\\xA0Dockerfile\\n\\nDockerfile\\xA0defines what goes on in the environment inside your container. Access to resources like networking interfaces and disk drives is virtualized inside this environment, which is isolated from the rest of your system, so you need to map ports to the outside world, and be specific about what files you want to \\\"copy in\\\" to that environment. However, after doing that, you can expect that the build of your app defined in this\\xA0Dockerfile\\xA0behaves the same wherever it runs.\\n\\n#### Dockerfile\\n\\nCreate an empty directory. Change directories (cd) into the new directory, create a file called\\xA0Dockerfile, copy-and-paste the following content into that file, and save it. Take note of the comments that explain each statement in your new Dockerfile.\\n\\n# Use an official Python runtime as a parent image\\n\\nFROM python:2.7-slim\\n\\n# Set the working directory to /app\\n\\nWORKDIR /app\\n\\n# Copy the current directory contents into the container at /app\\n\\nADD . /app\\n\\n# Install any needed packages specified in requirements.txt\\n\\nRUN pip install --trusted-host pypi.python.org -r requirements.txt\\n\\n# Make port 80 available to the world outside this container\\n\\nEXPOSE 80\\n\\n# Define environment variable\\n\\nENV NAME World\\n\\n# Run app.py when the container launches\\n\\nCMD [\\\"python\\\", \\\"app.py\\\"]\\n\\n**Are you behind a proxy server?**\\n\\nProxy servers can block connections to your web app once it's up and running. If you are behind a proxy server, add the following lines to your Dockerfile, using the\\xA0ENV\\xA0command to specify the host and port for your proxy servers:\\n\\n# Set proxy server, replace host:port with values for your servers\\n\\nENV http_proxy host:port\\n\\nENV https_proxy host:port\\n\\nAdd these lines before the call to\\xA0pip\\xA0so that the installation succeeds.\\n\\nThis\\xA0Dockerfile\\xA0refers to a couple of files we haven't created yet, namely\\xA0app.py\\xA0and\\xA0requirements.txt. Let's create those next.\\n\\n#### The app itself\\n\\nCreate two more files,\\xA0requirements.txt\\xA0and\\xA0app.py, and put them in the same folder with the\\xA0Dockerfile. This completes our app, which as you can see is quite simple. When the above\\xA0Dockerfile\\xA0is built into an image,\\xA0app.py\\xA0and\\xA0requirements.txt\\xA0is present because of that\\xA0Dockerfile's\\xA0ADD\\xA0command, and the output from\\xA0app.py\\xA0is accessible over HTTP thanks to the\\xA0EXPOSE\\xA0command.\\n\\n**requirements.txt**\\n\\nFlask\\n\\nRedis\\n\\n**app.py**\\n\\nfrom flask import Flask\\n\\nfrom redis import Redis, RedisError\\n```python\\nimport os\\n\\nimport socket\\n\\n# Connect to Redis\\n\\nredis = Redis(host=\\\"redis\\\", db=0, socket_connect_timeout=2, socket_timeout=2)\\n\\napp = Flask(__name__)\\n\\n\\\\@app.route(\\\"/\\\")\\n\\ndef hello():\\n\\ntry:\\n\\nvisits = redis.incr(\\\"counter\\\")\\n\\nexcept RedisError:\\n\\nvisits = \\\"`<i>cannot connect to Redis, counter disabled</i>`\\\"\\n\\nhtml = \\\"`<h3>Hello {name}!</h3>`\\\" \\\\\\n\\n\\\"`<b>Hostname:</b> {hostname}<br/>`\\\" \\\\\\n\\n\\\"`<b>Visits:</b>` {visits}\\\"\\n\\nreturn html.format(name=os.getenv(\\\"NAME\\\", \\\"world\\\"), hostname=socket.gethostname(), visits=visits)\\n\\nif __name__ == \\\"__main__\\\":\\n\\napp.run(host=\\\\'0.0.0.0\\\\', port=80)\\n\")),mdx(\"p\",null,\"Now we see that\\xA0pip install -r requirements.txt\\xA0installs the Flask and Redis libraries for Python, and the app prints the environment variable\\xA0NAME, as well as the output of a call to\\xA0socket.gethostname(). Finally, because Redis isn't running (as we've only installed the Python library, and not Redis itself), we should expect that the attempt to use it here fails and produces the error message.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": Accessing the name of the host when inside a container retrieves the container ID, which is like the process ID for a running executable.\"),mdx(\"p\",null,\"That's it! You don't need Python or anything in\\xA0requirements.txt\\xA0on your system, nor does building or running this image install them on your system. It doesn't seem like you've really set up an environment with Python and Flask, but you have.\"),mdx(\"h4\",null,\"Build the app\"),mdx(\"p\",null,\"We are ready to build the app. Make sure you are still at the top level of your new directory. Here's what\\xA0ls\\xA0should show:\"),mdx(\"p\",null,\"$ ls\"),mdx(\"p\",null,\"Dockerfile app.py requirements.txt\"),mdx(\"p\",null,\"Now run the build command. This creates a Docker image, which we're going to tag using\\xA0-t\\xA0so it has a friendly name.\"),mdx(\"p\",null,\"docker build -t friendlyhello .\"),mdx(\"p\",null,\"Where is your built image? It's in your machine's local Docker image registry:\"),mdx(\"p\",null,\"$ docker image ls\"),mdx(\"p\",null,\"REPOSITORY TAG IMAGE ID\"),mdx(\"p\",null,\"friendlyhello latest 326387cea398\"),mdx(\"h4\",null,\"Run the app\"),mdx(\"p\",null,\"Run the app, mapping your machine's port 4000 to the container's published port 80 using\\xA0-p:\"),mdx(\"p\",null,\"docker run -p 4000:80 friendlyhello\"),mdx(\"p\",null,\"You should see a message that Python is serving your app at\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://0.0.0.0:80\"}),\"http://0.0.0.0:80\"),\". But that message is coming from inside the container, which doesn't know you mapped port 80 of that container to 4000, making the correct URL\\xA0http://localhost:4000.\"),mdx(\"p\",null,\"Go to that URL in a web browser to see the display content served up on a web page.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": If you are using Docker Toolbox on Windows 7, use the Docker Machine IP instead of\\xA0localhost. For example, \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://192.168.99.100:4000/\"}),\"http://192.168.99.100:4000/\"),\". To find the IP address, use the command\\xA0docker-machine ip.\"),mdx(\"p\",null,\"You can also use the\\xA0curl\\xA0command in a shell to view the same content.\"),mdx(\"pre\",null,mdx(\"code\",_extends({parentName:\"pre\"},{\"className\":\"language-bash\"}),\"$ curl http://localhost:4000\\n`<h3>Hello World!</h3><b>Hostname:</b> 8fc990912a14<br/><b>Visits:</b> <i>cannot connect to Redis, counter disabled</i>`\\n\")),mdx(\"p\",null,\"This port remapping of\\xA04000:80\\xA0is to demonstrate the difference between what you\\xA0EXPOSE\\xA0within the\\xA0Dockerfile, and what you\\xA0publish\\xA0using\\xA0docker run -p. In later steps, we just map port 80 on the host to port 80 in the container and use\\xA0http://localhost.\"),mdx(\"p\",null,\"Hit\\xA0CTRL+C\\xA0in your terminal to quit.\"),mdx(\"p\",null,\"On Windows, explicitly stop the container\"),mdx(\"p\",null,\"On Windows systems,\\xA0CTRL+C\\xA0does not stop the container. So, first type\\xA0CTRL+C\\xA0to get the prompt back (or open another shell), then type\\xA0docker container ls\\xA0to list the running containers, followed by\\xA0docker container stop \",mdx(\"inlineCode\",{parentName:\"p\"},\"<Container NAME or ID>\"),\"\\xA0to stop the container. Otherwise, you get an error response from the daemon when you try to re-run the container in the next step.\"),mdx(\"p\",null,\"Now let's run the app in the background, in detached mode:\"),mdx(\"p\",null,\"docker run -d -p 4000:80 friendlyhello\"),mdx(\"p\",null,\"You get the long container ID for your app and then are kicked back to your terminal. Your container is running in the background. You can also see the abbreviated container ID with\\xA0docker container ls(and both work interchangeably when running commands):\"),mdx(\"pre\",null,mdx(\"code\",_extends({parentName:\"pre\"},{\"className\":\"language-bash\"}),\"$ docker container ls\\n\")),mdx(\"p\",null,\"CONTAINER ID IMAGE COMMAND CREATED\"),mdx(\"p\",null,\"1fa4ab2cf395 friendlyhello \\\"python app.py\\\" 28 seconds ago\"),mdx(\"p\",null,\"Notice that\\xA0CONTAINER ID\\xA0matches what's on\\xA0\",mdx(\"inlineCode\",{parentName:\"p\"},\"<http://localhost:4000>\"),\". Now use\\xA0docker container stop\\xA0to end the process, using the\\xA0CONTAINER ID, like so:\"),mdx(\"p\",null,\"docker container stop 1fa4ab2cf395\"),mdx(\"h4\",null,\"Share your image\"),mdx(\"p\",null,\"To demonstrate the portability of what we just created, let's upload our built image and run it somewhere else. After all, you need to know how to push to registries when you want to deploy containers to production.\"),mdx(\"p\",null,\"A registry is a collection of repositories, and a repository is a collection of images---sort of like a GitHub repository, except the code is already built. An account on a registry can create many repositories. The\\xA0docker\\xA0CLI uses Docker's public registry by default.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": We use Docker's public registry here just because it's free and pre-configured, but there are many public ones to choose from, and you can even set up your own private registry using\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/datacenter/dtr/2.2/guides/\"}),\"Docker Trusted Registry\"),\".\"),mdx(\"h4\",null,\"Log in with your Docker ID\"),mdx(\"p\",null,\"If you don't have a Docker account, sign up for one at\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://cloud.docker.com/\"}),\"cloud.docker.com\"),\". Make note of your username. Log in to the Docker public registry on your local machine.\"),mdx(\"p\",null,\"$ docker login\"),mdx(\"h4\",null,\"Tag the image\"),mdx(\"p\",null,\"The notation for associating a local image with a repository on a registry is\\xA0username/repository:tag. The tag is optional, but recommended, since it is the mechanism that registries use to give Docker images a version. Give the repository and tag meaningful names for the context, such as get-started:part2. This puts the image in the\\xA0get-started\\xA0repository and tag it as\\xA0part2.\"),mdx(\"p\",null,\"Now, put it all together to tag the image. Run\\xA0docker tag image\\xA0with your username, repository, and tag names so that the image uploads to your desired destination. The syntax of the command is:\"),mdx(\"p\",null,\"docker tag image username/repository:tag\"),mdx(\"p\",null,\"For example:\"),mdx(\"p\",null,\"docker tag friendlyhello john/get-started:part2\"),mdx(\"p\",null,\"Run\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/image_ls/\"}),\"docker image ls\"),\"\\xA0to see your newly tagged image.\"),mdx(\"p\",null,\"$ docker image ls\"),mdx(\"p\",null,\"REPOSITORY TAG IMAGE ID CREATED SIZE\"),mdx(\"p\",null,\"friendlyhello latest d9e555c53008 3 minutes ago 195MB\"),mdx(\"p\",null,\"john/get-started part2 d9e555c53008 3 minutes ago 195MB\"),mdx(\"p\",null,\"python 2.7-slim 1c7128a655f6 5 days ago 183MB\"),mdx(\"p\",null,\"...\"),mdx(\"h4\",null,\"Publish the image\"),mdx(\"p\",null,\"Upload your tagged image to the repository:\"),mdx(\"p\",null,\"docker push username/repository:tag\"),mdx(\"p\",null,\"Once complete, the results of this upload are publicly available. If you log in to\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://hub.docker.com/\"}),\"Docker Hub\"),\", you see the new image there, with its pull command.\"),mdx(\"h4\",null,\"Pull and run the image from the remote repository\"),mdx(\"p\",null,\"From now on, you can use\\xA0docker run\\xA0and run your app on any machine with this command:\"),mdx(\"p\",null,\"docker run -p 4000:80 username/repository:tag\"),mdx(\"p\",null,\"If the image isn't available locally on the machine, Docker pulls it from the repository.\"),mdx(\"p\",null,\"$ docker run -p 4000:80 john/get-started:part2\"),mdx(\"p\",null,\"Unable to find image \\\\'john/get-started:part2\\\\' locally\"),mdx(\"p\",null,\"part2: Pulling from john/get-started\"),mdx(\"p\",null,\"10a267c67f42: Already exists\"),mdx(\"p\",null,\"f68a39a6a5e4: Already exists\"),mdx(\"p\",null,\"9beaffc0cf19: Already exists\"),mdx(\"p\",null,\"3c1fe835fb6b: Already exists\"),mdx(\"p\",null,\"4c9f1fa8fcb8: Already exists\"),mdx(\"p\",null,\"ee7d8f576a14: Already exists\"),mdx(\"p\",null,\"fbccdcced46e: Already exists\"),mdx(\"p\",null,\"Digest: sha256:0601c866aab2adcc6498200efd0f754037e909e5fd42069adeff72d1e2439068\"),mdx(\"p\",null,\"Status: Downloaded newer image for john/get-started:part2\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Running on \",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"http://0.0.0.0:80/\"}),\"http://0.0.0.0:80/\"),\" (Press CTRL+C to quit)\")),mdx(\"p\",null,\"No matter where\\xA0docker run\\xA0executes, it pulls your image, along with Python and all the dependencies from\\xA0requirements.txt, and runs your code. It all travels together in a neat little package, and you don't need to install anything on the host machine for Docker to run it.\"),mdx(\"p\",null,\"Here is a list of the basic Docker commands from this page, and some related ones if you'd like to explore a bit before moving on.\"),mdx(\"p\",null,\"docker build -t friendlyhello . # Create image using this directory\\\\'s Dockerfile\"),mdx(\"p\",null,\"docker run -p 4000:80 friendlyhello # Run \\\"friendlyname\\\" mapping port 4000 to 80\"),mdx(\"p\",null,\"docker run -d -p 4000:80 friendlyhello # Same thing, but in detached mode\"),mdx(\"p\",null,\"docker container ls # List all running containers\"),mdx(\"p\",null,\"docker container ls -a # List all containers, even those not running\"),mdx(\"p\",null,\"docker container stop \",mdx(\"inlineCode\",{parentName:\"p\"},\"<hash>\"),\" # Gracefully stop the specified container\"),mdx(\"p\",null,\"docker container kill \",mdx(\"inlineCode\",{parentName:\"p\"},\"<hash>\"),\" # Force shutdown of the specified container\"),mdx(\"p\",null,\"docker container rm \",mdx(\"inlineCode\",{parentName:\"p\"},\"<hash>\"),\" # Remove specified container from this machine\"),mdx(\"p\",null,\"docker container rm $(docker container ls -a -q) # Remove all containers\"),mdx(\"p\",null,\"docker image ls -a # List all images on this machine\"),mdx(\"p\",null,\"docker image rm \",mdx(\"inlineCode\",{parentName:\"p\"},\"<image id>\"),\" # Remove specified image from this machine\"),mdx(\"p\",null,\"docker image rm $(docker image ls -a -q) # Remove all images from this machine\"),mdx(\"p\",null,\"docker login # Log in this CLI session using your Docker credentials\"),mdx(\"p\",null,\"docker tag \",mdx(\"inlineCode\",{parentName:\"p\"},\"<image> username/repository:tag # Tag <image>\"),\" for upload to registry\"),mdx(\"p\",null,\"docker push username/repository:tag # Upload tagged image to registry\"),mdx(\"p\",null,\"docker run username/repository:tag # Run image from a registry\"),mdx(\"h2\",null,mdx(\"a\",_extends({parentName:\"h2\"},{\"href\":\"https://docs.docker.com/compose/overview/\"})),\"Docker Compose\"),mdx(\"p\",null,\"In a distributed application, different pieces of the app are called \\\"services.\\\" For example, if you imagine a video sharing site, it probably includes a service for storing application data in a database, a service for video transcoding in the background after a user uploads something, a service for the front-end, and so on.\"),mdx(\"p\",null,\"Services are just \\\"containers in production.\\\" A service only runs one image, but it codifies the way that image runs---what ports it should use, how many replicas of the container should run so the service has the capacity it needs, and so on. Scaling a service changes the number of container instances running that piece of software, assigning more computing resources to the service in the process.\"),mdx(\"p\",null,\"Luckily, it's very easy to define, run, and scale services with the Docker platform -- just write a\\xA0docker-compose.yml\\xA0file.\"),mdx(\"h3\",null,\"Your first\\xA0docker-compose.yml\\xA0file\"),mdx(\"p\",null,\"A\\xA0docker-compose.yml\\xA0file is a YAML file that defines how Docker containers should behave in production.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"docker-compose.yml\")),mdx(\"p\",null,\"Save this file as\\xA0docker-compose.yml\\xA0wherever you want and update this\\xA0.yml\\xA0by replacing\\xA0username/repo:tag\\xA0with your image details.\"),mdx(\"p\",null,\"version: \\\"3\\\"\"),mdx(\"p\",null,\"services:\"),mdx(\"p\",null,\"web:\"),mdx(\"h1\",null,\"replace username/repo:tag with your name and image details\"),mdx(\"p\",null,\"image: username/repo:tag\"),mdx(\"p\",null,\"deploy:\"),mdx(\"p\",null,\"replicas: 5\"),mdx(\"p\",null,\"resources:\"),mdx(\"p\",null,\"limits:\"),mdx(\"p\",null,\"cpus: \\\"0.1\\\"\"),mdx(\"p\",null,\"memory: 50M\"),mdx(\"p\",null,\"restart_policy:\"),mdx(\"p\",null,\"condition: on-failure\"),mdx(\"p\",null,\"ports:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"\\\"80:80\\\"\")),mdx(\"p\",null,\"networks:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"webnet\")),mdx(\"p\",null,\"networks:\"),mdx(\"p\",null,\"webnet:\"),mdx(\"p\",null,\"This\\xA0docker-compose.yml\\xA0file tells Docker to do the following:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Pull\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/get-started/part2/\"}),\"the image\"),\"\\xA0from the registry.\"),mdx(\"li\",{parentName:\"ul\"},\"Run 5 instances of that image as a service called\\xA0web, limiting each one to use, at most, 10% of the CPU (across all cores), and 50MB of RAM.\"),mdx(\"li\",{parentName:\"ul\"},\"Immediately restart containers if one fails.\"),mdx(\"li\",{parentName:\"ul\"},\"Map port 80 on the host to\\xA0web's port 80.\"),mdx(\"li\",{parentName:\"ul\"},\"Instruct\\xA0web's containers to share port 80 via a load-balanced network called\\xA0webnet. (Internally, the containers themselves publish to\\xA0web's port 80 at an ephemeral port.)\"),mdx(\"li\",{parentName:\"ul\"},\"Define the\\xA0webnet\\xA0network with the default settings (which is a load-balanced overlay network).\")),mdx(\"h3\",null,\"Run your new load-balanced app\"),mdx(\"p\",null,\"Before we can use the\\xA0docker stack deploy\\xA0command we first run:\"),mdx(\"p\",null,\"docker swarm init\"),mdx(\"p\",null,\"Now let's run it. You need to give your app a name. Here, it is set to\\xA0getstartedlab:\"),mdx(\"p\",null,\"docker stack deploy -c docker-compose.yml getstartedlab\"),mdx(\"p\",null,\"Our single service stack is running 5 container instances of our deployed image on one host. Let's investigate.\"),mdx(\"p\",null,\"Get the service ID for the one service in our application:\"),mdx(\"p\",null,\"docker service ls\"),mdx(\"p\",null,\"Look for output for the\\xA0web\\xA0service, prepended with your app name. If you named it the same as shown in this example, the name is\\xA0getstartedlab_web. The service ID is listed as well, along with the number of replicas, image name, and exposed ports.\"),mdx(\"p\",null,\"A single container running in a service is called a\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"task\"),\". Tasks are given unique IDs that numerically increment, up to the number of\\xA0replicas\\xA0you defined in\\xA0docker-compose.yml. List the tasks for your service:\"),mdx(\"p\",null,\"docker service ps getstartedlab_web\"),mdx(\"p\",null,\"Tasks also show up if you just list all the containers on your system, though that is not filtered by service:\"),mdx(\"p\",null,\"docker container ls -q\"),mdx(\"p\",null,\"You can run\\xA0curl -4 http://localhost\\xA0several times in a row, or go to that URL in your browser and hit refresh a few times.\"),mdx(\"p\",null,\"Either way, the container ID changes, demonstrating the load-balancing; with each request, one of the 5 tasks is chosen, in a round-robin fashion, to respond. The container IDs match your output from the previous command (docker container ls -q).\"),mdx(\"h3\",null,\"Scale the app\"),mdx(\"p\",null,\"You can scale the app by changing the\\xA0replicas\\xA0value in\\xA0docker-compose.yml, saving the change, and re-running the\\xA0docker stack deploy\\xA0command:\"),mdx(\"p\",null,\"docker stack deploy -c docker-compose.yml getstartedlab\"),mdx(\"p\",null,\"Docker performs an in-place update, no need to tear the stack down first or kill any containers.\"),mdx(\"p\",null,\"Now, re-run\\xA0docker container ls -q\\xA0to see the deployed instances reconfigured. If you scaled up the replicas, more tasks, and hence, more containers, are started.\"),mdx(\"h4\",null,\"Take down the app and the swarm\"),mdx(\"p\",null,\"Take the app down with\\xA0docker stack rm:\"),mdx(\"p\",null,\"docker stack rm getstartedlab\"),mdx(\"p\",null,\"Take down the swarm.\"),mdx(\"p\",null,\"docker swarm leave --force\"),mdx(\"p\",null,\"It's as easy as that to stand up and scale your app with Docker.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": Compose files like this are used to define applications with Docker, and can be uploaded to cloud providers using\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/docker-cloud/\"}),\"Docker Cloud\"),\", or on any hardware or cloud provider you choose with\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://www.docker.com/enterprise-edition\"}),\"Docker Enterprise Edition\"),\".\"),mdx(\"h3\",null,\"Recap and cheat sheet\"),mdx(\"p\",null,\"Here's\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://asciinema.org/a/b5gai4rnflh7r0kie01fx6lip\"}),\"a terminal recording of what was covered on this section\"),\":\"),mdx(\"p\",null,\"To recap, while typing\\xA0docker run\\xA0is simple enough, the true implementation of a container in production is running it as a service. Services codify a container's behavior in a Compose file, and this file can be used to scale, limit, and redeploy our app. Changes to the service can be applied in place, as it runs, using the same command that launched the service:\\xA0docker stack deploy.\"),mdx(\"p\",null,\"Some commands to explore at this stage:\"),mdx(\"p\",null,\"docker stack ls # List stacks or apps\"),mdx(\"p\",null,\"docker stack deploy -c \",mdx(\"inlineCode\",{parentName:\"p\"},\"<composefile> <appname>\"),\" # Run the specified Compose file\"),mdx(\"p\",null,\"docker service ls # List running services associated with an app\"),mdx(\"p\",null,\"docker service ps \",mdx(\"inlineCode\",{parentName:\"p\"},\"<service>\"),\" # List tasks associated with an app\"),mdx(\"p\",null,\"docker inspect \",mdx(\"inlineCode\",{parentName:\"p\"},\"<task or container>\"),\" # Inspect task or container\"),mdx(\"p\",null,\"docker container ls -q # List container IDs\"),mdx(\"p\",null,\"docker stack rm \",mdx(\"inlineCode\",{parentName:\"p\"},\"<appname>\"),\" # Tear down an application\"),mdx(\"p\",null,\"docker swarm leave --force # Take down a single node swarm from the manager\"),mdx(\"h2\",null,mdx(\"a\",_extends({parentName:\"h2\"},{\"href\":\"https://docs.docker.com/get-started/part4/#introduction\"})),\"Docker Swarm\"),mdx(\"p\",null,mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://wiki.centos.org/HowTos/Virtualization/VirtualBox\"}),\"Installing Virtual box on centos\")),mdx(\"h3\",null,\"Understanding Swarm clusters\"),mdx(\"p\",null,\"A swarm is a group of machines that are running Docker and joined into a cluster. After that has happened, you continue to run the Docker commands you're used to, but now they are executed on a cluster by a\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"swarm manager\"),\". The machines in a swarm can be physical or virtual. After joining a swarm, they are referred to as\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"nodes\"),\".\"),mdx(\"p\",null,\"Swarm managers can use several strategies to run containers, such as \\\"emptiest node\\\" -- which fills the least utilized machines with containers. Or \\\"global\\\", which ensures that each machine gets exactly one instance of the specified container. You instruct the swarm manager to use these strategies in the Compose file, just like the one you have already been using.\"),mdx(\"p\",null,\"Swarm managers are the only machines in a swarm that can execute your commands or authorize other machines to join the swarm as\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"workers\"),\". Workers are just there to provide capacity and do not have the authority to tell any other machine what it can and cannot do.\"),mdx(\"p\",null,\"Up until now, you have been using Docker in a single-host mode on your local machine. But Docker also can be switched into\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"swarm mode\"),\", and that's what enables the use of swarms. Enabling swarm mode instantly makes the current machine a swarm manager. From then on, Docker runs the commands you execute on the swarm you're managing, rather than just on the current machine.\"),mdx(\"h3\",null,\"Set up your swarm\"),mdx(\"p\",null,\"A swarm is made up of multiple nodes, which can be either physical or virtual machines. The basic concept is simple enough: run\\xA0docker swarm init\\xA0to enable swarm mode and make your current machine a swarm manager, then run\\xA0docker swarm join\\xA0on other machines to have them join the swarm as workers.\"),mdx(\"h4\",null,\"Create a cluster\"),mdx(\"h5\",null,\"VMS ON YOUR LOCAL MACHINE (MAC, LINUX, WINDOWS 7 AND 8)\"),mdx(\"p\",null,\"You need a hypervisor that can create virtual machines (VMs), so\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://www.virtualbox.org/wiki/Downloads\"}),\"install Oracle VirtualBox\"),\"\\xA0for your machine's OS.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": If you are on a Windows system that has Hyper-V installed, such as Windows 10, there is no need to install VirtualBox and you should use Hyper-V instead. View the instructions for Hyper-V systems by clicking the Hyper-V tab above. If you are using\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/toolbox/overview/\"}),\"Docker Toolbox\"),\", you should already have VirtualBox installed as part of it, so you are good to go.\"),mdx(\"p\",null,\"Now, create a couple of VMs using\\xA0docker-machine, using the VirtualBox driver:\"),mdx(\"p\",null,\"docker-machine create --driver virtualbox myvm1\"),mdx(\"p\",null,\"docker-machine create --driver virtualbox myvm2\"),mdx(\"h5\",null,\"LIST THE VMS AND GET THEIR IP ADDRESSES\"),mdx(\"p\",null,\"You now have two VMs created, named\\xA0myvm1\\xA0and\\xA0myvm2.\"),mdx(\"p\",null,\"Use this command to list the machines and get their IP addresses.\"),mdx(\"p\",null,\"docker-machine ls\"),mdx(\"p\",null,\"Here is example output from this command.\"),mdx(\"p\",null,\"$ docker-machine ls\"),mdx(\"p\",null,\"NAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORS\"),mdx(\"p\",null,\"myvm1 - virtualbox Running tcp://192.168.99.100:2376 v17.06.2-ce\"),mdx(\"p\",null,\"myvm2 - virtualbox Running tcp://192.168.99.101:2376 v17.06.2-ce\"),mdx(\"h5\",null,\"INITIALIZE THE SWARM AND ADD NODES\"),mdx(\"p\",null,\"The first machine acts as the manager, which executes management commands and authenticates workers to join the swarm, and the second is a worker.\"),mdx(\"p\",null,\"You can send commands to your VMs using\\xA0docker-machine ssh. Instruct\\xA0myvm1\\xA0to become a swarm manager with\\xA0docker swarm init\\xA0and look for output like this:\"),mdx(\"p\",null,\"$ docker-machine ssh myvm1 \\\"docker swarm init --advertise-addr \",mdx(\"inlineCode\",{parentName:\"p\"},\"<myvm1 ip>\"),\"\\\"\"),mdx(\"p\",null,\"Swarm initialized: current node \",mdx(\"inlineCode\",{parentName:\"p\"},\"<node ID>\"),\" is now a manager.\"),mdx(\"p\",null,\"To add a worker to this swarm, run the following command:\"),mdx(\"p\",null,\"docker swarm join \\\\\"),mdx(\"p\",null,\"--token \",mdx(\"inlineCode\",{parentName:\"p\"},\"<token>\"),\" \\\\\"),mdx(\"p\",null,mdx(\"inlineCode\",{parentName:\"p\"},\"<myvm ip>:<port>\")),mdx(\"p\",null,\"To add a manager to this swarm, run \\\\'docker swarm join-token manager\\\\' and follow the instructions.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Ports 2377 and 2376\")),mdx(\"p\",null,\"Always run\\xA0docker swarm init\\xA0and\\xA0docker swarm join\\xA0with port 2377 (the swarm management port), or no port at all and let it take the default.\"),mdx(\"p\",null,\"The machine IP addresses returned by\\xA0docker-machine ls\\xA0include port 2376, which is the Docker daemon port. Do not use this port or\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://forums.docker.com/t/docker-swarm-join-with-virtualbox-connection-error-13-bad-certificate/31392/2\"}),\"you may experience errors\"),\".\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Having trouble using SSH? Try the --native-ssh flag\")),mdx(\"p\",null,\"Docker Machine has\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/machine/reference/ssh/#different-types-of-ssh\"}),\"the option to let you use your own system's SSH\"),\", if for some reason you're having trouble sending commands to your Swarm manager. Just specify the\\xA0--native-ssh\\xA0flag when invoking the\\xA0ssh\\xA0command:\"),mdx(\"p\",null,\"docker-machine --native-ssh ssh myvm1 ...\"),mdx(\"p\",null,\"As you can see, the response to\\xA0docker swarm init\\xA0contains a pre-configured\\xA0docker swarm join command for you to run on any nodes you want to add. Copy this command, and send it to\\xA0myvm2\\xA0via\\xA0docker-machine ssh\\xA0to have\\xA0myvm2\\xA0join your new swarm as a worker:\"),mdx(\"p\",null,\"$ docker-machine ssh myvm2 \\\"docker swarm join \\\\\"),mdx(\"p\",null,\"--token \",mdx(\"inlineCode\",{parentName:\"p\"},\"<token>\"),\" \\\\\"),mdx(\"p\",null,mdx(\"inlineCode\",{parentName:\"p\"},\"<ip>\"),\":2377\\\"\"),mdx(\"p\",null,\"This node joined a swarm as a worker.\"),mdx(\"p\",null,\"Congratulations, you have created your first swarm!\"),mdx(\"p\",null,\"Run\\xA0docker node ls\\xA0on the manager to view the nodes in this swarm:\"),mdx(\"p\",null,\"$ docker-machine ssh myvm1 \\\"docker node ls\\\"\"),mdx(\"p\",null,\"ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS\"),mdx(\"p\",null,\"brtu9urxwfd5j0zrmkubhpkbd myvm2 Ready Active\"),mdx(\"p\",null,\"rihwohkh3ph38fhillhhb84sk * myvm1 Ready Active Leader\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Leaving a swarm\")),mdx(\"p\",null,\"If you want to start over, you can run\\xA0docker swarm leave\\xA0from each node.\"),mdx(\"h3\",null,\"Deploy your app on the swarm cluster\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Configure a\\xA0docker-machine\\xA0shell to the swarm manager\")),mdx(\"p\",null,\"So far, you've been wrapping Docker commands in\\xA0docker-machine ssh\\xA0to talk to the VMs. Another option is to run\\xA0docker-machine env \",mdx(\"inlineCode\",{parentName:\"p\"},\"<machine>\"),\"\\xA0to get and run a command that configures your current shell to talk to the Docker daemon on the VM. This method works better for the next step because it allows you to use your local\\xA0docker-compose.yml\\xA0file to deploy the app \\\"remotely\\\" without having to copy it anywhere.\"),mdx(\"p\",null,\"Type\\xA0docker-machine env myvm1, then copy-paste and run the command provided as the last line of the output to configure your shell to talk to\\xA0myvm1, the swarm manager.\"),mdx(\"p\",null,\"The commands to configure your shell differ depending on whether you are Mac, Linux, or Windows, so examples of each are shown on the tabs below.\"),mdx(\"h4\",null,\"DOCKER MACHINE SHELL ENVIRONMENT ON MAC OR LINUX\"),mdx(\"p\",null,\"Run\\xA0docker-machine env myvm1\\xA0to get the command to configure your shell to talk to\\xA0myvm1.\"),mdx(\"pre\",null,mdx(\"code\",_extends({parentName:\"pre\"},{\"className\":\"language-bash\"}),\"$ docker-machine env myvm1\\nexport DOCKER_TLS_VERIFY=\\\"1\\\"\\nexport DOCKER_HOST=\\\"tcp://192.168.99.100:2376\\\"\\nexport DOCKER_CERT_PATH=\\\"/Users/sam/.docker/machine/machines/myvm1\\\"\\nexport DOCKER_MACHINE_NAME=\\\"myvm1\\\"\\n# Run this command to configure your shell:\\n# eval $(docker-machine env myvm1)\\n\")),mdx(\"p\",null,\"Run the given command to configure your shell to talk to\\xA0myvm1.\"),mdx(\"pre\",null,mdx(\"code\",_extends({parentName:\"pre\"},{\"className\":\"language-bash\"}),\"eval $(docker-machine env myvm1)\\n\")),mdx(\"p\",null,\"Run\\xA0docker-machine ls\\xA0to verify that\\xA0myvm1\\xA0is now the active machine, as indicated by the asterisk next to it.\"),mdx(\"pre\",null,mdx(\"code\",_extends({parentName:\"pre\"},{\"className\":\"language-bash\"}),\"$ docker-machine ls\\n\")),mdx(\"p\",null,\"NAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORS\"),mdx(\"p\",null,\"myvm1 * virtualbox Running tcp://192.168.99.100:2376 v17.06.2-ce\"),mdx(\"p\",null,\"myvm2 - virtualbox Running tcp://192.168.99.101:2376 v17.06.2-ce\"),mdx(\"h4\",null,\"Deploy the app on the swarm manager\"),mdx(\"p\",null,\"Now that you have\\xA0myvm1, you can use its powers as a swarm manager to deploy your app by using the same\\xA0docker stack deploy\\xA0command you used in part 3 to\\xA0myvm1, and your local copy of\\xA0docker-compose.yml. This command may take a few seconds to complete and the deployment takes some time to be available. Use the\\xA0docker service ps \",mdx(\"inlineCode\",{parentName:\"p\"},\"<service_name>\"),\"\\xA0command on a swarm manager to verify that all services have been redeployed.\"),mdx(\"p\",null,\"You are connected to\\xA0myvm1\\xA0by means of the\\xA0docker-machine\\xA0shell configuration, and you still have access to the files on your local host. Make sure you are in the same directory as before, which includes the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/get-started/part3/#docker-composeyml\"}),\"docker-compose.yml\\xA0\")),mdx(\"p\",null,\"Just like before, run the following command to deploy the app on\\xA0myvm1.\"),mdx(\"p\",null,\"docker stack deploy -c docker-compose.yml getstartedlab\"),mdx(\"p\",null,\"And that's it, the app is deployed on a swarm cluster!\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": If your image is stored on a private registry instead of Docker Hub, you need to be logged in using\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"docker login \",mdx(\"inlineCode\",{parentName:\"strong\"},\"<your-registry>\")),\"\\xA0and then you need to add the\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"--with-registry-auth\"),\"\\xA0flag to the above command. For example:\"),mdx(\"p\",null,\"docker login registry.example.com\"),mdx(\"p\",null,\"docker stack deploy --with-registry-auth -c docker-compose.yml getstartedlab\"),mdx(\"p\",null,\"This passes the login token from your local client to the swarm nodes where the service is deployed, using the encrypted WAL logs. With this information, the nodes can log into the registry and pull the image.\"),mdx(\"p\",null,\"$ docker stack ps getstartedlab\"),mdx(\"p\",null,\"ID NAME IMAGE NODE DESIRED STATE\"),mdx(\"p\",null,\"jq2g3qp8nzwx getstartedlab_web.1 john/get-started:part2 myvm1 Running\"),mdx(\"p\",null,\"88wgshobzoxl getstartedlab_web.2 john/get-started:part2 myvm2 Running\"),mdx(\"p\",null,\"vbb1qbkb0o2z getstartedlab_web.3 john/get-started:part2 myvm2 Running\"),mdx(\"p\",null,\"ghii74p9budx getstartedlab_web.4 john/get-started:part2 myvm1 Running\"),mdx(\"p\",null,\"0prmarhavs87 getstartedlab_web.5 john/get-started:part2 myvm2 Running\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Connecting to VMs with\\xA0docker-machine env\\xA0and\\xA0docker-machine ssh\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"To set your shell to talk to a different machine like\\xA0myvm2, simply re-rundocker-machine env\\xA0in the same or a different shell, then run the given command to point to\\xA0myvm2. This is always specific to the current shell. If you change to an unconfigured shell or open a new one, you need to re-run the commands. Use\\xA0docker-machine ls\\xA0to list machines, see what state they are in, get IP addresses, and find out which one, if any, you are connected to. To learn more, see the\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/machine/get-started/#create-a-machine\"}),\"Docker Machine getting started topics\"),\".\"),mdx(\"li\",{parentName:\"ul\"},\"Alternatively, you can wrap Docker commands in the form ofdocker-machine ssh \",mdx(\"inlineCode\",{parentName:\"li\"},\"<machine> \\\"<command>\"),\"\\\", which logs directly into the VM but doesn't give you immediate access to files on your local host.\"),mdx(\"li\",{parentName:\"ul\"},\"On Mac and Linux, you can use\\xA0docker-machine scp \",mdx(\"inlineCode\",{parentName:\"li\"},\"<file> <machine>\"),\":\",\"~\",\"\\xA0to copy files across machines, but Windows users need a Linux terminal emulator like\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://git-for-windows.github.io/\"}),\"Git Bash\"),\"\\xA0for this to work.\"),mdx(\"li\",{parentName:\"ul\"},\"This tutorial demos both\\xA0docker-machine ssh\\xA0and\\xA0docker-machine env, since these are available on all platforms via the\\xA0docker-machine\\xA0CLI.\")),mdx(\"h4\",null,\"Accessing your cluster\"),mdx(\"p\",null,\"You can access your app from the IP address of\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"either\"),\"\\xA0myvm1\\xA0or\\xA0myvm2.\"),mdx(\"p\",null,\"The network you created is shared between them and load-balancing. Run\\xA0docker-machine ls\\xA0to get your VMs' IP addresses and visit either of them on a browser, hitting refresh (or just\\xA0curl\\xA0them).\"),mdx(\"p\",null,\"The reason both IP addresses work is that nodes in a swarm participate in an ingress\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"routing mesh\"),\". This ensures that a service deployed at a certain port within your swarm always has that port reserved to itself, no matter what node is running the container. Here's a diagram of how a routing mesh for a service called\\xA0my-web\\xA0published at port\\xA08080\\xA0on a three-node swarm would look:\"),mdx(\"p\",null,\"Having connectivity trouble?\"),mdx(\"p\",null,\"Keep in mind that to use the ingress network in the swarm, you need to have the following ports open between the swarm nodes before you enable swarm mode:\"),mdx(\"p\",null,\"Port 7946 TCP/UDP for container network discovery.\"),mdx(\"p\",null,\"Port 4789 UDP for the container ingress network.\"),mdx(\"h3\",null,\"Iterating and scaling your app\"),mdx(\"p\",null,\"Scale the app by changing the\\xA0docker-compose.yml\\xA0file.\"),mdx(\"p\",null,\"Change the app behavior by editing code, then rebuild, and push the new image.\"),mdx(\"p\",null,\"In either case, simply run\\xA0docker stack deploy\\xA0again to deploy these changes.\"),mdx(\"p\",null,\"You can join any machine, physical or virtual, to this swarm, using the same\\xA0docker swarm join command you used on\\xA0myvm2, and capacity is added to your cluster. Just run\\xA0docker stack deploy afterwards, and your app can take advantage of the new resources.\"),mdx(\"h3\",null,\"Cleanup and reboot\"),mdx(\"h4\",null,\"Stacks and swarms\"),mdx(\"p\",null,\"You can tear down the stack with\\xA0docker stack rm. For example:\"),mdx(\"p\",null,\"docker stack rm getstartedlab\"),mdx(\"p\",null,\"Keep the swarm or remove it? At some point later, you can remove this swarm if you want to withdocker-machine ssh myvm2 \\\"docker swarm leave\\\"\\xA0on the worker and\\xA0docker-machine ssh myvm1 \\\"docker swarm leave --force\\\"\\xA0on the manager,\"),mdx(\"h4\",null,\"Unsetting docker-machine shell variable settings\"),mdx(\"p\",null,\"You can unset the\\xA0docker-machine\\xA0environment variables in your current shell with the following command:\"),mdx(\"p\",null,\"eval $(docker-machine env -u)\"),mdx(\"p\",null,\"This disconnects the shell from\\xA0docker-machine\\xA0created virtual machines, and allows you to continue working in the same shell, now using native\\xA0docker\\xA0commands (for example, on Docker for Mac or Docker for Windows). To learn more, see the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/machine/get-started/#unset-environment-variables-in-the-current-shell\"}),\"Machine topic on unsetting environment variables\"),\".\"),mdx(\"h4\",null,\"Restarting Docker machines\"),mdx(\"p\",null,\"If you shut down your local host, Docker machines stops running. You can check the status of machines by running\\xA0docker-machine ls.\"),mdx(\"p\",null,\"$ docker-machine ls\"),mdx(\"p\",null,\"NAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORS\"),mdx(\"p\",null,\"myvm1 - virtualbox Stopped Unknown\"),mdx(\"p\",null,\"myvm2 - virtualbox Stopped Unknown\"),mdx(\"p\",null,\"To restart a machine that's stopped, run:\"),mdx(\"p\",null,\"docker-machine start \",mdx(\"inlineCode\",{parentName:\"p\"},\"<machine-name>\")),mdx(\"p\",null,\"For example:\"),mdx(\"p\",null,\"$ docker-machine start myvm1\"),mdx(\"p\",null,\"Starting \\\"myvm1\\\"...\"),mdx(\"p\",null,\"(myvm1) Check network to re-create if needed...\"),mdx(\"p\",null,\"(myvm1) Waiting for an IP...\"),mdx(\"p\",null,\"Machine \\\"myvm1\\\" was started.\"),mdx(\"p\",null,\"Waiting for SSH to be available...\"),mdx(\"p\",null,\"Detecting the provisioner...\"),mdx(\"p\",null,\"Started machines may have new IP addresses. You may need to re-run the \",mdx(\"inlineCode\",{parentName:\"p\"},\"docker-machine env\"),\" command.\"),mdx(\"p\",null,\"$ docker-machine start myvm2\"),mdx(\"p\",null,\"Starting \\\"myvm2\\\"...\"),mdx(\"p\",null,\"(myvm2) Check network to re-create if needed...\"),mdx(\"p\",null,\"(myvm2) Waiting for an IP...\"),mdx(\"p\",null,\"Machine \\\"myvm2\\\" was started.\"),mdx(\"p\",null,\"Waiting for SSH to be available...\"),mdx(\"p\",null,\"Detecting the provisioner...\"),mdx(\"p\",null,\"Started machines may have new IP addresses. You may need to re-run the \",mdx(\"inlineCode\",{parentName:\"p\"},\"docker-machine env\"),\" command.\"),mdx(\"h3\",null,\"Recap and cheat sheet (optional)\"),mdx(\"p\",null,\"Here's\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://asciinema.org/a/113837\"}),\"a terminal recording of what was covered on this section\"),\":\"),mdx(\"p\",null,\"You learned what a swarm is, how nodes in swarms can be managers or workers, created a swarm, and deployed an application on it. You saw that the core Docker commands didn't change from part 3, they just had to be targeted to run on a swarm master. You also saw the power of Docker's networking in action, which kept load-balancing requests across containers, even though they were running on different machines. Finally, you learned how to iterate and scale your app on a cluster.\"),mdx(\"p\",null,\"Here are some commands you might like to run to interact with your swarm and your VMs a bit:\"),mdx(\"p\",null,\"docker-machine create --driver virtualbox myvm1 # Create a VM (Mac, Win7, Linux)\"),mdx(\"p\",null,\"docker-machine create -d hyperv --hyperv-virtual-switch \\\"myswitch\\\" myvm1 # Win10\"),mdx(\"p\",null,\"docker-machine env myvm1 # View basic information about your node\"),mdx(\"p\",null,\"docker-machine ssh myvm1 \\\"docker node ls\\\" # List the nodes in your swarm\"),mdx(\"p\",null,\"docker-machine ssh myvm1 \\\"docker node inspect \",mdx(\"inlineCode\",{parentName:\"p\"},\"<node ID>\"),\"\\\" # Inspect a node\"),mdx(\"p\",null,\"docker-machine ssh myvm1 \\\"docker swarm join-token -q worker\\\" # View join token\"),mdx(\"p\",null,\"docker-machine ssh myvm1 # Open an SSH session with the VM; type \\\"exit\\\" to end\"),mdx(\"p\",null,\"docker node ls # View nodes in swarm (while logged on to manager)\"),mdx(\"p\",null,\"docker-machine ssh myvm2 \\\"docker swarm leave\\\" # Make the worker leave the swarm\"),mdx(\"p\",null,\"docker-machine ssh myvm1 \\\"docker swarm leave -f\\\" # Make master leave, kill swarm\"),mdx(\"p\",null,\"docker-machine ls # list VMs, asterisk shows which VM this shell is talking to\"),mdx(\"p\",null,\"docker-machine start myvm1 # Start a VM that is currently not running\"),mdx(\"p\",null,\"docker-machine env myvm1 # show environment variables and command for myvm1\"),mdx(\"p\",null,\"eval $(docker-machine env myvm1) # Mac command to connect shell to myvm1\"),mdx(\"p\",null,\"& \\\"C:\\\\Program Files\\\\Docker\\\\Docker\\\\Resources\\\\bin\\\\docker-machine.exe\\\" env myvm1 | Invoke-Expression # Windows command to connect shell to myvm1\"),mdx(\"p\",null,\"docker stack deploy -c \",mdx(\"inlineCode\",{parentName:\"p\"},\"<file> <app>\"),\" # Deploy an app; command shell must be set to talk to manager (myvm1), uses local Compose file\"),mdx(\"p\",null,\"docker-machine scp docker-compose.yml myvm1:\",\"~\",\" # Copy file to node\\\\'s home dir (only required if you use ssh to connect to manager and deploy the app)\"),mdx(\"p\",null,\"docker-machine ssh myvm1 \\\"docker stack deploy -c \",mdx(\"inlineCode\",{parentName:\"p\"},\"<file> <app>\"),\"\\\" # Deploy an app using ssh (you must have first copied the Compose file to myvm1)\"),mdx(\"p\",null,\"eval $(docker-machine env -u) # Disconnect shell from VMs, use native docker\"),mdx(\"p\",null,\"docker-machine stop $(docker-machine ls -q) # Stop all running VMs\"),mdx(\"p\",null,\"docker-machine rm $(docker-machine ls -q) # Delete all VMs and their disk images\"),mdx(\"h2\",null,mdx(\"a\",_extends({parentName:\"h2\"},{\"href\":\"https://docs.docker.com/get-started/part5/\"})),\"Stacks\"),mdx(\"h3\",null,\"Introduction\"),mdx(\"p\",null,\"You learned how to set up a swarm, which is a cluster of machines running Docker, and deployed an application to it, with containers running in concert on multiple machines.\"),mdx(\"p\",null,\"You reach the top of the hierarchy of distributed applications: the\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"stack\"),\". A stack is a group of interrelated services that share dependencies and can be orchestrated and scaled together. A single stack can define and coordinating the functionality of an entire application (though very complex applications may want to use multiple stacks).\"),mdx(\"h3\",null,\"Add a new service and redeploy\"),mdx(\"p\",null,\"It's easy to add services to our\\xA0docker-compose.yml\\xA0file. First, let's add a free visualizer service that lets us look at how our swarm is scheduling containers.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Open\\xA0docker-compose.yml\\xA0in an editor and replace its contents with the following. Be sure to replace\\xA0username/repo:tag\\xA0with your image details.\")),mdx(\"p\",null,\"version: \\\"3\\\"\"),mdx(\"p\",null,\"services:\"),mdx(\"p\",null,\"web:\"),mdx(\"h1\",null,\"replace username/repo:tag with your name and image details\"),mdx(\"p\",null,\"image: username/repo:tag\"),mdx(\"p\",null,\"deploy:\"),mdx(\"p\",null,\"replicas: 5\"),mdx(\"p\",null,\"restart_policy:\"),mdx(\"p\",null,\"condition: on-failure\"),mdx(\"p\",null,\"resources:\"),mdx(\"p\",null,\"limits:\"),mdx(\"p\",null,\"cpus: \\\"0.1\\\"\"),mdx(\"p\",null,\"memory: 50M\"),mdx(\"p\",null,\"ports:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"\\\"80:80\\\"\")),mdx(\"p\",null,\"networks:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"webnet\")),mdx(\"p\",null,\"visualizer:\"),mdx(\"p\",null,\"image: dockersamples/visualizer:stable\"),mdx(\"p\",null,\"ports:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"\\\"8080:8080\\\"\")),mdx(\"p\",null,\"volumes:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"\\\"/var/run/docker.sock:/var/run/docker.sock\\\"\")),mdx(\"p\",null,\"deploy:\"),mdx(\"p\",null,\"placement:\"),mdx(\"p\",null,\"constraints: \",\"[node.role == manager]\"),mdx(\"p\",null,\"networks:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"webnet\")),mdx(\"p\",null,\"networks:\"),mdx(\"p\",null,\"webnet:\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Make sure your shell is configured to talk to\\xA0myvm1\\xA0(full examples are\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/get-started/part4/#configure-a-docker-machine-shell-to-the-swarm-manager\"}),\"here\"),\").\")),mdx(\"p\",null,\"Run\\xA0docker-machine ls\\xA0to list machines and make sure you are connected to\\xA0myvm1, as indicated by an asterisk next it.\"),mdx(\"p\",null,\"If needed, re-run\\xA0docker-machine env myvm1, then run the given command to configure the shell.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"On\\xA0\",mdx(\"strong\",{parentName:\"li\"},\"Mac or Linux\"),\"\\xA0the command is:\")),mdx(\"p\",null,\"eval $(docker-machine env myvm1)\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"On\\xA0\",mdx(\"strong\",{parentName:\"li\"},\"Windows\"),\"\\xA0the command is:\")),mdx(\"p\",null,\"& \\\"C:\\\\Program Files\\\\Docker\\\\Docker\\\\Resources\\\\bin\\\\docker-machine.exe\\\" env myvm1 | Invoke-Expression\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Re-run the\\xA0docker stack deploy\\xA0command on the manager, and whatever services need updating are updated:\")),mdx(\"p\",null,\"$ docker stack deploy -c docker-compose.yml getstartedlab\"),mdx(\"p\",null,\"Updating service getstartedlab_web (id: angi1bf5e4to03qu9f93trnxm)\"),mdx(\"p\",null,\"Creating service getstartedlab_visualizer (id: l9mnwkeq2jiononb5ihz9u7a4)\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Look at the visualizer.\")),mdx(\"p\",null,\"You saw in the Compose file that\\xA0visualizer\\xA0runs on port 8080. Get the IP address of one of your nodes by running\\xA0docker-machine ls. Go to either IP address at port 8080 and you can see the visualizer running:\"),mdx(\"p\",null,\"The single copy of\\xA0visualizer\\xA0is running on the manager as you expect, and the 5 instances of\\xA0web\\xA0are spread out across the swarm. You can corroborate this visualization by running\\xA0docker stack ps \",mdx(\"inlineCode\",{parentName:\"p\"},\"<stack>\"),\":\"),mdx(\"p\",null,\"docker stack ps getstartedlab\"),mdx(\"p\",null,\"The visualizer is a standalone service that can run in any app that includes it in the stack. It doesn't depend on anything else. Now let's create a service that\\xA0does\\xA0have a dependency: the Redis service that provides a visitor counter.\"),mdx(\"h3\",null,\"Persist the data\"),mdx(\"p\",null,\"Let's go through the same workflow once more to add a Redis database for storing app data.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Save this new\\xA0docker-compose.yml\\xA0file, which finally adds a Redis service. Be sure to replace\\xA0username/repo:tag\\xA0with your image details.\")),mdx(\"p\",null,\"version: \\\"3\\\"\"),mdx(\"p\",null,\"services:\"),mdx(\"p\",null,\"web:\"),mdx(\"h1\",null,\"replace username/repo:tag with your name and image details\"),mdx(\"p\",null,\"image: username/repo:tag\"),mdx(\"p\",null,\"deploy:\"),mdx(\"p\",null,\"replicas: 5\"),mdx(\"p\",null,\"restart_policy:\"),mdx(\"p\",null,\"condition: on-failure\"),mdx(\"p\",null,\"resources:\"),mdx(\"p\",null,\"limits:\"),mdx(\"p\",null,\"cpus: \\\"0.1\\\"\"),mdx(\"p\",null,\"memory: 50M\"),mdx(\"p\",null,\"ports:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"\\\"80:80\\\"\")),mdx(\"p\",null,\"networks:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"webnet\")),mdx(\"p\",null,\"visualizer:\"),mdx(\"p\",null,\"image: dockersamples/visualizer:stable\"),mdx(\"p\",null,\"ports:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"\\\"8080:8080\\\"\")),mdx(\"p\",null,\"volumes:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"\\\"/var/run/docker.sock:/var/run/docker.sock\\\"\")),mdx(\"p\",null,\"deploy:\"),mdx(\"p\",null,\"placement:\"),mdx(\"p\",null,\"constraints: \",\"[node.role == manager]\"),mdx(\"p\",null,\"networks:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"webnet\")),mdx(\"p\",null,\"redis:\"),mdx(\"p\",null,\"image: redis\"),mdx(\"p\",null,\"ports:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"\\\"6379:6379\\\"\")),mdx(\"p\",null,\"volumes:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"\\\"/home/docker/data:/data\\\"\")),mdx(\"p\",null,\"deploy:\"),mdx(\"p\",null,\"placement:\"),mdx(\"p\",null,\"constraints: \",\"[node.role == manager]\"),mdx(\"p\",null,\"command: redis-server --appendonly yes\"),mdx(\"p\",null,\"networks:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"webnet\")),mdx(\"p\",null,\"networks:\"),mdx(\"p\",null,\"webnet:\"),mdx(\"p\",null,\"Redis has an official image in the Docker library and has been granted the short\\xA0image\\xA0name of just\\xA0redis, so no\\xA0username/repo\\xA0notation here. The Redis port, 6379, has been pre-configured by Redis to be exposed from the container to the host, and here in our Compose file we expose it from the host to the world, so you can enter the IP for any of your nodes into Redis Desktop Manager and manage this Redis instance, if you so choose.\"),mdx(\"p\",null,\"Most importantly, there are a couple of things in the\\xA0redis\\xA0specification that make data persist between deployments of this stack:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"redis\\xA0always runs on the manager, so it's always using the same filesystem.\"),mdx(\"li\",{parentName:\"ul\"},\"redis\\xA0accesses an arbitrary directory in the host's file system as\\xA0/data\\xA0inside the container, which is where Redis stores data.\")),mdx(\"p\",null,\"Together, this is creating a \\\"source of truth\\\" in your host's physical filesystem for the Redis data. Without this, Redis would store its data in\\xA0/data\\xA0inside the container's filesystem, which would get wiped out if that container were ever redeployed.\"),mdx(\"p\",null,\"This source of truth has two components:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"The placement constraint you put on the Redis service, ensuring that it always uses the same host.\"),mdx(\"li\",{parentName:\"ul\"},\"The volume you created that lets the container access\\xA0./data\\xA0(on the host) as\\xA0/data(inside the Redis container). While containers come and go, the files stored on\\xA0./data\\xA0on the specified host persists, enabling continuity.\")),mdx(\"p\",null,\"You are ready to deploy your new Redis-using stack.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Create a\\xA0./data\\xA0directory on the manager:\")),mdx(\"p\",null,\"docker-machine ssh myvm1 \\\"mkdir ./data\\\"\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Make sure your shell is configured to talk to\\xA0myvm1\\xA0(full examples are\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/get-started/part4/#configure-a-docker-machine-shell-to-the-swarm-manager\"}),\"here\"),\").\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Run\\xA0docker-machine ls\\xA0to list machines and make sure you are connected to\\xA0myvm1, as indicated by an asterisk next it.\"),mdx(\"li\",{parentName:\"ul\"},\"If needed, re-run\\xA0docker-machine env myvm1, then run the given command to configure the shell.\",mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},\"On\\xA0\",mdx(\"strong\",{parentName:\"li\"},\"Mac or Linux\"),\"\\xA0the command is:\")))),mdx(\"p\",null,\"eval $(docker-machine env myvm1)\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"On\\xA0\",mdx(\"strong\",{parentName:\"li\"},\"Windows\"),\"\\xA0the command is:\")),mdx(\"p\",null,\"& \\\"C:\\\\Program Files\\\\Docker\\\\Docker\\\\Resources\\\\bin\\\\docker-machine.exe\\\" env myvm1 | Invoke-Expression\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Run\\xA0docker stack deploy\\xA0one more time.\")),mdx(\"p\",null,\"$ docker stack deploy -c docker-compose.yml getstartedlab\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Run\\xA0docker service ls\\xA0to verify that the three services are running as expected.\")),mdx(\"p\",null,\"ID NAME MODE REPLICAS IMAGE PORTS\"),mdx(\"p\",null,\"x7uij6xb4foj getstartedlab_redis replicated 1/1 redis:latest *:6379->6379/tcp\"),mdx(\"p\",null,\"n5rvhm52ykq7 getstartedlab_visualizer replicated 1/1 dockersamples/visualizer:stable *:8080->8080/tcp\"),mdx(\"p\",null,\"mifd433bti1d getstartedlab_web replicated 5/5 orangesnap/getstarted:latest *:80->80/tcp\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Check the web page at one of your nodes, such as\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"http://192.168.99.101\"}),\"http://192.168.99.101\"),\", and look at the results of the visitor counter, which is now live and storing information on Redis.\")),mdx(\"p\",null,\"Also, check the visualizer at port 8080 on either node's IP address, and notice see the\\xA0redis service running along with the\\xA0web\\xA0and\\xA0visualizer\\xA0services.\"),mdx(\"h2\",null,mdx(\"a\",_extends({parentName:\"h2\"},{\"href\":\"https://docs.docker.com/engine/docker-overview/\"})),\"Docker overview\"),mdx(\"p\",null,\"Docker is an open platform for developing, shipping, and running applications. Docker enables you to separate your applications from your infrastructure, so you can deliver software quickly. With Docker, you can manage your infrastructure in the same ways you manage your applications. By taking advantage of Docker's methodologies for shipping, testing, and deploying code quickly, you can significantly reduce the delay between writing code and running it in production.\"),mdx(\"h3\",null,\"The Docker platform\"),mdx(\"p\",null,\"Docker provides the ability to package and run an application in a loosely isolated environment called a container. The isolation and security allow you to run many containers simultaneously on a given host. Containers are lightweight because they don't need the extra load of a hypervisor but run directly within the host machine's kernel. This means you can run more containers on a given hardware combination than if you were using virtual machines. You can even run Docker containers within host machines that are virtual machines!\"),mdx(\"p\",null,\"Docker provides tooling and a platform to manage the lifecycle of your containers:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Develop your application and its supporting components using containers.\"),mdx(\"li\",{parentName:\"ul\"},\"The container becomes the unit for distributing and testing your application.\"),mdx(\"li\",{parentName:\"ul\"},\"When you're ready, deploy your application into your production environment, as a container or an orchestrated service. This works the same whether your production environment is a local data center, a cloud provider, or a hybrid of the two.\")),mdx(\"h3\",null,\"Docker Engine\"),mdx(\"p\",null,\"Docker Engine\\xA0is a client-server application with these major components:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"A server which is a type of long-running program called a daemon process (the\\xA0dockerd command).\"),mdx(\"li\",{parentName:\"ul\"},\"A REST API which specifies interfaces that programs can use to talk to the daemon and instruct it what to do.\"),mdx(\"li\",{parentName:\"ul\"})),mdx(\"p\",null,\"The CLI uses the Docker REST API to control or interact with the Docker daemon through scripting or direct CLI commands. Many other Docker applications use the underlying API and CLI.\"),mdx(\"p\",null,\"The daemon creates and manages Docker\\xA0objects, such as images, containers, networks, and volumes.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": Docker is licensed under the open source Apache 2.0 license.\"),mdx(\"p\",null,\"For more details, see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/docker-overview/#docker-architecture\"}),\"Docker Architecture\"),\".\"),mdx(\"h3\",null,\"What can I use Docker for?\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Fast, consistent delivery of your applications\")),mdx(\"p\",null,\"Docker streamlines the development lifecycle by allowing developers to work in standardized environments using local containers which provide your applications and services. Containers are great for continuous integration and continuous delivery (CI/CD) workflows.\"),mdx(\"p\",null,\"Consider the following example scenario:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Your developers write code locally and share their work with their colleagues using Docker containers.\"),mdx(\"li\",{parentName:\"ul\"},\"They use Docker to push their applications into a test environment and execute automated and manual tests.\"),mdx(\"li\",{parentName:\"ul\"},\"When developers find bugs, they can fix them in the development environment and redeploy them to the test environment for testing and validation.\"),mdx(\"li\",{parentName:\"ul\"},\"When testing is complete, getting the fix to the customer is as simple as pushing the updated image to the production environment.\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Responsive deployment and scaling\")),mdx(\"p\",null,\"Docker's container-based platform allows for highly portable workloads. Docker containers can run on a developer's local laptop, on physical or virtual machines in a data center, on cloud providers, or in a mixture of environments.\"),mdx(\"p\",null,\"Docker's portability and lightweight nature also make it easy to dynamically manage workloads, scaling up or tearing down applications and services as business needs dictate, in near real time.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Running more workloads on the same hardware\")),mdx(\"p\",null,\"Docker is lightweight and fast. It provides a viable, cost-effective alternative to hypervisor-based virtual machines, so you can use more of your compute capacity to achieve your business goals. Docker is perfect for high density environments and for small and medium deployments where you need to do more with fewer resources.\"),mdx(\"h3\",null,\"Docker architecture\"),mdx(\"h4\",null,\"The Docker daemon\"),mdx(\"p\",null,\"The Docker daemon (dockerd) listens for Docker API requests and manages Docker objects such as images, containers, networks, and volumes. A daemon can also communicate with other daemons to manage Docker services.\"),mdx(\"h4\",null,\"The Docker client\"),mdx(\"p\",null,\"The Docker client (docker) is the primary way that many Docker users interact with Docker. When you use commands such as\\xA0docker run, the client sends these commands to\\xA0dockerd, which carries them out. The\\xA0docker\\xA0command uses the Docker API. The Docker client can communicate with more than one daemon.\"),mdx(\"h4\",null,\"Docker registries\"),mdx(\"p\",null,\"A Docker\\xA0registry\\xA0stores Docker images. Docker Hub and Docker Cloud are public registries that anyone can use, and Docker is configured to look for images on Docker Hub by default. You can even run your own private registry. If you use Docker Datacenter (DDC), it includes Docker Trusted Registry (DTR).\"),mdx(\"p\",null,\"When you use the\\xA0docker pull\\xA0or\\xA0docker run\\xA0commands, the required images are pulled from your configured registry. When you use the\\xA0docker push\\xA0command, your image is pushed to your configured registry.\"),mdx(\"p\",null,mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://store.docker.com/\"}),\"Docker store\"),\"\\xA0allows you to buy and sell Docker images or distribute them for free. For instance, you can buy a Docker image containing an application or service from a software vendor and use the image to deploy the application into your testing, staging, and production environments. You can upgrade the application by pulling the new version of the image and redeploying the containers.\"),mdx(\"h4\",null,\"Docker objects\"),mdx(\"p\",null,\"When you use Docker, you are creating and using images, containers, networks, volumes, plugins, and other objects. This section is a brief overview of some of those objects.\"),mdx(\"h5\",null,\"IMAGES\"),mdx(\"p\",null,\"An\\xA0image\\xA0is a read-only template with instructions for creating a Docker container. Often, an image is\\xA0based on\\xA0another image, with some additional customization. For example, you may build an image which is based on the\\xA0ubuntu\\xA0image, but installs the Apache web server and your application, as well as the configuration details needed to make your application run.\"),mdx(\"p\",null,\"You might create your own images, or you might only use those created by others and published in a registry. To build your own image, you create a\\xA0Dockerfile\\xA0with a simple syntax for defining the steps needed to create the image and run it. Each instruction in a Dockerfile creates a layer in the image. When you change the Dockerfile and rebuild the image, only those layers which have changed are rebuilt. This is part of what makes images so lightweight, small, and fast, when compared to other virtualization technologies.\"),mdx(\"h5\",null,\"CONTAINERS\"),mdx(\"p\",null,\"A container is a runnable instance of an image. You can create, start, stop, move, or delete a container using the Docker API or CLI. You can connect a container to one or more networks, attach storage to it, or even create a new image based on its current state.\"),mdx(\"p\",null,\"By default, a container is relatively well isolated from other containers and its host machine. You can control how isolated a container's network, storage, or other underlying subsystems are from other containers or from the host machine.\"),mdx(\"p\",null,\"A container is defined by its image as well as any configuration options you provide to it when you create or start it. When a container is removed, any changes to its state that are not stored in persistent storage disappear.\"),mdx(\"h6\",null,\"Example\\xA0\",mdx(\"strong\",{parentName:\"h6\"},\"docker run\"),\"\\xA0command\"),mdx(\"p\",null,\"The following command runs an\\xA0ubuntu\\xA0container, attaches interactively to your local command-line session, and runs\\xA0/bin/bash.\"),mdx(\"p\",null,\"$ docker run -i -t ubuntu /bin/bash\"),mdx(\"p\",null,\"When you run this command, the following happens (assuming you are using the default registry configuration):\"),mdx(\"p\",null,\"If you do not have the\\xA0ubuntu\\xA0image locally, Docker pulls it from your configured registry, as though you had run\\xA0docker pull ubuntu\\xA0manually.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Docker creates a new container, as though you had run a\\xA0docker container create\\xA0command manually.\"),mdx(\"li\",{parentName:\"ol\"},\"Docker allocates a read-write filesystem to the container, as its final layer. This allows a running container to create or modify files and directories in its local filesystem.\"),mdx(\"li\",{parentName:\"ol\"},\"Docker creates a network interface to connect the container to the default network, since you did not specify any networking options. This includes assigning an IP address to the container. By default, containers can connect to external networks using the host machine's network connection.\"),mdx(\"li\",{parentName:\"ol\"},\"Docker starts the container and executes\\xA0/bin/bash. Because the container is run interactively and attached to your terminal (due to the\\xA0-i\\xA0and\\xA0-t) flags, you can provide input using your keyboard and output is logged to your terminal.\"),mdx(\"li\",{parentName:\"ol\"},\"When you type\\xA0exit\\xA0to terminate the\\xA0/bin/bash\\xA0command, the container stops but is not removed. You can start it again or remove it.\")),mdx(\"h5\",null,\"Services\"),mdx(\"p\",null,\"Services allow you to scale containers across multiple Docker daemons, which all work together as a\\xA0swarm\\xA0with multiple\\xA0managers\\xA0and\\xA0workers. Each member of a swarm is a Docker daemon, and the daemons all communicate using the Docker API. A service allows you to define the desired state, such as the number of replicas of the service that must be available at any given time. By default, the service is load-balanced across all worker nodes. To the consumer, the Docker service appears to be a single application. Docker Engine supports swarm mode in Docker 1.12 and higher.\"),mdx(\"h3\",null,\"The underlying technology\"),mdx(\"p\",null,\"Docker is written in\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://golang.org/\"}),\"Go\"),\"\\xA0and takes advantage of several features of the Linux kernel to deliver its functionality.\"),mdx(\"h4\",null,\"Namespaces\"),mdx(\"p\",null,\"Docker uses a technology called\\xA0namespaces\\xA0to provide the isolated workspace called the\\xA0container. When you run a container, Docker creates a set of\\xA0namespaces\\xA0for that container.\"),mdx(\"p\",null,\"These namespaces provide a layer of isolation. Each aspect of a container runs in a separate namespace and its access is limited to that namespace.\"),mdx(\"p\",null,\"Docker Engine uses namespaces such as the following on Linux:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"The\\xA0pid\\xA0namespace:\"),\"\\xA0Process isolation (PID: Process ID).\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"The\\xA0net\\xA0namespace:\"),\"\\xA0Managing network interfaces (NET: Networking).\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"The\\xA0ipc\\xA0namespace:\"),\"\\xA0Managing access to IPC resources (IPC: InterProcess Communication).\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"The\\xA0mnt\\xA0namespace:\"),\"\\xA0Managing filesystem mount points (MNT: Mount).\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"The\\xA0uts\\xA0namespace:\"),\"\\xA0Isolating kernel and version identifiers. (UTS: Unix Timesharing System).\")),mdx(\"h4\",null,\"Control groups\"),mdx(\"p\",null,\"Docker Engine on Linux also relies on another technology called\\xA0control groups\\xA0(cgroups). A cgroup limits an application to a specific set of resources. Control groups allow Docker Engine to share available hardware resources to containers and optionally enforce limits and constraints. For example, you can limit the memory available to a specific container.\"),mdx(\"h4\",null,\"Union file systems\"),mdx(\"p\",null,\"Union file systems, or UnionFS, are file systems that operate by creating layers, making them very lightweight and fast. Docker Engine uses UnionFS to provide the building blocks for containers. Docker Engine can use multiple UnionFS variants, including AUFS, btrfs, vfs, and DeviceMapper.\"),mdx(\"h4\",null,\"Container format\"),mdx(\"p\",null,\"Docker Engine combines the namespaces, control groups, and UnionFS into a wrapper called a container format. The default container format is\\xA0libcontainer. In the future, Docker may support other container formats by integrating with technologies such as BSD Jails or Solaris Zones.\"),mdx(\"h1\",null,mdx(\"a\",_extends({parentName:\"h1\"},{\"href\":\"https://docs.docker.com/develop/\"})),\"Develop with Docker\"),mdx(\"p\",null,\"This page lists resources for application developers using Docker.\"),mdx(\"h2\",null,\"Develop new apps on Docker\"),mdx(\"p\",null,\"If you're just getting started developing a brand-new app on Docker, check out these resources to understand some of the most common patterns for getting the most benefits from Docker.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Learn to\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/get-started/part2/\"}),\"build an image from a Dockerfile\")),mdx(\"li\",{parentName:\"ul\"},\"Use\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/userguide/eng-image/multistage-build/\"}),\"multistage builds\"),\"\\xA0to keep your images lean\"),mdx(\"li\",{parentName:\"ul\"},\"Manage application data using\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/admin/volumes/volumes/\"}),\"volumes\"),\"\\xA0and\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/admin/volumes/bind-mounts/\"}),\"bind mounts\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/get-started/part3/\"}),\"Scale your app\"),\"\\xA0as a swarm service\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/get-started/part5/\"}),\"Define your app stack\"),\"\\xA0using a compose file\"),mdx(\"li\",{parentName:\"ul\"},\"General application development best practices\")),mdx(\"h2\",null,\"Learn about language-specific app development with Docker\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://github.com/docker/labs/tree/master/developer-tools/java/\"}),\"Docker for Java developers\"),\"\\xA0lab\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://github.com/docker/labs/tree/master/developer-tools/nodejs/porting\"}),\"Port a node.js app to Docker\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://github.com/docker/labs/tree/master/developer-tools/ruby\"}),\"Ruby on Rails app on Docker\"),\"\\xA0lab\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/examples/dotnetcore/\"}),\"Dockerize a .Net Core application\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/compose/aspnet-mssql-compose/\"}),\"Dockerize an ASP.NET Core application with SQL Server on Linux\"),\"\\xA0using Docker Compose\")),mdx(\"h2\",null,\"Advanced development with the SDK or API\"),mdx(\"p\",null,\"When you're comfortable developing apps by writing Dockerfiles or compose files and using the Docker CLI, you can take it to the next level by using the Docker Engine SDK for Go or Python or using the HTTP API directly.\"),mdx(\"h2\",null,mdx(\"a\",_extends({parentName:\"h2\"},{\"href\":\"https://docs.docker.com/develop/dev-best-practices/\"})),\"Docker development best practices\"),mdx(\"h3\",null,\"How to keep your images small\"),mdx(\"p\",null,\"Small images are faster to pull over the network and faster to load into memory when starting containers or services. There are a few rules of thumb to keep image size small:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Start with an appropriate base image. For instance, if you need a JDK, consider basing your image on the official\\xA0openjdk\\xA0image, rather than starting with a generic\\xA0ubuntu\\xA0image and installing\\xA0openjdk\\xA0as part of the Dockerfile.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/userguide/eng-image/multistage-build/\"}),\"Use multistage builds\"),\". For instance, you can use the\\xA0maven\\xA0image to build your Java application, then reset to the\\xA0tomcat\\xA0image and copy the Java artifacts into the correct location to deploy your app, all in the same Dockerfile. This means that your final image doesn't include all the libraries and dependencies pulled in by the build, but only the artifacts and the environment needed to run them.\"),mdx(\"li\",{parentName:\"ul\"},\"If you need to use a version of Docker that does not include multistage builds, try to reduce the number of layers in your image by \",mdx(\"strong\",{parentName:\"li\"},\"minimizing the number of separate\\xA0RUN commands\"),\" in your Dockerfile. You can do this by consolidating multiple commands into a single\\xA0RUN\\xA0line and using your shell's mechanisms to combine them together. Consider the following two fragments. The first creates two layers in the image, while the second only creates one.\")),mdx(\"p\",null,\"RUN apt-get -y update\"),mdx(\"p\",null,\"RUN apt-get install -y python\"),mdx(\"p\",null,\"RUN apt-get -y update && apt-get install -y python\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"If you have \",mdx(\"strong\",{parentName:\"li\"},\"multiple images with a lot in common, consider creating your own\\xA0\"),mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/userguide/eng-image/baseimages/\"}),mdx(\"strong\",{parentName:\"a\"},\"base image\")),\"\\xA0with the shared components, and basing your unique images on that. Docker only needs to load the common layers once, and they are cached. This means that your derivative images use memory on the Docker host more efficiently and load more quickly.\"),mdx(\"li\",{parentName:\"ul\"},\"To keep your production image lean but allow for debugging, consider using the production image as the base image for the debug image. Additional testing or debugging tooling can be added on top of the production image.\"),mdx(\"li\",{parentName:\"ul\"},\"When building images, always tag them with useful tags which codify version information, intended destination (prod\\xA0or\\xA0test, for instance), stability, or other information that is useful when deploying the application in different environments. Do not rely on the automatically-created\\xA0latest\\xA0tag.\")),mdx(\"h3\",null,\"Where and how to persist application data\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Avoid\"),\"\\xA0storing application data in your container's writable layer using\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/userguide/storagedriver/\"}),\"storage drivers\"),\". This increases the size of your container and is less efficient from an I/O perspective than using volumes or bind mounts.\"),mdx(\"li\",{parentName:\"ul\"},\"Instead, store data using\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/admin/volumes/volumes/\"}),\"volumes\"),\".\"),mdx(\"li\",{parentName:\"ul\"},\"One case where it is appropriate to use\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/admin/volumes/bind-mounts/\"}),\"bind mounts\"),\"\\xA0is during development, when you may want to mount your source directory or a binary you just built into your container. For production, use a volume instead, mounting it into the same location as you mounted a bind mount during development.\"),mdx(\"li\",{parentName:\"ul\"},\"For production, use\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/secrets/\"}),\"secrets\"),\"\\xA0to store sensitive application data used by services, and use\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/configs/\"}),\"configs\"),\" for non-sensitive data such as configuration files. If you currently use standalone containers, consider migrating to use single-replica services, so that you can take advantage of these service-only features.\")),mdx(\"h3\",null,\"Use swarm services when possible\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"When possible, design your application with the ability to scale using swarm services.\"),mdx(\"li\",{parentName:\"ul\"},\"Even if you only need to run a single instance of your application, swarm services provide several advantages over standalone containers. A service's configuration is declarative, and Docker is always working to keep the desired and actual state in sync.\"),mdx(\"li\",{parentName:\"ul\"},\"Networks and volumes can be connected and disconnected from swarm services, and Docker handles redeploying the individual service containers in a non-disruptive way. Standalone containers need to be manually stopped, removed, and recreated to accommodate configuration changes.\"),mdx(\"li\",{parentName:\"ul\"},\"Several features, such as the ability to store\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/secrets/\"}),\"secrets\"),\"\\xA0and\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/configs/\"}),\"configs\"),\", are only available to services rather than standalone containers. These features allow you to keep your images as generic as possible and to avoid storing sensitive data within the Docker images or containers themselves.\"),mdx(\"li\",{parentName:\"ul\"},\"Let\\xA0docker stack deploy\\xA0handle any image pulls for you, instead of using\\xA0docker pull. This way, your deployment doesn't try to pull from nodes that are down. Also, when new nodes are added to the swarm, images are pulled automatically.\")),mdx(\"p\",null,\"There are limitations around sharing data amongst nodes of a swarm service. If you use\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/docker-for-aws/persistent-data-volumes/\"}),\"Docker for AWS\"),\" or\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/develop/docker-for-azure/persistent-data-volumes/\"}),\"Docker for Azure\"),\", you can use the Cloudstor plugin to share data amongst your swarm service nodes. You can also write your application data into a separate database which supports simultaneous updates.\"),mdx(\"h3\",null,\"Use CI/CD for testing and deployment\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"When you check a change into source control or create a pull request, use\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/docker-cloud/builds/automated-build/\"}),\"Docker Cloud\"),\"\\xA0or another CI/CD pipeline to automatically build and tag a Docker image and test it. Docker Cloud can also deploy tested apps straight into production.\"),mdx(\"li\",{parentName:\"ul\"},\"Take this even further with\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/enterprise/\"}),\"Docker EE\"),\"\\xA0by requiring your development, testing, and security teams to sign images before they can be deployed into production. This way, you can be sure that before an image is deployed into production, it has been tested and signed off by, for instance, development, quality, and security teams.\")),mdx(\"h3\",null,\"Differences in development and production environments\"),mdx(\"hr\",null),mdx(\"p\",null,\"  Development                                                          Production\\nUse bind mounts to give your container access to your source code.   Use volumes to store container data.\\nUse Docker for Mac or Docker for Windows.                            Use Docker EE if possible, with\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/security/userns-remap/\"}),\"userns mapping\"),\"\\xA0for greater isolation of Docker processes from host processes.\\nDon't worry about time drift.                                        Always run an NTP client on the Docker host and within each container process and sync them all to the same NTP server. If you use swarm services, also ensure that each Docker node syncs its clocks to the same time source as the containers.\"),mdx(\"hr\",null),mdx(\"h2\",null,\"Develop Images\"),mdx(\"h3\",null,mdx(\"a\",_extends({parentName:\"h3\"},{\"href\":\"https://docs.docker.com/develop/develop-images/dockerfile_best-practices/\"})),\"Best practices for writing Dockerfiles\"),mdx(\"p\",null,\"Docker can build images automatically by reading the instructions from a\\xA0Dockerfile, a text file that contains all the commands, in order, needed to build a given image.\\xA0Dockerfiles adhere to a specific format and use a specific set of instructions.\"),mdx(\"p\",null,\"This covers the best practices and methods recommended by Docker, Inc. and the Docker community for building efficient images. To see many of these practices and recommendations in action, check out the Dockerfile for\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/docker-library/buildpack-deps/blob/master/jessie/Dockerfile\"}),\"buildpack-deps\"),\".\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": for more detailed explanations of any of the Dockerfile commands mentioned here, visit the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/builder/\"}),\"Dockerfile Reference\"),\"\\xA0page.\"),mdx(\"h4\",null,\"General guidelines and recommendations\"),mdx(\"h5\",null,\"Containers should be ephemeral\"),mdx(\"p\",null,\"The container produced by the image your\\xA0Dockerfile\\xA0defines should be as ephemeral as possible. By \\\"ephemeral,\\\" we mean that it can be stopped and destroyed and a new one built and put in place with an absolute minimum of set-up and configuration. You may want to take a look at the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://12factor.net/processes\"}),\"Processes\"),\"\\xA0section of the 12 Factor app methodology to get a feel for the motivations of running containers in such a stateless fashion.\"),mdx(\"h6\",null,\"Use a .dockerignore file\"),mdx(\"p\",null,\"The current working you directory where are located when you issue a\\xA0docker build\\xA0command is called the\\xA0build context, and the\\xA0Dockerfile\\xA0must be somewhere within this build context. By default, it is assumed to be in the current directory, but you can specify a different location by using the\\xA0-fflag. Regardless of where the\\xA0Dockerfile\\xA0lives, all the recursive contents of files and directories in the current directory are sent to the Docker daemon as the\\xA0build context. Inadvertently including files that are not necessary for building the image results in a larger build context and larger image size. These in turn can increase build time, time to pull and push the image, and the runtime size of containers. To see how big your build context is, look for a message like the following, when you build your\\xA0Dockerfile.\"),mdx(\"p\",null,\"Sending build context to Docker daemon 187.8MB\"),mdx(\"p\",null,\"To exclude files which are not relevant to the build, without restructuring your source repository, use a\\xA0.dockerignore\\xA0file. This file supports exclusion patterns similar to\\xA0.gitignore\\xA0files. For information on creating one, see the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/builder/#dockerignore-file\"}),\".dockerignore file\"),\". In addition to using a\\xA0.dockerignore\\xA0file, check out the information below on\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#use-multi-stage-builds\"}),\"multi-stage builds\"),\".\"),mdx(\"h5\",null,\"Use multi-stage builds\"),mdx(\"p\",null,\"If you use Docker 17.05 or higher, you can use\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/develop/develop-images/multistage-build/\"}),\"multi-stage builds\"),\"\\xA0to drastically reduce the size of your final image, without the need to jump through hoops to reduce the number of intermediate layers or remove intermediate files during the build.\"),mdx(\"p\",null,\"Images being built by the final stage only, you can most of the time benefit both the build cache and minimize images layers.\"),mdx(\"p\",null,\"Your build stage may contain several layers, ordered from the less frequently changed to the more frequently changed for example:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Install tools you need to build your application\"),mdx(\"li\",{parentName:\"ul\"},\"Install or update library dependencies\"),mdx(\"li\",{parentName:\"ul\"},\"Generate your application\")),mdx(\"p\",null,\"A Dockerfile for a go application could look like:\"),mdx(\"p\",null,\"FROM golang:1.9.2-alpine3.6 AS build\"),mdx(\"h1\",null,\"Install tools required to build the project\"),mdx(\"h1\",null,\"We need to run \",mdx(\"inlineCode\",{parentName:\"h1\"},\"docker build --no-cache .\"),\" to update those dependencies\"),mdx(\"p\",null,\"RUN apk add --no-cache git\"),mdx(\"p\",null,\"RUN go get github.com/golang/dep/cmd/dep\"),mdx(\"h1\",null,\"Gopkg.toml and Gopkg.lock lists project dependencies\"),mdx(\"h1\",null,\"These layers are only re-built when Gopkg files are updated\"),mdx(\"p\",null,\"COPY Gopkg.lock Gopkg.toml /go/src/project/\"),mdx(\"p\",null,\"WORKDIR /go/src/project/\"),mdx(\"h1\",null,\"Install library dependencies\"),mdx(\"p\",null,\"RUN dep ensure -vendor-only\"),mdx(\"h1\",null,\"Copy all project and build it\"),mdx(\"h1\",null,\"This layer is rebuilt when ever a file has changed in the project directory\"),mdx(\"p\",null,\"COPY . /go/src/project/\"),mdx(\"p\",null,\"RUN go build -o /bin/project\"),mdx(\"h1\",null,\"This results in a single layer image\"),mdx(\"p\",null,\"FROM scratch\"),mdx(\"p\",null,\"COPY --from=build /bin/project /bin/project\"),mdx(\"p\",null,\"ENTRYPOINT \",\"[\\\"/bin/project\\\"]\"),mdx(\"p\",null,\"CMD \",\"[\\\"--help\\\"]\"),mdx(\"h5\",null,\"Avoid installing unnecessary packages\"),mdx(\"p\",null,\"To reduce complexity, dependencies, file sizes, and build times, you should avoid installing extra or unnecessary packages just because they might be \\\"nice to have.\\\" For example, you don't need to include a text editor in a database image.\"),mdx(\"h5\",null,\"Each container should have only one concern\"),mdx(\"p\",null,\"Decoupling applications into multiple containers makes it much easier to scale horizontally and reuse containers. For instance, a web application stack might consist of three separate containers, each with its own unique image, to manage the web application, database, and an in-memory cache in a decoupled manner.\"),mdx(\"p\",null,\"You may have heard that there should be \\\"one process per container\\\". While this mantra has good intentions, it is not necessarily true that there should be only one operating system process per container. In addition to the fact that containers can now be\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/run/#specifying-an-init-process\"}),\"spawned with an init process\"),\", some programs might spawn additional processes of their own accord. For instance,\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://www.celeryproject.org/\"}),\"Celery\"),\"\\xA0can spawn multiple worker processes, or\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://httpd.apache.org/\"}),\"Apache\"),\"\\xA0might create a process per request. While \\\"one process per container\\\" is frequently a good rule of thumb, it is not a hard and fast rule. Use your best judgment to keep containers as clean and modular as possible.\"),mdx(\"p\",null,\"If containers depend on each other, you can use\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/userguide/networking/\"}),\"Docker container networks\"),\"\\xA0to ensure that these containers can communicate.\"),mdx(\"h5\",null,\"Minimize the number of layers\"),mdx(\"p\",null,\"Prior to Docker 17.05, and even more, prior to Docker 1.10, it was important to minimize the number of layers in your image. The following improvements have mitigated this need:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"In Docker 1.10 and higher, only\\xA0RUN,\\xA0COPY, and\\xA0ADD\\xA0instructions create layers. Other instructions create temporary intermediate images, and no longer directly increase the size of the build.\"),mdx(\"li\",{parentName:\"ul\"},\"Docker 17.05 and higher add support for\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/develop/develop-images/multistage-build/\"}),\"multi-stage builds\"),\", which allow you to copy only the artifacts you need into the final image. This allows you to include tools and debug information in your intermediate build stages without increasing the size of the final image.\")),mdx(\"h5\",null,\"Sort multi-line arguments\"),mdx(\"p\",null,\"Whenever possible, ease later changes by sorting multi-line arguments alphanumerically. This helps you avoid duplication of packages and make the list much easier to update. This also makes PRs a lot easier to read and review. Adding a space before a backslash (\",\")\",\" helps as well.\"),mdx(\"p\",null,\"Here's an example from the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/docker-library/buildpack-deps\"}),\"buildpack-deps\\xA0image\"),\":\"),mdx(\"p\",null,\"RUN apt-get update && apt-get install -y \\\\\"),mdx(\"p\",null,\"bzr \\\\\"),mdx(\"p\",null,\"cvs \\\\\"),mdx(\"p\",null,\"git \\\\\"),mdx(\"p\",null,\"mercurial \\\\\"),mdx(\"p\",null,\"subversion\"),mdx(\"h5\",null,\"Build cache\"),mdx(\"p\",null,\"During the process of building an image Docker steps through the instructions in your\\xA0Dockerfile executing each in the order specified. As each instruction is examined Docker looks for an existing image in its cache that it can reuse, rather than creating a new (duplicate) image. If you do not want to use the cache at all you can use the\\xA0--no-cache=true\\xA0option on the\\xA0docker build\\xA0command.\"),mdx(\"p\",null,\"However, if you do let Docker use its cache then it is very important to understand when it can, and cannot, find a matching image. The basic rules that Docker follows are outlined below:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Starting with a parent image that is already in the cache, the next instruction is compared against all child images derived from that base image to see if one of them was built using the exact same instruction. If not, the cache is invalidated.\"),mdx(\"li\",{parentName:\"ul\"},\"In most cases simply comparing the instruction in the\\xA0Dockerfile\\xA0with one of the child images is sufficient. However, certain instructions require a little more examination and explanation.\"),mdx(\"li\",{parentName:\"ul\"},\"For the\\xA0ADD\\xA0and\\xA0COPY\\xA0instructions, the contents of the file(s) in the image are examined and a checksum is calculated for each file. The last-modified and last-accessed times of the file(s) are not considered in these checksums. During the cache lookup, the checksum is compared against the checksum in the existing images. If anything has changed in the file(s), such as the contents and metadata, then the cache is invalidated.\"),mdx(\"li\",{parentName:\"ul\"},\"Aside from the\\xA0ADD\\xA0and\\xA0COPY\\xA0commands, cache checking does not look at the files in the container to determine a cache match. For example, when processing a\\xA0RUN apt-get -y update command the files updated in the container are not examined to determine if a cache hit exists. In that case just the command string itself is used to find a match.\")),mdx(\"p\",null,\"Once the cache is invalidated, all subsequent\\xA0Dockerfile\\xA0commands generate new images and the cache is not used.\"),mdx(\"h4\",null,\"The Dockerfile instructions\"),mdx(\"p\",null,\"These recommendations help you to write an efficient and maintainable\\xA0Dockerfile.\"),mdx(\"h5\",null,\"FROM\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/builder/#from\"}),\"Dockerfile reference for the FROM instruction\"))),mdx(\"p\",null,\"Whenever possible, use current Official Repositories as the basis for your image. We recommend the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://hub.docker.com/_/alpine/\"}),\"Alpine image\"),\"\\xA0since it's very tightly controlled and kept minimal (currently under 5 mb), while still being a full distribution.\"),mdx(\"h5\",null,\"LABEL\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/config/labels-custom-metadata/\"}),\"Understanding object labels\"))),mdx(\"p\",null,\"You can add labels to your image to help organize images by project, record licensing information, to aid in automation, or for other reasons. For each label, add a line beginning with\\xA0LABEL\\xA0and with one or more key-value pairs. The following examples show the different acceptable formats. Explanatory comments are included inline.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": If your string contains spaces, it must be quoted,\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"or\"),\"\\xA0the spaces must be escaped. If your string contains inner quote characters (\\\"), escape them as well.\"),mdx(\"h1\",null,\"Set one or more individual labels\"),mdx(\"p\",null,\"LABEL com.example.version=\\\"0.0.1-beta\\\"\"),mdx(\"p\",null,\"LABEL vendor=\\\"ACME Incorporated\\\"\"),mdx(\"p\",null,\"LABEL com.example.release-date=\\\"2015-02-12\\\"\"),mdx(\"p\",null,\"LABEL com.example.version.is-production=\\\"\\\"\"),mdx(\"p\",null,\"An image can have more than one label. Prior to Docker 1.10, it was recommended to combine all labels into a single\\xA0LABEL\\xA0instruction, to prevent extra layers from being created. This is no longer necessary, but combining labels is still supported.\"),mdx(\"h1\",null,\"Set multiple labels on one line\"),mdx(\"p\",null,\"LABEL com.example.version=\\\"0.0.1-beta\\\" com.example.release-date=\\\"2015-02-12\\\"\"),mdx(\"p\",null,\"The above can also be written as:\"),mdx(\"h1\",null,\"Set multiple labels at once, using line-continuation characters to break long lines\"),mdx(\"p\",null,\"LABEL vendor=ACME\\\\ Incorporated \\\\\"),mdx(\"p\",null,\"com.example.is-beta= \\\\\"),mdx(\"p\",null,\"com.example.is-production=\\\"\\\" \\\\\"),mdx(\"p\",null,\"com.example.version=\\\"0.0.1-beta\\\" \\\\\"),mdx(\"p\",null,\"com.example.release-date=\\\"2015-02-12\\\"\"),mdx(\"p\",null,\"See\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/labels-custom-metadata/\"}),\"Understanding object labels\"),\"\\xA0for guidelines about acceptable label keys and values. For information about querying labels, refer to the items related to filtering in\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/labels-custom-metadata/#managing-labels-on-objects\"}),\"Managing labels on objects\"),\". See also \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/builder/#label\"}),\"LABEL\"),\"\\xA0in the Dockerfile reference.\"),mdx(\"h5\",null,\"RUN\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/builder/#run\"}),\"Dockerfile reference for the RUN instruction\"))),mdx(\"p\",null,\"As always, to make your\\xA0Dockerfile\\xA0more readable, understandable, and maintainable, split long or complex\\xA0RUN\\xA0statements on multiple lines separated with backslashes.\"),mdx(\"h6\",null,\"APT-GET\"),mdx(\"p\",null,\"Probably the most common use-case for\\xA0RUN\\xA0is an application of\\xA0apt-get. The\\xA0RUN apt-get command, because it installs packages, has several gotchas to look out for.\"),mdx(\"p\",null,\"You should avoid\\xA0RUN apt-get upgrade\\xA0or\\xA0dist-upgrade, as many of the \\\"essential\\\" packages from the parent images can't upgrade inside an\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/run/#security-configuration\"}),\"unprivileged container\"),\". If a package contained in the parent image is out-of-date, you should contact its maintainers. If you know there's a package,\\xA0foo, that needs to be updated, use\\xA0apt-get install -y foo\\xA0to update automatically.\"),mdx(\"p\",null,\"Always combine\\xA0RUN apt-get update\\xA0with\\xA0apt-get install\\xA0in the same\\xA0RUN\\xA0statement. For example:\"),mdx(\"p\",null,\"RUN apt-get update && apt-get install -y \\\\\"),mdx(\"p\",null,\"package-bar \\\\\"),mdx(\"p\",null,\"package-baz \\\\\"),mdx(\"p\",null,\"package-foo\"),mdx(\"p\",null,\"Using\\xA0apt-get update\\xA0alone in a\\xA0RUN\\xA0statement causes caching issues and subsequent\\xA0apt-get install\\xA0instructions fail. For example, say you have a Dockerfile:\"),mdx(\"p\",null,\"FROM ubuntu:14.04\"),mdx(\"p\",null,\"RUN apt-get update\"),mdx(\"p\",null,\"RUN apt-get install -y curl\"),mdx(\"p\",null,\"After building the image, all layers are in the Docker cache. Suppose you later modify\\xA0apt-get installby adding extra package:\"),mdx(\"p\",null,\"FROM ubuntu:14.04\"),mdx(\"p\",null,\"RUN apt-get update\"),mdx(\"p\",null,\"RUN apt-get install -y curl nginx\"),mdx(\"p\",null,\"Docker sees the initial and modified instructions as identical and reuses the cache from previous steps. As a result the\\xA0apt-get update\\xA0is\\xA0NOT\\xA0executed because the build uses the cached version. Because the\\xA0apt-get update\\xA0is not run, your build can potentially get an outdated version of the\\xA0curl\\xA0and\\xA0nginx\\xA0packages.\"),mdx(\"p\",null,\"Using\\xA0RUN apt-get update && apt-get install -y\\xA0ensures your Dockerfile installs the latest package versions with no further coding or manual intervention. This technique is known as \\\"cache busting\\\". You can also achieve cache-busting by specifying a package version. This is known as version pinning, for example:\"),mdx(\"p\",null,\"RUN apt-get update && apt-get install -y \\\\\"),mdx(\"p\",null,\"package-bar \\\\\"),mdx(\"p\",null,\"package-baz \\\\\"),mdx(\"p\",null,\"package-foo=1.3.*\"),mdx(\"p\",null,\"Version pinning forces the build to retrieve a version regardless of what's in the cache. This technique can also reduce failures due to unanticipated changes in required packages.\"),mdx(\"p\",null,\"Below is a well-formed\\xA0RUN\\xA0instruction that demonstrates all the\\xA0apt-get\\xA0recommendations.\"),mdx(\"p\",null,\"RUN apt-get update && apt-get install -y \\\\\"),mdx(\"p\",null,\"aufs-tools \\\\\"),mdx(\"p\",null,\"automake \\\\\"),mdx(\"p\",null,\"build-essential \\\\\"),mdx(\"p\",null,\"curl \\\\\"),mdx(\"p\",null,\"dpkg-sig \\\\\"),mdx(\"p\",null,\"libcap-dev \\\\\"),mdx(\"p\",null,\"libsqlite3-dev \\\\\"),mdx(\"p\",null,\"mercurial \\\\\"),mdx(\"p\",null,\"reprepro \\\\\"),mdx(\"p\",null,\"ruby1.9.1 \\\\\"),mdx(\"p\",null,\"ruby1.9.1-dev \\\\\"),mdx(\"p\",null,\"s3cmd=1.1.* \\\\\"),mdx(\"p\",null,\"&& rm -rf /var/lib/apt/lists/*\"),mdx(\"p\",null,\"The\\xA0s3cmd\\xA0instructions specifies a version\\xA01.1.*. If the image previously used an older version, specifying the new one causes a cache bust of\\xA0apt-get update\\xA0and ensure the installation of the new version. Listing packages on each line can also prevent mistakes in package duplication.\"),mdx(\"p\",null,\"In addition, when you clean up the apt cache by removing\\xA0/var/lib/apt/lists\\xA0reduces the image size, since the apt cache is not stored in a layer. Since the\\xA0RUN\\xA0statement starts with\\xA0apt-get update, the package cache is always refreshed prior to\\xA0apt-get install.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": The official Debian and Ubuntu images\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/moby/moby/blob/03e2923e42446dbb830c654d0eec323a0b4ef02a/contrib/mkimage/debootstrap#L82-L105\"}),\"automatically run\\xA0apt-get clean\"),\", so explicit invocation is not required.\"),mdx(\"h6\",null,\"USING PIPES\"),mdx(\"p\",null,\"Some\\xA0RUN\\xA0commands depend on the ability to pipe the output of one command into another, using the pipe character (|), as in the following example:\"),mdx(\"p\",null,\"RUN wget -O - \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://some.site\"}),\"https://some.site\"),\" | wc -l > /number\"),mdx(\"p\",null,\"Docker executes these commands using the\\xA0/bin/sh -c\\xA0interpreter, which only evaluates the exit code of the last operation in the pipe to determine success. In the example above this build step succeeds and produces a new image so long as the\\xA0wc -l\\xA0command succeeds, even if the\\xA0wget command fails.\"),mdx(\"p\",null,\"If you want the command to fail due to an error at any stage in the pipe, prepend\\xA0set -o pipefail &&to ensure that an unexpected error prevents the build from inadvertently succeeding. For example:\"),mdx(\"p\",null,\"RUN set -o pipefail && wget -O - \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://some.site\"}),\"https://some.site\"),\" | wc -l > /number\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": Not all shells support the\\xA0-o pipefail\\xA0option. In such cases (such as the\\xA0dash\\xA0shell, which is the default shell on Debian-based images), consider using the\\xA0exec\\xA0form of\\xA0RUN\\xA0to explicitly choose a shell that does support the\\xA0pipefail\\xA0option. For example:\"),mdx(\"p\",null,\"RUN \",\"[\\\"/bin/bash\\\", \\\"-c\\\", \\\"set -o pipefail && wget -O - https://some.site | wc -l > /number\\\"]\"),mdx(\"h5\",null,\"CMD\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/builder/#cmd\"}),\"Dockerfile reference for the CMD instruction\"))),mdx(\"p\",null,\"The\\xA0CMD\\xA0instruction should be used to run the software contained by your image, along with any arguments.\\xA0CMD\\xA0should almost always be used in the form of\\xA0CMD \",\"[\\\"executable\\\", \\\"param1\\\", \\\"param2\\\" ...]\",\". Thus, if the image is for a service, such as Apache and Rails, you would run something like\\xA0CMD \",\"[\\\"apache2\\\",\\\"-DFOREGROUND\\\"]\",\". Indeed, this form of the instruction is recommended for any service-based image.\"),mdx(\"p\",null,\"In most other cases,\\xA0CMD\\xA0should be given an interactive shell, such as bash, python and perl. For example,\\xA0CMD \",\"[\\\"perl\\\", \\\"-de0\\\"]\",\",\\xA0CMD \",\"[\\\"python\\\"]\",\", or\\xA0CMD \",\"[\\\"php\\\", \\\"-a\\\"]\",\". Using this form means that when you execute something like\\xA0docker run -it python, you'll get dropped into a usable shell, ready to go.\\xA0CMD\\xA0should rarely be used in the manner of\\xA0CMD \",\"[\\\"param\\\", \\\"param\\\"]\",\"\\xA0in conjunction with\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/builder/#entrypoint\"}),\"ENTRYPOINT\"),\", unless you and your expected users are already quite familiar with how\\xA0ENTRYPOINT works.\"),mdx(\"h5\",null,\"EXPOSE\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/builder/#expose\"}),\"Dockerfile reference for the EXPOSE instruction\"))),mdx(\"p\",null,\"The\\xA0EXPOSE\\xA0instruction indicates the ports on which a container listens for connections. Consequently, you should use the common, traditional port for your application. For example, an image containing the Apache web server would use\\xA0EXPOSE 80, while an image containing MongoDB would use\\xA0EXPOSE 27017\\xA0and so on.\"),mdx(\"p\",null,\"For external access, your users can execute\\xA0docker run\\xA0with a flag indicating how to map the specified port to the port of their choice. For container linking, Docker provides environment variables for the path from the recipient container back to the source (ie,\\xA0MYSQL_PORT_3306_TCP).\"),mdx(\"h5\",null,\"ENV\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/builder/#env\"}),\"Dockerfile reference for the ENV instruction\"))),mdx(\"p\",null,\"To make new software easier to run, you can use\\xA0ENV\\xA0to update the\\xA0PATH\\xA0environment variable for the software your container installs. For example,\\xA0ENV PATH /usr/local/nginx/bin:$PATH\\xA0ensures that\\xA0CMD \",\"[\\\"nginx\\\"]\",\"\\xA0just works.\"),mdx(\"p\",null,\"The\\xA0ENV\\xA0instruction is also useful for providing required environment variables specific to services you wish to containerize, such as Postgres's\\xA0PGDATA.\"),mdx(\"p\",null,\"Lastly,\\xA0ENV\\xA0can also be used to set commonly used version numbers so that version bumps are easier to maintain, as seen in the following example:\"),mdx(\"p\",null,\"ENV PG_MAJOR 9.3\"),mdx(\"p\",null,\"ENV PG_VERSION 9.3.4\"),mdx(\"p\",null,\"RUN curl -SL \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://example.com/postgres-$PG_VERSION.tar.xz\"}),\"http://example.com/postgres-$PG_VERSION.tar.xz\"),\" | tar -xJC /usr/src/postgress && ...\"),mdx(\"p\",null,\"ENV PATH /usr/local/postgres-$PG_MAJOR/bin:$PATH\"),mdx(\"p\",null,\"Like having constant variables in a program (as opposed to hard-coding values), this approach lets you change a single\\xA0ENV\\xA0instruction to auto-magically bump the version of the software in your container.\"),mdx(\"p\",null,\"Each\\xA0ENV\\xA0line creates a new intermediate layer, just like\\xA0RUN\\xA0commands. This means that even if you unset the environment variable in a future layer, it persists in this layer and its value can be dumped. You can test this by creating a Dockerfile like the following, and then building it.\"),mdx(\"p\",null,\"FROM alpine\"),mdx(\"p\",null,\"ENV ADMIN_USER=\\\"mark\\\"\"),mdx(\"p\",null,\"RUN echo $ADMIN_USER > ./mark\"),mdx(\"p\",null,\"RUN unset ADMIN_USER\"),mdx(\"p\",null,\"CMD sh\"),mdx(\"p\",null,\"$ docker run --rm -it test sh echo $ADMIN_USER\"),mdx(\"p\",null,\"mark\"),mdx(\"p\",null,\"To prevent this, and really unset the environment variable, use a\\xA0RUN\\xA0command with shell commands, to set, use, and unset the variable all in a single layer. You can separate your commands with;\\xA0or\\xA0&&. If you use the second method, and one of the commands fails, the\\xA0docker build\\xA0also fails. This is usually a good idea. Using\\xA0\\\\\\xA0as a line continuation character for Linux Dockerfiles improves readability. You could also put all the commands into a shell script and have the\\xA0RUN\\xA0command just run that shell script.\"),mdx(\"p\",null,\"FROM alpine\"),mdx(\"p\",null,\"RUN export ADMIN_USER=\\\"mark\\\" \\\\\"),mdx(\"p\",null,\"&& echo $ADMIN_USER > ./mark \\\\\"),mdx(\"p\",null,\"&& unset ADMIN_USER\"),mdx(\"p\",null,\"CMD sh\"),mdx(\"p\",null,\"$ docker run --rm -it test sh echo $ADMIN_USER\"),mdx(\"h5\",null,\"ADD or COPY\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/builder/#add\"}),\"Dockerfile reference for the ADD instruction\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/builder/#copy\"}),\"Dockerfile reference for the COPY instruction\"))),mdx(\"p\",null,\"Although\\xA0ADD\\xA0and\\xA0COPY\\xA0are functionally similar, generally speaking,\\xA0COPY\\xA0is preferred. That's because it's more transparent than\\xA0ADD.\\xA0COPY\\xA0only supports the basic copying of local files into the container, while\\xA0ADD\\xA0has some features (like local-only tar extraction and remote URL support) that are not immediately obvious. Consequently, the best use for\\xA0ADD\\xA0is local tar file auto-extraction into the image, as in\\xA0ADD rootfs.tar.xz /.\"),mdx(\"p\",null,\"If you have multiple\\xA0Dockerfile\\xA0steps that use different files from your context,\\xA0COPY\\xA0them individually, rather than all at once. This ensures that each step's build cache is only invalidated (forcing the step to be re-run) if the specifically required files change.\"),mdx(\"p\",null,\"For example:\"),mdx(\"p\",null,\"COPY requirements.txt /tmp/\"),mdx(\"p\",null,\"RUN pip install --requirement /tmp/requirements.txt\"),mdx(\"p\",null,\"COPY . /tmp/\"),mdx(\"p\",null,\"Results in fewer cache invalidations for the\\xA0RUN\\xA0step, than if you put the\\xA0COPY . /tmp/\\xA0before it.\"),mdx(\"p\",null,\"Because image size matters, using\\xA0ADD\\xA0to fetch packages from remote URLs is strongly discouraged; you should use\\xA0curl\\xA0or\\xA0wget\\xA0instead. That way you can delete the files you no longer need after they've been extracted, and you don't have to add another layer in your image. For example, you should avoid doing things like:\"),mdx(\"p\",null,\"ADD \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://example.com/big.tar.xz\"}),\"http://example.com/big.tar.xz\"),\" /usr/src/things/\"),mdx(\"p\",null,\"RUN tar -xJf /usr/src/things/big.tar.xz -C /usr/src/things\"),mdx(\"p\",null,\"RUN make -C /usr/src/things all\"),mdx(\"p\",null,\"And instead, do something like:\"),mdx(\"p\",null,\"RUN mkdir -p /usr/src/things \\\\\"),mdx(\"p\",null,\"&& curl -SL \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://example.com/big.tar.xz\"}),\"http://example.com/big.tar.xz\"),\" \\\\\"),mdx(\"p\",null,\"| tar -xJC /usr/src/things \\\\\"),mdx(\"p\",null,\"&& make -C /usr/src/things all\"),mdx(\"p\",null,\"For other items (files, directories) that do not require\\xA0ADD's tar auto-extraction capability, you should always use\\xA0COPY.\"),mdx(\"h5\",null,\"ENTRYPOINT\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/builder/#entrypoint\"}),\"Dockerfile reference for the ENTRYPOINT instruction\"))),mdx(\"p\",null,\"The best use for\\xA0ENTRYPOINT\\xA0is to set the image's main command, allowing that image to be run as though it was that command (and then use\\xA0CMD\\xA0as the default flags).\"),mdx(\"p\",null,\"Let's start with an example of an image for the command line tool\\xA0s3cmd:\"),mdx(\"p\",null,\"ENTRYPOINT \",\"[\\\"s3cmd\\\"]\"),mdx(\"p\",null,\"CMD \",\"[\\\"--help\\\"]\"),mdx(\"p\",null,\"Now the image can be run like this to show the command's help:\"),mdx(\"p\",null,\"$ docker run s3cmd\"),mdx(\"p\",null,\"Or using the right parameters to execute a command:\"),mdx(\"p\",null,\"$ docker run s3cmd ls s3://mybucket\"),mdx(\"p\",null,\"This is useful because the image name can double as a reference to the binary as shown in the command above.\"),mdx(\"p\",null,\"The\\xA0ENTRYPOINT\\xA0instruction can also be used in combination with a helper script, allowing it to function in a similar way to the command above, even when starting the tool may require more than one step.\"),mdx(\"p\",null,\"For example, the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://hub.docker.com/_/postgres/\"}),\"Postgres Official Image\"),\"\\xA0uses the following script as its\\xA0ENTRYPOINT:\"),mdx(\"p\",null,\"#!/bin/bash\"),mdx(\"p\",null,\"set -e\"),mdx(\"p\",null,\"if \",\"[ \\\"$1\\\" = \\\\'postgres\\\\' ]\",\"; then\"),mdx(\"p\",null,\"chown -R postgres \\\"$PGDATA\\\"\"),mdx(\"p\",null,\"if \",\"[ -z \\\"$(ls -A \\\"$PGDATA\\\")\\\" ]\",\"; then\"),mdx(\"p\",null,\"gosu postgres initdb\"),mdx(\"p\",null,\"fi\"),mdx(\"p\",null,\"exec gosu postgres \\\"$@\\\"\"),mdx(\"p\",null,\"fi\"),mdx(\"p\",null,\"exec \\\"$@\\\"\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": This script uses\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://wiki.bash-hackers.org/commands/builtin/exec\"}),\"the\\xA0exec\\xA0Bash command\"),\"\\xA0so that the final running application becomes the container's PID 1. This allows the application to receive any Unix signals sent to the container. See the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/builder/#entrypoint\"}),\"ENTRYPOINT\"),\"\\xA0help for more details.\"),mdx(\"p\",null,\"The helper script is copied into the container and run via\\xA0ENTRYPOINT\\xA0on container start:\"),mdx(\"p\",null,\"COPY ./docker-entrypoint.sh /\"),mdx(\"p\",null,\"ENTRYPOINT \",\"[\\\"/docker-entrypoint.sh\\\"]\"),mdx(\"p\",null,\"CMD \",\"[\\\"postgres\\\"]\"),mdx(\"p\",null,\"This script allows the user to interact with Postgres in several ways.\"),mdx(\"p\",null,\"It can simply start Postgres:\"),mdx(\"p\",null,\"$ docker run postgres\"),mdx(\"p\",null,\"Or, it can be used to run Postgres and pass parameters to the server:\"),mdx(\"p\",null,\"$ docker run postgres postgres --help\"),mdx(\"p\",null,\"Lastly, it could also be used to start a totally different tool, such as Bash:\"),mdx(\"p\",null,\"$ docker run --rm -it postgres bash\"),mdx(\"h5\",null,\"VOLUME\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/builder/#volume\"}),\"Dockerfile reference for the VOLUME instruction\"))),mdx(\"p\",null,\"The\\xA0VOLUME\\xA0instruction should be used to expose any database storage area, configuration storage, or files/folders created by your docker container. You are strongly encouraged to use\\xA0VOLUME\\xA0for any mutable and/or user-serviceable parts of your image.\"),mdx(\"h5\",null,\"USER\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/builder/#user\"}),\"Dockerfile reference for the USER instruction\"))),mdx(\"p\",null,\"If a service can run without privileges, use\\xA0USER\\xA0to change to a non-root user. Start by creating the user and group in the\\xA0Dockerfile\\xA0with something like\\xA0RUN groupadd -r postgres && useradd --no-log-init -r -g postgres postgres.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": Users and groups in an image get a non-deterministic UID/GID in that the \\\"next\\\" UID/GID gets assigned regardless of image rebuilds. So, if it's critical, you should assign an explicit UID/GID.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": Due to an\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/golang/go/issues/13548\"}),\"unresolved bug\"),\"\\xA0in the Go archive/tar package's handling of sparse files, attempting to create a user with a sufficiently large UID inside a Docker container can lead to disk exhaustion as\\xA0/var/log/faillog\\xA0in the container layer is filled with NUL (\\\\0) characters. Passing the\\xA0--no-log-init\\xA0flag to useradd works around this issue. The Debian/Ubuntu\\xA0adduser\\xA0wrapper does not support the\\xA0--no-log-init\\xA0flag and should be avoided.\"),mdx(\"p\",null,\"Avoid installing or using\\xA0sudo\\xA0since it has unpredictable TTY and signal-forwarding behavior that can cause problems. If you absolutely need functionality similar to\\xA0sudo, such as initializing the daemon as\\xA0root\\xA0but running it as non-root), consider using\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/tianon/gosu\"}),\"\\\"gosu\\\"\"),\".\"),mdx(\"p\",null,\"Lastly, to reduce layers and complexity, avoid switching\\xA0USER\\xA0back and forth frequently.\"),mdx(\"h5\",null,\"WORKDIR\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/builder/#workdir\"}),\"Dockerfile reference for the WORKDIR instruction\"))),mdx(\"p\",null,\"For clarity and reliability, you should always use absolute paths for your\\xA0WORKDIR. Also, you should use\\xA0WORKDIR\\xA0instead of proliferating instructions like\\xA0RUN cd ... && do-something, which are hard to read, troubleshoot, and maintain.\"),mdx(\"h5\",null,\"ONBUILD\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/builder/#onbuild\"}),\"Dockerfile reference for the ONBUILD instruction\"))),mdx(\"p\",null,\"An\\xA0ONBUILD\\xA0command executes after the current\\xA0Dockerfile\\xA0build completes.\\xA0ONBUILD\\xA0executes in any child image derived\\xA0FROM\\xA0the current image. Think of the\\xA0ONBUILD\\xA0command as an instruction the parent\\xA0Dockerfile\\xA0gives to the child\\xA0Dockerfile.\"),mdx(\"p\",null,\"A Docker build executes\\xA0ONBUILD\\xA0commands before any command in a child\\xA0Dockerfile.\"),mdx(\"p\",null,\"ONBUILD\\xA0is useful for images that are going to be built\\xA0FROM\\xA0a given image. For example, you would use\\xA0ONBUILD\\xA0for a language stack image that builds arbitrary user software written in that language within the\\xA0Dockerfile, as you can see in\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/docker-library/ruby/blob/master/2.4/jessie/onbuild/Dockerfile\"}),\"Ruby's\\xA0ONBUILD\\xA0variants\"),\".\"),mdx(\"p\",null,\"Images built from\\xA0ONBUILD\\xA0should get a separate tag, for example:\\xA0ruby:1.9-onbuild\\xA0or\\xA0ruby:2.0-onbuild.\"),mdx(\"p\",null,\"Be careful when putting\\xA0ADD\\xA0or\\xA0COPY\\xA0in\\xA0ONBUILD. The \\\"onbuild\\\" image fails catastrophically if the new build's context is missing the resource being added. Adding a separate tag, as recommended above, helps mitigate this by allowing the\\xA0Dockerfile\\xA0author to make a choice.\"),mdx(\"h4\",null,\"Examples for Official Repositories\"),mdx(\"p\",null,\"These Official Repositories have exemplary\\xA0Dockerfiles:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://hub.docker.com/_/golang/\"}),\"Go\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://hub.docker.com/_/perl/\"}),\"Perl\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://hub.docker.com/_/hylang/\"}),\"Hy\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://hub.docker.com/_/ruby/\"}),\"Ruby\"))),mdx(\"h4\",null,\"Additional resources\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/builder/\"}),\"Dockerfile Reference\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/develop/develop-images/baseimages/\"}),\"More about Base Images\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/docker-hub/builds/\"}),\"More about Automated Builds\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/docker-hub/official_repos/\"}),\"Guidelines for Creating Official Repositories\"))),mdx(\"h3\",null,mdx(\"a\",_extends({parentName:\"h3\"},{\"href\":\"https://docs.docker.com/develop/develop-images/baseimages\"})),\"Create a base image\"),mdx(\"p\",null,\"Most Dockerfiles start from a parent image. If you need to completely control the contents of your image, you might need to create a base image instead. Here's the difference:\"),mdx(\"p\",null,\"A\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/glossary/?term=parent%20image\"}),\"parent image\"),\"\\xA0is the image that your image is based on. It refers to the contents of the\\xA0FROMdirective in the Dockerfile. Each subsequent declaration in the Dockerfile modifies this parent image. Most Dockerfiles start from a parent image, rather than a base image. However, the terms are sometimes used interchangeably.\"),mdx(\"p\",null,\"A\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/glossary/?term=base%20image\"}),\"base image\"),\"\\xA0either has no\\xA0FROM\\xA0line in its Dockerfile, or has\\xA0FROM scratch.\"),mdx(\"p\",null,\"This topic shows you several ways to create a base image. The specific process will depend heavily on the Linux distribution you want to package. We have some examples below, and you are encouraged to submit pull requests to contribute new ones.\"),mdx(\"h4\",null,\"Create a full image using tar\"),mdx(\"p\",null,\"In general, start with a working machine that is running the distribution you'd like to package as a parent image, though that is not required for some tools like Debian's\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://wiki.debian.org/Debootstrap\"}),\"Debootstrap\"),\", which you can also use to build Ubuntu images.\"),mdx(\"p\",null,\"It can be as simple as this to create an Ubuntu parent image:\"),mdx(\"p\",null,\"$ sudo debootstrap xenial xenial > /dev/null\"),mdx(\"p\",null,\"$ sudo tar -C xenial -c . | docker import - xenial\"),mdx(\"p\",null,\"a29c15f1bf7a\"),mdx(\"p\",null,\"$ docker run xenial cat /etc/lsb-release\"),mdx(\"p\",null,\"DISTRIB_ID=Ubuntu\"),mdx(\"p\",null,\"DISTRIB_RELEASE=16.04\"),mdx(\"p\",null,\"DISTRIB_CODENAME=xenial\"),mdx(\"p\",null,\"DISTRIB_DESCRIPTION=\\\"Ubuntu 16.04 LTS\\\"\"),mdx(\"p\",null,\"There are more example scripts for creating parent images in the Docker GitHub Repo:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://github.com/moby/moby/blob/master/contrib/mkimage/busybox-static\"}),\"BusyBox\")),mdx(\"li\",{parentName:\"ul\"},\"CentOS / Scientific Linux CERN (SLC)\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://github.com/moby/moby/blob/master/contrib/mkimage/rinse\"}),\"on Debian/Ubuntu\"),\"\\xA0or\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://github.com/moby/moby/blob/master/contrib/mkimage-yum.sh\"}),\"on CentOS/RHEL/SLC/etc.\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://github.com/moby/moby/blob/master/contrib/mkimage/debootstrap\"}),\"Debian / Ubuntu\"))),mdx(\"h4\",null,\"Create a simple parent image using scratch\"),mdx(\"p\",null,\"You can use Docker's reserved, minimal image,\\xA0scratch, as a starting point for building containers. Using the\\xA0scratch\\xA0\\\"image\\\" signals to the build process that you want the next command in the\\xA0Dockerfile\\xA0to be the first filesystem layer in your image.\"),mdx(\"p\",null,\"While\\xA0scratch\\xA0appears in Docker's repository on the hub, you can't pull it, run it, or tag any image with the name\\xA0scratch. Instead, you can refer to it in your\\xA0Dockerfile. For example, to create a minimal container using\\xA0scratch:\"),mdx(\"p\",null,\"FROM scratch\"),mdx(\"p\",null,\"ADD hello /\"),mdx(\"p\",null,\"CMD \",\"[\\\"/hello\\\"]\"),mdx(\"p\",null,\"Assuming you built the \\\"hello\\\" executable example by following the instructions at \",mdx(\"inlineCode\",{parentName:\"p\"},\"<https://github.com/docker-library/hello-world/>\"),\", and you compiled it with the\\xA0-static\\xA0flag, you can build this Docker image using this\\xA0docker build\\xA0command:\"),mdx(\"p\",null,\"docker build --tag hello .\"),mdx(\"p\",null,\"Don't forget the\\xA0.\\xA0character at the end, which sets the build context to the current directory.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": Because Docker for Mac and Docker for Windows use a Linux VM, you need a Linux binary, rather than a Mac or Windows binary. You can use a Docker container to build it:\"),mdx(\"p\",null,\"$ docker run --rm -it -v $PWD:/build ubuntu:16.04\"),mdx(\"p\",null,\"container# apt-get update && apt-get install build-essential\"),mdx(\"p\",null,\"container# cd /build\"),mdx(\"p\",null,\"container# gcc -o hello -static -nostartfiles hello.c\"),mdx(\"p\",null,\"To run your new image, use the\\xA0docker run\\xA0command:\"),mdx(\"p\",null,\"docker run --rm hello\"),mdx(\"p\",null,\"This example creates the hello-world image used in the tutorials. If you want to test it out, you can clone \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/docker-library/hello-world\"}),\"the image repo\"),\".\"),mdx(\"h4\",null,\"More resources\"),mdx(\"p\",null,\"There are lots more resources available to help you write your\\xA0Dockerfile.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"There's a\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/builder/\"}),\"complete guide to all the instructions\"),\"\\xA0available for use in a\\xA0Dockerfile\\xA0in the reference section.\"),mdx(\"li\",{parentName:\"ul\"},\"To help you write a clear, readable, maintainable\\xA0Dockerfile, we've also written a\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/develop/develop-images/dockerfile_best-practices/\"}),\"Dockerfile best practices guide\"),\".\"),mdx(\"li\",{parentName:\"ul\"},\"If your goal is to create a new Official Repository, be sure to read up on Docker's\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/docker-hub/official_repos/\"}),\"Official Repositories\"),\".\")),mdx(\"h3\",null,mdx(\"a\",_extends({parentName:\"h3\"},{\"href\":\"https://docs.docker.com/develop/develop-images/multistage-build/4\"})),\"Use multi-stage builds\"),mdx(\"p\",null,\"Multi-stage builds are a new feature requiring Docker 17.05 or higher on the daemon and client. Multistage builds are useful to anyone who has struggled to optimize Dockerfiles while keeping them easy to read and maintain.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Acknowledgment\"),\": Special thanks to\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://twitter.com/alexellisuk\"}),\"Alex Ellis\"),\"\\xA0for granting permission to use his blog post\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://blog.alexellis.io/mutli-stage-docker-builds/\"}),\"Builder pattern vs. Multi-stage builds in Docker\"),\"\\xA0as the basis of the examples below.\"),mdx(\"h4\",null,\"Before multi-stage builds\"),mdx(\"p\",null,\"One of the most challenging things about building images is keeping the image size down. Each instruction in the Dockerfile adds a layer to the image, and you need to remember to clean up any artifacts you don't need before moving on to the next layer. To write a efficient Dockerfile, you have traditionally needed to employ shell tricks and other logic to keep the layers as small as possible and to ensure that each layer has the artifacts it needs from the previous layer and nothing else.\"),mdx(\"p\",null,\"It was actually very common to have one Dockerfile to use for development (which contained everything needed to build your application), and a slimmed-down one to use for production, which only contained your application and exactly what was needed to run it. This has been referred to as the \\\"builder pattern\\\". Maintaining two Dockerfiles is not ideal.\"),mdx(\"p\",null,\"Here's an example of a\\xA0Dockerfile.build\\xA0and\\xA0Dockerfile\\xA0which adhere to the builder pattern above:\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Dockerfile.build\"),\":\"),mdx(\"p\",null,\"FROM golang:1.7.3\"),mdx(\"p\",null,\"WORKDIR /go/src/github.com/alexellis/href-counter/\"),mdx(\"p\",null,\"COPY app.go .\"),mdx(\"p\",null,\"RUN go get -d -v golang.org/x/net/html \\\\\"),mdx(\"p\",null,\"&& CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .\"),mdx(\"p\",null,\"Notice that this example also artificially compresses two\\xA0RUN\\xA0commands together using the Bash\\xA0&&operator, to avoid creating an additional layer in the image. This is failure-prone and hard to maintain. It's easy to insert another command and forget to continue the line using the\\xA0\\\\\\xA0character, for example.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Dockerfile\"),\":\"),mdx(\"p\",null,\"FROM alpine:latest\"),mdx(\"p\",null,\"RUN apk --no-cache add ca-certificates\"),mdx(\"p\",null,\"WORKDIR /root/\"),mdx(\"p\",null,\"COPY app .\"),mdx(\"p\",null,\"CMD \",\"[\\\"./app\\\"]\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"build.sh\"),\":\"),mdx(\"p\",null,\"#!/bin/sh\"),mdx(\"p\",null,\"echo Building alexellis2/href-counter:build\"),mdx(\"p\",null,\"docker build --build-arg https_proxy=$https_proxy --build-arg http_proxy=$http_proxy \\\\\"),mdx(\"p\",null,\"-t alexellis2/href-counter:build . -f Dockerfile.build\"),mdx(\"p\",null,\"docker container create --name extract alexellis2/href-counter:build\"),mdx(\"p\",null,\"docker container cp extract:/go/src/github.com/alexellis/href-counter/app ./app\"),mdx(\"p\",null,\"docker container rm -f extract\"),mdx(\"p\",null,\"echo Building alexellis2/href-counter:latest\"),mdx(\"p\",null,\"docker build --no-cache -t alexellis2/href-counter:latest .\"),mdx(\"p\",null,\"rm ./app\"),mdx(\"p\",null,\"When you run the\\xA0build.sh\\xA0script, it needs to build the first image, create a container from it to copy the artifact out, then build the second image. Both images take up room on your system and you still have the\\xA0app\\xA0artifact on your local disk as well.\"),mdx(\"p\",null,\"Multi-stage builds vastly simplify this situation!\"),mdx(\"h4\",null,\"Use multi-stage builds\"),mdx(\"p\",null,\"With multi-stage builds, you use multiple\\xA0FROM\\xA0statements in your Dockerfile. Each\\xA0FROM\\xA0instruction can use a different base, and each of them begins a new stage of the build. You can selectively copy artifacts from one stage to another, leaving behind everything you don't want in the final image. To show how this works, Let's adapt the Dockerfile from the previous section to use multi-stage builds.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Dockerfile\"),\":\"),mdx(\"p\",null,\"FROM golang:1.7.3\"),mdx(\"p\",null,\"WORKDIR /go/src/github.com/alexellis/href-counter/\"),mdx(\"p\",null,\"RUN go get -d -v golang.org/x/net/html\"),mdx(\"p\",null,\"COPY app.go .\"),mdx(\"p\",null,\"RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .\"),mdx(\"p\",null,\"FROM alpine:latest\"),mdx(\"p\",null,\"RUN apk --no-cache add ca-certificates\"),mdx(\"p\",null,\"WORKDIR /root/\"),mdx(\"p\",null,\"COPY --from=0 /go/src/github.com/alexellis/href-counter/app .\"),mdx(\"p\",null,\"CMD \",\"[\\\"./app\\\"]\"),mdx(\"p\",null,\"You only need the single Dockerfile. You don't need a separate build script, either. Just run\\xA0docker build.\"),mdx(\"p\",null,\"$ docker build -t alexellis2/href-counter:latest .\"),mdx(\"p\",null,\"The result is the same tiny production image as before, with a significant reduction in complexity. You don't need to create any intermediate images and you don't need to extract any artifacts to your local system at all.\"),mdx(\"p\",null,\"How does it work? The second\\xA0FROM\\xA0instruction starts a new build stage with the\\xA0alpine:latest image as its base. The\\xA0COPY --from=0\\xA0line copies just the built artifact from the previous stage into this new stage. The Go SDK and any intermediate artifacts are left behind, and not saved in the final image.\"),mdx(\"h4\",null,\"Name your build stages\"),mdx(\"p\",null,\"By default, the stages are not named, and you refer to them by their integer number, starting with 0 for the first\\xA0FROM\\xA0instruction. However, you can name your stages, by adding an\\xA0as \",mdx(\"inlineCode\",{parentName:\"p\"},\"<NAME>\"),\"\\xA0to the\\xA0FROMinstruction. This example improves the previous one by naming the stages and using the name in the\\xA0COPY\\xA0instruction. This means that even if the instructions in your Dockerfile are re-ordered later, the\\xA0COPY\\xA0doesn't break.\"),mdx(\"p\",null,\"FROM golang:1.7.3 as builder\"),mdx(\"p\",null,\"WORKDIR /go/src/github.com/alexellis/href-counter/\"),mdx(\"p\",null,\"RUN go get -d -v golang.org/x/net/html\"),mdx(\"p\",null,\"COPY app.go .\"),mdx(\"p\",null,\"RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .\"),mdx(\"p\",null,\"FROM alpine:latest\"),mdx(\"p\",null,\"RUN apk --no-cache add ca-certificates\"),mdx(\"p\",null,\"WORKDIR /root/\"),mdx(\"p\",null,\"COPY --from=builder /go/src/github.com/alexellis/href-counter/app .\"),mdx(\"p\",null,\"CMD \",\"[\\\"./app\\\"]\"),mdx(\"h4\",null,\"Stop at a specific build stage\"),mdx(\"p\",null,\"When you build your image, you don't necessarily need to build the entire Dockerfile including every stage. You can specify a target build stage. The following command assumes you are using the previous\\xA0Dockerfile\\xA0but stops at the stage named\\xA0builder:\"),mdx(\"p\",null,\"$ docker build --target builder -t alexellis2/href-counter:latest .\"),mdx(\"p\",null,\"A few scenarios where this might be very powerful are:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Debugging a specific build stage\"),mdx(\"li\",{parentName:\"ul\"},\"Using a\\xA0debug\\xA0stage with all debugging symbols or tools enabled, and a lean\\xA0production\\xA0stage\"),mdx(\"li\",{parentName:\"ul\"},\"Using a\\xA0testing\\xA0stage in which your app gets populated with test data, but building for production using a different stage which uses real data\")),mdx(\"h4\",null,\"Use an external image as a \\\"stage\\\"\"),mdx(\"p\",null,\"When using multi-stage builds, you are not limited to copying from stages you created earlier in your Dockerfile. You can use the\\xA0COPY --from\\xA0instruction to copy from a separate image, either using the local image name, a tag available locally or on a Docker registry, or a tag ID. The Docker client pulls the image if necessary and copies the artifact from there. The syntax is:\"),mdx(\"p\",null,\"COPY --from=nginx:latest /etc/nginx/nginx.conf /nginx.conf\"),mdx(\"h3\",null,\"Dockerfile reference (Unread) (REF)\"),mdx(\"p\",null,\"Docker can build images automatically by reading the instructions from a\\xA0Dockerfile. A\\xA0Dockerfile is a text document that contains all the commands a user could call on the command line to assemble an image. Using\\xA0docker build\\xA0users can create an automated build that executes several command-line instructions in succession.\"),mdx(\"p\",null,\"This page describes the commands you can use in a\\xA0Dockerfile. When you are done reading this page, refer to the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices/\"}),\"Dockerfile\\xA0Best Practices\"),\"\\xA0for a tip-oriented guide.\"),mdx(\"h4\",null,\"Usage\"),mdx(\"p\",null,\"The\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/build/\"}),\"docker build\"),\"\\xA0command builds an image from a\\xA0Dockerfile\\xA0and a\\xA0context. The build's context is the set of files at a specified location\\xA0PATH\\xA0or\\xA0URL. The\\xA0PATH\\xA0is a directory on your local filesystem. The\\xA0URL\\xA0is a Git repository location.\"),mdx(\"p\",null,\"A context is processed recursively. So, a\\xA0PATH\\xA0includes any subdirectories and the\\xA0URL\\xA0includes the repository and its submodules. This example shows a build command that uses the current directory as context:\"),mdx(\"p\",null,\"$ docker build .\"),mdx(\"p\",null,\"Sending build context to Docker daemon 6.51 MB\"),mdx(\"p\",null,\"...\"),mdx(\"p\",null,\"The build is run by the Docker daemon, not by the CLI. The first thing a build process does is send the entire context (recursively) to the daemon. In most cases, it's best to start with an empty directory as context and keep your Dockerfile in that directory. Add only the files needed for building the Dockerfile.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Warning\"),\": Do not use your root directory,\\xA0/, as the\\xA0PATH\\xA0as it causes the build to transfer the entire contents of your hard drive to the Docker daemon.\"),mdx(\"p\",null,\"To use a file in the build context, the\\xA0Dockerfile\\xA0refers to the file specified in an instruction, for example, a\\xA0COPY\\xA0instruction. To increase the build's performance, exclude files and directories by adding a\\xA0.dockerignore\\xA0file to the context directory. For information about how to\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/builder/#dockerignore-file\"}),\"create a\\xA0.dockerignore\\xA0file\"),\"\\xA0see the documentation on this page.\"),mdx(\"p\",null,\"Traditionally, the\\xA0Dockerfile\\xA0is called\\xA0Dockerfile\\xA0and located in the root of the context. You use the\\xA0-f\\xA0flag with\\xA0docker build\\xA0to point to a Dockerfile anywhere in your file system.\"),mdx(\"p\",null,\"$ docker build -f /path/to/a/Dockerfile .\"),mdx(\"p\",null,\"You can specify a repository and tag at which to save the new image if the build succeeds:\"),mdx(\"p\",null,\"$ docker build -t shykes/myapp .\"),mdx(\"p\",null,\"To tag the image into multiple repositories after the build, add multiple\\xA0-t\\xA0parameters when you run the\\xA0build\\xA0command:\"),mdx(\"p\",null,\"$ docker build -t shykes/myapp:1.0.2 -t shykes/myapp:latest .\"),mdx(\"p\",null,\"Before the Docker daemon runs the instructions in the\\xA0Dockerfile, it performs a preliminary validation of the\\xA0Dockerfile\\xA0and returns an error if the syntax is incorrect:\"),mdx(\"p\",null,\"$ docker build -t test/myapp .\"),mdx(\"p\",null,\"Sending build context to Docker daemon 2.048 kB\"),mdx(\"p\",null,\"Error response from daemon: Unknown instruction: RUNCMD\"),mdx(\"p\",null,\"The Docker daemon runs the instructions in the\\xA0Dockerfile\\xA0one-by-one, committing the result of each instruction to a new image if necessary, before finally outputting the ID of your new image. The Docker daemon will automatically clean up the context you sent.\"),mdx(\"p\",null,\"Note that each instruction is run independently and causes a new image to be created - so\\xA0RUN cd /tmp\\xA0will not have any effect on the next instructions.\"),mdx(\"p\",null,\"Whenever possible, Docker will re-use the intermediate images (cache), to accelerate the\\xA0docker build process significantly. This is indicated by the\\xA0Using cache\\xA0message in the console output. (For more information, see the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices/#build-cache\"}),\"Build cache section\"),\"\\xA0in the\\xA0Dockerfile\\xA0best practices guide):\"),mdx(\"p\",null,\"$ docker build -t svendowideit/ambassador .\"),mdx(\"p\",null,\"Sending build context to Docker daemon 15.36 kB\"),mdx(\"p\",null,\"Step 1/4 : FROM alpine:3.2\"),mdx(\"p\",null,\"---> 31f630c65071\"),mdx(\"p\",null,\"Step 2/4 : MAINTAINER SvenDowideit\\\\@home.org.au\"),mdx(\"p\",null,\"---> Using cache\"),mdx(\"p\",null,\"---> 2a1c91448f5f\"),mdx(\"p\",null,\"Step 3/4 : RUN apk update && apk add socat && rm -r /var/cache/\"),mdx(\"p\",null,\"---> Using cache\"),mdx(\"p\",null,\"---> 21ed6e7fbb73\"),mdx(\"p\",null,\"Step 4/4 : CMD env | grep \",mdx(\"em\",{parentName:\"p\"},\"TCP= | (sed \\\\'s/.*_PORT\"),\"(\",\"[0-9]\",mdx(\"em\",{parentName:\"p\"},\")\",\"_TCP=tcp:\\\\/\\\\/\",\"(\",\".\"),\")\",\":\",\"(\",\".*\",\")\",\"/socat -t 100000000 TCP4-LISTEN:\\\\1,fork,reuseaddr TCP4:\\\\2:\\\\3 \\\\&/\\\\' && echo wait) | sh\"),mdx(\"p\",null,\"---> Using cache\"),mdx(\"p\",null,\"---> 7ea8aef582cc\"),mdx(\"p\",null,\"Successfully built 7ea8aef582cc\"),mdx(\"p\",null,\"Build cache is only used from images that have a local parent chain. This means that these images were created by previous builds or the whole chain of images was loaded with\\xA0docker load. If you wish to use build cache of a specific image you can specify it with\\xA0--cache-from\\xA0option. Images specified with--cache-from\\xA0do not need to have a parent chain and may be pulled from other registries.\"),mdx(\"p\",null,\"When you're done with your build, you're ready to look into\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/tutorials/dockerrepos/#/contributing-to-docker-hub\"}),\"Pushing a repository to its registry\"),\".\"),mdx(\"h4\",null,\"Format\"),mdx(\"p\",null,\"Here is the format of the\\xA0Dockerfile:\"),mdx(\"h1\",null,\"Comment\"),mdx(\"p\",null,\"INSTRUCTION arguments\"),mdx(\"p\",null,\"The instruction is not case-sensitive. However, convention is for them to be UPPERCASE to distinguish them from arguments more easily.\"),mdx(\"p\",null,\"Docker runs instructions in a\\xA0Dockerfile\\xA0in order. A\\xA0Dockerfile\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"must start with a \",mdx(\"inlineCode\",{parentName:\"strong\"},\"FROM\"),\" instruction\"),\". The\\xA0FROM\\xA0instruction specifies the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/glossary/#base-image\"}),\"Base Image\"),\"\\xA0from which you are building.\\xA0FROM\\xA0may only be preceded by one or more\\xA0ARG\\xA0instructions, which declare arguments that are used in\\xA0FROMlines in the\\xA0Dockerfile.\"),mdx(\"p\",null,\"Docker treats lines that\\xA0begin\\xA0with\\xA0#\\xA0as a comment, unless the line is a valid\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/builder/#parser-directives\"}),\"parser directive\"),\". A\\xA0#marker anywhere else in a line is treated as an argument. This allows statements like:\"),mdx(\"h1\",null,\"Comment\"),mdx(\"p\",null,\"RUN echo \\\\'we are running some # of cool things\\\\'\"),mdx(\"p\",null,\"Line continuation characters are not supported in comments.\"),mdx(\"h4\",null,\"Parser directives\"),mdx(\"p\",null,\"Parser directives are optional, and affect the way in which subsequent lines in a\\xA0Dockerfile\\xA0are handled. Parser directives do not add layers to the build, and will not be shown as a build step. Parser directives are written as a special type of comment in the form\\xA0# directive=value. A single directive may only be used once.\"),mdx(\"p\",null,\"Once a comment, empty line or builder instruction has been processed, Docker no longer looks for parser directives. Instead it treats anything formatted as a parser directive as a comment and does not attempt to validate if it might be a parser directive. Therefore, all parser directives must be at the very top of a\\xA0Dockerfile.\"),mdx(\"p\",null,\"Parser directives are not case-sensitive. However, convention is for them to be lowercase. Convention is also to include a blank line following any parser directives. Line continuation characters are not supported in parser directives.\"),mdx(\"p\",null,\"Due to these rules, the following examples are all invalid:\"),mdx(\"p\",null,\"Invalid due to line continuation:\"),mdx(\"h1\",null,\"direc \\\\\"),mdx(\"p\",null,\"tive=value\"),mdx(\"p\",null,\"Invalid due to appearing twice:\"),mdx(\"h1\",null,\"directive=value1\"),mdx(\"h1\",null,\"directive=value2\"),mdx(\"p\",null,\"FROM ImageName\"),mdx(\"p\",null,\"Treated as a comment due to appearing after a builder instruction:\"),mdx(\"p\",null,\"FROM ImageName\"),mdx(\"h1\",null,\"directive=value\"),mdx(\"p\",null,\"Treated as a comment due to appearing after a comment which is not a parser directive:\"),mdx(\"h1\",null,\"About my dockerfile\"),mdx(\"h1\",null,\"directive=value\"),mdx(\"p\",null,\"FROM ImageName\"),mdx(\"p\",null,\"The unknown directive is treated as a comment due to not being recognized. In addition, the known directive is treated as a comment due to appearing after a comment which is not a parser directive.\"),mdx(\"h1\",null,\"unknowndirective=value\"),mdx(\"h1\",null,\"knowndirective=value\"),mdx(\"p\",null,\"Non-line-breaking whitespace is permitted in a parser directive. Hence, the following lines are all treated identically:\"),mdx(\"p\",null,\"#directive=value\"),mdx(\"h1\",null,\"directive =value\"),mdx(\"h1\",null,\"directive= value\"),mdx(\"h1\",null,\"directive = value\"),mdx(\"h1\",null,\"dIrEcTiVe=value\"),mdx(\"p\",null,\"The following parser directive is supported:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"escape\")),mdx(\"h4\",null,\"escape\"),mdx(\"h1\",null,\"escape=\\\\ (backslash)\"),mdx(\"p\",null,\"Or\"),mdx(\"h1\",null,\"escape=` (backtick)\"),mdx(\"p\",null,\"The\\xA0escape\\xA0directive sets the character used to escape characters in a\\xA0Dockerfile. If not specified, the default escape character is\\xA0.\"),mdx(\"p\",null,\"The escape character is used both to escape characters in a line, and to escape a newline. This allows a\\xA0Dockerfile\\xA0instruction to span multiple lines. Note that regardless of whether the\\xA0escape\\xA0parser directive is included in a\\xA0Dockerfile,\\xA0\",mdx(\"em\",{parentName:\"p\"},\"escaping is not performed in a\\xA0\"),\"RUN\",mdx(\"em\",{parentName:\"p\"},\"\\xA0command, except at the end of a line.\")),mdx(\"p\",null,\"Setting the escape character to\\xA0\",mdx(\"inlineCode\",{parentName:\"p\"},\"\\xA0is especially useful on\\xA0Windows, where\\xA0\\\\\\xA0is the directory path separator.\\xA0\"),\"\\xA0is consistent with\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://technet.microsoft.com/en-us/library/hh847755.aspx\"}),\"Windows PowerShell\"),\".\"),mdx(\"p\",null,\"Consider the following example which would fail in a non-obvious way on\\xA0Windows. The second\\xA0\\\\\\xA0at the end of the second line would be interpreted as an escape for the newline, instead of a target of the escape from the first\\xA0. Similarly, the\\xA0\\\\\\xA0at the end of the third line would, assuming it was actually handled as an instruction, cause it be treated as a line continuation. The result of this dockerfile is that second and third lines are considered a single instruction:\"),mdx(\"p\",null,\"FROM microsoft/nanoserver\"),mdx(\"p\",null,\"COPY testfile.txt c:\",\"\\\\\"),mdx(\"p\",null,\"RUN dir c:\\\\\"),mdx(\"p\",null,\"Results in:\"),mdx(\"p\",null,\"PS C:\\\\John> docker build -t cmd .\"),mdx(\"p\",null,\"Sending build context to Docker daemon 3.072 kB\"),mdx(\"p\",null,\"Step 1/2 : FROM microsoft/nanoserver\"),mdx(\"p\",null,\"---> 22738ff49c6d\"),mdx(\"p\",null,\"Step 2/2 : COPY testfile.txt c:\\\\RUN dir c:\"),mdx(\"p\",null,\"GetFileAttributesEx c:RUN: The system cannot find the file specified.\"),mdx(\"p\",null,\"PS C:\\\\John>\"),mdx(\"p\",null,\"One solution to the above would be to use\\xA0/\\xA0as the target of both the\\xA0COPY\\xA0instruction, and\\xA0dir. However, this syntax is, at best, confusing as it is not natural for paths on\\xA0Windows, and at worst, error prone as not all commands on\\xA0Windows\\xA0support\\xA0/\\xA0as the path separator.\"),mdx(\"p\",null,\"By adding the\\xA0escape\\xA0parser directive, the following\\xA0Dockerfile\\xA0succeeds as expected with the use of natural platform semantics for file paths on\\xA0Windows:\"),mdx(\"h1\",null,\"escape=`\"),mdx(\"p\",null,\"FROM microsoft/nanoserver\"),mdx(\"p\",null,\"COPY testfile.txt c:\\\\\"),mdx(\"p\",null,\"RUN dir c:\\\\\"),mdx(\"p\",null,\"Results in:\"),mdx(\"p\",null,\"PS C:\\\\John> docker build -t succeeds --no-cache=true .\"),mdx(\"p\",null,\"Sending build context to Docker daemon 3.072 kB\"),mdx(\"p\",null,\"Step 1/3 : FROM microsoft/nanoserver\"),mdx(\"p\",null,\"---> 22738ff49c6d\"),mdx(\"p\",null,\"Step 2/3 : COPY testfile.txt c:\\\\\"),mdx(\"p\",null,\"---> 96655de338de\"),mdx(\"p\",null,\"Removing intermediate container 4db9acbb1682\"),mdx(\"p\",null,\"Step 3/3 : RUN dir c:\\\\\"),mdx(\"p\",null,\"---> Running in a2c157f842f5\"),mdx(\"p\",null,\"Volume in drive C has no label.\"),mdx(\"p\",null,\"Volume Serial Number is 7E6D-E0F7\"),mdx(\"p\",null,\"Directory of c:\\\\\"),mdx(\"p\",null,\"10/05/2016 05:04 PM 1,894 License.txt\"),mdx(\"p\",null,\"10/05/2016 02:22 PM \",mdx(\"inlineCode\",{parentName:\"p\"},\"<DIR>\"),\" Program Files\"),mdx(\"p\",null,\"10/05/2016 02:14 PM \",mdx(\"inlineCode\",{parentName:\"p\"},\"<DIR>\"),\" Program Files (x86)\"),mdx(\"p\",null,\"10/28/2016 11:18 AM 62 testfile.txt\"),mdx(\"p\",null,\"10/28/2016 11:20 AM \",mdx(\"inlineCode\",{parentName:\"p\"},\"<DIR>\"),\" Users\"),mdx(\"p\",null,\"10/28/2016 11:20 AM \",mdx(\"inlineCode\",{parentName:\"p\"},\"<DIR>\"),\" Windows\"),mdx(\"p\",null,\"2 File(s) 1,956 bytes\"),mdx(\"p\",null,\"4 Dir(s) 21,259,096,064 bytes free\"),mdx(\"p\",null,\"---> 01c7f3bef04f\"),mdx(\"p\",null,\"Removing intermediate container a2c157f842f5\"),mdx(\"p\",null,\"Successfully built 01c7f3bef04f\"),mdx(\"p\",null,\"PS C:\\\\John>\"),mdx(\"h4\",null,\"Environment replacement\"),mdx(\"p\",null,\"Environment variables (declared with\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/builder/#env\"}),\"the\\xA0ENV\\xA0statement\"),\") can also be used in certain instructions as variables to be interpreted by the\\xA0Dockerfile. Escapes are also handled for including variable-like syntax into a statement literally.\"),mdx(\"p\",null,\"Environment variables are notated in the\\xA0Dockerfile\\xA0either with\\xA0$variable_name\\xA0or\\xA0${variable_name}. They are treated equivalently and the brace syntax is typically used to address issues with variable names with no whitespace, like\\xA0${foo}_bar.\"),mdx(\"p\",null,\"The\\xA0${variable_name}\\xA0syntax also supports a few of the standard\\xA0bash\\xA0modifiers as specified below:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"${variable:-word}\\xA0indicates that if\\xA0variable\\xA0is set then the result will be that value. If\\xA0variable\\xA0is not set then\\xA0word\\xA0will be the result.\"),mdx(\"li\",{parentName:\"ul\"},\"${variable:+word}\\xA0indicates that if\\xA0variable\\xA0is set then\\xA0word\\xA0will be the result, otherwise the result is the empty string.\")),mdx(\"p\",null,\"In all cases,\\xA0word\\xA0can be any string, including additional environment variables.\"),mdx(\"p\",null,\"Escaping is possible by adding a\\xA0\\\\\\xA0before the variable:\\xA0\\\\$foo\\xA0or\\xA0\\\\${foo}, for example, will translate to\\xA0$foo\\xA0and\\xA0${foo}\\xA0literals respectively.\"),mdx(\"p\",null,\"Example (parsed representation is displayed after the\\xA0#):\"),mdx(\"p\",null,\"FROM busybox\"),mdx(\"p\",null,\"ENV foo /bar\"),mdx(\"p\",null,\"WORKDIR ${foo} # WORKDIR /bar\"),mdx(\"p\",null,\"ADD . $foo # ADD . /bar\"),mdx(\"p\",null,\"COPY \\\\$foo /quux # COPY $foo /quux\"),mdx(\"p\",null,\"Environment variables are supported by the following list of instructions in the\\xA0Dockerfile:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"ADD\"),mdx(\"li\",{parentName:\"ul\"},\"COPY\"),mdx(\"li\",{parentName:\"ul\"},\"ENV\"),mdx(\"li\",{parentName:\"ul\"},\"EXPOSE\"),mdx(\"li\",{parentName:\"ul\"},\"FROM\"),mdx(\"li\",{parentName:\"ul\"},\"LABEL\"),mdx(\"li\",{parentName:\"ul\"},\"STOPSIGNAL\"),mdx(\"li\",{parentName:\"ul\"},\"USER\"),mdx(\"li\",{parentName:\"ul\"},\"VOLUME\"),mdx(\"li\",{parentName:\"ul\"},\"WORKDIR\"),mdx(\"li\",{parentName:\"ul\"},\"ONBUILD\\xA0(when combined with one of the supported instructions above)\")),mdx(\"p\",null,\"Environment variable substitution will use the same value for each variable throughout the entire instruction. In other words, in this example:\"),mdx(\"p\",null,\"ENV abc=hello\"),mdx(\"p\",null,\"ENV abc=bye def=$abc\"),mdx(\"p\",null,\"ENV ghi=$abc\"),mdx(\"p\",null,\"will result in\\xA0def\\xA0having a value of\\xA0hello, not\\xA0bye. However,\\xA0ghi\\xA0will have a value of\\xA0byebecause it is not part of the same instruction that set\\xA0abc\\xA0to\\xA0bye.\"),mdx(\"h4\",null,\".dockerignore file\"),mdx(\"p\",null,\"Before the docker CLI sends the context to the docker daemon, it looks for a file named\\xA0.dockerignorein the root directory of the context. If this file exists, the CLI modifies the context to exclude files and directories that match patterns in it. This helps to avoid unnecessarily sending large or sensitive files and directories to the daemon and potentially adding them to images using\\xA0ADD\\xA0or\\xA0COPY.\"),mdx(\"p\",null,\"The CLI interprets the\\xA0.dockerignore\\xA0file as a newline-separated list of patterns similar to the file globs of Unix shells. For the purposes of matching, the root of the context is considered to be both the working and the root directory. For example, the patterns\\xA0/foo/bar\\xA0and\\xA0foo/bar\\xA0both exclude a file or directory named\\xA0bar\\xA0in the\\xA0foo\\xA0subdirectory of\\xA0PATH\\xA0or in the root of the git repository located at\\xA0URL. Neither excludes anything else.\"),mdx(\"p\",null,\"If a line in\\xA0.dockerignore\\xA0file starts with\\xA0#\\xA0in column 1, then this line is considered as a comment and is ignored before interpreted by the CLI.\"),mdx(\"p\",null,\"Here is an example\\xA0.dockerignore\\xA0file:\"),mdx(\"h1\",null,\"comment\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"/temp\")),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"/\"),\"/temp*\"),mdx(\"p\",null,\"temp?\"),mdx(\"p\",null,\"This file causes the following build behavior:\"),mdx(\"hr\",null),mdx(\"p\",null,\"  Rule           Behavior\"),mdx(\"h1\",null,\"comment     Ignored.\"),mdx(\"p\",null,\"  \",mdx(\"em\",{parentName:\"p\"},\"/temp\"),\"      Exclude files and directories whose names start with\\xA0temp\\xA0in any immediate subdirectory of the root. For example, the plain file\\xA0/somedir/temporary.txt\\xA0is excluded, as is the directory\\xA0/somedir/temp.\\n\",mdx(\"em\",{parentName:\"p\"},\"/\"),\"/temp*   Exclude files and directories starting with\\xA0temp\\xA0from any subdirectory that is two levels below the root. For example,\\xA0/somedir/subdir/temporary.txt\\xA0is excluded.\\ntemp?          Exclude files and directories in the root directory whose names are a one-character extension of\\xA0temp. For example,\\xA0/tempa\\xA0and\\xA0/tempb\\xA0are excluded.\"),mdx(\"hr\",null),mdx(\"p\",null,\"Matching is done using Go's\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://golang.org/pkg/path/filepath#Match\"}),\"filepath.Match\"),\"\\xA0rules. A preprocessing step removes leading and trailing whitespace and eliminates.\\xA0and\\xA0..\\xA0elements using Go's\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://golang.org/pkg/path/filepath/#Clean\"}),\"filepath.Clean\"),\". Lines that are blank after preprocessing are ignored.\"),mdx(\"p\",null,\"Beyond Go's filepath. Match rules, Docker also supports a special wildcard string\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"\\xA0that matches any number of directories (including zero). For example,\\xA0\"),\"/*.go\\xA0will exclude all files that end with\\xA0.gothat are found in all directories, including the root of the build context.\"),mdx(\"p\",null,\"Lines starting with\\xA0!\\xA0(exclamation mark) can be used to make exceptions to exclusions. The following is an example\\xA0.dockerignore\\xA0file that uses this mechanism:\"),mdx(\"p\",null,\"*.md\"),mdx(\"p\",null,\"!README.md\"),mdx(\"p\",null,\"All markdown files\\xA0except\\xA0README.md\\xA0are excluded from the context.\"),mdx(\"p\",null,\"The placement of!\\xA0exception rules influences the behavior: the last line of the\\xA0.dockerignore\\xA0that matches a particular file determines whether it is included or excluded. Consider the following example:\"),mdx(\"p\",null,\"*.md\"),mdx(\"p\",null,\"!README*.md\"),mdx(\"p\",null,\"README-secret.md\"),mdx(\"p\",null,\"No markdown files are included in the context except README files other than\\xA0README-secret.md.\"),mdx(\"p\",null,\"Now consider this example:\"),mdx(\"p\",null,\"*.md\"),mdx(\"p\",null,\"README-secret.md\"),mdx(\"p\",null,\"!README*.md\"),mdx(\"p\",null,\"All of the README files are included. The middle line has no effect because\\xA0!README*.md\\xA0matches\\xA0README-secret.md\\xA0and comes last.\"),mdx(\"p\",null,\"You can even use the\\xA0.dockerignore\\xA0file to exclude the\\xA0Dockerfile\\xA0and\\xA0.dockerignore\\xA0files. These files are still sent to the daemon because it needs them to do its job. But the\\xA0ADD\\xA0and\\xA0COPY instructions do not copy them to the image.\"),mdx(\"p\",null,\"Finally, you may want to specify which files to include in the context, rather than which to exclude. To achieve this, specify\\xA0*\\xA0as the first pattern, followed by one or more\\xA0!\\xA0exception patterns.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": For historical reasons, the pattern\\xA0.\\xA0is ignored.\"),mdx(\"h4\",null,\"FROM\"),mdx(\"p\",null,\"FROM \",mdx(\"inlineCode\",{parentName:\"p\"},\"<image> [AS <name>\"),\"]\"),mdx(\"p\",null,\"Or\"),mdx(\"p\",null,\"FROM \",mdx(\"inlineCode\",{parentName:\"p\"},\"<image>[:<tag>] [AS <name>\"),\"]\"),mdx(\"p\",null,\"Or\"),mdx(\"p\",null,\"FROM \",mdx(\"inlineCode\",{parentName:\"p\"},\"<image>[@<digest>] [AS <name>\"),\"]\"),mdx(\"p\",null,\"The\\xA0FROM\\xA0instruction initializes a new build stage and sets the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/glossary/#base-image\"}),\"Base Image\"),\"\\xA0for subsequent instructions. As such, a valid\\xA0Dockerfile\\xA0must start with a\\xA0FROM\\xA0instruction. The image can be any valid image -- it is especially easy to start by\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"pulling an image\"),\"\\xA0from the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/tutorials/dockerrepos/\"}),\"Public Repositories\"),\".\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"ARG\\xA0is the only instruction that may precede\\xA0FROM\\xA0in the\\xA0Dockerfile. See\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/builder/#understand-how-arg-and-from-interact\"}),\"Understand how ARG and FROM interact\"),\".\"),mdx(\"li\",{parentName:\"ul\"},\"FROM\\xA0can appear multiple times within a single\\xA0Dockerfile\\xA0to create multiple images or use one build stage as a dependency for another. Simply make a note of the last image ID output by the commit before each new\\xA0FROM\\xA0instruction. Each\\xA0FROM\\xA0instruction clears any state created by previous instructions.\"),mdx(\"li\",{parentName:\"ul\"},\"Optionally a name can be given to a new build stage by adding\\xA0AS name\\xA0to the\\xA0FROMinstruction. The name can be used in subsequent\\xA0FROM\\xA0and\\xA0COPY --from=\",mdx(\"inlineCode\",{parentName:\"li\"},\"<name|index>\"),\"instructions to refer to the image built in this stage.\"),mdx(\"li\",{parentName:\"ul\"},\"The\\xA0tag\\xA0or\\xA0digest\\xA0values are optional. If you omit either of them, the builder assumes a\\xA0latest\\xA0tag by default. The builder returns an error if it cannot find the\\xA0tag\\xA0value.\")),mdx(\"h5\",null,\"Understand how ARG and FROM interact\"),mdx(\"p\",null,\"FROM\\xA0instructions support variables that are declared by any\\xA0ARG\\xA0instructions that occur before the first\\xA0FROM.\"),mdx(\"p\",null,\"ARG CODE_VERSION=latest\"),mdx(\"p\",null,\"FROM base:${CODE_VERSION}\"),mdx(\"p\",null,\"CMD /code/run-app\"),mdx(\"p\",null,\"FROM extras:${CODE_VERSION}\"),mdx(\"p\",null,\"CMD /code/run-extras\"),mdx(\"p\",null,\"An\\xA0ARG\\xA0declared before a\\xA0FROM\\xA0is outside of a build stage, so it can't be used in any instruction after a\\xA0FROM. To use the default value of an\\xA0ARG\\xA0declared before the first\\xA0FROM\\xA0use an\\xA0ARG\\xA0instruction without a value inside of a build stage:\"),mdx(\"p\",null,\"ARG VERSION=latest\"),mdx(\"p\",null,\"FROM busybox:$VERSION\"),mdx(\"p\",null,\"ARG VERSION\"),mdx(\"p\",null,\"RUN echo $VERSION > image_version\"),mdx(\"h4\",null,\"RUN\"),mdx(\"p\",null,\"RUN has 2 forms:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"RUN \",mdx(\"inlineCode\",{parentName:\"li\"},\"<command>\"),\"\\xA0(shell\\xA0form, the command is run in a shell, which by default is\\xA0/bin/sh -c\\xA0on Linux or\\xA0cmd /S /C\\xA0on Windows)\"),mdx(\"li\",{parentName:\"ul\"},\"RUN \",\"[\\\"executable\\\", \\\"param1\\\", \\\"param2\\\"]\",\"\\xA0(exec\\xA0form)\")),mdx(\"p\",null,\"The\\xA0RUN\\xA0instruction will execute any commands in a new layer on top of the current image and commit the results. The resulting committed image will be used for the next step in the\\xA0Dockerfile.\"),mdx(\"p\",null,\"Layering\\xA0RUN\\xA0instructions and generating commits conforms to the core concepts of Docker where commits are cheap and containers can be created from any point in an image's history, much like source control.\"),mdx(\"p\",null,\"The\\xA0exec\\xA0form makes it possible to avoid shell string munging, and to\\xA0RUN\\xA0commands using a base image that does not contain the specified shell executable.\"),mdx(\"p\",null,\"The default shell for the\\xA0shell\\xA0form can be changed using the\\xA0SHELL\\xA0command.\"),mdx(\"p\",null,\"In the\\xA0shell\\xA0form you can use a\\xA0\\\\\\xA0(backslash) to continue a single RUN instruction onto the next line. For example, consider these two lines:\"),mdx(\"p\",null,\"RUN /bin/bash -c \\\\'source $HOME/.bashrc; \\\\\"),mdx(\"p\",null,\"echo $HOME\\\\'\"),mdx(\"p\",null,\"Together they are equivalent to this single line:\"),mdx(\"p\",null,\"RUN /bin/bash -c \\\\'source $HOME/.bashrc; echo $HOME\\\\'\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": To use a different shell, other than '/bin/sh', use the\\xA0exec\\xA0form passing in the desired shell. For example,\\xA0RUN \",\"[\\\"/bin/bash\\\", \\\"-c\\\", \\\"echo hello\\\"]\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": The\\xA0exec\\xA0form is parsed as a JSON array, which means that you must use double-quotes (\\\") around words not single-quotes (').\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note: Unlike the\\xA0shell\\xA0form, the\\xA0exec\\xA0form does not invoke a command shell. This means that normal shell processing does not happen. For example,\\xA0RUN \",\"[ \\\"echo\\\", \\\"$HOME\\\" ]\",\"\\xA0will not do variable substitution on\\xA0$HOME. If you want shell processing then either use the\\xA0shell\\xA0form or execute a shell directly, for example:\\xA0RUN \",\"[ \\\"sh\\\", \\\"-c\\\", \\\"echo $HOME\\\" ]\",\". When using the exec form and executing a shell directly, as in the case for the shell form, it is the shell that is doing the environment variable expansion, not docker.\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": In the\\xA0JSON\\xA0form, it is necessary to escape backslashes. This is particularly relevant on Windows where the backslash is the path separator. The following line would otherwise be treated as\\xA0shell\\xA0form due to not being valid JSON, and fail in an unexpected way:RUN \",\"[\\\"c:\\\\windows\\\\system32\\\\tasklist.exe\\\"]\",\"\\xA0The correct syntax for this example is:RUN \",\"[\\\"c:\",\"\\\\\",\"windows\",\"\\\\\",\"system32\",\"\\\\\",\"tasklist.exe\\\"]\"),mdx(\"p\",null,\"The cache for\\xA0RUN\\xA0instructions isn't invalidated automatically during the next build. The cache for an instruction like\\xA0RUN apt-get dist-upgrade -y\\xA0will be reused during the next build. The cache for\\xA0RUNinstructions can be invalidated by using the\\xA0--no-cache\\xA0flag, for example\\xA0docker build --no-cache.\"),mdx(\"p\",null,\"See the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices/#/build-cache\"}),\"Dockerfile\\xA0Best Practices guide\"),\"\\xA0for more information.\"),mdx(\"p\",null,\"The cache for\\xA0RUN\\xA0instructions can be invalidated by\\xA0ADD\\xA0instructions. See\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/builder/#add\"}),\"below\"),\"\\xA0for details.\"),mdx(\"h5\",null,\"Known issues (RUN)\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://github.com/docker/docker/issues/783\"}),\"Issue 783\"),\"\\xA0is about file permissions problems that can occur when using the AUFS file system. You might notice it during an attempt to\\xA0rm\\xA0a file, for example.\"),mdx(\"li\",{parentName:\"ul\"},\"For systems that have recent aufs version (i.e.,\\xA0dirperm1\\xA0mount option can be set), docker will attempt to fix the issue automatically by mounting the layers with\\xA0dirperm1\\xA0option. More details on\\xA0dirperm1\\xA0option can be found at\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://github.com/sfjro/aufs3-linux/tree/aufs3.18/Documentation/filesystems/aufs\"}),\"aufs\\xA0man page\"))),mdx(\"p\",null,\"If your system doesn't have support for\\xA0dirperm1, the issue describes a workaround.\"),mdx(\"h4\",null,\"CMD\"),mdx(\"p\",null,\"The\\xA0CMD\\xA0instruction has three forms:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"CMD \",\"[\\\"executable\\\",\\\"param1\\\",\\\"param2\\\"]\",\"\\xA0(exec\\xA0form, this is the preferred form)\"),mdx(\"li\",{parentName:\"ul\"},\"CMD \",\"[\\\"param1\\\",\\\"param2\\\"]\",\"\\xA0(as\\xA0default parameters to ENTRYPOINT)\"),mdx(\"li\",{parentName:\"ul\"},\"CMD command param1 param2\\xA0(shell\\xA0form)\")),mdx(\"p\",null,\"There can only be one\\xA0CMD\\xA0instruction in a\\xA0Dockerfile. If you list more than one\\xA0CMD\\xA0then only the last\\xA0CMD\\xA0will take effect.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"The main purpose of a\\xA0\"),\"CMD\",mdx(\"strong\",{parentName:\"p\"},\"\\xA0is to provide defaults for an executing container.\"),\"\\xA0These defaults can include an executable, or they can omit the executable, in which case you must specify an\\xA0ENTRYPOINT instruction as well.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": If\\xA0CMD\\xA0is used to provide default arguments for the\\xA0ENTRYPOINT\\xA0instruction, both the\\xA0CMD\\xA0and\\xA0ENTRYPOINT\\xA0instructions should be specified with the JSON array format.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": The\\xA0exec\\xA0form is parsed as a JSON array, which means that you must use double-quotes (\\\") around words not single-quotes (').\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": Unlike the\\xA0shell\\xA0form, the\\xA0exec\\xA0form does not invoke a command shell. This means that normal shell processing does not happen. For example,\\xA0CMD \",\"[ \\\"echo\\\", \\\"$HOME\\\" ]\",\"\\xA0will not do variable substitution on\\xA0$HOME. If you want shell processing then either use the\\xA0shell\\xA0form or execute a shell directly, for example:\\xA0CMD \",\"[ \\\"sh\\\", \\\"-c\\\", \\\"echo $HOME\\\" ]\",\". When using the exec form and executing a shell directly, as in the case for the shell form, it is the shell that is doing the environment variable expansion, not docker.\"),mdx(\"p\",null,\"When used in the shell or exec formats, the\\xA0CMD\\xA0instruction sets the command to be executed when running the image.\"),mdx(\"p\",null,\"If you use the\\xA0shell\\xA0form of the\\xA0CMD, then the\\xA0\",mdx(\"inlineCode\",{parentName:\"p\"},\"<command>\"),\"\\xA0will execute in\\xA0/bin/sh -c:\"),mdx(\"p\",null,\"FROM ubuntu\"),mdx(\"p\",null,\"CMD echo \\\"This is a test.\\\" | wc -\"),mdx(\"p\",null,\"If you want to\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"run your\"),\"\\xA0\",mdx(\"inlineCode\",{parentName:\"p\"},\"<command>\"),\"\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"without a shell\"),\"\\xA0then you must express the command as a JSON array and give the full path to the executable.\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"This array form is the preferred format of\\xA0\"),\"CMD\",mdx(\"strong\",{parentName:\"p\"},\".\"),\"\\xA0Any additional parameters must be individually expressed as strings in the array:\"),mdx(\"p\",null,\"FROM ubuntu\"),mdx(\"p\",null,\"CMD \",\"[\\\"/usr/bin/wc\\\",\\\"--help\\\"]\"),mdx(\"p\",null,\"If you would like your container to run the same executable every time, then you should consider using\\xA0ENTRYPOINT\\xA0in combination with\\xA0CMD. See\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/builder/#entrypoint\"}),\"ENTRYPOINT\"),\".\"),mdx(\"p\",null,\"If the user specifies arguments to\\xA0docker run\\xA0then they will override the default specified in\\xA0CMD.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": Don't confuse\\xA0RUN\\xA0with\\xA0CMD.\\xA0RUN\\xA0actually runs a command and commits the result;\\xA0CMD\\xA0does not execute anything at build time but specifies the intended command for the image.\"),mdx(\"h4\",null,\"LABEL\"),mdx(\"p\",null,\"LABEL \",mdx(\"inlineCode\",{parentName:\"p\"},\"<key>=<value> <key>=<value> <key>=<value>\"),\" ...\"),mdx(\"p\",null,\"The\\xA0LABEL\\xA0instruction adds metadata to an image. A\\xA0LABEL\\xA0is a key-value pair. To include spaces within a\\xA0LABEL\\xA0value, use quotes and backslashes as you would in command-line parsing. A few usage examples:\"),mdx(\"p\",null,\"LABEL \\\"com.example.vendor\\\"=\\\"ACME Incorporated\\\"\"),mdx(\"p\",null,\"LABEL com.example.label-with-value=\\\"foo\\\"\"),mdx(\"p\",null,\"LABEL version=\\\"1.0\\\"\"),mdx(\"p\",null,\"LABEL description=\\\"This text illustrates \\\\\"),mdx(\"p\",null,\"that label-values can span multiple lines.\\\"\"),mdx(\"p\",null,\"An image can have more than one label. You can specify multiple labels on a single line. Prior to Docker 1.10, this decreased the size of the final image, but this is no longer the case. You may still choose to specify multiple labels in a single instruction, in one of the following two ways:\"),mdx(\"p\",null,\"LABEL multi.label1=\\\"value1\\\" multi.label2=\\\"value2\\\" other=\\\"value3\\\"\"),mdx(\"p\",null,\"LABEL multi.label1=\\\"value1\\\" \\\\\"),mdx(\"p\",null,\"multi.label2=\\\"value2\\\" \\\\\"),mdx(\"p\",null,\"other=\\\"value3\\\"\"),mdx(\"p\",null,\"Labels included in base or parent images (images in the\\xA0FROM\\xA0line) are inherited by your image. If a label already exists but with a different value, the most-recently-applied value overrides any previously-set value.\"),mdx(\"p\",null,\"To view an image's labels, use the\\xA0docker inspect\\xA0command.\"),mdx(\"p\",null,\"\\\"Labels\\\": {\"),mdx(\"p\",null,\"\\\"com.example.vendor\\\": \\\"ACME Incorporated\\\"\"),mdx(\"p\",null,\"\\\"com.example.label-with-value\\\": \\\"foo\\\",\"),mdx(\"p\",null,\"\\\"version\\\": \\\"1.0\\\",\"),mdx(\"p\",null,\"\\\"description\\\": \\\"This text illustrates that label-values can span multiple lines.\\\",\"),mdx(\"p\",null,\"\\\"multi.label1\\\": \\\"value1\\\",\"),mdx(\"p\",null,\"\\\"multi.label2\\\": \\\"value2\\\",\"),mdx(\"p\",null,\"\\\"other\\\": \\\"value3\\\"\"),mdx(\"p\",null,\"},\"),mdx(\"h4\",null,\"MAINTAINER (deprecated)\"),mdx(\"p\",null,\"MAINTAINER \",mdx(\"inlineCode\",{parentName:\"p\"},\"<name>\")),mdx(\"p\",null,\"The\\xA0MAINTAINER\\xA0instruction sets the\\xA0Author\\xA0field of the generated images. The\\xA0LABEL\\xA0instruction is a much more flexible version of this and you should use it instead, as it enables setting any metadata you require, and can be viewed easily, for example with\\xA0docker inspect. To set a label corresponding to the\\xA0MAINTAINER\\xA0field you could use:\"),mdx(\"p\",null,\"LABEL maintainer=\\\"SvenDowideit\\\\@home.org.au\\\"\"),mdx(\"p\",null,\"This will then be visible from\\xA0docker inspect\\xA0with the other labels.\"),mdx(\"h4\",null,\"EXPOSE\"),mdx(\"p\",null,\"EXPOSE \",mdx(\"inlineCode\",{parentName:\"p\"},\"<port> [<port>/<protocol>\"),\"...]\"),mdx(\"p\",null,\"The\\xA0EXPOSE\\xA0instruction informs Docker that the container listens on the specified network ports at runtime. You can specify whether the port listens on TCP or UDP, and the default is TCP if the protocol is not specified.\"),mdx(\"p\",null,\"The\\xA0EXPOSE\\xA0instruction does not actually publish the port. It functions as a type of documentation between the person who builds the image and the person who runs the container, about which ports are intended to be published. To publish the port when running the container, use the\\xA0-p\\xA0flag on\\xA0docker run\\xA0to publish and map one or more ports, or the\\xA0-P\\xA0flag to publish all exposed ports and map them to high-order ports.\"),mdx(\"p\",null,\"To set up port redirection on the host system, see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/run/#expose-incoming-ports\"}),\"using the -P flag\"),\". The\\xA0docker network\\xA0command supports creating networks for communication among containers without the need to expose or publish specific ports, because the containers connected to the network can communicate with each other over any port. For detailed information, see the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/userguide/networking/\"}),\"overview of this feature\"),\").\"),mdx(\"h4\",null,\"ENV\"),mdx(\"p\",null,\"ENV \",mdx(\"inlineCode\",{parentName:\"p\"},\"<key> <value>\")),mdx(\"p\",null,\"ENV \",mdx(\"inlineCode\",{parentName:\"p\"},\"<key>=<value>\"),\" ...\"),mdx(\"p\",null,\"The\\xA0ENV\\xA0instruction sets the environment variable\\xA0\",mdx(\"inlineCode\",{parentName:\"p\"},\"<key>\\xA0to the value\\xA0<value>\"),\". This value will be in the environment of all \\\"descendant\\\"\\xA0Dockerfile\\xA0commands and can be\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/builder/#environment-replacement\"}),\"replaced inline\"),\"\\xA0in many as well.\"),mdx(\"p\",null,\"The\\xA0ENV\\xA0instruction has two forms. The first form,\\xA0ENV \",mdx(\"inlineCode\",{parentName:\"p\"},\"<key> <value>, will set a single variable to a value. The entire string after the first space will be treated as the\\xA0<value>\"),\"\\xA0- including characters such as spaces and quotes.\"),mdx(\"p\",null,\"The second form,\\xA0ENV \",mdx(\"inlineCode\",{parentName:\"p\"},\"<key>=<value>\"),\" ..., allows for multiple variables to be set at one time. Notice that the second form uses the equals sign (=) in the syntax, while the first form does not. Like command line parsing, quotes and backslashes can be used to include spaces within values.\"),mdx(\"p\",null,\"For example:\"),mdx(\"p\",null,\"ENV myName=\\\"John Doe\\\" myDog=Rex\\\\ The\\\\ Dog \\\\\"),mdx(\"p\",null,\"myCat=fluffy\"),mdx(\"p\",null,\"and\"),mdx(\"p\",null,\"ENV myName John Doe\"),mdx(\"p\",null,\"ENV myDog Rex The Dog\"),mdx(\"p\",null,\"ENV myCat fluffy\"),mdx(\"p\",null,\"will yield the same net results in the final image, but the first form is preferred because it produces a single cache layer.\"),mdx(\"p\",null,\"The environment variables set using\\xA0ENV\\xA0will persist when a container is run from the resulting image. You can view the values using\\xA0docker inspect, and change them using\\xA0docker run --env \",mdx(\"inlineCode\",{parentName:\"p\"},\"<key>=<value>\"),\".\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": Environment persistence can cause unexpected side effects. For example, setting\\xA0ENV DEBIAN_FRONTEND noninteractive\\xA0may confuse apt-get users on a Debian-based image. To set a value for a single command, use\\xA0RUN \",mdx(\"inlineCode\",{parentName:\"p\"},\"<key>=<value> <command>\"),\".\"),mdx(\"h4\",null,\"ADD\"),mdx(\"p\",null,mdx(\"inlineCode\",{parentName:\"p\"},\"ADD [--chown=<user>:<group>] [\\\"<src>\\\",... \\\"<dest>\\\"]\"),\"\\xA0(this form is required for paths containing whitespace)\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": The\\xA0--chown\\xA0feature is only supported on Dockerfiles used to build Linux containers, and will not work on Windows containers. Since user and group ownership concepts do not translate between Linux and Windows, the use of\\xA0/etc/passwd\\xA0and\\xA0/etc/group\\xA0for translating user and group names to IDs restricts this feature to only be viable for for Linux OS-based containers.\"),mdx(\"p\",null,\"The\\xA0ADD\\xA0instruction copies new files, directories or remote file URLs from\\xA0\",mdx(\"inlineCode\",{parentName:\"p\"},\"<src>\"),\"\\xA0and adds them to the filesystem of the image at the path\\xA0\",mdx(\"inlineCode\",{parentName:\"p\"},\"<dest>\"),\".\"),mdx(\"p\",null,\"Multiple\\xA0\",mdx(\"inlineCode\",{parentName:\"p\"},\"<src>\"),\"\\xA0resources may be specified but if they are files or directories, their paths are interpreted as relative to the source of the context of the build.\"),mdx(\"p\",null,\"Each\\xA0\",mdx(\"inlineCode\",{parentName:\"p\"},\"<src>\"),\"\\xA0may contain wildcards and matching will be done using Go's\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://golang.org/pkg/path/filepath#Match\"}),\"filepath.Match\"),\"\\xA0rules. For example:\"),mdx(\"p\",null,\"ADD hom* /mydir/ # adds all files starting with \\\"hom\\\"\"),mdx(\"p\",null,\"ADD hom?.txt /mydir/ # ? is replaced with any single character, e.g., \\\"home.txt\\\"\"),mdx(\"p\",null,\"The\\xA0\",mdx(\"inlineCode\",{parentName:\"p\"},\"<dest>\"),\"\\xA0is an absolute path, or a path relative to\\xA0WORKDIR, into which the source will be copied inside the destination container.\"),mdx(\"p\",null,\"ADD test relativeDir/ # adds \\\"test\\\" to \",mdx(\"inlineCode\",{parentName:\"p\"},\"WORKDIR\"),\"/relativeDir/\"),mdx(\"p\",null,\"ADD test /absoluteDir/ # adds \\\"test\\\" to /absoluteDir/\"),mdx(\"p\",null,\"When adding files or directories that contain special characters (such as\\xA0\",\"[\\xA0and\\xA0]\",\"), you need to escape those paths following the Golang rules to prevent them from being treated as a matching pattern. For example, to add a file named\\xA0arr\",\"[0]\",\".txt, use the following;\"),mdx(\"p\",null,\"ADD arr[[]0].txt /mydir/ # copy a file named \\\"arr\",\"[0]\",\".txt\\\" to /mydir/\"),mdx(\"p\",null,\"All new files and directories are created with a UID and GID of 0, unless the optional\\xA0--chown\\xA0flag specifies a given username, groupname, or UID/GID combination to request specific ownership of the content added. The format of the\\xA0--chown\\xA0flag allows for either username and groupname strings or direct integer UID and GID in any combination. Providing a username without groupname or a UID without GID will use the same numeric UID as the GID. If a username or groupname is provided, the container's root filesystem\\xA0/etc/passwd\\xA0and\\xA0/etc/group\\xA0files will be used to perform the translation from name to integer UID or GID respectively. The following examples show valid definitions for the\\xA0--chown\\xA0flag:\"),mdx(\"p\",null,\"ADD --chown=55:mygroup files* /somedir/\"),mdx(\"p\",null,\"ADD --chown=bin files* /somedir/\"),mdx(\"p\",null,\"ADD --chown=1 files* /somedir/\"),mdx(\"p\",null,\"ADD --chown=10:11 files* /somedir/\"),mdx(\"p\",null,\"If the container root filesystem does not contain either\\xA0/etc/passwd\\xA0or\\xA0/etc/group\\xA0files and either user or group names are used in the\\xA0--chown\\xA0flag, the build will fail on the\\xA0ADD\\xA0operation. Using numeric IDs requires no lookup and will not depend on container root filesystem content.\"),mdx(\"p\",null,\"In the case where\\xA0\",mdx(\"inlineCode\",{parentName:\"p\"},\"<src>\"),\"\\xA0is a remote file URL, the destination will have permissions of 600. If the remote file being retrieved has an HTTP\\xA0Last-Modified\\xA0header, the timestamp from that header will be used to set the\\xA0mtime\\xA0on the destination file. However, like any other file processed during an\\xA0ADD,\\xA0mtime\\xA0will not be included in the determination of whether or not the file has changed and the cache should be updated.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": If you build by passing a\\xA0Dockerfile\\xA0through STDIN (docker build - < somefile), there is no build context, so the\\xA0Dockerfile\\xA0can only contain a URL based\\xA0ADD\\xA0instruction. You can also pass a compressed archive through STDIN: (docker build - < archive.tar.gz), the\\xA0Dockerfile\\xA0at the root of the archive and the rest of the archive will be used as the context of the build.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": If your URL files are protected using authentication, you will need to use\\xA0RUN wget,\\xA0RUN curl\\xA0or use another tool from within the container as the\\xA0ADD\\xA0instruction does not support authentication.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": The first encountered\\xA0ADD\\xA0instruction will invalidate the cache for all following instructions from the Dockerfile if the contents of\\xA0\",mdx(\"inlineCode\",{parentName:\"p\"},\"<src>\"),\"\\xA0have changed. This includes invalidating the cache for\\xA0RUN\\xA0instructions. See the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices/#/build-cache\"}),\"Dockerfile\\xA0Best Practices guide\"),\"\\xA0for more information.\"),mdx(\"p\",null,\"ADD\\xA0obeys the following rules:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"The\\xA0\",mdx(\"inlineCode\",{parentName:\"li\"},\"<src>\"),\"\\xA0path must be inside the\\xA0context\\xA0of the build; you cannot\\xA0ADD ../something /something, because the first step of a\\xA0docker build\\xA0is to send the context directory (and subdirectories) to the docker daemon.\"),mdx(\"li\",{parentName:\"ul\"},\"If\\xA0\",mdx(\"inlineCode\",{parentName:\"li\"},\"<src>\"),\"\\xA0is a URL and\\xA0\",mdx(\"inlineCode\",{parentName:\"li\"},\"<dest>\"),\"\\xA0does not end with a trailing slash, then a file is downloaded from the URL and copied to\\xA0\",mdx(\"inlineCode\",{parentName:\"li\"},\"<dest>\"),\".\"),mdx(\"li\",{parentName:\"ul\"},\"If\\xA0\",mdx(\"inlineCode\",{parentName:\"li\"},\"<src>\"),\"\\xA0is a URL and\\xA0\",mdx(\"inlineCode\",{parentName:\"li\"},\"<dest>\"),\"\\xA0does end with a trailing slash, then the filename is inferred from the URL and the file is downloaded to\\xA0\",mdx(\"inlineCode\",{parentName:\"li\"},\"<dest>/<filename>\"),\". For instance,\\xA0ADD \",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"http://example.com/foobar\"}),\"http://example.com/foobar\"),\" /\\xA0would create the file\\xA0/foobar. The URL must have a nontrivial path so that an appropriate filename can be discovered in this case (\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"http://example.com\"}),\"http://example.com\"),\"\\xA0will not work).\"),mdx(\"li\",{parentName:\"ul\"},\"If\\xA0\",mdx(\"inlineCode\",{parentName:\"li\"},\"<src>\"),\"\\xA0is a directory, the entire contents of the directory are copied, including filesystem metadata.\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": The directory itself is not copied, just its contents.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"If\\xA0\",mdx(\"inlineCode\",{parentName:\"li\"},\"<src>\"),\"\\xA0is a\\xA0local\\xA0tar archive in a recognized compression format (identity, gzip, bzip2 or xz) then it is unpacked as a directory. Resources from\\xA0remote\\xA0URLs are\\xA0\",mdx(\"strong\",{parentName:\"li\"},\"not\"),\"\\xA0decompressed. When a directory is copied or unpacked, it has the same behavior as\\xA0tar -x, the result is the union of:\")),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Whatever existed at the destination path and\"),mdx(\"li\",{parentName:\"ol\"},\"The contents of the source tree, with conflicts resolved in favor of \\\"2.\\\" on a file-by-file basis.\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Note\"),\": Whether a file is identified as a recognized compression format or not is done solely based on the contents of the file, not the name of the file. For example, if an empty file happens to end with\\xA0.tar.gz\\xA0this will not be recognized as a compressed file and\\xA0\",mdx(\"strong\",{parentName:\"li\"},\"will not\"),\"generate any kind of decompression error message, rather the file will simply be copied to the destination.\"),mdx(\"li\",{parentName:\"ul\"},\"If\\xA0\",mdx(\"inlineCode\",{parentName:\"li\"},\"<src>\"),\"\\xA0is any other kind of file, it is copied individually along with its metadata. In this case, if\\xA0\",mdx(\"inlineCode\",{parentName:\"li\"},\"<dest>\"),\"\\xA0ends with a trailing slash\\xA0/, it will be considered a directory and the contents of\\xA0\",mdx(\"inlineCode\",{parentName:\"li\"},\"<src>\"),\"\\xA0will be written at \",mdx(\"inlineCode\",{parentName:\"li\"},\"<dest>/base(<src>\"),\").\"),mdx(\"li\",{parentName:\"ul\"},\"If multiple\\xA0\",mdx(\"inlineCode\",{parentName:\"li\"},\"<src>\"),\"\\xA0resources are specified, either directly or due to the use of a wildcard, then\\xA0\",mdx(\"inlineCode\",{parentName:\"li\"},\"<dest>\"),\"\\xA0must be a directory, and it must end with a slash\\xA0/.\"),mdx(\"li\",{parentName:\"ul\"},\"If\\xA0\",mdx(\"inlineCode\",{parentName:\"li\"},\"<dest>\"),\"\\xA0does not end with a trailing slash, it will be considered a regular file and the contents of\\xA0\",mdx(\"inlineCode\",{parentName:\"li\"},\"<src>\"),\"\\xA0will be written at\\xA0\",mdx(\"inlineCode\",{parentName:\"li\"},\"<dest>\"),\".\"),mdx(\"li\",{parentName:\"ul\"},\"If\\xA0\",mdx(\"inlineCode\",{parentName:\"li\"},\"<dest>\"),\"\\xA0doesn't exist, it is created along with all missing directories in its path.\")),mdx(\"h4\",null,\"COPY\"),mdx(\"p\",null,\"COPY has two forms:\"),mdx(\"p\",null,mdx(\"inlineCode\",{parentName:\"p\"},\"COPY [--chown=<user>:<group>] [\\\"<src>\\\",... \\\"<dest>\\\"]\"),\"\\xA0(this form is required for paths containing whitespace)\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": The\\xA0--chown\\xA0feature is only supported on Dockerfiles used to build Linux containers, and will not work on Windows containers. Since user and group ownership concepts do not translate between Linux and Windows, the use of\\xA0/etc/passwd\\xA0and\\xA0/etc/group\\xA0for translating user and group names to IDs restricts this feature to only be viable for for Linux OS-based containers.\"),mdx(\"p\",null,\"The\\xA0COPY\\xA0instruction copies new files or directories from\\xA0\",mdx(\"inlineCode\",{parentName:\"p\"},\"<src>\"),\"\\xA0and adds them to the filesystem of the container at the path\\xA0\",mdx(\"inlineCode\",{parentName:\"p\"},\"<dest>\"),\".\"),mdx(\"p\",null,\"Multiple\\xA0\",mdx(\"inlineCode\",{parentName:\"p\"},\"<src>\"),\"\\xA0resources may be specified but the paths of files and directories will be interpreted as relative to the source of the context of the build.\"),mdx(\"p\",null,\"Each\\xA0\",mdx(\"inlineCode\",{parentName:\"p\"},\"<src>\"),\"\\xA0may contain wildcards and matching will be done using Go's\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://golang.org/pkg/path/filepath#Match\"}),\"filepath.Match\"),\"\\xA0rules. For example:\"),mdx(\"p\",null,\"COPY hom* /mydir/ # adds all files starting with \\\"hom\\\"\"),mdx(\"p\",null,\"COPY hom?.txt /mydir/ # ? is replaced with any single character, e.g., \\\"home.txt\\\"\"),mdx(\"p\",null,\"The\\xA0\",mdx(\"inlineCode\",{parentName:\"p\"},\"<dest>\"),\"\\xA0is an absolute path, or a path relative to\\xA0WORKDIR, into which the source will be copied inside the destination container.\"),mdx(\"p\",null,\"COPY test relativeDir/ # adds \\\"test\\\" to \",mdx(\"inlineCode\",{parentName:\"p\"},\"WORKDIR\"),\"/relativeDir/\"),mdx(\"p\",null,\"COPY test /absoluteDir/ # adds \\\"test\\\" to /absoluteDir/\"),mdx(\"p\",null,\"When copying files or directories that contain special characters (such as\\xA0\",\"[\\xA0and\\xA0]\",\"), you need to escape those paths following the Golang rules to prevent them from being treated as a matching pattern. For example, to copy a file named\\xA0\",mdx(\"inlineCode\",{parentName:\"p\"},\"arr[0].txt\"),\", use the following;\"),mdx(\"pre\",null,mdx(\"code\",_extends({parentName:\"pre\"},{\"className\":\"language-bash\"}),\"COPY arr[[]0].txt /mydir/ # copy a file named \\\"arr[0].txt\\\" to /mydir/\\n\")),mdx(\"p\",null,\"All new files and directories are created with a UID and GID of 0, unless the optional\\xA0--chown\\xA0flag specifies a given username, groupname, or UID/GID combination to request specific ownership of the copied content. The format of the\\xA0--chown\\xA0flag allows for either username and groupname strings or direct integer UID and GID in any combination. Providing a username without groupname or a UID without GID will use the same numeric UID as the GID. If a username or groupname is provided, the container's root filesystem\\xA0/etc/passwd\\xA0and\\xA0/etc/group\\xA0files will be used to perform the translation from name to integer UID or GID respectively. The following examples show valid definitions for the\\xA0--chown\\xA0flag:\"),mdx(\"pre\",null,mdx(\"code\",_extends({parentName:\"pre\"},{\"className\":\"language-bash\"}),\"COPY --chown=55:mygroup files* /somedir/\\nCOPY --chown=bin files* /somedir/\\nCOPY --chown=1 files* /somedir/\\nCOPY --chown=10:11 files* /somedir/\\n\")),mdx(\"p\",null,\"If the container root filesystem does not contain either\\xA0/etc/passwd\\xA0or\\xA0/etc/group\\xA0files and either user or group names are used in the\\xA0--chown\\xA0flag, the build will fail on the\\xA0COPY\\xA0operation. Using numeric IDs requires no lookup and will not depend on container root filesystem content.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": If you build using STDIN (docker build - < somefile), there is no build context, so\\xA0COPYcan't be used.\"),mdx(\"p\",null,\"Optionally\\xA0COPY\\xA0accepts a flag\\xA0--from=\",mdx(\"inlineCode\",{parentName:\"p\"},\"<name|index>\"),\"\\xA0that can be used to set the source location to a previous build stage (created with\\xA0FROM .. AS \",mdx(\"inlineCode\",{parentName:\"p\"},\"<name>\"),\") that will be used instead of a build context sent by the user. The flag also accepts a numeric index assigned for all previous build stages started withFROM\\xA0instruction. In case a build stage with a specified name can't be found an image with the same name is attempted to be used instead.\"),mdx(\"p\",null,\"COPY\\xA0obeys the following rules:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"The\\xA0\",mdx(\"inlineCode\",{parentName:\"li\"},\"<src>\"),\"\\xA0path must be inside the\\xA0context\\xA0of the build; you cannot\\xA0COPY ../something /something, because the first step of a\\xA0docker build\\xA0is to send the context directory (and subdirectories) to the docker daemon.\"),mdx(\"li\",{parentName:\"ul\"},\"If\\xA0\",mdx(\"inlineCode\",{parentName:\"li\"},\"<src>\"),\"\\xA0is a directory, the entire contents of the directory are copied, including filesystem metadata.\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": The directory itself is not copied, just its contents.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"If\\xA0\",mdx(\"inlineCode\",{parentName:\"li\"},\"<src>\"),\"\\xA0is any other kind of file, it is copied individually along with its metadata. In this case, if\\xA0\",mdx(\"inlineCode\",{parentName:\"li\"},\"<dest>\"),\"\\xA0ends with a trailing slash\\xA0/, it will be considered a directory and the contents of\\xA0\",mdx(\"inlineCode\",{parentName:\"li\"},\"<src>\"),\"\\xA0will be written at\\xA0\",mdx(\"inlineCode\",{parentName:\"li\"},\"<dest>/base(<src>\"),\").\"),mdx(\"li\",{parentName:\"ul\"},\"If multiple\\xA0\",mdx(\"inlineCode\",{parentName:\"li\"},\"<src>\"),\"\\xA0resources are specified, either directly or due to the use of a wildcard, then\\xA0\",mdx(\"inlineCode\",{parentName:\"li\"},\"<dest>\"),\"\\xA0must be a directory, and it must end with a slash\\xA0/.\"),mdx(\"li\",{parentName:\"ul\"},\"If\\xA0\",mdx(\"inlineCode\",{parentName:\"li\"},\"<dest>\"),\"\\xA0does not end with a trailing slash, it will be considered a regular file and the contents of\\xA0\",mdx(\"inlineCode\",{parentName:\"li\"},\"<src>\"),\"\\xA0will be written at\\xA0\",mdx(\"inlineCode\",{parentName:\"li\"},\"<dest>\"),\".\"),mdx(\"li\",{parentName:\"ul\"},\"If\\xA0\",mdx(\"inlineCode\",{parentName:\"li\"},\"<dest>\"),\"\\xA0doesn't exist, it is created along with all missing directories in its path.\")),mdx(\"h4\",null,\"ENTRYPOINT\"),mdx(\"p\",null,\"ENTRYPOINT has two forms:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"ENTRYPOINT \",\"[\\\"executable\\\", \\\"param1\\\", \\\"param2\\\"]\",\"\\xA0(exec\\xA0form, preferred)\"),mdx(\"li\",{parentName:\"ul\"},\"ENTRYPOINT command param1 param2\\xA0(shell\\xA0form)\")),mdx(\"p\",null,\"An\\xA0ENTRYPOINT\\xA0allows you to configure a container that will run as an executable.\"),mdx(\"p\",null,\"For example, the following will start nginx with its default content, listening on port 80:\"),mdx(\"pre\",null,mdx(\"code\",_extends({parentName:\"pre\"},{\"className\":\"language-bash\"}),\"docker run -i -t --rm -p 80:80 nginx\\n\")),mdx(\"p\",null,\"Command line arguments to\\xA0docker run \",mdx(\"inlineCode\",{parentName:\"p\"},\"<image>\"),\"\\xA0will be appended after all elements in an\\xA0exec\\xA0form\\xA0ENTRYPOINT, and will override all elements specified using\\xA0CMD. This allows arguments to be passed to the entry point, i.e.,\\xA0\",mdx(\"inlineCode\",{parentName:\"p\"},\"docker run <image>\"),\" \",mdx(\"inlineCode\",{parentName:\"p\"},\"-d\"),\"\\xA0will pass the\\xA0\",mdx(\"inlineCode\",{parentName:\"p\"},\"-d\"),\"\\xA0argument to the entry point. You can override the\\xA0ENTRYPOINT\\xA0instruction using the\\xA0docker run \",mdx(\"inlineCode\",{parentName:\"p\"},\"--entrypoint\"),\"\\xA0flag.\"),mdx(\"p\",null,\"The\\xA0shell\\xA0form prevents any\\xA0CMD\\xA0or\\xA0run\\xA0command line arguments from being used, but has the disadvantage that your\\xA0ENTRYPOINT\\xA0will be started as a subcommand of\\xA0\",mdx(\"inlineCode\",{parentName:\"p\"},\"/bin/sh -c\"),\", which does not pass signals. This means that the executable will not be the container's\\xA0PID 1\\xA0- and will\\xA0not\\xA0receive Unix signals - so your executable will not receive a\\xA0\",mdx(\"inlineCode\",{parentName:\"p\"},\"SIGTERM\"),\"\\xA0from\\xA0docker stop \",mdx(\"inlineCode\",{parentName:\"p\"},\"<container>\"),\".\"),mdx(\"p\",null,\"Only the last\\xA0ENTRYPOINT\\xA0instruction in the\\xA0Dockerfile\\xA0will have an effect.\"),mdx(\"h5\",null,\"Exec form ENTRYPOINT example\"),mdx(\"p\",null,\"You can use the\\xA0exec\\xA0form of\\xA0ENTRYPOINT\\xA0to set fairly stable default commands and arguments and then use either form of\\xA0CMD\\xA0to set additional defaults that are more likely to be changed.\"),mdx(\"pre\",null,mdx(\"code\",_extends({parentName:\"pre\"},{\"className\":\"language-docker\"}),\"FROM ubuntu\\nENTRYPOINT [\\\"top\\\", \\\"-b\\\"]\\nCMD [\\\"-c\\\"]\\n\")),mdx(\"p\",null,\"When you run the container, you can see that\\xA0top\\xA0is the only process:\"),mdx(\"pre\",null,mdx(\"code\",_extends({parentName:\"pre\"},{\"className\":\"language-bash\"}),\"$ docker run -it --rm --name test top -H\\n\\ntop - 08:25:00 up 7:27, 0 users, load average: 0.00, 0.01, 0.05\\n\\nThreads: 1 total, 1 running, 0 sleeping, 0 stopped, 0 zombie\\n\\n%Cpu(s): 0.1 us, 0.1 sy, 0.0 ni, 99.7 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st\\n\\nKiB Mem: 2056668 total, 1616832 used, 439836 free, 99352 buffers\\n\\nKiB Swap: 1441840 total, 0 used, 1441840 free. 1324440 cached Mem\\n\\nPID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND\\n\\n1 root 20 0 19744 2336 2080 R 0.0 0.1 0:00.04 top\\n\")),mdx(\"p\",null,\"To examine the result further, you can use\\xA0docker exec:\"),mdx(\"pre\",null,mdx(\"code\",_extends({parentName:\"pre\"},{\"className\":\"language-bash\"}),\"$ docker exec -it test ps aux\\n\\nUSER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND\\n\\nroot 1 2.6 0.1 19752 2352 ? Ss+ 08:24 0:00 top -b -H\\n\\nroot 7 0.0 0.1 15572 2164 ? R+ 08:25 0:00 ps aux\\n\")),mdx(\"p\",null,\"And you can gracefully request\\xA0top\\xA0to shut down using\\xA0docker stop test.\"),mdx(\"p\",null,\"The following\\xA0Dockerfile\\xA0shows using the\\xA0ENTRYPOINT\\xA0to run Apache in the foreground (i.e., as\\xA0PID 1):\"),mdx(\"pre\",null,mdx(\"code\",_extends({parentName:\"pre\"},{\"className\":\"language-docker\"}),\"FROM debian:stable\\nRUN apt-get update && apt-get install -y --force-yes apache2\\nEXPOSE 80 443\\nVOLUME [\\\"/var/www\\\", \\\"/var/log/apache2\\\", \\\"/etc/apache2\\\"]\\nENTRYPOINT [\\\"/usr/sbin/apache2ctl\\\", \\\"-D\\\", \\\"FOREGROUND\\\"]\\n\")),mdx(\"p\",null,\"If you need to write a starter script for a single executable, you can ensure that the final executable receives the Unix signals by using\\xA0exec\\xA0and\\xA0gosu\\xA0commands:\"),mdx(\"pre\",null,mdx(\"code\",_extends({parentName:\"pre\"},{\"className\":\"language-bash\"}),\"#!/usr/bin/env bash\\nset -e\\nif [ \\\"$1\\\" = \\\\'postgres\\\\' ]; then\\nchown -R postgres \\\"$PGDATA\\\"\\nif [ -z \\\"$(ls -A \\\"$PGDATA\\\")\\\" ]; then\\ngosu postgres initdb\\nfi\\n\\nexec gosu postgres \\\"$@\\\"\\nfi\\nexec \\\"$@\\\"\\n\")),mdx(\"p\",null,\"Lastly, if you need to do some extra cleanup (or communicate with other containers) on shutdown, or are co-ordinating more than one executable, you may need to ensure that the\\xA0ENTRYPOINT\\xA0script receives the Unix signals, passes them on, and then does some more work:\"),mdx(\"pre\",null,mdx(\"code\",_extends({parentName:\"pre\"},{\"className\":\"language-bash\"}),\"#!/bin/sh\\n\\n# Note: I\\\\'ve written this using sh so it works in the busybox container too\\n\\n# USE the trap if you need to also do manual cleanup after the service is stopped,\\n\\n# or need to start multiple services in the one container\\ntrap \\\"echo TRAPed signal\\\" HUP INT QUIT TERM\\n\\n# start service in background here\\n/usr/sbin/apachectl start\\necho \\\"[hit enter key to exit] or run \\\\'docker stop `<container>`\\\\'\\\" read\\n\\n# stop service and clean up here\\necho \\\"stopping apache\\\"\\n/usr/sbin/apachectl stop\\necho \\\"exited $0\\\"\\n\")),mdx(\"p\",null,\"If you run this image with\\xA0docker run -it --rm -p 80:80 --name test apache, you can then examine the container's processes with\\xA0docker exec, or\\xA0docker top, and then ask the script to stop Apache:\"),mdx(\"pre\",null,mdx(\"code\",_extends({parentName:\"pre\"},{\"className\":\"language-bash\"}),\"$ docker exec -it test ps aux\\nUSER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND\\nroot 1 0.1 0.0 4448 692 ? Ss+ 00:42 0:00 /bin/sh /run.sh 123 cmd cmd2\\nroot 19 0.0 0.2 71304 4440 ? Ss 00:42 0:00 /usr/sbin/apache2 -k start\\nwww-data 20 0.2 0.2 360468 6004 ? Sl 00:42 0:00 /usr/sbin/apache2 -k start\\nwww-data 21 0.2 0.2 360468 6000 ? Sl 00:42 0:00 /usr/sbin/apache2 -k start\\nroot 81 0.0 0.1 15572 2140 ? R+ 00:44 0:00 ps aux\\n\\n$ docker top test\\nPID USER COMMAND\\n10035 root {run.sh} /bin/sh /run.sh 123 cmd cmd2\\n10054 root /usr/sbin/apache2 -k start\\n10055 33 /usr/sbin/apache2 -k start\\n10056 33 /usr/sbin/apache2 -k start\\n\\n$ /usr/bin/time docker stop test\\ntest\\nreal 0m 0.27s\\nuser 0m 0.03s\\nsys 0m 0.03s\\n\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note:\"),\"\\xA0you can override the\\xA0ENTRYPOINT\\xA0setting using\\xA0--entrypoint, but this can only set the binary to\\xA0exec\\xA0(no\\xA0sh -c\\xA0will be used).\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": The\\xA0exec\\xA0form is parsed as a JSON array, which means that you must use double-quotes (\\\") around words not single-quotes (').\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": Unlike the\\xA0shell\\xA0form, the\\xA0exec\\xA0form does not invoke a command shell. This means that normal shell processing does not happen. For example,\\xA0ENTRYPOINT \",\"[ \\\"echo\\\", \\\"$HOME\\\" ]\",\"\\xA0will not do variable substitution on\\xA0$HOME. If you want shell processing then either use the\\xA0shellform or execute a shell directly, for example:\\xA0ENTRYPOINT \",\"[ \\\"sh\\\", \\\"-c\\\", \\\"echo $HOME\\\" ]\",\". When using the exec form and executing a shell directly, as in the case for the shell form, it is the shell that is doing the environment variable expansion, not docker.\"),mdx(\"h5\",null,\"Shell form ENTRYPOINT example\"),mdx(\"p\",null,\"You can specify a plain string for the\\xA0ENTRYPOINT\\xA0and it will execute in\\xA0/bin/sh -c. This form will use shell processing to substitute shell environment variables, and will ignore any\\xA0CMD\\xA0or\\xA0docker runcommand line arguments. To ensure that\\xA0docker stop\\xA0will signal any long running\\xA0ENTRYPOINTexecutable correctly, you need to remember to start it with\\xA0exec:\"),mdx(\"p\",null,\"FROM ubuntu\"),mdx(\"p\",null,\"ENTRYPOINT exec top -b\"),mdx(\"p\",null,\"When you run this image, you'll see the single\\xA0PID 1\\xA0process:\"),mdx(\"p\",null,\"$ docker run -it --rm --name test top\"),mdx(\"p\",null,\"Mem: 1704520K used, 352148K free, 0K shrd, 0K buff, 140368121167873K cached\"),mdx(\"p\",null,\"CPU: 5% usr 0% sys 0% nic 94% idle 0% io 0% irq 0% sirq\"),mdx(\"p\",null,\"Load average: 0.08 0.03 0.05 2/98 6\"),mdx(\"p\",null,\"PID PPID USER STAT VSZ %VSZ %CPU COMMAND\"),mdx(\"p\",null,\"1 0 root R 3164 0% 0% top -b\"),mdx(\"p\",null,\"Which will exit cleanly on\\xA0docker stop:\"),mdx(\"p\",null,\"$ /usr/bin/time docker stop test\"),mdx(\"p\",null,\"test\"),mdx(\"p\",null,\"real 0m 0.20s\"),mdx(\"p\",null,\"user 0m 0.02s\"),mdx(\"p\",null,\"sys 0m 0.04s\"),mdx(\"p\",null,\"If you forget to add\\xA0exec\\xA0to the beginning of your\\xA0ENTRYPOINT:\"),mdx(\"p\",null,\"FROM ubuntu\"),mdx(\"p\",null,\"ENTRYPOINT top -b\"),mdx(\"p\",null,\"CMD --ignored-param1\"),mdx(\"p\",null,\"You can then run it (giving it a name for the next step):\"),mdx(\"p\",null,\"$ docker run -it --name test top --ignored-param2\"),mdx(\"p\",null,\"Mem: 1704184K used, 352484K free, 0K shrd, 0K buff, 140621524238337K cached\"),mdx(\"p\",null,\"CPU: 9% usr 2% sys 0% nic 88% idle 0% io 0% irq 0% sirq\"),mdx(\"p\",null,\"Load average: 0.01 0.02 0.05 2/101 7\"),mdx(\"p\",null,\"PID PPID USER STAT VSZ %VSZ %CPU COMMAND\"),mdx(\"p\",null,\"1 0 root S 3168 0% 0% /bin/sh -c top -b cmd cmd2\"),mdx(\"p\",null,\"7 1 root R 3164 0% 0% top -b\"),mdx(\"p\",null,\"You can see from the output of\\xA0top\\xA0that the specified\\xA0ENTRYPOINT\\xA0is not\\xA0PID 1.\"),mdx(\"p\",null,\"If you then run\\xA0docker stop test, the container will not exit cleanly - the\\xA0stop\\xA0command will be forced to send a\\xA0SIGKILL\\xA0after the timeout:\"),mdx(\"p\",null,\"$ docker exec -it test ps aux\"),mdx(\"p\",null,\"PID USER COMMAND\"),mdx(\"p\",null,\"1 root /bin/sh -c top -b cmd cmd2\"),mdx(\"p\",null,\"7 root top -b\"),mdx(\"p\",null,\"8 root ps aux\"),mdx(\"p\",null,\"$ /usr/bin/time docker stop test\"),mdx(\"p\",null,\"test\"),mdx(\"p\",null,\"real 0m 10.19s\"),mdx(\"p\",null,\"user 0m 0.04s\"),mdx(\"p\",null,\"sys 0m 0.03s\"),mdx(\"h5\",null,\"Understand how CMD and ENTRYPOINT interact\"),mdx(\"p\",null,\"Both\\xA0CMD\\xA0and\\xA0ENTRYPOINT\\xA0instructions define what command gets executed when running a container. There are few rules that describe their co-operation.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Dockerfile should specify at least one of\\xA0CMD\\xA0or\\xA0ENTRYPOINT\\xA0commands.\"),mdx(\"li\",{parentName:\"ol\"},\"ENTRYPOINT\\xA0should be defined when using the container as an executable.\"),mdx(\"li\",{parentName:\"ol\"},\"CMD\\xA0should be used as a way of defining default arguments for an\\xA0ENTRYPOINT\\xA0command or for executing an ad-hoc command in a container.\"),mdx(\"li\",{parentName:\"ol\"},\"CMD\\xA0will be overridden when running the container with alternative arguments.\")),mdx(\"p\",null,\"The table below shows what command is executed for different\\xA0ENTRYPOINT\\xA0/\\xA0CMD\\xA0combinations:\"),mdx(\"hr\",null),mdx(\"p\",null,\"  \\xA0                                  No ENTRYPOINT                ENTRYPOINT exec_entry p1_entry   ENTRYPOINT \",\"[\\\"exec_entry\\\", \\\"p1_entry\\\"]\",\"\\n\",mdx(\"strong\",{parentName:\"p\"},\"No CMD\"),\"                         error, not allowed           /bin/sh -c exec_entry p1_entry   exec_entry p1_entry\\n\",mdx(\"strong\",{parentName:\"p\"},\"CMD \",\"[\\\"exec_cmd\\\", \\\"p1_cmd\\\"]\"),\"   exec_cmd p1_cmd              /bin/sh -c exec_entry p1_entry   exec_entry p1_entry exec_cmd p1_cmd\\n\",mdx(\"strong\",{parentName:\"p\"},\"CMD \",\"[\\\"p1_cmd\\\", \\\"p2_cmd\\\"]\"),\"     p1_cmd p2_cmd                /bin/sh -c exec_entry p1_entry   exec_entry p1_entry p1_cmd p2_cmd\\n\",mdx(\"strong\",{parentName:\"p\"},\"CMD exec_cmd p1_cmd\"),\"            /bin/sh -c exec_cmd p1_cmd   /bin/sh -c exec_entry p1_entry   exec_entry p1_entry /bin/sh -c exec_cmd p1_cmd\"),mdx(\"hr\",null),mdx(\"h4\",null,\"VOLUME\"),mdx(\"p\",null,\"VOLUME \",\"[\\\"/data\\\"]\"),mdx(\"p\",null,\"The\\xA0VOLUME\\xA0instruction creates a mount point with the specified name and marks it as holding externally mounted volumes from native host or other containers. The value can be a JSON array,\\xA0VOLUME \",\"[\\\"/var/log/\\\"]\",\", or a plain string with multiple arguments, such as\\xA0VOLUME /var/log\\xA0or\\xA0VOLUME /var/log /var/db. For more information/examples and mounting instructions via the Docker client, refer to\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/tutorials/dockervolumes/#/mount-a-host-directory-as-a-data-volume\"}),\"Share Directories via Volumes\"),\"\\xA0documentation.\"),mdx(\"p\",null,\"The\\xA0docker run\\xA0command initializes the newly created volume with any data that exists at the specified location within the base image. For example, consider the following Dockerfile snippet:\"),mdx(\"p\",null,\"FROM ubuntu\"),mdx(\"p\",null,\"RUN mkdir /myvol\"),mdx(\"p\",null,\"RUN echo \\\"hello world\\\" > /myvol/greeting\"),mdx(\"p\",null,\"VOLUME /myvol\"),mdx(\"p\",null,\"This Dockerfile results in an image that causes\\xA0docker run\\xA0to create a new mount point at\\xA0/myvoland copy the\\xA0greeting\\xA0file into the newly created volume.\"),mdx(\"h5\",null,\"Notes about specifying volumes\"),mdx(\"p\",null,\"Keep the following things in mind about volumes in the\\xA0Dockerfile.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Volumes on Windows-based containers\"),\": When using Windows-based containers, the destination of a volume inside the container must be one of:\",mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},\"a non-existing or empty directory\"),mdx(\"li\",{parentName:\"ul\"},\"a drive other than\\xA0C:\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Changing the volume from within the Dockerfile\"),\": If any build steps change the data within the volume after it has been declared, those changes will be discarded.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"JSON formatting\"),\": The list is parsed as a JSON array. You must enclose words with double quotes (\\\")rather than single quotes (\\\\').\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"The host directory is declared at container run-time\"),\": The host directory (the mountpoint) is, by its nature, host-dependent. This is to preserve image portability, since a given host directory can't be guaranteed to be available on all hosts. For this reason, you can't mount a host directory from within the Dockerfile. The\\xA0VOLUME\\xA0instruction does not support specifying a\\xA0host-dirparameter. You must specify the mountpoint when you create or run the container.\")),mdx(\"h4\",null,\"USER\"),mdx(\"p\",null,\"USER \",mdx(\"inlineCode\",{parentName:\"p\"},\"<user>[:<group>\"),\"] or\"),mdx(\"p\",null,\"USER \",mdx(\"inlineCode\",{parentName:\"p\"},\"<UID>[:<GID>\"),\"]\"),mdx(\"p\",null,\"The\\xA0USER\\xA0instruction sets the user name (or UID) and optionally the user group (or GID) to use when running the image and for any\\xA0RUN,\\xA0CMD\\xA0and\\xA0ENTRYPOINT\\xA0instructions that follow it in the\\xA0Dockerfile.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Warning\"),\": When the user doesn't have a primary group then the image (or the next instructions) will be run with the\\xA0root\\xA0group.\"),mdx(\"p\",null,\"On Windows, the user must be created first if it's not a built-in account. This can be done with the\\xA0net user\\xA0command called as part of a Dockerfile.\"),mdx(\"p\",null,\"FROM microsoft/windowsservercore\"),mdx(\"h1\",null,\"Create Windows user in the container\"),mdx(\"p\",null,\"RUN net user /add patrick\"),mdx(\"h1\",null,\"Set it for subsequent commands\"),mdx(\"p\",null,\"USER patrick\"),mdx(\"h4\",null,\"WORKDIR\"),mdx(\"p\",null,\"WORKDIR /path/to/workdir\"),mdx(\"p\",null,\"The\\xA0WORKDIR\\xA0instruction sets the working directory for any\\xA0RUN,\\xA0CMD,\\xA0ENTRYPOINT,\\xA0COPY\\xA0and\\xA0ADDinstructions that follow it in the\\xA0Dockerfile. If the\\xA0WORKDIR\\xA0doesn't exist, it will be created even if it's not used in any subsequent\\xA0Dockerfile\\xA0instruction.\"),mdx(\"p\",null,\"The\\xA0WORKDIR\\xA0instruction can be used multiple times in a\\xA0Dockerfile. If a relative path is provided, it will be relative to the path of the previous\\xA0WORKDIR\\xA0instruction. For example:\"),mdx(\"p\",null,\"WORKDIR /a\"),mdx(\"p\",null,\"WORKDIR b\"),mdx(\"p\",null,\"WORKDIR c\"),mdx(\"p\",null,\"RUN pwd\"),mdx(\"p\",null,\"The output of the final\\xA0pwd\\xA0command in this\\xA0Dockerfile\\xA0would be\\xA0/a/b/c.\"),mdx(\"p\",null,\"The\\xA0WORKDIR\\xA0instruction can resolve environment variables previously set using\\xA0ENV. You can only use environment variables explicitly set in the\\xA0Dockerfile. For example:\"),mdx(\"p\",null,\"ENV DIRPATH /path\"),mdx(\"p\",null,\"WORKDIR $DIRPATH/$DIRNAME\"),mdx(\"p\",null,\"RUN pwd\"),mdx(\"p\",null,\"The output of the final\\xA0pwd\\xA0command in this\\xA0Dockerfile\\xA0would be\\xA0/path/$DIRNAME\"),mdx(\"h4\",null,\"ARG\"),mdx(\"p\",null,\"ARG \",mdx(\"inlineCode\",{parentName:\"p\"},\"<name>[=<default value>\"),\"]\"),mdx(\"p\",null,\"The\\xA0ARG\\xA0instruction defines a variable that users can pass at build-time to the builder with the\\xA0docker build\\xA0command using the\\xA0--build-arg \",mdx(\"inlineCode\",{parentName:\"p\"},\"<varname>=<value>\"),\"\\xA0flag. If a user specifies a build argument that was not defined in the Dockerfile, the build outputs a warning.\"),mdx(\"p\",null,\"[Warning]\",\" One or more build-args \",\"[foo]\",\" were not consumed.\"),mdx(\"p\",null,\"A Dockerfile may include one or more\\xA0ARG\\xA0instructions. For example, the following is a valid Dockerfile:\"),mdx(\"p\",null,\"FROM busybox\"),mdx(\"p\",null,\"ARG user1\"),mdx(\"p\",null,\"ARG buildno\"),mdx(\"p\",null,\"...\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Warning:\"),\"\\xA0It is not recommended to use build-time variables for passing secrets like github keys, user credentials etc. Build-time variable values are visible to any user of the image with the\\xA0docker history\\xA0command.\"),mdx(\"h5\",null,\"Default values\"),mdx(\"p\",null,\"An\\xA0ARG\\xA0instruction can optionally include a default value:\"),mdx(\"p\",null,\"FROM busybox\"),mdx(\"p\",null,\"ARG user1=someuser\"),mdx(\"p\",null,\"ARG buildno=1\"),mdx(\"p\",null,\"...\"),mdx(\"p\",null,\"If an\\xA0ARG\\xA0instruction has a default value and if there is no value passed at build-time, the builder uses the default.\"),mdx(\"h5\",null,\"Scope\"),mdx(\"p\",null,\"An\\xA0ARG\\xA0variable definition comes into effect from the line on which it is defined in the\\xA0Dockerfile\\xA0not from the argument's use on the command-line or elsewhere. For example, consider this Dockerfile:\"),mdx(\"p\",null,\"1 FROM busybox\"),mdx(\"p\",null,\"2 USER ${user:-some_user}\"),mdx(\"p\",null,\"3 ARG user\"),mdx(\"p\",null,\"4 USER $user\"),mdx(\"p\",null,\"...\"),mdx(\"p\",null,\"A user builds this file by calling:\"),mdx(\"p\",null,\"$ docker build --build-arg user=what_user .\"),mdx(\"p\",null,\"The\\xA0USER\\xA0at line 2 evaluates to\\xA0some_user\\xA0as the\\xA0user\\xA0variable is defined on the subsequent line 3. The\\xA0USER\\xA0at line 4 evaluates to\\xA0what_user\\xA0as\\xA0user\\xA0is defined and the\\xA0what_user\\xA0value was passed on the command line. Prior to its definition by an\\xA0ARG\\xA0instruction, any use of a variable results in an empty string.\"),mdx(\"p\",null,\"An\\xA0ARG\\xA0instruction goes out of scope at the end of the build stage where it was defined. To use an arg in multiple stages, each stage must include the\\xA0ARG\\xA0instruction.\"),mdx(\"p\",null,\"FROM busybox\"),mdx(\"p\",null,\"ARG SETTINGS\"),mdx(\"p\",null,\"RUN ./run/setup $SETTINGS\"),mdx(\"p\",null,\"FROM busybox\"),mdx(\"p\",null,\"ARG SETTINGS\"),mdx(\"p\",null,\"RUN ./run/other $SETTINGS\"),mdx(\"h5\",null,\"Using ARG variables\"),mdx(\"p\",null,\"You can use an\\xA0ARG\\xA0or an\\xA0ENV\\xA0instruction to specify variables that are available to the\\xA0RUNinstruction. Environment variables defined using the\\xA0ENV\\xA0instruction always override an\\xA0ARGinstruction of the same name. Consider this Dockerfile with an\\xA0ENV\\xA0and\\xA0ARG\\xA0instruction.\"),mdx(\"p\",null,\"1 FROM ubuntu\"),mdx(\"p\",null,\"2 ARG CONT_IMG_VER\"),mdx(\"p\",null,\"3 ENV CONT_IMG_VER v1.0.0\"),mdx(\"p\",null,\"4 RUN echo $CONT_IMG_VER\"),mdx(\"p\",null,\"Then, assume this image is built with this command:\"),mdx(\"p\",null,\"$ docker build --build-arg CONT_IMG_VER=v2.0.1 .\"),mdx(\"p\",null,\"In this case, the\\xA0RUN\\xA0instruction uses\\xA0v1.0.0\\xA0instead of the\\xA0ARG\\xA0setting passed by the user:v2.0.1This behavior is similar to a shell script where a locally scoped variable overrides the variables passed as arguments or inherited from environment, from its point of definition.\"),mdx(\"p\",null,\"Using the example above but a different\\xA0ENV\\xA0specification you can create more useful interactions between\\xA0ARG\\xA0and\\xA0ENV\\xA0instructions:\"),mdx(\"p\",null,\"1 FROM ubuntu\"),mdx(\"p\",null,\"2 ARG CONT_IMG_VER\"),mdx(\"p\",null,\"3 ENV CONT_IMG_VER ${CONT_IMG_VER:-v1.0.0}\"),mdx(\"p\",null,\"4 RUN echo $CONT_IMG_VER\"),mdx(\"p\",null,\"Unlike an\\xA0ARG\\xA0instruction,\\xA0ENV\\xA0values are always persisted in the built image. Consider a docker build without the\\xA0--build-arg\\xA0flag:\"),mdx(\"p\",null,\"$ docker build .\"),mdx(\"p\",null,\"Using this Dockerfile example,\\xA0CONT_IMG_VER\\xA0is persisted in the image but its value would be\\xA0v1.0.0\\xA0as it is the default set in line 3 by the\\xA0ENV\\xA0instruction.\"),mdx(\"p\",null,\"The variable expansion technique in this example allows you to pass arguments from the command line and persist them in the final image by leveraging the\\xA0ENV\\xA0instruction. Variable expansion is only supported for\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/builder/#environment-replacement\"}),\"a limited set of Dockerfile instructions.\")),mdx(\"h5\",null,\"Predefined ARGs\"),mdx(\"p\",null,\"Docker has a set of predefined\\xA0ARG\\xA0variables that you can use without a corresponding\\xA0ARGinstruction in the Dockerfile.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"HTTP_PROXY\"),mdx(\"li\",{parentName:\"ul\"},\"http_proxy\"),mdx(\"li\",{parentName:\"ul\"},\"HTTPS_PROXY\"),mdx(\"li\",{parentName:\"ul\"},\"https_proxy\"),mdx(\"li\",{parentName:\"ul\"},\"FTP_PROXY\"),mdx(\"li\",{parentName:\"ul\"},\"ftp_proxy\"),mdx(\"li\",{parentName:\"ul\"},\"NO_PROXY\"),mdx(\"li\",{parentName:\"ul\"},\"no_proxy\")),mdx(\"p\",null,\"To use these, simply pass them on the command line using the flag:\"),mdx(\"p\",null,\"--build-arg \",mdx(\"inlineCode\",{parentName:\"p\"},\"<varname>=<value>\")),mdx(\"p\",null,\"By default, these pre-defined variables are excluded from the output of\\xA0docker history. Excluding them reduces the risk of accidentally leaking sensitive authentication information in an\\xA0HTTP_PROXYvariable.\"),mdx(\"p\",null,\"For example, consider building the following Dockerfile using--build-arg HTTP_PROXY=http://user:pass\\\\@proxy.lon.example.com\"),mdx(\"p\",null,\"FROM ubuntu\"),mdx(\"p\",null,\"RUN echo \\\"Hello World\\\"\"),mdx(\"p\",null,\"In this case, the value of the\\xA0HTTP_PROXY\\xA0variable is not available in the\\xA0docker history\\xA0and is not cached. If you were to change location, and your proxy server changed to\\xA0http://user:pass\\\\@proxy.sfo.example.com, a subsequent build does not result in a cache miss.\"),mdx(\"p\",null,\"If you need to override this behaviour then you may do so by adding an\\xA0ARG\\xA0statement in the Dockerfile as follows:\"),mdx(\"p\",null,\"FROM ubuntu\"),mdx(\"p\",null,\"ARG HTTP_PROXY\"),mdx(\"p\",null,\"RUN echo \\\"Hello World\\\"\"),mdx(\"p\",null,\"When building this Dockerfile, the\\xA0HTTP_PROXY\\xA0is preserved in the\\xA0docker history, and changing its value invalidates the build cache.\"),mdx(\"h5\",null,\"Impact on build caching\"),mdx(\"p\",null,\"ARG\\xA0variables are not persisted into the built image as\\xA0ENV\\xA0variables are. However,\\xA0ARG\\xA0variables do impact the build cache in similar ways. If a Dockerfile defines an\\xA0ARG\\xA0variable whose value is different from a previous build, then a \\\"cache miss\\\" occurs upon its first usage, not its definition. In particular, all\\xA0RUN\\xA0instructions following an\\xA0ARG\\xA0instruction use the\\xA0ARG\\xA0variable implicitly (as an environment variable), thus can cause a cache miss. All predefined\\xA0ARG\\xA0variables are exempt from caching unless there is a matching\\xA0ARG\\xA0statement in the\\xA0Dockerfile.\"),mdx(\"p\",null,\"For example, consider these two Dockerfile:\"),mdx(\"p\",null,\"1 FROM ubuntu\"),mdx(\"p\",null,\"2 ARG CONT_IMG_VER\"),mdx(\"p\",null,\"3 RUN echo $CONT_IMG_VER\"),mdx(\"p\",null,\"1 FROM ubuntu\"),mdx(\"p\",null,\"2 ARG CONT_IMG_VER\"),mdx(\"p\",null,\"3 RUN echo hello\"),mdx(\"p\",null,\"If you specify\\xA0--build-arg CONT_IMG_VER=\",mdx(\"inlineCode\",{parentName:\"p\"},\"<value>\\xA0on the command line, in both cases, the specification on line 2 does not cause a cache miss; line 3 does cause a cache miss.ARG CONT_IMG_VER\\xA0causes the RUN line to be identified as the same as running\\xA0CONT_IMG_VER=<value>\\xA0echo hello, so if the\\xA0<value>\"),\"changes, we get a cache miss.\"),mdx(\"p\",null,\"Consider another example under the same command line:\"),mdx(\"p\",null,\"1 FROM ubuntu\"),mdx(\"p\",null,\"2 ARG CONT_IMG_VER\"),mdx(\"p\",null,\"3 ENV CONT_IMG_VER $CONT_IMG_VER\"),mdx(\"p\",null,\"4 RUN echo $CONT_IMG_VER\"),mdx(\"p\",null,\"In this example, the cache miss occurs on line 3. The miss happens because the variable's value in the\\xA0ENV\\xA0references the\\xA0ARG\\xA0variable and that variable is changed through the command line. In this example, the\\xA0ENV\\xA0command causes the image to include the value.\"),mdx(\"p\",null,\"If an\\xA0ENV\\xA0instruction overrides an\\xA0ARG\\xA0instruction of the same name, like this Dockerfile:\"),mdx(\"p\",null,\"1 FROM ubuntu\"),mdx(\"p\",null,\"2 ARG CONT_IMG_VER\"),mdx(\"p\",null,\"3 ENV CONT_IMG_VER hello\"),mdx(\"p\",null,\"4 RUN echo $CONT_IMG_VER\"),mdx(\"p\",null,\"Line 3 does not cause a cache miss because the value of\\xA0CONT_IMG_VER\\xA0is a constant (hello). As a result, the environment variables and values used on the\\xA0RUN\\xA0(line 4) doesn't change between builds.\"),mdx(\"h4\",null,\"ONBUILD\"),mdx(\"p\",null,\"ONBUILD \",\"[INSTRUCTION]\"),mdx(\"p\",null,\"The\\xA0ONBUILD\\xA0instruction adds to the image a\\xA0trigger\\xA0instruction to be executed at a later time, when the image is used as the base for another build. The trigger will be executed in the context of the downstream build, as if it had been inserted immediately after the\\xA0FROM\\xA0instruction in the downstream\\xA0Dockerfile.\"),mdx(\"p\",null,\"Any build instruction can be registered as a trigger.\"),mdx(\"p\",null,\"This is useful if you are building an image which will be used as a base to build other images, for example an application build environment or a daemon which may be customized with user-specific configuration.\"),mdx(\"p\",null,\"For example, if your image is a reusable Python application builder, it will require application source code to be added in a particular directory, and it might require a build script to be called\\xA0after\\xA0that. You can't just call\\xA0ADD\\xA0and\\xA0RUN\\xA0now, because you don't yet have access to the application source code, and it will be different for each application build. You could simply provide application developers with a boilerplate\\xA0Dockerfile\\xA0to copy-paste into their application, but that is inefficient, error-prone and difficult to update because it mixes with application-specific code.\"),mdx(\"p\",null,\"The solution is to use\\xA0ONBUILD\\xA0to register advance instructions to run later, during the next build stage.\"),mdx(\"p\",null,\"Here's how it works:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"When it encounters an\\xA0ONBUILD\\xA0instruction, the builder adds a trigger to the metadata of the image being built. The instruction does not otherwise affect the current build.\"),mdx(\"li\",{parentName:\"ul\"},\"At the end of the build, a list of all triggers is stored in the image manifest, under the key\\xA0OnBuild. They can be inspected with the\\xA0docker inspect\\xA0command.\"),mdx(\"li\",{parentName:\"ul\"},\"Later the image may be used as a base for a new build, using the\\xA0FROM\\xA0instruction. As part of processing the\\xA0FROM\\xA0instruction, the downstream builder looks for\\xA0ONBUILD\\xA0triggers, and executes them in the same order they were registered. If any of the triggers fail, the\\xA0FROMinstruction is aborted which in turn causes the build to fail. If all triggers succeed, the\\xA0FROMinstruction completes and the build continues as usual.\"),mdx(\"li\",{parentName:\"ul\"},\"Triggers are cleared from the final image after being executed. In other words they are not inherited by \\\"grand-children\\\" builds.\")),mdx(\"p\",null,\"For example, you might add something like this:\"),mdx(\"p\",null,\"[...]\"),mdx(\"p\",null,\"ONBUILD ADD . /app/src\"),mdx(\"p\",null,\"ONBUILD RUN /usr/local/bin/python-build --dir /app/src\"),mdx(\"p\",null,\"[...]\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Warning\"),\": Chaining\\xA0ONBUILD\\xA0instructions using\\xA0ONBUILD ONBUILD\\xA0isn't allowed.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Warning\"),\": The\\xA0ONBUILD\\xA0instruction may not trigger\\xA0FROM\\xA0or\\xA0MAINTAINER\\xA0instructions.\"),mdx(\"h4\",null,\"STOPSIGNAL\"),mdx(\"p\",null,\"STOPSIGNAL signal\"),mdx(\"p\",null,\"The\\xA0STOPSIGNAL\\xA0instruction sets the system call signal that will be sent to the container to exit. This signal can be a valid unsigned number that matches a position in the kernel's syscall table, for instance 9, or a signal name in the format SIGNAME, for instance SIGKILL.\"),mdx(\"h4\",null,\"HEALTHCHECK\"),mdx(\"p\",null,\"The\\xA0HEALTHCHECK\\xA0instruction has two forms:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"HEALTHCHECK \",\"[OPTIONS]\",\" CMD command\\xA0(check container health by running a command inside the container)\"),mdx(\"li\",{parentName:\"ul\"},\"HEALTHCHECK NONE\\xA0(disable any healthcheck inherited from the base image)\")),mdx(\"p\",null,\"The\\xA0HEALTHCHECK\\xA0instruction tells Docker how to test a container to check that it is still working. This can detect cases such as a web server that is stuck in an infinite loop and unable to handle new connections, even though the server process is still running.\"),mdx(\"p\",null,\"When a container has a healthcheck specified, it has a\\xA0health status\\xA0in addition to its normal status. This status is initially\\xA0starting. Whenever a health check passes, it becomes\\xA0healthy\\xA0(whatever state it was previously in). After a certain number of consecutive failures, it becomes\\xA0unhealthy.\"),mdx(\"p\",null,\"The options that can appear before\\xA0CMD\\xA0are:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"--interval=DURATION\\xA0(default:\\xA030s)\"),mdx(\"li\",{parentName:\"ul\"},\"--timeout=DURATION\\xA0(default:\\xA030s)\"),mdx(\"li\",{parentName:\"ul\"},\"--start-period=DURATION\\xA0(default:\\xA00s)\"),mdx(\"li\",{parentName:\"ul\"},\"--retries=N\\xA0(default:\\xA03)\")),mdx(\"p\",null,\"The health check will first run\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"interval\"),\"\\xA0seconds after the container is started, and then again\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"interval\"),\"seconds after each previous check completes.\"),mdx(\"p\",null,\"If a single run of the check takes longer than\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"timeout\"),\"\\xA0seconds then the check is considered to have failed.\"),mdx(\"p\",null,\"It takes\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"retries\"),\"\\xA0consecutive failures of the health check for the container to be considered\\xA0unhealthy.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"start period\"),\"\\xA0provides initialization time for containers that need time to bootstrap. Probe failure during that period will not be counted towards the maximum number of retries. However, if a health check succeeds during the start period, the container is considered started and all consecutive failures will be counted towards the maximum number of retries.\"),mdx(\"p\",null,\"There can only be one\\xA0HEALTHCHECK\\xA0instruction in a Dockerfile. If you list more than one then only the last\\xA0HEALTHCHECK\\xA0will take effect.\"),mdx(\"p\",null,\"The command after the\\xA0CMD\\xA0keyword can be either a shell command (e.g.\\xA0HEALTHCHECK CMD /bin/check-running) or an\\xA0exec\\xA0array (as with other Dockerfile commands; see e.g.\\xA0ENTRYPOINT\\xA0for details).\"),mdx(\"p\",null,\"The command's exit status indicates the health status of the container. The possible values are:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"0: success - the container is healthy and ready for use\"),mdx(\"li\",{parentName:\"ul\"},\"1: unhealthy - the container is not working correctly\"),mdx(\"li\",{parentName:\"ul\"},\"2: reserved - do not use this exit code\")),mdx(\"p\",null,\"For example, to check every five minutes or so that a web-server is able to serve the site's main page within three seconds:\"),mdx(\"p\",null,\"HEALTHCHECK --interval=5m --timeout=3s \\\\\"),mdx(\"p\",null,\"CMD curl -f http://localhost/ || exit 1\"),mdx(\"p\",null,\"To help debug failing probes, any output text (UTF-8 encoded) that the command writes on stdout or stderr will be stored in the health status and can be queried with\\xA0docker inspect. Such output should be kept short (only the first 4096 bytes are stored currently).\"),mdx(\"p\",null,\"When the health status of a container changes, a\\xA0health_status\\xA0event is generated with the new status.\"),mdx(\"p\",null,\"The\\xA0HEALTHCHECK\\xA0feature was added in Docker 1.12.\"),mdx(\"h4\",null,\"SHELL\"),mdx(\"p\",null,\"SHELL \",\"[\\\"executable\\\", \\\"parameters\\\"]\"),mdx(\"p\",null,\"The\\xA0SHELL\\xA0instruction allows the default shell used for the\\xA0shell\\xA0form of commands to be overridden. The default shell on Linux is\\xA0\",\"[\\\"/bin/sh\\\", \\\"-c\\\"]\",\", and on Windows is\\xA0\",\"[\\\"cmd\\\", \\\"/S\\\", \\\"/C\\\"]\",\". The\\xA0SHELL\\xA0instruction\\xA0must\\xA0be written in JSON form in a Dockerfile.\"),mdx(\"p\",null,\"The\\xA0SHELL\\xA0instruction is particularly useful on Windows where there are two commonly used and quite different native shells:\\xA0cmd\\xA0and\\xA0powershell, as well as alternate shells available including\\xA0sh.\"),mdx(\"p\",null,\"The\\xA0SHELL\\xA0instruction can appear multiple times. Each\\xA0SHELL\\xA0instruction overrides all previous\\xA0SHELL\\xA0instructions, and affects all subsequent instructions. For example:\"),mdx(\"p\",null,\"FROM microsoft/windowsservercore\"),mdx(\"h1\",null,\"Executed as cmd /S /C echo default\"),mdx(\"p\",null,\"RUN echo default\"),mdx(\"h1\",null,\"Executed as cmd /S /C powershell -command Write-Host default\"),mdx(\"p\",null,\"RUN powershell -command Write-Host default\"),mdx(\"h1\",null,\"Executed as powershell -command Write-Host hello\"),mdx(\"p\",null,\"SHELL \",\"[\\\"powershell\\\", \\\"-command\\\"]\"),mdx(\"p\",null,\"RUN Write-Host hello\"),mdx(\"h1\",null,\"Executed as cmd /S /C echo hello\"),mdx(\"p\",null,\"SHELL \",\"[\\\"cmd\\\", \\\"/S\\\"\\\", \\\"/C\\\"]\"),mdx(\"p\",null,\"RUN echo hello\"),mdx(\"p\",null,\"The following instructions can be affected by the\\xA0SHELL\\xA0instruction when the\\xA0shell\\xA0form of them is used in a Dockerfile:\\xA0RUN,\\xA0CMD\\xA0and\\xA0ENTRYPOINT.\"),mdx(\"p\",null,\"The following example is a common pattern found on Windows which can be streamlined by using the\\xA0SHELL\\xA0instruction:\"),mdx(\"p\",null,\"...\"),mdx(\"p\",null,\"RUN powershell -command Execute-MyCmdlet -param1 \\\"c:\\\\foo.txt\\\"\"),mdx(\"p\",null,\"...\"),mdx(\"p\",null,\"The command invoked by docker will be:\"),mdx(\"p\",null,\"cmd /S /C powershell -command Execute-MyCmdlet -param1 \\\"c:\\\\foo.txt\\\"\"),mdx(\"p\",null,\"This is inefficient for two reasons. First, there is an un-necessary cmd.exe command processor (aka shell) being invoked. Second, each\\xA0RUN\\xA0instruction in the\\xA0shell\\xA0form requires an extra\\xA0powershell -command\\xA0prefixing the command.\"),mdx(\"p\",null,\"To make this more efficient, one of two mechanisms can be employed. One is to use the JSON form of the RUN command such as:\"),mdx(\"p\",null,\"...\"),mdx(\"p\",null,\"RUN \",\"[\\\"powershell\\\", \\\"-command\\\", \\\"Execute-MyCmdlet\\\", \\\"-param1 \\\\\\\"c:\",\"\\\\\",\"foo.txt\\\\\\\"\\\"]\"),mdx(\"p\",null,\"...\"),mdx(\"p\",null,\"While the JSON form is unambiguous and does not use the un-necessary cmd.exe, it does require more verbosity through double-quoting and escaping. The alternate mechanism is to use the\\xA0SHELLinstruction and the\\xA0shell\\xA0form, making a more natural syntax for Windows users, especially when combined with the\\xA0escape\\xA0parser directive:\"),mdx(\"h1\",null,\"escape=`\"),mdx(\"p\",null,\"FROM microsoft/nanoserver\"),mdx(\"p\",null,\"SHELL \",\"[\\\"powershell\\\",\\\"-command\\\"]\"),mdx(\"p\",null,\"RUN New-Item -ItemType Directory C:\\\\Example\"),mdx(\"p\",null,\"ADD Execute-MyCmdlet.ps1 c:\\\\example\\\\\"),mdx(\"p\",null,\"RUN c:\\\\example\\\\Execute-MyCmdlet -sample \\\\'hello world\\\\'\"),mdx(\"p\",null,\"Resulting in:\"),mdx(\"p\",null,\"PS E:\\\\docker\\\\build\\\\shell> docker build -t shell .\"),mdx(\"p\",null,\"Sending build context to Docker daemon 4.096 kB\"),mdx(\"p\",null,\"Step 1/5 : FROM microsoft/nanoserver\"),mdx(\"p\",null,\"---> 22738ff49c6d\"),mdx(\"p\",null,\"Step 2/5 : SHELL powershell -command\"),mdx(\"p\",null,\"---> Running in 6fcdb6855ae2\"),mdx(\"p\",null,\"---> 6331462d4300\"),mdx(\"p\",null,\"Removing intermediate container 6fcdb6855ae2\"),mdx(\"p\",null,\"Step 3/5 : RUN New-Item -ItemType Directory C:\\\\Example\"),mdx(\"p\",null,\"---> Running in d0eef8386e97\"),mdx(\"p\",null,\"Directory: C:\\\\\"),mdx(\"p\",null,\"Mode LastWriteTime Length Name\"),mdx(\"hr\",null),mdx(\"p\",null,\"d----- 10/28/2016 11:26 AM Example\"),mdx(\"p\",null,\"---> 3f2fbf1395d9\"),mdx(\"p\",null,\"Removing intermediate container d0eef8386e97\"),mdx(\"p\",null,\"Step 4/5 : ADD Execute-MyCmdlet.ps1 c:\\\\example\\\\\"),mdx(\"p\",null,\"---> a955b2621c31\"),mdx(\"p\",null,\"Removing intermediate container b825593d39fc\"),mdx(\"p\",null,\"Step 5/5 : RUN c:\\\\example\\\\Execute-MyCmdlet \\\\'hello world\\\\'\"),mdx(\"p\",null,\"---> Running in be6d8e63fe75\"),mdx(\"p\",null,\"hello world\"),mdx(\"p\",null,\"---> 8e559e9bf424\"),mdx(\"p\",null,\"Removing intermediate container be6d8e63fe75\"),mdx(\"p\",null,\"Successfully built 8e559e9bf424\"),mdx(\"p\",null,\"PS E:\\\\docker\\\\build\\\\shell>\"),mdx(\"p\",null,\"The\\xA0SHELL\\xA0instruction could also be used to modify the way in which a shell operates. For example, using\\xA0SHELL cmd /S /C /V:ON|OFF\\xA0on Windows, delayed environment variable expansion semantics could be modified.\"),mdx(\"p\",null,\"The\\xA0SHELL\\xA0instruction can also be used on Linux should an alternate shell be required such as\\xA0zsh,\\xA0csh,\\xA0tcsh\\xA0and others.\"),mdx(\"p\",null,\"The\\xA0SHELL\\xA0feature was added in Docker 1.12.\"),mdx(\"h4\",null,\"Dockerfile examples\"),mdx(\"p\",null,\"Below you can see some examples of Dockerfile syntax. If you're interested in something more realistic, look at the list of\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/examples/\"}),\"Dockerization examples\"),\".\"),mdx(\"h1\",null,\"Nginx\"),mdx(\"h1\",null),mdx(\"h1\",null,\"VERSION 0.0.1\"),mdx(\"p\",null,\"FROM ubuntu\"),mdx(\"p\",null,\"LABEL Description=\\\"This image is used to start the foobar executable\\\" Vendor=\\\"ACME Products\\\" Version=\\\"1.0\\\"\"),mdx(\"p\",null,\"RUN apt-get update && apt-get install -y inotify-tools nginx apache2 openssh-server\"),mdx(\"h1\",null,\"Firefox over VNC\"),mdx(\"h1\",null),mdx(\"h1\",null,\"VERSION 0.3\"),mdx(\"p\",null,\"FROM ubuntu\"),mdx(\"h1\",null,\"Install vnc, xvfb in order to create a \\\\'fake\\\\' display and firefox\"),mdx(\"p\",null,\"RUN apt-get update && apt-get install -y x11vnc xvfb firefox\"),mdx(\"p\",null,\"RUN mkdir \",\"~\",\"/.vnc\"),mdx(\"h1\",null,\"Setup a password\"),mdx(\"p\",null,\"RUN x11vnc -storepasswd 1234 \",\"~\",\"/.vnc/passwd\"),mdx(\"h1\",null,\"Autostart firefox (might not be the best way, but it does the trick)\"),mdx(\"p\",null,\"RUN bash -c \\\\'echo \\\"firefox\\\" >> /.bashrc\\\\'\"),mdx(\"p\",null,\"EXPOSE 5900\"),mdx(\"p\",null,\"CMD \",\"[\\\"x11vnc\\\", \\\"-forever\\\", \\\"-usepw\\\", \\\"-create\\\"]\"),mdx(\"h1\",null,\"Multiple images example\"),mdx(\"h1\",null),mdx(\"h1\",null,\"VERSION 0.1\"),mdx(\"p\",null,\"FROM ubuntu\"),mdx(\"p\",null,\"RUN echo foo > bar\"),mdx(\"h1\",null,\"Will output something like ===> 907ad6c2736f\"),mdx(\"p\",null,\"FROM ubuntu\"),mdx(\"p\",null,\"RUN echo moo > oink\"),mdx(\"h1\",null,\"Will output something like ===> 695d7793cbe4\"),mdx(\"h1\",null,\"You\\\\'ll now have two images, 907ad6c2736f with /bar, and 695d7793cbe4 with\"),mdx(\"h1\",null,\"/oink.\"),mdx(\"h3\",null,\"Manage images\"),mdx(\"p\",null,\"The easiest way to make your images available for use by others inside or outside your organization is to use a Docker registry, such as\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/develop/develop-images/image_management/#docker-hub\"}),\"Docker Hub\"),\",\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/develop/develop-images/image_management/#docker-trusted-registry\"}),\"Docker Trusted Registry\"),\", or by running your own\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/develop/develop-images/image_management/#docker-registry\"}),\"private registry\"),\".\"),mdx(\"h4\",null,\"Docker Hub\"),mdx(\"p\",null,mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/docker-hub/\"}),\"Docker Hub\"),\"\\xA0is a public registry managed by Docker, Inc. It centralizes information about organizations, user accounts, and images. It includes a web UI, authentication and authorization using organizations, CLI and API access using commands such as\\xA0docker login,\\xA0docker pull, and\\xA0docker push, comments, stars, search, and more. Docker Hub is also integrated into\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/docker-store/\"}),\"Docker Store\"),\", which is a marketplace that allows you to buy and sell entitlements to non-free images.\"),mdx(\"h4\",null,\"Docker Registry\"),mdx(\"p\",null,\"The Docker Registry is a component of Docker's ecosystem. A registry is a storage and content delivery system, holding named Docker images, available in different tagged versions. For example, the image\\xA0distribution/registry, with tags\\xA02.0\\xA0and\\xA0latest. Users interact with a registry by using docker push and pull commands such as\\xA0docker pull myregistry.com/stevvooe/batman:voice.\"),mdx(\"p\",null,\"Docker Hub is an instance of a Docker Registry.\"),mdx(\"h4\",null,\"Docker Trusted Registry\"),mdx(\"p\",null,mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/datacenter/dtr/2.1/guides/\"}),\"Docker Trusted Registry\"),\"\\xA0is part of Docker Enterprise Edition, and is a private, secure Docker registry which includes features such as image signing and content trust, role-based access controls, and other Enterprise-grade features.\"),mdx(\"h4\",null,\"Content Trust\"),mdx(\"p\",null,\"When transferring data among networked systems,\\xA0trust\\xA0is a central concern. When communicating over an untrusted medium such as the internet, it is critical to ensure the integrity and publisher of all the data a system operates on. You use Docker to push and pull images (data) to a registry. Content trust gives you the ability to both verify the integrity and the publisher of all the data received from a registry over any channel.\"),mdx(\"p\",null,\"See\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/security/trust/\"}),\"Content trust\"),\"\\xA0for information about configuring and using this feature on Docker clients.\"),mdx(\"h3\",null,\"Samples (To Be Done)\"),mdx(\"h4\",null,\"Tutorial labs\"),mdx(\"p\",null,\"Learn how to develop and ship containerized applications, by walking through a sample that exhibits canonical practices. These labs are from the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/docker/labs/tree/master\"}),\"Docker Labs repository\"),\".\"),mdx(\"hr\",null),mdx(\"p\",null,\"  Sample                                                                                                                          Description\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/docker/labs/tree/master/beginner/\"}),\"Docker for Beginners\"),\"                                                    A good \\\"Docker 101\\\" course.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/docker/labs/tree/master/swarm-mode\"}),\"Docker Swarm mode\"),\"                                                      Use Docker for natively managing a cluster of Docker Engines called a swarm.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/docker/labs/tree/master/developer-tools/README.md\"}),\"Configuring developer tools and programming languages\"),\"   How to set-up and use common developer tools and programming languages with Docker.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/docker/labs/tree/master/developer-tools/java-debugging\"}),\"Live Debugging Java with Docker\"),\"                    Java developers can use Docker to build a development environment where they can run, test, and live debug code running within a container.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/docker/labs/tree/master/developer-tools/java/\"}),\"Docker for Java Developers\"),\"                                  Offers Java developers an intro-level and self-paced hands-on workshop with Docker.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/docker/labs/tree/master/developer-tools/nodejs-debugging\"}),\"Live Debugging a Node.js application in Docker\"),\"   Node developers can use Docker to build a development environment where they can run, test, and live debug code running within a container.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/docker/labs/tree/master/developer-tools/nodejs/porting/\"}),\"Dockerizing a Node.js application\"),\"                 This tutorial starts with a simple Node.js application and details the steps needed to Dockerize it and ensure its scalability.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/docker/labs/tree/master/windows/readme.md\"}),\"Docker for ASP.NET and Windows containers\"),\"                       Docker supports Windows containers, too! Learn how to run ASP.NET, SQL Server, and more in these tutorials.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/docker/labs/tree/master/security/README.md\"}),\"Docker Security\"),\"                                                How to take advantage of Docker security features.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/docker/labs/tree/master/12factor\"}),\"Building a 12-factor application with Docker\"),\"                             Use Docker to create an app that conforms to Heroku's \\\"12 factors for cloud-native applications.\\\"\"),mdx(\"hr\",null),mdx(\"h4\",null,\"Library references\"),mdx(\"p\",null,\"These docs are imported from\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/docker-library/docs/\"}),\"the official Docker Library docs\"),\", and help you use some of the most popular software that has been \\\"Dockerized\\\" into Docker images.\"),mdx(\"hr\",null),mdx(\"p\",null,\"  Image name                                                                        Description\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/adminer/\"}),\"adminer\"),\"                       Database management in a single PHP file.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/aerospike/\"}),\"aerospike\"),\"                   Aerospike -- the reliable, high performance, distributed database optimized for flash and RAM.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/alpine/\"}),\"alpine\"),\"                         A minimal Docker image based on Alpine Linux with a complete package index and only 5 MB in size!\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/amazonlinux/\"}),\"amazonlinux\"),\"               Amazon Linux provides a stable, secure, and high-performance execution environment for applications.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/arangodb/\"}),\"arangodb\"),\"                     ArangoDB - a distributed database with a flexible data model for documents, graphs, and key-values.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/backdrop/\"}),\"backdrop\"),\"                     The comprehensive CMS for small to medium sized businesses and non-profits.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/bash/\"}),\"bash\"),\"                             Bash is the GNU Project's Bourne Again SHell\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/bonita/\"}),\"bonita\"),\"                         Bonita is an open-source business process management and workflow suite\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/buildpack-deps/\"}),\"buildpack-deps\"),\"         A collection of common build dependencies used for installing various modules, e.g., gems.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/busybox/\"}),\"busybox\"),\"                       Busybox base image.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/cassandra/\"}),\"cassandra\"),\"                   Apache Cassandra is an open-source distributed storage system.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/centos/\"}),\"centos\"),\"                         The official build of CentOS.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/chronograf/\"}),\"chronograf\"),\"                 Chronograf is a visualization tool for time series data in InfluxDB.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/cirros/\"}),\"cirros\"),\"                         CirrOS is a Tiny OS that specializes in running on a cloud.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/clearlinux/\"}),\"clearlinux\"),\"                 Official docker build of Clear Linux OS for Intel Architecture\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/clefos/\"}),\"clefos\"),\"                         The official build of ClefOS.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/clojure/\"}),\"clojure\"),\"                       Clojure is a dialect of Lisp that runs on the JVM.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/composer/\"}),\"composer\"),\"                     Composer is a dependency manager written in and for PHP.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/consul/\"}),\"consul\"),\"                         Consul is a datacenter runtime that provides service discovery, configuration, and orchestration.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/convertigo/\"}),\"convertigo\"),\"                 Convertigo is an open source MBaaS/MADP platform for mobile application development and back-end.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/couchbase/\"}),\"couchbase\"),\"                   Couchbase Server is a NoSQL document database with a distributed architecture.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/couchdb/\"}),\"couchdb\"),\"                       CouchDB is a database that uses JSON for documents, an HTTP API, & JavaScript/declarative indexing.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/crate/\"}),\"crate\"),\"                           CrateDB is a distributed SQL database handles massive amounts of machine data in real-time.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/crux/\"}),\"crux\"),\"                             CRUX is a lightweight Linux distribution targeted at experienced Linux users\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/debian/\"}),\"debian\"),\"                         Debian is a Linux distribution that's composed entirely of free and open-source software.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/docker/\"}),\"docker\"),\"                         Docker in Docker!\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/drupal/\"}),\"drupal\"),\"                         Drupal is an open source content management platform powering millions of websites and applications.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/eclipse-mosquitto/\"}),\"eclipse-mosquitto\"),\"   Eclipse Mosquitto is an open source message broker which implements MQTT version 3.1 and 3.1.1\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/eggdrop/\"}),\"eggdrop\"),\"                       The official Docker image of Eggdrop- IRC's oldest actively-developed bot!\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/elasticsearch/\"}),\"elasticsearch\"),\"           Elasticsearch is a powerful open source search and analytics engine that makes data easy to explore.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/elixir/\"}),\"elixir\"),\"                         Elixir is a dynamic, functional language for building scalable and maintainable applications.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/erlang/\"}),\"erlang\"),\"                         Erlang is a programming language used to build massively scalable systems with high availability.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/euleros/\"}),\"euleros\"),\"                       The official release of EulerOS.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/fedora/\"}),\"fedora\"),\"                         Official Docker builds of Fedora\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/flink/\"}),\"flink\"),\"                           Apache Flink\\xAE is a powerful open-source distributed stream and batch processing framework.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/fsharp/\"}),\"fsharp\"),\"                         F# is a multi-paradigm language encompassing functional, imperative, and object-oriented styles\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/gazebo/\"}),\"gazebo\"),\"                         Gazebo is an open source project for simulating robots, offering robust physics and rendering.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/gcc/\"}),\"gcc\"),\"                               The GNU Compiler Collection is a compiling system that supports several languages.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/geonetwork/\"}),\"geonetwork\"),\"                 GeoNetwork is a FOSS catalog for spatially referenced resources.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/ghost/\"}),\"ghost\"),\"                           Ghost is a free and open source blogging platform written in JavaScript\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/golang/\"}),\"golang\"),\"                         Go (golang) is a general purpose, higher-level, imperative programming language.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/gradle/\"}),\"gradle\"),\"                         Gradle is a build tool with a focus on build automation and support for multi-language development.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/groovy/\"}),\"groovy\"),\"                         Apache Groovy is a multi-faceted language for the Java platform.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/haproxy/\"}),\"haproxy\"),\"                       HAProxy - The Reliable, High Performance TCP/HTTP Load Balancer\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/haskell/\"}),\"haskell\"),\"                       Haskell is an advanced purely-functional programming language.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/haxe/\"}),\"haxe\"),\"                             Haxe is a modern, high level, static typed programming language with multiple compilation targets.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/hello-seattle/\"}),\"hello-seattle\"),\"           Hello from DockerCon 2016 (Seattle)!\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/hello-world/\"}),\"hello-world\"),\"               Hello World! (an example of minimal Dockerization)\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/hola-mundo/\"}),\"hola-mundo\"),\"                 \\xA1Hola de DockerCon EU 2015 (Barcelona)!\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/httpd/\"}),\"httpd\"),\"                           The Apache HTTP Server Project\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/hylang/\"}),\"hylang\"),\"                         Hy is a Lisp dialect that translates expressions into Python's abstract syntax tree.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/ibmjava/\"}),\"ibmjava\"),\"                       Official IBM\\xAE SDK, Java\\u2122 Technology Edition Docker Image.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/influxdb/\"}),\"influxdb\"),\"                     InfluxDB is an open source time series database for recording metrics, events, and analytics.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/irssi/\"}),\"irssi\"),\"                           irssi - The IRC client of the future\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/jenkins/\"}),\"jenkins\"),\"                       Official Jenkins Docker image\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/jetty/\"}),\"jetty\"),\"                           Jetty provides a Web server and javax.servlet container.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/joomla/\"}),\"joomla\"),\"                         Joomla! is an open source content management system.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/jruby/\"}),\"jruby\"),\"                           JRuby (\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://www.jruby.org\"}),\"http://www.jruby.org\"),\") is an implementation of Ruby (\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://www.ruby-lang.org\"}),\"http://www.ruby-lang.org\"),\") on the JVM.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/julia/\"}),\"julia\"),\"                           Julia is a high-level, high-performance dynamic programming language for technical computing.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/kaazing-gateway/\"}),\"kaazing-gateway\"),\"       Official build of Kaazing Gateway.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/kapacitor/\"}),\"kapacitor\"),\"                   Kapacitor is an open source framework for processing, monitoring, and alerting on time series data.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/kibana/\"}),\"kibana\"),\"                         Kibana gives shape to any kind of data --- structured and unstructured --- indexed in Elasticsearch.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/known/\"}),\"known\"),\"                           Blogging, meet social. Known is a social publishing platform.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/kong/\"}),\"kong\"),\"                             Open-source Microservice & API Management layer built on top of NGINX.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/lightstreamer/\"}),\"lightstreamer\"),\"           Lightstreamer is a real-time messaging server optimized for the Internet.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/logstash/\"}),\"logstash\"),\"                     Logstash is a tool for managing events and logs.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/mageia/\"}),\"mageia\"),\"                         Official Mageia base image\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/mariadb/\"}),\"mariadb\"),\"                       MariaDB is a community-developed fork of MySQL intended to remain free under the GNU GPL.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/maven/\"}),\"maven\"),\"                           Apache Maven is a software project management and comprehension tool.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/mediawiki/\"}),\"mediawiki\"),\"                   MediaWiki is a free software open source wiki package written in PHP.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/memcached/\"}),\"memcached\"),\"                   Free & open source, high-performance, distributed memory object caching system.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/mongo-express/\"}),\"mongo-express\"),\"           Web-based MongoDB admin interface, written with Node.js and express\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/mongo/\"}),\"mongo\"),\"                           MongoDB document databases provide high availability and easy scalability.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/mono/\"}),\"mono\"),\"                             Mono is an open source implementation of Microsoft's .NET Framework\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/mysql/\"}),\"mysql\"),\"                           MySQL is a widely used, open-source relational database management system (RDBMS).\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/nats-streaming/\"}),\"nats-streaming\"),\"         NATS Streaming is an open-source, high-performance, cloud native messaging streaming system.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/nats/\"}),\"nats\"),\"                             NATS is an open-source, high-performance, cloud native messaging system.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/neo4j/\"}),\"neo4j\"),\"                           Neo4j is a highly scalable, robust native graph database.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/neurodebian/\"}),\"neurodebian\"),\"               NeuroDebian provides neuroscience research software for Debian, Ubuntu, and other derivatives.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/nextcloud/\"}),\"nextcloud\"),\"                   A safe home for all your data\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/nginx/\"}),\"nginx\"),\"                           Official build of Nginx.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/node/\"}),\"node\"),\"                             Node.js is a JavaScript-based platform for server-side and networking applications.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/notary/\"}),\"notary\"),\"                         Notary server and signer cooperatively handle signing and distribution of notary repositories.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/nuxeo/\"}),\"nuxeo\"),\"                           Nuxeo is an open source Content Management Platform that is completely customizable.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/odoo/\"}),\"odoo\"),\"                             Odoo (formerly known as OpenERP) is a suite of open-source business apps.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/open-liberty/\"}),\"open-liberty\"),\"             Official Open Liberty image.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/openjdk/\"}),\"openjdk\"),\"                       OpenJDK is an open-source implementation of the Java Platform, Standard Edition\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/opensuse/\"}),\"opensuse\"),\"                     This project contains the stable releases of the openSUSE distribution.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/oraclelinux/\"}),\"oraclelinux\"),\"               Oracle Linux is an open-source operating system suitable for general purpose or Oracle workloads.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/orientdb/\"}),\"orientdb\"),\"                     OrientDB a Multi-Model Open Source NoSQL DBMS that combines graphs and documents.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/owncloud/\"}),\"owncloud\"),\"                     ownCloud is a self-hosted file sync and share server.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/percona/\"}),\"percona\"),\"                       Percona Server is a fork of the MySQL relational database management system created by Percona.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/perl/\"}),\"perl\"),\"                             Perl is a high-level, general-purpose, interpreted, dynamic programming language.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/photon/\"}),\"photon\"),\"                         Photon OS is a technology preview of a minimal Linux container host.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/php-zendserver/\"}),\"php-zendserver\"),\"         Zend Server - the integrated PHP application platform for mobile and web apps.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/php/\"}),\"php\"),\"                               While designed for web development, the PHP scripting language also provides general-purpose use.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/piwik/\"}),\"piwik\"),\"                           Piwik is the leading open-source analytics platform that gives you more than powerful analytics.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/plone/\"}),\"plone\"),\"                           Plone is a free and open source content management system built on top of Zope.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/postgres/\"}),\"postgres\"),\"                     The PostgreSQL object-relational database system provides reliability and data integrity.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/pypy/\"}),\"pypy\"),\"                             PyPy is a fast, compliant alternative implementation of the Python language.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/python/\"}),\"python\"),\"                         Python is an interpreted, interactive, object-oriented, open-source programming language.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/r-base/\"}),\"r-base\"),\"                         R is a system for statistical computation and graphics.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/rabbitmq/\"}),\"rabbitmq\"),\"                     RabbitMQ is an open source multi-protocol messaging broker.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/rakudo-star/\"}),\"rakudo-star\"),\"               Rakudo Perl 6, or simply Rakudo, is a compiler for the Perl 6 programming language.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/rapidoid/\"}),\"rapidoid\"),\"                     Rapidoid is a high-performance HTTP server and modern Java web framework / application container.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/redis/\"}),\"redis\"),\"                           Redis is an open source key-value store that functions as a data structure server.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/redmine/\"}),\"redmine\"),\"                       Redmine is a flexible project management web application written using Ruby on Rails framework\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/registry/\"}),\"registry\"),\"                     The Docker Registry 2.0 implementation for storing and distributing Docker images\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/rethinkdb/\"}),\"rethinkdb\"),\"                   RethinkDB is an open-source, document database that makes it easy to build and scale realtime apps.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/rocket.chat/\"}),\"rocket.chat\"),\"               The Complete Open Source Chat Solution\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/ros/\"}),\"ros\"),\"                               The Robot Operating System (ROS) is an open source project for building robot applications.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/ruby/\"}),\"ruby\"),\"                             Ruby is a dynamic, reflective, object-oriented, general-purpose, open-source programming language.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/rust/\"}),\"rust\"),\"                             Rust is a systems programming language focused on safety, speed, and concurrency.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/scratch/\"}),\"scratch\"),\"                       an explicitly empty image, especially for building images \\\"FROM scratch\\\"\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/sentry/\"}),\"sentry\"),\"                         Sentry is a realtime, platform-agnostic error logging and aggregation platform\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/silverpeas/\"}),\"silverpeas\"),\"                 Silverpeas is a turnkey and open-source Collaborative and Social-Networking Portal.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/sl/\"}),\"sl\"),\"                                 Official containers for Scientific Linux(SL)\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/solr/\"}),\"solr\"),\"                             Solr is the popular, blazing-fast, open source enterprise search platform built on Apache Lucene\\u2122.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/sonarqube/\"}),\"sonarqube\"),\"                   SonarQube is an open source platform for continuous inspection of code quality.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/sourcemage/\"}),\"sourcemage\"),\"                 Source Mage is a source-based GNU/Linux distribution with maximum flexibility in customization.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/spiped/\"}),\"spiped\"),\"                         Spiped is a utility for creating symmetrically encrypted and authenticated pipes between sockets.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/storm/\"}),\"storm\"),\"                           Apache Storm is a free and open source distributed realtime computation system.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/swarm/\"}),\"swarm\"),\"                           Swarm: a Docker-native clustering system.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/swift/\"}),\"swift\"),\"                           Swift is a general-purpose programming language using a modern approach to safety and performance.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/swipl/\"}),\"swipl\"),\"                           SWI-Prolog offers a comprehensive free Prolog environment.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/teamspeak/\"}),\"teamspeak\"),\"                   TeamSpeak is software for quality voice communication via the Internet.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/telegraf/\"}),\"telegraf\"),\"                     Telegraf is an agent for collecting metrics and writing them to InfluxDB or other outputs.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/thrift/\"}),\"thrift\"),\"                         Thrift is a framework for generating client and services from an IDL.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/tomcat/\"}),\"tomcat\"),\"                         Apache Tomcat is an open source implementation of the Java Servlet and JavaServer Pages technologies\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/tomee/\"}),\"tomee\"),\"                           Apache TomEE is an all-Apache Java EE certified stack where Apache Tomcat is top dog.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/traefik/\"}),\"traefik\"),\"                       Tr\\xE6f\\u026Ak, a modern reverse proxy\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/ubuntu/\"}),\"ubuntu\"),\"                         Ubuntu is a Debian-based Linux operating system based on free software.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/vault/\"}),\"vault\"),\"                           Vault is a tool for securely accessing secrets via a unified interface and tight access control.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/websphere-liberty/\"}),\"websphere-liberty\"),\"   Official IBM WebSphere Application Server for Developers Liberty image.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/wordpress/\"}),\"wordpress\"),\"                   The WordPress rich content management system can utilize plugins, widgets, and themes.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/xwiki/\"}),\"xwiki\"),\"                           XWiki: The Advanced Open Source Enterprise Wiki.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/znc/\"}),\"znc\"),\"                               ZNC - An advanced IRC bouncer\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/samples/library/zookeeper/\"}),\"zookeeper\"),\"                   Apache ZooKeeper is an open-source server which enables highly reliable distributed coordination.\"),mdx(\"hr\",null),mdx(\"h4\",null,\"Sample applications\"),mdx(\"p\",null,\"Run popular software using Docker.\"),mdx(\"hr\",null),mdx(\"p\",null,\"  Sample                                                                                       Description\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/examples/apt-cacher-ng\"}),\"apt-cacher-ng\"),\"                       Run a Dockerized apt-cacher-ng instance.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/compose/aspnet-mssql-compose\"}),\"ASP.NET Core + SQL Server on Linux\"),\"   Run a Dockerized ASP.NET Core + SQL Server environment.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/examples/couchdb_data_volumes\"}),\"CouchDB\"),\"                      Run a Dockerized CouchDB instance.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/compose/django/\"}),\"Django + PostgreSQL\"),\"                               Run a Dockerized Django + PostgreSQL environment.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/examples/postgresql_service\"}),\"PostgreSQL\"),\"                     Run a Dockerized PosgreSQL instance.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/compose/rails/\"}),\"Rails + PostgreSQL\"),\"                                 Run a Dockerized Rails + PostgreSQL environment.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/examples/running_riak_service\"}),\"Riak\"),\"                         Run a Dockerized Riak instance.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/examples/running_ssh_service\"}),\"SSHd\"),\"                          Run a Dockerized SSHd instance.\"),mdx(\"hr\",null),mdx(\"h2\",null,\"Develop with Docker Engine SDKs and API\"),mdx(\"p\",null,\"Docker provides an API for interacting with the Docker daemon (called the Docker Engine API), as well as SDKs for Go and Python. The SDKs allow you to build and scale Docker apps and solutions quickly and easily. If Go or Python don't work for you, you can use the Docker Engine API directly.\"),mdx(\"p\",null,\"The Docker Engine API is a RESTful API accessed by an HTTP client such as\\xA0wget\\xA0or\\xA0curl, or the HTTP library which is part of most modern programming languages.\"),mdx(\"h3\",null,\"Install the SDKs\"),mdx(\"p\",null,\"Use the following commands to install the Go or Python SDK. Both SDKs can be installed and coexist together.\"),mdx(\"h4\",null,\"Go SDK\"),mdx(\"p\",null,\"go get github.com/docker/docker/client\"),mdx(\"p\",null,mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://godoc.org/github.com/docker/docker/client\"}),\"Read the full Docker Engine Go SDK reference\"),\".\"),mdx(\"h4\",null,\"Python SDK\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Recommended\"),\": Run\\xA0pip install docker.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"If you can't use\\xA0pip\"),\":\",mdx(\"ol\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ol\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://pypi.python.org/pypi/docker/\"}),\"Download the package directly\"),\".\"),mdx(\"li\",{parentName:\"ol\"},\"Extract it and change to the extracted directory,\"),mdx(\"li\",{parentName:\"ol\"},\"Run\\xA0python setup.py install.\")))),mdx(\"p\",null,mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docker-py.readthedocs.io/\"}),\"Read the full Docker Engine Python SDK reference\"),\".\"),mdx(\"h3\",null,\"View the API reference\"),mdx(\"p\",null,\"You can\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/latest/\"}),\"view the reference for the latest version of the API\"),\"\\xA0or\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/version-history/\"}),\"choose a specific version\"),\".\"),mdx(\"h3\",null,\"Versioned API and SDK\"),mdx(\"p\",null,\"The version of the Docker Engine API you should use depends upon the version of your Docker daemon and Docker client.\"),mdx(\"p\",null,\"A given version of the Docker Engine SDK supports a specific version of the Docker Engine API, as well as all earlier versions. If breaking changes occur, they are documented prominently.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Daemon and client API mismatches\")),mdx(\"p\",null,\"The Docker daemon and client do not necessarily need to be the same version at all times. However, keep the following in mind.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"If the daemon is newer than the client, the client does not know about new features or deprecated API endpoints in the daemon.\"),mdx(\"li\",{parentName:\"ul\"},\"If the client is newer than the daemon, the client can request API endpoints that the daemon does not know about.\")),mdx(\"p\",null,\"A new version of the API is released when new features are added. The Docker API is backward-compatible, so you do not need to update code that uses the API unless you need to take advantage of new features.\"),mdx(\"p\",null,\"To see the highest version of the API your Docker daemon and client support, use\\xA0docker version:\"),mdx(\"p\",null,\"$ docker version\"),mdx(\"p\",null,\"Client:\"),mdx(\"p\",null,\"Version: 17.04.0-ce\"),mdx(\"p\",null,\"API version: 1.28\"),mdx(\"p\",null,\"Go version: go1.7.5\"),mdx(\"p\",null,\"Git commit: 4845c56\"),mdx(\"p\",null,\"Built: Wed Apr 5 06:06:36 2017\"),mdx(\"p\",null,\"OS/Arch: darwin/amd64\"),mdx(\"p\",null,\"Server:\"),mdx(\"p\",null,\"Version: 17.04.0-ce\"),mdx(\"p\",null,\"API version: 1.28 (minimum version 1.12)\"),mdx(\"p\",null,\"Go version: go1.7.5\"),mdx(\"p\",null,\"Git commit: 4845c56\"),mdx(\"p\",null,\"Built: Tue Apr 4 00:37:25 2017\"),mdx(\"p\",null,\"OS/Arch: linux/amd64\"),mdx(\"p\",null,\"Experimental: true\"),mdx(\"p\",null,\"You can specify the API version to use, in one of the following ways:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"When using the SDK, use the latest version you can, but at least the version that incorporates the API version with the features you need.\"),mdx(\"li\",{parentName:\"ul\"},\"When using\\xA0curl\\xA0directly, specify the version as the first part of the URL. For instance, if the endpoint is\\xA0/containers/, you can use\\xA0/v1.27/containers/.\"),mdx(\"li\",{parentName:\"ul\"},\"To force the Docker CLI or the Docker Engine SDKs to use an old version version of the API than the version reported by\\xA0docker version, set the environment variable\\xA0DOCKER_API_VERSION\\xA0to the correct version. This works on Linux, Windows, or macOS clients.\"),mdx(\"li\",{parentName:\"ul\"},\"DOCKER_API_VERSION=\\\\'1.27\\\\'\")),mdx(\"p\",null,\"While the environment variable is set, that version of the API is used, even if the Docker daemon supports a newer version.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"For the SDKs, you can also specify the API version programmatically, as a parameter to the\\xA0client\\xA0object. See the\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://github.com/moby/moby/blob/master/client/client.go#L136\"}),\"Go constructor\"),\"\\xA0or the\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docker-py.readthedocs.io/en/stable/client.html\"}),\"Python SDK documentation for\\xA0client\"),\".\")),mdx(\"h4\",null,\"Docker EE and CE API mismatch\"),mdx(\"p\",null,\"If you use Docker EE in production, we recommend using Docker EE in development too. If you can't, such as when your developers use Docker for Mac or Docker for Windows and manually build and push images, then your developers need to configure their Docker clients to use the same version of the API reported by their Docker daemon. This prevents the developer from using a feature that is not yet supported on the daemon where the workload runs in production. You can do this one of two ways:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Configure the Docker client to connect to an external daemon running Docker EE. You can use the\\xA0-H\\xA0flag on the\\xA0docker\\xA0command or set the\\xA0DOCKER_HOST\\xA0environment variable. The client uses the daemon's latest supported API version.\"),mdx(\"li\",{parentName:\"ul\"},\"Configure the Docker client to use a specific API by setting the\\xA0DOCKER_API_VERSION\\xA0environment variable to the API version to use, such as\\xA01.30.\")),mdx(\"h4\",null,\"API version matrix\"),mdx(\"p\",null,\"Docker does not recommend running versions prior to 1.12, which means you are encouraged to use an API version of 1.24 or higher.\"),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Docker version\"),\"   \",mdx(\"strong\",{parentName:\"p\"},\"Maximum API version\"),\"                             \",mdx(\"strong\",{parentName:\"p\"},\"Change log\")),mdx(\"hr\",null),mdx(\"p\",null,\"  18.02                \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/v1.36/\"}),\"1.36\"),\"   \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/version-history/#v136-api-changes\"}),\"changes\"),\"\\n17.12                \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/v1.35/\"}),\"1.35\"),\"   \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/version-history/#v135-api-changes\"}),\"changes\"),\"\\n17.11                \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/v1.34/\"}),\"1.34\"),\"   \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/version-history/#v134-api-changes\"}),\"changes\"),\"\\n17.10                \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/v1.33/\"}),\"1.33\"),\"   \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/version-history/#v133-api-changes\"}),\"changes\"),\"\\n17.09                \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/v1.32/\"}),\"1.32\"),\"   \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/version-history/#v132-api-changes\"}),\"changes\"),\"\\n17.07                \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/v1.31/\"}),\"1.31\"),\"   \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/version-history/#v131-api-changes\"}),\"changes\"),\"\\n17.06                \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/v1.30/\"}),\"1.30\"),\"   \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/version-history/#v130-api-changes\"}),\"changes\"),\"\\n17.05                \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/v1.29/\"}),\"1.29\"),\"   \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/version-history/#v129-api-changes\"}),\"changes\"),\"\\n17.04                \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/v1.28/\"}),\"1.28\"),\"   \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/version-history/#v128-api-changes\"}),\"changes\"),\"\\n17.03.1              \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/v1.27/\"}),\"1.27\"),\"   \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/version-history/#v127-api-changes\"}),\"changes\"),\"\\n17.03                \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/v1.27/\"}),\"1.26\"),\"   \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/version-history/#v126-api-changes\"}),\"changes\"),\"\\n1.13.1               \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/v1.26/\"}),\"1.26\"),\"   \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/version-history/#v126-api-changes\"}),\"changes\"),\"\\n1.13                 \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/v1.26/\"}),\"1.25\"),\"   \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/version-history/#v125-api-changes\"}),\"changes\"),\"\\n1.12                 \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/v1.24/\"}),\"1.24\"),\"   \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/version-history/#v124-api-changes\"}),\"changes\"),\"\\n1.11                 \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/v1.23/\"}),\"1.23\"),\"   \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/version-history/#v123-api-changes\"}),\"changes\"),\"\\n1.10                 \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/v1.22/\"}),\"1.22\"),\"   \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/version-history/#v122-api-changes\"}),\"changes\"),\"\\n1.9                  \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/v1.21/\"}),\"1.21\"),\"   \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/version-history/#v121-api-changes\"}),\"changes\"),\"\\n1.8                  \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/v1.20/\"}),\"1.20\"),\"   \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/version-history/#v120-api-changes\"}),\"changes\"),\"\\n1.7                  \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/v1.19/\"}),\"1.19\"),\"   \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/version-history/#v119-api-changes\"}),\"changes\"),\"\\n1.6                  \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/v1.18/\"}),\"1.18\"),\"   \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/version-history/#v118-api-changes\"}),\"changes\")),mdx(\"h4\",null,\"Choose the SDK or API version to use\"),mdx(\"p\",null,\"Use the following guidelines to choose the SDK or API version to use in your code:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"If you're starting a new project, use the\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/api/latest/\"}),\"latest version\"),\", but do specify the version you are using. This helps prevent surprises.\"),mdx(\"li\",{parentName:\"ul\"},\"If you need a new feature, update your code to use at least the minimum version that supports the feature, and prefer the latest version you can use.\"),mdx(\"li\",{parentName:\"ul\"},\"Otherwise, continue to use the version that your code is already using.\")),mdx(\"h3\",null,\"SDK and API quickstart\"),mdx(\"p\",null,\"As an example, the\\xA0docker run\\xA0command can be easily implemented using the Docker API directly, or using the Python or Go SDK.\"),mdx(\"pre\",null,mdx(\"code\",_extends({parentName:\"pre\"},{\"className\":\"language-python\"}),\"import docker\\n\\nclient = docker.from_env()\\n\\nprint client.containers.run(\\\"alpine\\\", [\\\"echo\\\", \\\"hello\\\", \\\"world\\\"])\\n\\npackage main\\n\\nimport (\\n\\n\\\"io\\\"\\n\\n\\\"os\\\"\\n\\n\\\"github.com/docker/docker/client\\\"\\n\\n\\\"github.com/docker/docker/api/types\\\"\\n\\n\\\"github.com/docker/docker/api/types/container\\\"\\n\\n\\\"golang.org/x/net/context\\\"\\n\\n)\\n\\nfunc main() {\\n\\nctx := context.Background()\\n\\ncli, err := client.NewEnvClient()\\n\\nif err != nil {\\n\\npanic(err)\\n\\n}\\n\\n_, err = cli.ImagePull(ctx, \\\"docker.io/library/alpine\\\", types.ImagePullOptions{})\\n\\nif err != nil {\\n\\npanic(err)\\n\\n}\\n\\nresp, err := cli.ContainerCreate(ctx, &container.Config{\\n\\nImage: \\\"alpine\\\",\\n\\nCmd: []string{\\\"echo\\\", \\\"hello world\\\"},\\n\\n}, nil, nil, \\\"\\\")\\n\\nif err != nil {\\n\\npanic(err)\\n\\n}\\n\\nif err := cli.ContainerStart(ctx, resp.ID, types.ContainerStartOptions{}); err != nil {\\n\\npanic(err)\\n\\n}\\n\\nstatusCh, errCh := cli.ContainerWait(ctx, resp.ID, container.WaitConditionNotRunning)\\n\\nselect {\\n\\ncase err := <-errCh:\\n\\nif err != nil {\\n\\npanic(err)\\n\\n}\\n\\ncase <-statusCh:\\n\\n}\\n\\nout, err := cli.ContainerLogs(ctx, resp.ID, types.ContainerLogsOptions{ShowStdout: true})\\n\\nif err != nil {\\n\\npanic(err)\\n\\n}\\n\\nio.Copy(os.Stdout, out)\\n\\n}\\n\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"HTTP\")),mdx(\"pre\",null,mdx(\"code\",_extends({parentName:\"pre\"},{\"className\":\"language-bash\"}),\"$ curl --unix-socket /var/run/docker.sock -H \\\"Content-Type: application/json\\\" \\\\ -d \\\\'{\\\"Image\\\": \\\"alpine\\\", \\\"Cmd\\\": [\\\"echo\\\", \\\"hello world\\\"]}\\\\' \\\\\\n-X POST http:/v1.24/containers/create {\\\"Id\\\":\\\"1c6594faf5\\\",\\\"Warnings\\\":null}\\n\\n$ curl --unix-socket /var/run/docker.sock -X POST http:/v1.24/containers/1c6594faf5/start\\n\\n$ curl --unix-socket /var/run/docker.sock -X POST http:/v1.24/containers/1c6594faf5/wait\\n\\n{\\\"StatusCode\\\":0}\\n\\n$ curl --unix-socket /var/run/docker.sock \\\"http:/v1.24/containers/1c6594faf5/logs?stdout=1\\\"\\n\\nhello world\\n\")),mdx(\"h3\",null,\"Unofficial libraries\"),mdx(\"p\",null,\"There are a number of community supported libraries available for other languages. They have not been tested by Docker, so if you run into any issues, file them with the library maintainers.\"),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Language\"),\"            \",mdx(\"strong\",{parentName:\"p\"},\"Library\")),mdx(\"hr\",null),mdx(\"p\",null,\"  C                       \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/danielsuo/libdocker\"}),\"libdocker\"),\"\\nC#                     \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/ahmetalpbalkan/Docker.DotNet\"}),\"Docker.DotNet\"),\"\\nC++                     \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/lasote/docker_client\"}),\"lasote/docker_client\"),\"\\nDart                    \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/bwu-dart/bwu_docker\"}),\"bwu_docker\"),\"\\nErlang                  \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/proger/erldocker\"}),\"erldocker\"),\"\\nGradle                  \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/gesellix/gradle-docker-plugin\"}),\"gradle-docker-plugin\"),\"\\nGroovy                  \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/gesellix/docker-client\"}),\"docker-client\"),\"\\nHaskell                 \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/denibertovic/docker-hs\"}),\"docker-hs\"),\"\\nHTML (Web Components)   \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/kapalhq/docker-elements\"}),\"docker-elements\"),\"\\nJava                    \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/spotify/docker-client\"}),\"docker-client\"),\"\\nJava                    \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/docker-java/docker-java\"}),\"docker-java\"),\"\\nNodeJS                  \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/apocas/dockerode\"}),\"dockerode\"),\"\\nNodeJS                  \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/arhea/harbor-master\"}),\"harbor-master\"),\"\\nPerl                    \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/alambike/eixo-docker\"}),\"Eixo::Docker\"),\"\\nPHP                     \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/docker-php/docker-php\"}),\"Docker-PHP\"),\"\\nRuby                    \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/swipely/docker-api\"}),\"docker-api\"),\"\\nRust                    \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/abh1nav/docker-rust\"}),\"docker-rust\"),\"\\nRust                    \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/softprops/shiplift\"}),\"shiplift\"),\"\\nScala                   \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/softprops/tugboat\"}),\"tugboat\"),\"\\nScala                   \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/almoehi/reactive-docker\"}),\"reactive-docker\"),\"\\nSwift                   \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/valeriomazzeo/docker-client-swift\"}),\"docker-client-swift\")),mdx(\"h2\",null,mdx(\"a\",_extends({parentName:\"h2\"},{\"href\":\"https://docs.docker.com/develop/sdk/examples/\"})),\"Examples using the Docker Engine SDKs and Docker API\"),mdx(\"h1\",null,\"Configuring Networks\"),mdx(\"h2\",null,\"Network Overview\"),mdx(\"p\",null,\"One of the reasons Docker containers and services are so powerful is that you can connect them together, or connect them to non-Docker workloads. Docker containers and services do not even need to be aware that they are deployed on Docker, or whether their peers are also Docker workloads or not. Whether your Docker hosts run Linux, Windows, or a mix of the two, you can use Docker to manage them in a platform-agnostic way.\"),mdx(\"p\",null,\"This topic defines some basic Docker networking concepts and prepares you to design and deploy your applications to take full advantage of these capabilities.\"),mdx(\"p\",null,\"Most of this content applies to all Docker installations. However,\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/network/#docker-ee-networking-features\"}),\"a few advanced features\"),\"\\xA0are only available to Docker EE customers.\"),mdx(\"h3\",null,\"Scope of this topic\"),mdx(\"p\",null,\"This topic does\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"not\"),\"\\xA0go into OS-specific details about how Docker networks work, so you will not find information about how Docker manipulates\\xA0iptables\\xA0rules on Linux or how it manipulates routing rules on Windows servers, and you will not find detailed information about how Docker forms and encapsulates packets or handles encryption. See\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/network/iptables/\"}),\"Docker and iptables\"),\"\\xA0and\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://success.docker.com/Architecture/Docker_Reference_Architecture%3A_Designing_Scalable%2C_Portable_Docker_Container_Networks\"}),\"Docker Reference Architecture: Designing Scalable, Portable Docker Container Networks\"),\"\\xA0for a much greater depth of technical detail.\"),mdx(\"p\",null,\"In addition, this topic does not provide any tutorials for how to create, manage, and use Docker networks. Each section includes links to relevant tutorials and command references.\"),mdx(\"h3\",null,\"Network drivers\"),mdx(\"p\",null,\"Docker's networking subsystem is pluggable, using drivers. Several drivers exist by default, and provide core networking functionality:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"bridge: The default network driver. If you don't specify a driver, this is the type of network you are creating.\\xA0\",mdx(\"strong\",{parentName:\"li\"},\"Bridge networks are usually used when your applications run in standalone containers that need to communicate.\"),\"\\xA0See\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/bridge/\"}),\"bridge networks\"),\".\"),mdx(\"li\",{parentName:\"ul\"},\"host: For standalone containers, remove network isolation between the container and the Docker host, and use the host's networking directly.\\xA0host\\xA0is only available for swarm services on Docker 17.06 and higher. See\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/host/\"}),\"use the host network\"),\".\"),mdx(\"li\",{parentName:\"ul\"},\"overlay: Overlay networks connect multiple Docker daemons together and enable swarm services to communicate with each other. You can also use overlay networks to facilitate communication between a swarm service and a standalone container, or between two standalone containers on different Docker daemons. This strategy removes the need to do OS-level routing between these containers. See\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/overlay/\"}),\"overlay networks\"),\".\"),mdx(\"li\",{parentName:\"ul\"},\"macvlan: Macvlan networks allow you to assign a MAC address to a container, making it appear as a physical device on your network. The Docker daemon routes traffic to containers by their MAC addresses. Using the\\xA0macvlan\\xA0driver is sometimes the best choice when dealing with legacy applications that expect to be directly connected to the physical network, rather than routed through the Docker host's network stack. See\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/macvlan/\"}),\"Macvlan networks\"),\".\"),mdx(\"li\",{parentName:\"ul\"},\"none: For this container, disable all networking. Usually used in conjunction with a custom network driver.\\xA0none\\xA0is not available for swarm services. See\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/none/\"}),\"disable container networking\"),\".\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/extend/plugins_services/\"}),\"Network plugins\"),\": You can install and use third-party network plugins with Docker. These plugins are available from\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://store.docker.com/search?category=network&q=&type=plugin\"}),\"Docker Store\"),\"\\xA0or from third-party vendors. See the vendor's documentation for installing and using a given network plugin.\")),mdx(\"h4\",null,\"Network driver summary\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"User-defined bridge networks\"),\"\\xA0are best when you need multiple containers to communicate on the same Docker host.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Host networks\"),\"\\xA0are best when the network stack should not be isolated from the Docker host, but you want other aspects of the container to be isolated.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Overlay networks\"),\"\\xA0are best when you need containers running on different Docker hosts to communicate, or when multiple applications work together using swarm services.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Macvlan networks\"),\"\\xA0are best when you are migrating from a VM setup or need your containers to look like physical hosts on your network, each with a unique MAC address.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Third-party network plugins\"),\"\\xA0allow you to integrate Docker with specialized network stacks.\")),mdx(\"h3\",null,\"Docker EE networking features\"),mdx(\"p\",null,\"The following two features are only possible when using Docker EE and managing your Docker services using Universal Control Plane (UCP):\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"The\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/datacenter/ucp/2.2/guides/admin/configure/use-domain-names-to-access-services/\"}),\"HTTP routing mesh\"),\"\\xA0allows you to share the same network IP address and port among multiple services. UCP routes the traffic to the appropriate service using the combination of hostname and port, as requested from the client.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/datacenter/ucp/2.2/guides/user/services/use-domain-names-to-access-services/#sticky-sessions\"}),\"Session stickiness\"),\"\\xA0allows you to specify information in the HTTP header which UCP uses to route subsequent requests to the same service task, for applications which require stateful sessions.\")),mdx(\"h3\",null,\"Networking tutorials\"),mdx(\"p\",null,\"Now that you understand the basics about Docker networks, deepen your understanding using the following tutorials:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/network-tutorial-standalone/\"}),\"Standalone networking tutorial\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/network-tutorial-host/\"}),\"Host networking tutorial\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/network-tutorial-overlay/\"}),\"Overlay networking tutorial\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/network-tutorial-macvlan/\"}),\"Macvlan networking tutorial\"))),mdx(\"h2\",null,\"Use bridge networks\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA09 minutes\")),mdx(\"p\",null,\"In terms of networking, a bridge network is a Link Layer device which forwards traffic between network segments. A bridge can be a hardware device or a software device running within a host machine's kernel.\"),mdx(\"p\",null,\"In terms of Docker, a bridge network uses a software bridge which allows containers connected to the same bridge network to communicate, while providing isolation from containers which are not connected to that bridge network. The Docker bridge driver automatically installs rules in the host machine so that containers on different bridge networks cannot communicate directly with each other.\"),mdx(\"p\",null,\"Bridge networks apply to containers running on the\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"same\"),\"\\xA0Docker daemon host. For communication among containers running on different Docker daemon hosts, you can either manage routing at the OS level, or you can use an\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/network/overlay/\"}),\"overlay network\"),\".\"),mdx(\"p\",null,\"When you start Docker, a\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/network/bridge/#use-the-default-bridge-network\"}),\"default bridge network\"),\"\\xA0(also called\\xA0bridge) is created automatically, and newly-started containers connect to it unless otherwise specified. You can also create user-defined custom bridge networks.\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"User-defined bridge networks are superior to the default\\xA0bridge\\xA0network.\")),mdx(\"h3\",null,\"Differences between user-defined bridges and the default bridge\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"User-defined bridges provide better isolation and interoperability between containerized applications\"),\".\")),mdx(\"p\",null,\"Containers connected to the same user-defined bridge network automatically expose\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"all ports\"),\"\\xA0to each other, and\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"no ports\"),\"\\xA0to the outside world. This allows containerized applications to communicate with each other easily, without accidentally opening access to the outside world.\"),mdx(\"p\",null,\"Imagine an application with a web front-end and a database back-end. The outside world needs access to the web front-end (perhaps on port 80), but only the front-end itself needs access to the database host and port. Using a user-defined bridge, only the web port needs to be opened, and the database application doesn't need any ports open, since the web front-end can reach it over the user-defined bridge.\"),mdx(\"p\",null,\"If you run the same application stack on the default bridge network, you need to open both the web port and the database port, using the\\xA0-p\\xA0or\\xA0--publish\\xA0flag for each. This means the Docker host needs to block access to the database port by other means.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"User-defined bridges provide automatic DNS resolution between containers\"),\".\")),mdx(\"p\",null,\"Containers on the default bridge network can only access each other by IP addresses, unless you use the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/network/links/\"}),\"--link\\xA0option\"),\", which is considered legacy. On a user-defined bridge network, containers can resolve each other by name or alias.\"),mdx(\"p\",null,\"Imagine the same application as in the previous point, with a web front-end and a database back-end. If you call your containers\\xA0web\\xA0and\\xA0db, the web container can connect to the db container at\\xA0db, no matter which Docker host the application stack is running on.\"),mdx(\"p\",null,\"If you run the same application stack on the default bridge network, you need to manually create links between the containers (using the legacy\\xA0--link\\xA0flag). These links need to be created in both directions, so you can see this gets complex with more than two containers which need to communicate. Alternatively, you can manipulate the\\xA0/etc/hosts\\xA0files within the containers, but this creates problems that are difficult to debug.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Containers can be attached and detached from user-defined networks on the fly\"),\".\")),mdx(\"p\",null,\"During a container's lifetime, you can connect or disconnect it from user-defined networks on the fly. To remove a container from the default bridge network, you need to stop the container and recreate it with different network options.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Each user-defined network creates a configurable bridge\"),\".\")),mdx(\"p\",null,\"If your containers use the default bridge network, you can configure it, but all the containers use the same settings, such as MTU and\\xA0iptables\\xA0rules. In addition, configuring the default bridge network happens outside of Docker itself, and requires a restart of Docker.\"),mdx(\"p\",null,\"User-defined bridge networks are created and configured using\\xA0docker network create. If different groups of applications have different network requirements, you can configure each user-defined bridge separately, as you create it.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Linked containers on the default bridge network share environment variables\"),\".\")),mdx(\"p\",null,\"Originally, the only way to share environment variables between two containers was to link them using the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/network/links/\"}),\"--link\\xA0flag\"),\". This type of variable sharing is not possible with user-defined networks. However, there are superior ways to share environment variables. A few ideas:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},\"Multiple containers can mount a file or directory containing the shared information, using a Docker volume.\"),mdx(\"li\",{parentName:\"ul\"},\"Multiple containers can be started together using\\xA0docker-compose\\xA0and the compose file can define the shared variables.\"),mdx(\"li\",{parentName:\"ul\"},\"You can use swarm services instead of standalone containers, and take advantage of shared\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/secrets/\"}),\"secrets\"),\"\\xA0and\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/configs/\"}),\"configs\"),\".\")))),mdx(\"p\",null,\"Containers connected to the same user-defined bridge network effectively expose all ports to each other. For a port to be accessible to containers or non-Docker hosts on different networks, that port must be\\xA0published\\xA0using the\\xA0-p\\xA0or\\xA0--publish\\xA0flag.\"),mdx(\"h3\",null,\"Manage a user-defined bridge\"),mdx(\"p\",null,\"Use the\\xA0docker network create\\xA0command to create a user-defined bridge network.\"),mdx(\"p\",null,\"$ docker network create my-net\"),mdx(\"p\",null,\"You can specify the subnet, the IP address range, the gateway, and other options. See the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/network_create/#specify-advanced-options\"}),\"docker network create\"),\"\\xA0reference or the output of\\xA0docker network create --help\\xA0for details.\"),mdx(\"p\",null,\"Use the\\xA0docker network rm\\xA0command to remove a user-defined bridge network. If containers are currently connected to the network,\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/network/bridge/#disconnect-a-container-from-a-user-defined-bridge\"}),\"disconnect them\"),\"\\xA0first.\"),mdx(\"p\",null,\"$ docker network rm my-net\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"What's really happening?\")),mdx(\"p\",null,\"When you create or remove a user-defined bridge or connect or disconnect a container from a user-defined bridge, Docker uses tools specific to the operating system to manage the underlying network infrastructure (such as adding or removing bridge devices or configuring\\xA0iptables\\xA0rules on Linux). These details should be considered implementation details. Let Docker manage your user-defined networks for you.\"),mdx(\"h3\",null,\"Connect a container to a user-defined bridge\"),mdx(\"p\",null,\"When you create a new container, you can specify one or more\\xA0--network\\xA0flags. This example connects a Nginx container to the\\xA0my-net\\xA0network. It also publishes port 80 in the container to port 8080 on the Docker host, so external clients can access that port. Any other container connected to the\\xA0my-net\\xA0network has access to all ports on the\\xA0my-nginx\\xA0container, and vice versa.\"),mdx(\"p\",null,\"$ docker create --name my-nginx \\\\\"),mdx(\"p\",null,\"--network my-net \\\\\"),mdx(\"p\",null,\"--publish 8080:80 \\\\\"),mdx(\"p\",null,\"nginx:latest\"),mdx(\"p\",null,\"To connect a\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"running\"),\"\\xA0container to an existing user-defined bridge, use the\\xA0docker network connectcommand. The following command connects an already-running\\xA0my-nginx\\xA0container to an already-existing\\xA0my-net\\xA0network:\"),mdx(\"p\",null,\"$ docker network connect my-net my-nginx\"),mdx(\"h3\",null,\"Disconnect a container from a user-defined bridge\"),mdx(\"p\",null,\"To disconnect a running container from a user-defined bridge, use the\\xA0docker network disconnectcommand. The following command disconnects the\\xA0my-nginx\\xA0container from the\\xA0my-net\\xA0network.\"),mdx(\"p\",null,\"$ docker network disconnect my-net my-nginx\"),mdx(\"h3\",null,\"Use IPv6\"),mdx(\"p\",null,\"If you need IPv6 support for Docker containers, you need to\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/daemon/ipv6/\"}),\"enable the option\"),\"\\xA0on the Docker daemon and reload its configuration, before creating any IPv6 networks or assigning containers IPv6 addresses.\"),mdx(\"p\",null,\"When you create your network, you can specify the\\xA0--ipv6\\xA0flag to enable IPv6. You can't selectively disable IPv6 support on the default\\xA0bridge\\xA0network.\"),mdx(\"h3\",null,\"Enable forwarding from Docker containers to the outside world\"),mdx(\"p\",null,\"By default, traffic from containers connected to the default bridge network is\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"not\"),\"\\xA0forwarded to the outside world. To enable forwarding, you need to change two settings. These are not Docker commands and they affect the Docker host's kernel.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Configure the Linux kernel to allow IP forwarding.\"),mdx(\"li\",{parentName:\"ol\"},\"$ sysctl net.ipv4.conf.all.forwarding=1\"),mdx(\"li\",{parentName:\"ol\"},\"Change the policy for the\\xA0iptables\\xA0FORWARD\\xA0policy from\\xA0DROP\\xA0to\\xA0ACCEPT.\"),mdx(\"li\",{parentName:\"ol\"},\"$ sudo iptables -P FORWARD ACCEPT\")),mdx(\"p\",null,\"These settings do not persist across a reboot, so you may need to add them to a start-up script.\"),mdx(\"h3\",null,\"Use the default bridge network\"),mdx(\"p\",null,\"The default\\xA0bridge\\xA0network is considered a legacy detail of Docker and is not recommended for production use. Configuring it is a manual operation, and it has\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/network/bridge/#differences-between-user-defined-bridges-and-the-default-bridge\"}),\"technical shortcomings\"),\".\"),mdx(\"h4\",null,\"Connect a container to the default bridge network\"),mdx(\"p\",null,\"If you do not specify a network using the\\xA0--network\\xA0flag, and you do specify a network driver, your container is connected to the default\\xA0bridge\\xA0network by default. Containers connected to the default\\xA0bridge\\xA0network can communicate, but only by IP address, unless they are linked using the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/network/links/\"}),\"legacy\\xA0--link\\xA0flag\"),\".\"),mdx(\"h4\",null,\"Configure the default bridge network\"),mdx(\"p\",null,\"To configure the default\\xA0bridge\\xA0network, you specify options in\\xA0daemon.json. Here is an example\\xA0daemon.json\\xA0with several options specified. Only specify the settings you need to customize.\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"bip\\\": \\\"192.168.1.5/24\\\",\"),mdx(\"p\",null,\"\\\"fixed-cidr\\\": \\\"192.168.1.5/25\\\",\"),mdx(\"p\",null,\"\\\"fixed-cidr-v6\\\": \\\"2001:db8::/64\\\",\"),mdx(\"p\",null,\"\\\"mtu\\\": 1500,\"),mdx(\"p\",null,\"\\\"default-gateway\\\": \\\"10.20.1.1\\\",\"),mdx(\"p\",null,\"\\\"default-gateway-v6\\\": \\\"2001:db8:abcd::89\\\",\"),mdx(\"p\",null,\"\\\"dns\\\": \",\"[\\\"10.20.1.2\\\",\\\"10.20.1.3\\\"]\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"Restart Docker for the changes to take effect.\"),mdx(\"h4\",null,\"Use IPv6 with the default bridge network\"),mdx(\"p\",null,\"If you configure Docker for IPv6 support (see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/network/bridge/#use-ipv6\"}),\"Use IPv6\"),\"), the default bridge network is also configured for IPv6 automatically. Unlike user-defined bridges, you can't selectively disable IPv6 on the default bridge.\"),mdx(\"h3\",null,\"Next steps\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Go through the\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/network-tutorial-standalone/\"}),\"standalone networking tutorial\")),mdx(\"li\",{parentName:\"ul\"},\"Learn about\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/config/container/container-networking/\"}),\"networking from the container's point of view\")),mdx(\"li\",{parentName:\"ul\"},\"Learn about\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/overlay/\"}),\"overlay networks\")),mdx(\"li\",{parentName:\"ul\"},\"Learn about\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/macvlan/\"}),\"Macvlan networks\"))),mdx(\"h2\",null,\"Use overlay networks\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA010 minutes\")),mdx(\"p\",null,\"The\\xA0overlay\\xA0network driver creates a distributed network among multiple Docker daemon hosts. This network sits on top of (overlays) the host-specific networks allows containers connected to it (including swarm service containers) to communicate securely. Docker transparently handles routing of each packet to and from the correct Docker daemon host and the correct destination container.\"),mdx(\"p\",null,\"When you initialize a swarm or join a Docker host to an existing swarm, two new networks are created on that Docker host:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"an overlay network called\\xA0ingress, which handles control and data traffic related to swarm services. When you create a swarm service and do not connect it to a user-defined overlay network, it connects to the\\xA0ingress\\xA0network by default.\"),mdx(\"li\",{parentName:\"ul\"},\"a bridge network called\\xA0docker_gwbridge, which connects the individual Docker daemon to the other daemons participating in the swarm.\")),mdx(\"p\",null,\"You can create user-defined\\xA0overlay\\xA0networks using\\xA0docker network create, in the same way that you can create user-defined\\xA0bridge\\xA0networks. Services or containers can be connected to more than one network at a time. Services or containers can only communicate across networks they are each connected to.\"),mdx(\"p\",null,\"Although you can connect both swarm services and standalone containers to an overlay network, the default behaviors and configuration concerns are different. For that reason, the rest of this topic is divided into operations that apply to all overlay networks, those that apply to swarm service networks, and those that apply to overlay networks used by standalone containers.\"),mdx(\"h3\",null,\"Operations for all overlay networks\"),mdx(\"h4\",null,\"Create an overlay network\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Prerequisites:\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Firewall rules for Docker daemons using overlay networks\")),mdx(\"p\",null,\"You need the following ports open to traffic to and from each Docker host participating on an overlay network:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},\"TCP port 2377 for cluster management communications\"),mdx(\"li\",{parentName:\"ul\"},\"TCP and UDP port 7946 for communication among nodes\"),mdx(\"li\",{parentName:\"ul\"},\"UDP port 4789 for overlay network traffic\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},\"Before you can create an overlay network, you need to either initialize your Docker daemon as a swarm manager using\\xA0docker swarm init\\xA0or join it to an existing swarm using\\xA0docker swarm join. Either of these creates the default\\xA0ingress\\xA0overlay network which is used by swarm services by default. You need to do this even if you never plan to use swarm services. Afterward, you can create additional user-defined overlay networks.\"))),mdx(\"p\",null,\"To create an overlay network for use with swarm services, use a command like the following:\"),mdx(\"p\",null,\"$ docker network create -d overlay my-overlay\"),mdx(\"p\",null,\"To create an overlay network which can be used by swarm services\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"or\"),\"\\xA0standalone containers to communicate with other standalone containers running on other Docker daemons, add the\\xA0--attachable\\xA0flag:\"),mdx(\"p\",null,\"$ docker network create -d overlay --attachable my-attachable-overlay\"),mdx(\"p\",null,\"You can specify the IP address range, subnet, gateway, and other options. Seedocker network create --help\\xA0for details.\"),mdx(\"h4\",null,\"Encrypt traffic on an overlay network\"),mdx(\"p\",null,\"All swarm service management traffic is encrypted by default, using the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://en.wikipedia.org/wiki/Galois/Counter_Mode\"}),\"AES algorithm\"),\"\\xA0in GCM mode. Manager nodes in the swarm rotate the key used to encrypt gossip data every 12 hours.\"),mdx(\"p\",null,\"To encrypt application data as well, add\\xA0--opt encrypted\\xA0when creating the overlay network. This enables IPSEC encryption at the level of the vxlan. This encryption imposes a non-negligible performance penalty, so you should test this option before using it in production.\"),mdx(\"p\",null,\"When you enable overlay encryption, Docker creates IPSEC tunnels between all the nodes where tasks are scheduled for services attached to the overlay network. These tunnels also use the AES algorithm in GCM mode and manager nodes automatically rotate the keys every 12 hours.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Do not attach Windows nodes to encrypted overlay networks.\")),mdx(\"p\",null,\"Overlay network encryption is not supported on Windows. If a Windows node attempts to connect to an encrypted overlay network, no error is detected but the node cannot communicate.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"SWARM MODE OVERLAY NETWORKS AND STANDALONE CONTAINERS\")),mdx(\"p\",null,\"You can use the overlay network feature with both\\xA0--opt encrypted --attachable\\xA0and attach unmanaged containers to that network:\"),mdx(\"p\",null,\"$ docker network create --opt encrypted --driver overlay --attachable my-attachable-multi-host-network\"),mdx(\"h4\",null,\"Customize the default ingress network\"),mdx(\"p\",null,\"Most users never need to configure the\\xA0ingress\\xA0network, but Docker 17.05 and higher allow you to do so. This can be useful if the automatically-chosen subnet conflicts with one that already exists on your network, or you need to customize other low-level network settings such as the MTU.\"),mdx(\"p\",null,\"Customizing the\\xA0ingress\\xA0network involves removing and recreating it. This is usually done before you create any services in the swarm. If you have existing services which publish ports, those services need to be removed before you can remove the\\xA0ingress\\xA0network.\"),mdx(\"p\",null,\"During the time that no\\xA0ingress\\xA0network exists, existing services which do not publish ports continue to function but are not load-balanced. This affects services which publish ports, such as a WordPress service which publishes port 80.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Inspect the\\xA0ingress\\xA0network using\\xA0docker network inspect ingress, and remove any services whose containers are connected to it. These are services that publish ports, such as a WordPress service which publishes port 80. If all such services are not stopped, the next step fails.\"),mdx(\"li\",{parentName:\"ol\"},\"Remove the existing\\xA0ingress\\xA0network:\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker network rm ingress\"),mdx(\"li\",{parentName:\"ol\"},\"WARNING! Before removing the routing-mesh network, make sure all the nodes\"),mdx(\"li\",{parentName:\"ol\"},\"in your swarm run the same docker engine version. Otherwise, removal may not\"),mdx(\"li\",{parentName:\"ol\"},\"be effective and functionality of newly created ingress networks will be\"),mdx(\"li\",{parentName:\"ol\"},\"impaired.\"),mdx(\"li\",{parentName:\"ol\"},\"Are you sure you want to continue? \",\"[y/N]\"),mdx(\"li\",{parentName:\"ol\"},\"Create a new overlay network using the\\xA0--ingress\\xA0flag, along with the custom options you want to set. This example sets the MTU to 1200, sets the subnet to\\xA010.11.0.0/16, and sets the gateway to\\xA010.11.0.2.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker network create \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--driver overlay \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--ingress \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--subnet=10.11.0.0/16 \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--gateway=10.11.0.2 \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--opt com.docker.network.mtu=1200 \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"my-ingress\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": You can name your\\xA0ingress\\xA0network something other than\\xA0ingress, but you can only have one. An attempt to create a second one fails.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Restart the services that you stopped in the first step.\")),mdx(\"h4\",null,\"Customize the docker_gwbridge interface\"),mdx(\"p\",null,\"The\\xA0docker_gwbridge\\xA0is a virtual bridge that connects the overlay networks (including the\\xA0ingressnetwork) to an individual Docker daemon's physical network. Docker creates it automatically when you initialize a swarm or join a Docker host to a swarm, but it is not a Docker device. It exists in the kernel of the Docker host. If you need to customize its settings, you must do so before joining the Docker host to the swarm, or after temporarily removing the host from the swarm.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Stop Docker.\"),mdx(\"li\",{parentName:\"ol\"},\"Delete the existing\\xA0docker_gwbridge\\xA0interface.\"),mdx(\"li\",{parentName:\"ol\"},\"$ sudo ip link set docker_gwbridge down\"),mdx(\"li\",{parentName:\"ol\"},\"$ sudo ip link del name docker_gwbridge\"),mdx(\"li\",{parentName:\"ol\"},\"Start Docker. Do not join or initialize the swarm.\"),mdx(\"li\",{parentName:\"ol\"},\"Create or re-create the\\xA0docker_gwbridge\\xA0bridge manually with your custom settings, using the\\xA0docker network create\\xA0command. This example uses the subnet\\xA010.11.0.0/16. For a full list of customizable options, see\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/network_create/#bridge-driver-options\"}),\"Bridge driver options\"),\".\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker network create \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--subnet 10.11.0.0/16 \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--opt com.docker.network.bridge.name=docker_gwbridge \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--opt com.docker.network.bridge.enable_icc=false \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--opt com.docker.network.bridge.enable_ip_masquerade=true \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"docker_gwbridge\"),mdx(\"li\",{parentName:\"ol\"},\"Initialize or join the swarm. Since the bridge already exists, Docker does not create it with automatic settings.\")),mdx(\"h3\",null,\"Operations for swarm services\"),mdx(\"h4\",null,\"Publish ports on an overlay network\"),mdx(\"p\",null,\"Swarm services connected to the same overlay network effectively expose all ports to each other. For a port to be accessible outside of the service, that port must be\\xA0published\\xA0using the\\xA0-p\\xA0or\\xA0--publishflag on\\xA0docker service create\\xA0or\\xA0docker service update. Both the legacy colon-separated syntax and the newer comma-separated value syntax are supported. The longer syntax is preferred because it is somewhat self-documenting.\"),mdx(\"p\",null,\"+-----------------------------------+-----------------------------------+\\n| \",mdx(\"strong\",{parentName:\"p\"},\"Flag value\"),\"                    | \",mdx(\"strong\",{parentName:\"p\"},\"Description\"),\"                   |\\n+===================================+===================================+\\n| -p 8080:80\\xA0or\\\\                    | Map TCP port 80 on the service to |\\n| -p published=8080,target=80       | port 8080 on the routing mesh.    |\\n+-----------------------------------+-----------------------------------+\\n| -p 8080:80/udp\\xA0or\\\\                | Map UDP port 80 on the service to |\\n| -p                                | port 8080 on the routing mesh.    |\\n| publ                              |                                   |\\n| ished=8080,target=80,protocol=udp |                                   |\\n+-----------------------------------+-----------------------------------+\\n| -p 8080:80/tcp -p                 | Map TCP port 80 on the service to |\\n| 8080:80/udp\\xA0or\\xA0\\\\                  | TCP port 8080 on the routing      |\\n| -p                                | mesh, and map UDP port 80 on the  |\\n| publ                              | service to UDP port 8080 on the   |\\n| ished=8080,target=80,protocol=tcp | routine mesh.                     |\\n| -p                                |                                   |\\n| publ                              |                                   |\\n| ished=8080,target=80,protocol=udp |                                   |\\n+-----------------------------------+-----------------------------------+\"),mdx(\"h4\",null,\"Bypass the routing mesh for a swarm service\"),mdx(\"p\",null,\"By default, swarm services which publish ports do so using the routing mesh. When you connect to a published port on any swarm node (whether it is running a given service or not), you are redirected to a worker which is running that service, transparently. Effectively, Docker acts as a load balancer for your swarm services. Services using the routing mesh are running in\\xA0virtual IP (VIP) mode. Even a service running on each node (by means of the\\xA0--global\\xA0flag) uses the routing mesh. When using the routing mesh, there is no guarantee about which Docker node services client requests.\"),mdx(\"p\",null,\"To bypass the routing mesh, you can start a service using\\xA0DNS Round Robin (DNSRR) mode, by setting the\\xA0--endpoint-mode\\xA0flag to\\xA0dnsrr. You must run your own load balancer in front of the service. A DNS query for the service name on the Docker host returns a list of IP addresses for the nodes running the service. Configure your load balancer to consume this list and balance the traffic across the nodes.\"),mdx(\"h4\",null,\"Separate control and data traffic\"),mdx(\"p\",null,\"By default, control traffic relating to swarm management and traffic to and from your applications runs over the same network, though the swarm control traffic is encrypted. You can configure Docker to use separate network interfaces for handling the two different types of traffic. When you initialize or join the swarm, specify\\xA0--advertise-addr\\xA0and\\xA0--datapath-addr\\xA0separately. You must do this for each node joining the swarm.\"),mdx(\"h3\",null,\"Operations for standalone containers on overlay networks\"),mdx(\"h4\",null,\"Attach a standalone container to an overlay network\"),mdx(\"p\",null,\"The\\xA0ingress\\xA0network is create without the\\xA0--attachable\\xA0flag, which means that only swarm services can use it, and not standalone containers. You can connect standalone containers to user-defined overlay networks which are created with the\\xA0--attachable\\xA0flag. This gives standalone containers running on different Docker daemons the ability to communicate without the need to set up routing on the individual Docker daemon hosts.\"),mdx(\"h4\",null,\"Publish ports\"),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Flag value\"),\"                  \",mdx(\"strong\",{parentName:\"p\"},\"Description\")),mdx(\"hr\",null),mdx(\"p\",null,\"  -p 8080:80                      Map TCP port 80 in the container to port 8080 on the overlay network.\\n-p 8080:80/udp                  Map UDP port 80 in the container to port 8080 on the overlay network.\\n-p 8080:80/tcp -p 8080:80/udp   Map TCP port 80 in the container to TCP port 8080 on the overlay network, and map UDP port 80 in the container to UDP port 8080 on the overlay networkt.\"),mdx(\"h3\",null,\"Next steps\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Go through the\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/network-tutorial-overlay/\"}),\"overlay networking tutorial\")),mdx(\"li\",{parentName:\"ul\"},\"Learn about\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/config/containers/container-networking/\"}),\"networking from the container's point of view\")),mdx(\"li\",{parentName:\"ul\"},\"Learn about\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/bridge/\"}),\"standalone bridge networks\")),mdx(\"li\",{parentName:\"ul\"},\"Learn about\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/macvlan/\"}),\"Macvlan networks\"))),mdx(\"h2\",null,\"Use host networking\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA01 minute\")),mdx(\"p\",null,\"If you use the\\xA0host\\xA0network driver for a container, that container's network stack is not isolated from the Docker host. For instance, if you run a container which binds to port 80 and you use\\xA0hostnetworking, the container's application will be available on port 80 on the host's IP address.\"),mdx(\"p\",null,\"In Docker 17.06 and higher, you can also use a\\xA0host\\xA0network for a swarm service, by passing\\xA0--network host\\xA0to the\\xA0docker container create\\xA0command. In this case, control traffic (traffic related to managing the swarm and the service) is still sent across an overlay network, but the individual swarm service containers send data using the Docker daemon's host network and ports. This creates some extra limitations. For instance, if a service container binds to port 80, only one service container can run on a given swarm node.\"),mdx(\"p\",null,\"If your container or service publishes no ports, host networking has no effect.\"),mdx(\"h3\",null,\"Next steps\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Go through the\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/network-tutorial-host/\"}),\"host networking tutorial\")),mdx(\"li\",{parentName:\"ul\"},\"Learn about\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/config/containers/container-networking/\"}),\"networking from the container's point of view\")),mdx(\"li\",{parentName:\"ul\"},\"Learn about\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/bridge/\"}),\"bridge networks\")),mdx(\"li\",{parentName:\"ul\"},\"Learn about\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/overlay/\"}),\"overlay networks\")),mdx(\"li\",{parentName:\"ul\"},\"Learn about\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/macvlan/\"}),\"Macvlan networks\"))),mdx(\"h2\",null,\"Use Macvlan networks\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA03 minutes\")),mdx(\"p\",null,\"Some applications, especially legacy applications or applications which monitor network traffic, expect to be directly connected to the physical network. In this type of situation, you can use the\\xA0macvlannetwork driver to assign a MAC address to each container's virtual network interface, making it appear to be a physical network interface directly connected to the physical network. In this case, you need to designate a physical interface on your Docker host to use for the Macvlan, as well as the subnet and gateway of the Macvlan. You can even isolate your Macvlan networks using different physical network interfaces. Keep the following things in mind:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"It is very easy to unintentionally damage your network due IP address exhaustion or to \\\"VLAN spread\\\", which is a situation in which you have an inappropriately large number of unique MAC addresses in your network.\"),mdx(\"li\",{parentName:\"ul\"},\"Your networking equipment needs to be able to handle \\\"promiscuous mode\\\", where one physical interface can be assigned multiple MAC addresses.\"),mdx(\"li\",{parentName:\"ul\"},\"If your application can work using a bridge (on a single Docker host) or overlay (to communicate across multiple Docker hosts), these solutions may be better in the long term.\")),mdx(\"h3\",null,\"Create a macvlan network\"),mdx(\"p\",null,\"When you create a Macvlan network, it can either be in bridge mode or 802.1q trunk bridge mode.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"In bridge mode,Macvlan traffic goes through a physical device on the host.\"),mdx(\"li\",{parentName:\"ul\"},\"In 802.1q trunk bridge mode, traffic goes through an 802.1q sub-interface which Docker creates on the fly. This allows you to control routing and filtering at a more granular level.\")),mdx(\"h4\",null,\"Bridge mode\"),mdx(\"p\",null,\"To create a Macvlan network which bridges with a given physical network interface, use\\xA0--driver macvlan\\xA0with the\\xA0docker network create\\xA0command. You also need to specify the\\xA0parent, which is the interface the traffic will physically go through on the Docker host.\"),mdx(\"p\",null,\"$ docker network create -d macvlan \\\\\"),mdx(\"p\",null,\"--subnet=172.16.86.0/24 \\\\\"),mdx(\"p\",null,\"--gateway=172.16.86.1 \\\\\"),mdx(\"p\",null,\"-o parent=eth0 pub_net\"),mdx(\"p\",null,\"If you need to exclude IP addresses from being used in the Macvlan network, such as when a given IP address is already in use, use\\xA0--aux-addresses:\"),mdx(\"p\",null,\"$ docker network create -d macvlan \\\\\"),mdx(\"p\",null,\"--subnet=192.168.32.0/24 \\\\\"),mdx(\"p\",null,\"--ip-range=192.168.32.128/25 \\\\\"),mdx(\"p\",null,\"--gateway=192.168.32.254 \\\\\"),mdx(\"p\",null,\"-o parent=eth0 macnet32\"),mdx(\"h4\",null,\"802.1q trunk bridge mode\"),mdx(\"p\",null,\"If you specify a\\xA0parent\\xA0interface name with a dot included, such as\\xA0eth0.50, Docker interprets that as a sub-interface of\\xA0eth0\\xA0and creates the sub-interface automatically.\"),mdx(\"p\",null,\"$ docker network create -d macvlan \\\\\"),mdx(\"p\",null,\"--subnet=192.168.50.0/24 \\\\\"),mdx(\"p\",null,\"--gateway=192.168.50.1 \\\\\"),mdx(\"p\",null,\"-o parent=eth0.50 macvlan50\"),mdx(\"h4\",null,\"Use an ipvlan instead of macvlan\"),mdx(\"p\",null,\"In the above example, you are still using a L3 bridge. You can use\\xA0ipvlan\\xA0instead, and get an L2 bridge. Specify\\xA0-o ipvlan_mode=l2.\"),mdx(\"p\",null,\"$ docker network create -d ipvlan \\\\\"),mdx(\"p\",null,\"--subnet=192.168.210.0/24 \\\\\"),mdx(\"p\",null,\"--subnet=192.168.212.0/24 \\\\\"),mdx(\"p\",null,\"--gateway=192.168.210.254 \\\\\"),mdx(\"p\",null,\"--gateway=192.168.212.254 \\\\\"),mdx(\"p\",null,\"-o ipvlan_mode=l2 ipvlan210\"),mdx(\"h3\",null,\"Use IPv6\"),mdx(\"p\",null,\"If you have\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/daemon/ipv6/\"}),\"configured the Docker daemon to allow IPv6\"),\", you can use dual-stack IPv4/IPv6 Macvlan networks.\"),mdx(\"p\",null,\"$ docker network create -d macvlan \\\\\"),mdx(\"p\",null,\"--subnet=192.168.216.0/24 --subnet=192.168.218.0/24 \\\\\"),mdx(\"p\",null,\"--gateway=192.168.216.1 --gateway=192.168.218.1 \\\\\"),mdx(\"p\",null,\"--subnet=2001:db8:abc8::/64 --gateway=2001:db8:abc8::10 \\\\\"),mdx(\"p\",null,\"-o parent=eth0.218 \\\\\"),mdx(\"p\",null,\"-o macvlan_mode=bridge macvlan216\"),mdx(\"h3\",null,\"Next steps\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Go through the\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/network-tutorial-macvlan/\"}),\"macvlan networking tutorial\")),mdx(\"li\",{parentName:\"ul\"},\"Learn about\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/config/containers/container-networking/\"}),\"networking from the container's point of view\")),mdx(\"li\",{parentName:\"ul\"},\"Learn about\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/bridge/\"}),\"bridge networks\")),mdx(\"li\",{parentName:\"ul\"},\"Learn about\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/overlay/\"}),\"overlay networks\")),mdx(\"li\",{parentName:\"ul\"},\"Learn about\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/host/\"}),\"host networking\")),mdx(\"li\",{parentName:\"ul\"},\"Learn about\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/macvlan/\"}),\"Macvlan networks\"))),mdx(\"h2\",null,\"Disable networking for a container\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA01 minute\")),mdx(\"p\",null,\"If you want to completely disable the networking stack on a container, you can use the\\xA0--network noneflag when starting the container. Within the container, only the loopback device is created. The following example illustrates this.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Create the container.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker run --rm -dit \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--network none \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--name no-net-alpine \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"alpine:latest \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"ash\"),mdx(\"li\",{parentName:\"ol\"},\"Check the container's network stack, by executing some common networking commands within the container. Notice that no\\xA0eth0\\xA0was created.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker exec no-net-alpine ip link show\"),mdx(\"li\",{parentName:\"ol\"},\"1: lo: \",mdx(\"inlineCode\",{parentName:\"li\"},\"<LOOPBACK,UP,LOWER_UP>\"),\" mtu 65536 qdisc noqueue state UNKNOWN qlen 1\"),mdx(\"li\",{parentName:\"ol\"},\"link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\"),mdx(\"li\",{parentName:\"ol\"},\"2: tunl0\\\\@NONE: \",mdx(\"inlineCode\",{parentName:\"li\"},\"<NOARP>\"),\" mtu 1480 qdisc noop state DOWN qlen 1\"),mdx(\"li\",{parentName:\"ol\"},\"link/ipip 0.0.0.0 brd 0.0.0.0\"),mdx(\"li\",{parentName:\"ol\"},\"3: ip6tnl0\\\\@NONE: \",mdx(\"inlineCode\",{parentName:\"li\"},\"<NOARP>\"),\" mtu 1452 qdisc noop state DOWN qlen 1\"),mdx(\"li\",{parentName:\"ol\"},\"link/tunnel6 00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00 brd 00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker exec no-net-alpine ip route\")),mdx(\"p\",null,\"The second command returns empty because there is no routing table.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Stop the container. It is removed automatically because it was created with the\\xA0--rm\\xA0flag.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker container rm no-net-alpine\")),mdx(\"h3\",null,\"Next steps\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Go through the\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/network-tutorial-host/\"}),\"host networking tutorial\")),mdx(\"li\",{parentName:\"ul\"},\"Learn about\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/config/containers/container-networking/\"}),\"networking from the container's point of view\")),mdx(\"li\",{parentName:\"ul\"},\"Learn about\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/bridge/\"}),\"bridge networks\")),mdx(\"li\",{parentName:\"ul\"},\"Learn about\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/overlay/\"}),\"overlay networks\")),mdx(\"li\",{parentName:\"ul\"},\"Learn about\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/macvlan/\"}),\"Macvlan networks\"))),mdx(\"h2\",null,\"Networing Tutorials\"),mdx(\"h3\",null,\"Networking with standalone containers\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA018 minutes\")),mdx(\"p\",null,\"This series of tutorials deals with networking for standalone Docker containers. For networking with swarm services, see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/network/network-tutorial-overlay/\"}),\"Networking with swarm services\"),\". If you need to learn more about Docker networking in general, see the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/network/\"}),\"overview\"),\".\"),mdx(\"p\",null,\"This topic includes three different tutorials. You can run each of them on Linux, Windows, or a Mac, but for the last two, you need a second Docker host running elsewhere.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/network-tutorial-standalone/#use-the-default-bridge-network\"}),\"Use the default bridge network\"),\"\\xA0demonstrates how to use the default\\xA0bridge\\xA0network that Docker sets up for you automatically. This network is not the best choice for production systems.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/network-tutorial-standalone/#use-user-defined-bridge-networks\"}),\"Use user-defined bridge networks\"),\"\\xA0shows how to create and use your own custom bridge networks, to connect containers running on the same Docker host. This is recommended for standalone containers running in production.\")),mdx(\"p\",null,\"Although\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/network/overlay/\"}),\"overlay networks\"),\"\\xA0are generally used for swarm services, Docker 17.06 and higher allow you to use an overlay network for standalone containers. That's covered as part of the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/network/network-tutorial-overlay/#use-an-overlay-network-for-standalone-containers\"}),\"tutorial on using overlay networks\"),\".\"),mdx(\"h4\",null,\"Use the default bridge network\"),mdx(\"p\",null,\"In this example, you start two different\\xA0alpine\\xA0containers on the same Docker host and do some tests to understand how they communicate with each other. You need to have Docker installed and running.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Open a terminal window. List current networks before you do anything else. Here's what you should see if you've never added a network or initialized a swarm on this Docker daemon. You may see different networks, but you should at least see these (the network IDs will be different):\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker network ls\"),mdx(\"li\",{parentName:\"ol\"},\"NETWORK ID NAME DRIVER SCOPE\"),mdx(\"li\",{parentName:\"ol\"},\"17e324f45964 bridge bridge local\"),mdx(\"li\",{parentName:\"ol\"},\"6ed54d316334 host host local\"),mdx(\"li\",{parentName:\"ol\"},\"7092879f2cc8 none null local\")),mdx(\"p\",null,\"The default\\xA0bridge\\xA0network is listed, along with\\xA0host\\xA0and\\xA0none. The latter two are not fully-fledged networks, but are used to start a container connected directly to the Docker daemon host's networking stack, or to start a container with no network devices.\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"This tutorial will connect two containers to the\\xA0bridge\\xA0network.\")),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Start two\\xA0alpine\\xA0containers running\\xA0ash, which is Alpine's default shell rather than\\xA0bash. The\\xA0-dit\\xA0flags mean to start the container detached (in the background), interactive (with the ability to type into it), and with a TTY (so you can see the input and output). Since you are starting it detached, you won't be connected to the container right away. Instead, the container's ID will be printed. Because you have not specified any\\xA0--network\\xA0flags, the containers connect to the default\\xA0bridge\\xA0network.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker run -dit --name alpine1 alpine ash\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker run -dit --name alpine2 alpine ash\")),mdx(\"p\",null,\"Check that both containers are actually started:\"),mdx(\"p\",null,\"$ docker container ls\"),mdx(\"p\",null,\"CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES\"),mdx(\"p\",null,\"602dbf1edc81 alpine \\\"ash\\\" 4 seconds ago Up 3 seconds alpine2\"),mdx(\"p\",null,\"da33b7aa74b0 alpine \\\"ash\\\" 17 seconds ago Up 16 seconds alpine1\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Inspect the\\xA0bridge\\xA0network to see what containers are connected to it.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker network inspect bridge\"),mdx(\"li\",{parentName:\"ol\"},\"[\"),mdx(\"li\",{parentName:\"ol\"},\"{\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Name\\\": \\\"bridge\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Id\\\": \\\"17e324f459648a9baaea32b248d3884da102dde19396c25b30ec800068ce6b10\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Created\\\": \\\"2017-06-22T20:27:43.826654485Z\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Scope\\\": \\\"local\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Driver\\\": \\\"bridge\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"EnableIPv6\\\": false,\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"IPAM\\\": {\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Driver\\\": \\\"default\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Options\\\": null,\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Config\\\": [\"),mdx(\"li\",{parentName:\"ol\"},\"{\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Subnet\\\": \\\"172.17.0.0/16\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Gateway\\\": \\\"172.17.0.1\\\"\"),mdx(\"li\",{parentName:\"ol\"},\"}\"),mdx(\"li\",{parentName:\"ol\"},\"]\"),mdx(\"li\",{parentName:\"ol\"},\"},\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Internal\\\": false,\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Attachable\\\": false,\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Containers\\\": {\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"602dbf1edc81813304b6cf0a647e65333dc6fe6ee6ed572dc0f686a3307c6a2c\\\": {\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Name\\\": \\\"alpine2\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"EndpointID\\\": \\\"03b6aafb7ca4d7e531e292901b43719c0e34cc7eef565b38a6bf84acf50f38cd\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"MacAddress\\\": \\\"02:42:ac:11:00:03\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"IPv4Address\\\": \\\"172.17.0.3/16\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"IPv6Address\\\": \\\"\\\"\"),mdx(\"li\",{parentName:\"ol\"},\"},\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"da33b7aa74b0bf3bda3ebd502d404320ca112a268aafe05b4851d1e3312ed168\\\": {\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Name\\\": \\\"alpine1\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"EndpointID\\\": \\\"46c044a645d6afc42ddd7857d19e9dcfb89ad790afb5c239a35ac0af5e8a5bc5\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"MacAddress\\\": \\\"02:42:ac:11:00:02\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"IPv4Address\\\": \\\"172.17.0.2/16\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"IPv6Address\\\": \\\"\\\"\"),mdx(\"li\",{parentName:\"ol\"},\"}\"),mdx(\"li\",{parentName:\"ol\"},\"},\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Options\\\": {\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"com.docker.network.bridge.default_bridge\\\": \\\"true\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"com.docker.network.bridge.enable_icc\\\": \\\"true\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"com.docker.network.bridge.enable_ip_masquerade\\\": \\\"true\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"com.docker.network.bridge.host_binding_ipv4\\\": \\\"0.0.0.0\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"com.docker.network.bridge.name\\\": \\\"docker0\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"com.docker.network.driver.mtu\\\": \\\"1500\\\"\"),mdx(\"li\",{parentName:\"ol\"},\"},\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Labels\\\": {}\"),mdx(\"li\",{parentName:\"ol\"},\"}\"),mdx(\"li\",{parentName:\"ol\"},\"]\")),mdx(\"p\",null,\"Near the top, information about the\\xA0bridge\\xA0network is listed, including the IP address of the gateway between the Docker host and the\\xA0bridge\\xA0network (172.17.0.1). Under the\\xA0Containers\\xA0key, each connected container is listed, along with information about its IP address (172.17.0.2\\xA0for\\xA0alpine1\\xA0and\\xA0172.17.0.3\\xA0for\\xA0alpine2).\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"The containers are running in the background. Use the\\xA0docker attach\\xA0command to connect to\\xA0alpine1.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker attach alpine1\"),mdx(\"li\",{parentName:\"ol\"},\"/ #\")),mdx(\"p\",null,\"The prompt changes to\\xA0#\\xA0to indicate that you are the\\xA0root\\xA0user within the container. Use the\\xA0ip addr show\\xA0command to show the network interfaces for\\xA0alpine1\\xA0as they look from within the container:\"),mdx(\"h1\",null,\"ip addr show\"),mdx(\"p\",null,\"1: lo: \",mdx(\"inlineCode\",{parentName:\"p\"},\"<LOOPBACK,UP,LOWER_UP>\"),\" mtu 65536 qdisc noqueue state UNKNOWN qlen 1\"),mdx(\"p\",null,\"link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\"),mdx(\"p\",null,\"inet 127.0.0.1/8 scope host lo\"),mdx(\"p\",null,\"valid_lft forever preferred_lft forever\"),mdx(\"p\",null,\"inet6 ::1/128 scope host\"),mdx(\"p\",null,\"valid_lft forever preferred_lft forever\"),mdx(\"p\",null,\"27: eth0\\\\@if28: \",mdx(\"inlineCode\",{parentName:\"p\"},\"<BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN>\"),\" mtu 1500 qdisc noqueue state UP\"),mdx(\"p\",null,\"link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff\"),mdx(\"p\",null,\"inet 172.17.0.2/16 scope global eth0\"),mdx(\"p\",null,\"valid_lft forever preferred_lft forever\"),mdx(\"p\",null,\"inet6 fe80::42:acff:fe11:2/64 scope link\"),mdx(\"p\",null,\"valid_lft forever preferred_lft forever\"),mdx(\"p\",null,\"The first interface is the loopback device. Ignore it for now. Notice that the second interface has the IP address\\xA0172.17.0.2, which is the same address shown for\\xA0alpine1\\xA0in the previous step.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"From within\\xA0alpine1, make sure you can connect to the internet by pinging\\xA0google.com. The\\xA0-c 2\\xA0flag limits the command to two\\xA0ping\\xA0attempts.\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"h1\",{parentName:\"li\"},\"ping -c 2 google.com\")),mdx(\"li\",{parentName:\"ol\"},\"PING google.com (172.217.3.174): 56 data bytes\"),mdx(\"li\",{parentName:\"ol\"},\"64 bytes from 172.217.3.174: seq=0 ttl=41 time=9.841 ms\"),mdx(\"li\",{parentName:\"ol\"},\"64 bytes from 172.217.3.174: seq=1 ttl=41 time=9.897 ms\"),mdx(\"li\",{parentName:\"ol\"},\"--- google.com ping statistics ---\"),mdx(\"li\",{parentName:\"ol\"},\"2 packets transmitted, 2 packets received, 0% packet loss\"),mdx(\"li\",{parentName:\"ol\"},\"round-trip min/avg/max = 9.841/9.869/9.897 ms\"),mdx(\"li\",{parentName:\"ol\"},\"Now try to ping the second container. First, ping it by its IP address,\\xA0172.17.0.3:\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"h1\",{parentName:\"li\"},\"ping -c 2 172.17.0.3\")),mdx(\"li\",{parentName:\"ol\"},\"PING 172.17.0.3 (172.17.0.3): 56 data bytes\"),mdx(\"li\",{parentName:\"ol\"},\"64 bytes from 172.17.0.3: seq=0 ttl=64 time=0.086 ms\"),mdx(\"li\",{parentName:\"ol\"},\"64 bytes from 172.17.0.3: seq=1 ttl=64 time=0.094 ms\"),mdx(\"li\",{parentName:\"ol\"},\"--- 172.17.0.3 ping statistics ---\"),mdx(\"li\",{parentName:\"ol\"},\"2 packets transmitted, 2 packets received, 0% packet loss\"),mdx(\"li\",{parentName:\"ol\"},\"round-trip min/avg/max = 0.086/0.090/0.094 ms\")),mdx(\"p\",null,\"This succeeds. Next, try pinging the\\xA0alpine2\\xA0container by container name. This will fail.\"),mdx(\"h1\",null,\"ping -c 2 alpine2\"),mdx(\"p\",null,\"ping: bad address \\\\'alpine2\\\\'\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Detach from\\xA0alpine1\\xA0without stopping it by using the detach sequence,\\xA0CTRL\\xA0+\\xA0p\\xA0CTRL\\xA0+\\xA0q\\xA0(hold down\\xA0CTRL\\xA0and type\\xA0p\\xA0followed by\\xA0q). If you wish, attach to\\xA0alpine2\\xA0and repeat steps 4, 5, and 6 there, substituting\\xA0alpine1\\xA0for\\xA0alpine2.\"),mdx(\"li\",{parentName:\"ol\"},\"Stop and remove both containers.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker container stop alpine1 alpine2\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker container rm alpine1 alpine2\")),mdx(\"p\",null,\"Remember, the default\\xA0bridge\\xA0network is not recommended for production. To learn about user-defined bridge networks, continue to the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/network/network-tutorial-standalone/#use-user-defined-bridge-networks\"}),\"next tutorial\"),\".\"),mdx(\"h4\",null,\"Use user-defined bridge networks\"),mdx(\"p\",null,\"In this example, we again start two\\xA0alpine\\xA0containers, but attach them to a user-defined network called\\xA0alpine-net\\xA0which we have already created. These containers are not connected to the default\\xA0bridge\\xA0network at all. We then start a third\\xA0alpine\\xA0container which is connected to the\\xA0bridgenetwork but not connected to\\xA0alpine-net, and a fourth\\xA0alpine\\xA0container which is connected to both networks.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Create the\\xA0alpine-net\\xA0network. You do not need the\\xA0--driver bridge\\xA0flag since it's the default, but this example shows how to specify it.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker network create --driver bridge alpine-net\"),mdx(\"li\",{parentName:\"ol\"},\"List Docker's networks:\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker network ls\"),mdx(\"li\",{parentName:\"ol\"},\"NETWORK ID NAME DRIVER SCOPE\"),mdx(\"li\",{parentName:\"ol\"},\"e9261a8c9a19 alpine-net bridge local\"),mdx(\"li\",{parentName:\"ol\"},\"17e324f45964 bridge bridge local\"),mdx(\"li\",{parentName:\"ol\"},\"6ed54d316334 host host local\"),mdx(\"li\",{parentName:\"ol\"},\"7092879f2cc8 none null local\")),mdx(\"p\",null,\"Inspect the\\xA0alpine-net\\xA0network. This shows you its IP address and the fact that no containers are connected to it:\"),mdx(\"p\",null,\"$ docker network inspect alpine-net\"),mdx(\"p\",null,\"[\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"Name\\\": \\\"alpine-net\\\",\"),mdx(\"p\",null,\"\\\"Id\\\": \\\"e9261a8c9a19eabf2bf1488bf5f208b99b1608f330cff585c273d39481c9b0ec\\\",\"),mdx(\"p\",null,\"\\\"Created\\\": \\\"2017-09-25T21:38:12.620046142Z\\\",\"),mdx(\"p\",null,\"\\\"Scope\\\": \\\"local\\\",\"),mdx(\"p\",null,\"\\\"Driver\\\": \\\"bridge\\\",\"),mdx(\"p\",null,\"\\\"EnableIPv6\\\": false,\"),mdx(\"p\",null,\"\\\"IPAM\\\": {\"),mdx(\"p\",null,\"\\\"Driver\\\": \\\"default\\\",\"),mdx(\"p\",null,\"\\\"Options\\\": {},\"),mdx(\"p\",null,\"\\\"Config\\\": [\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"Subnet\\\": \\\"172.18.0.0/16\\\",\"),mdx(\"p\",null,\"\\\"Gateway\\\": \\\"172.18.0.1\\\"\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"]\"),mdx(\"p\",null,\"},\"),mdx(\"p\",null,\"\\\"Internal\\\": false,\"),mdx(\"p\",null,\"\\\"Attachable\\\": false,\"),mdx(\"p\",null,\"\\\"Containers\\\": {},\"),mdx(\"p\",null,\"\\\"Options\\\": {},\"),mdx(\"p\",null,\"\\\"Labels\\\": {}\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"]\"),mdx(\"p\",null,\"Notice that this network's gateway is\\xA0172.18.0.1, as opposed to the default bridge network, whose gateway is\\xA0172.17.0.1. The exact IP address may be different on your system.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Create your four containers. Notice the\\xA0--network\\xA0flags. You can only connect to one network during the\\xA0docker run\\xA0command, so you need to use\\xA0docker network attach\\xA0afterward to connect\\xA0alpine4\\xA0to the\\xA0bridge\\xA0network as well.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker run -dit --name alpine1 --network alpine-net alpine ash\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker run -dit --name alpine2 --network alpine-net alpine ash\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker run -dit --name alpine3 alpine ash\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker run -dit --name alpine4 --network alpine-net alpine ash\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker network connect bridge alpine4\")),mdx(\"p\",null,\"Verify that all containers are running:\"),mdx(\"p\",null,\"$ docker container ls\"),mdx(\"p\",null,\"CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES\"),mdx(\"p\",null,\"156849ccd902 alpine \\\"ash\\\" 41 seconds ago Up 41 seconds alpine4\"),mdx(\"p\",null,\"fa1340b8d83e alpine \\\"ash\\\" 51 seconds ago Up 51 seconds alpine3\"),mdx(\"p\",null,\"a535d969081e alpine \\\"ash\\\" About a minute ago Up About a minute alpine2\"),mdx(\"p\",null,\"0a02c449a6e9 alpine \\\"ash\\\" About a minute ago Up About a minute alpine1\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Inspect the\\xA0bridge\\xA0network and the\\xA0alpine-net\\xA0network again:\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker network inspect bridge\"),mdx(\"li\",{parentName:\"ol\"},\"[\"),mdx(\"li\",{parentName:\"ol\"},\"{\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Name\\\": \\\"bridge\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Id\\\": \\\"17e324f459648a9baaea32b248d3884da102dde19396c25b30ec800068ce6b10\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Created\\\": \\\"2017-06-22T20:27:43.826654485Z\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Scope\\\": \\\"local\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Driver\\\": \\\"bridge\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"EnableIPv6\\\": false,\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"IPAM\\\": {\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Driver\\\": \\\"default\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Options\\\": null,\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Config\\\": [\"),mdx(\"li\",{parentName:\"ol\"},\"{\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Subnet\\\": \\\"172.17.0.0/16\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Gateway\\\": \\\"172.17.0.1\\\"\"),mdx(\"li\",{parentName:\"ol\"},\"}\"),mdx(\"li\",{parentName:\"ol\"},\"]\"),mdx(\"li\",{parentName:\"ol\"},\"},\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Internal\\\": false,\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Attachable\\\": false,\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Containers\\\": {\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"156849ccd902b812b7d17f05d2d81532ccebe5bf788c9a79de63e12bb92fc621\\\": {\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Name\\\": \\\"alpine4\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"EndpointID\\\": \\\"7277c5183f0da5148b33d05f329371fce7befc5282d2619cfb23690b2adf467d\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"MacAddress\\\": \\\"02:42:ac:11:00:03\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"IPv4Address\\\": \\\"172.17.0.3/16\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"IPv6Address\\\": \\\"\\\"\"),mdx(\"li\",{parentName:\"ol\"},\"},\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"fa1340b8d83eef5497166951184ad3691eb48678a3664608ec448a687b047c53\\\": {\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Name\\\": \\\"alpine3\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"EndpointID\\\": \\\"5ae767367dcbebc712c02d49556285e888819d4da6b69d88cd1b0d52a83af95f\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"MacAddress\\\": \\\"02:42:ac:11:00:02\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"IPv4Address\\\": \\\"172.17.0.2/16\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"IPv6Address\\\": \\\"\\\"\"),mdx(\"li\",{parentName:\"ol\"},\"}\"),mdx(\"li\",{parentName:\"ol\"},\"},\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Options\\\": {\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"com.docker.network.bridge.default_bridge\\\": \\\"true\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"com.docker.network.bridge.enable_icc\\\": \\\"true\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"com.docker.network.bridge.enable_ip_masquerade\\\": \\\"true\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"com.docker.network.bridge.host_binding_ipv4\\\": \\\"0.0.0.0\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"com.docker.network.bridge.name\\\": \\\"docker0\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"com.docker.network.driver.mtu\\\": \\\"1500\\\"\"),mdx(\"li\",{parentName:\"ol\"},\"},\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Labels\\\": {}\"),mdx(\"li\",{parentName:\"ol\"},\"}\"),mdx(\"li\",{parentName:\"ol\"},\"]\")),mdx(\"p\",null,\"Containers\\xA0alpine3\\xA0and\\xA0alpine4\\xA0are connected to the\\xA0bridge\\xA0network.\"),mdx(\"p\",null,\"$ docker network inspect alpine-net\"),mdx(\"p\",null,\"[\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"Name\\\": \\\"alpine-net\\\",\"),mdx(\"p\",null,\"\\\"Id\\\": \\\"e9261a8c9a19eabf2bf1488bf5f208b99b1608f330cff585c273d39481c9b0ec\\\",\"),mdx(\"p\",null,\"\\\"Created\\\": \\\"2017-09-25T21:38:12.620046142Z\\\",\"),mdx(\"p\",null,\"\\\"Scope\\\": \\\"local\\\",\"),mdx(\"p\",null,\"\\\"Driver\\\": \\\"bridge\\\",\"),mdx(\"p\",null,\"\\\"EnableIPv6\\\": false,\"),mdx(\"p\",null,\"\\\"IPAM\\\": {\"),mdx(\"p\",null,\"\\\"Driver\\\": \\\"default\\\",\"),mdx(\"p\",null,\"\\\"Options\\\": {},\"),mdx(\"p\",null,\"\\\"Config\\\": [\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"Subnet\\\": \\\"172.18.0.0/16\\\",\"),mdx(\"p\",null,\"\\\"Gateway\\\": \\\"172.18.0.1\\\"\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"]\"),mdx(\"p\",null,\"},\"),mdx(\"p\",null,\"\\\"Internal\\\": false,\"),mdx(\"p\",null,\"\\\"Attachable\\\": false,\"),mdx(\"p\",null,\"\\\"Containers\\\": {\"),mdx(\"p\",null,\"\\\"0a02c449a6e9a15113c51ab2681d72749548fb9f78fae4493e3b2e4e74199c4a\\\": {\"),mdx(\"p\",null,\"\\\"Name\\\": \\\"alpine1\\\",\"),mdx(\"p\",null,\"\\\"EndpointID\\\": \\\"c83621678eff9628f4e2d52baf82c49f974c36c05cba152db4c131e8e7a64673\\\",\"),mdx(\"p\",null,\"\\\"MacAddress\\\": \\\"02:42:ac:12:00:02\\\",\"),mdx(\"p\",null,\"\\\"IPv4Address\\\": \\\"172.18.0.2/16\\\",\"),mdx(\"p\",null,\"\\\"IPv6Address\\\": \\\"\\\"\"),mdx(\"p\",null,\"},\"),mdx(\"p\",null,\"\\\"156849ccd902b812b7d17f05d2d81532ccebe5bf788c9a79de63e12bb92fc621\\\": {\"),mdx(\"p\",null,\"\\\"Name\\\": \\\"alpine4\\\",\"),mdx(\"p\",null,\"\\\"EndpointID\\\": \\\"058bc6a5e9272b532ef9a6ea6d7f3db4c37527ae2625d1cd1421580fd0731954\\\",\"),mdx(\"p\",null,\"\\\"MacAddress\\\": \\\"02:42:ac:12:00:04\\\",\"),mdx(\"p\",null,\"\\\"IPv4Address\\\": \\\"172.18.0.4/16\\\",\"),mdx(\"p\",null,\"\\\"IPv6Address\\\": \\\"\\\"\"),mdx(\"p\",null,\"},\"),mdx(\"p\",null,\"\\\"a535d969081e003a149be8917631215616d9401edcb4d35d53f00e75ea1db653\\\": {\"),mdx(\"p\",null,\"\\\"Name\\\": \\\"alpine2\\\",\"),mdx(\"p\",null,\"\\\"EndpointID\\\": \\\"198f3141ccf2e7dba67bce358d7b71a07c5488e3867d8b7ad55a4c695ebb8740\\\",\"),mdx(\"p\",null,\"\\\"MacAddress\\\": \\\"02:42:ac:12:00:03\\\",\"),mdx(\"p\",null,\"\\\"IPv4Address\\\": \\\"172.18.0.3/16\\\",\"),mdx(\"p\",null,\"\\\"IPv6Address\\\": \\\"\\\"\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"},\"),mdx(\"p\",null,\"\\\"Options\\\": {},\"),mdx(\"p\",null,\"\\\"Labels\\\": {}\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"]\"),mdx(\"p\",null,\"Containers\\xA0alpine1,\\xA0alpine2, and\\xA0alpine4\\xA0are connected to the\\xA0alpine-net\\xA0network.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"On user-defined networks like\\xA0alpine-net, containers can not only communicate by IP address, but can also resolve a container name to an IP address. This capability is called\\xA0\",mdx(\"strong\",{parentName:\"li\"},\"automatic service discovery\"),\". Let's connect to\\xA0alpine1\\xA0and test this out.\\xA0alpine1\\xA0should be able to resolvealpine2\\xA0and\\xA0alpine4\\xA0(and\\xA0alpine1, itself) to IP addresses.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker container attach alpine1\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"h1\",{parentName:\"li\"},\"ping -c 2 alpine2\")),mdx(\"li\",{parentName:\"ol\"},\"PING alpine2 (172.18.0.3): 56 data bytes\"),mdx(\"li\",{parentName:\"ol\"},\"64 bytes from 172.18.0.3: seq=0 ttl=64 time=0.085 ms\"),mdx(\"li\",{parentName:\"ol\"},\"64 bytes from 172.18.0.3: seq=1 ttl=64 time=0.090 ms\"),mdx(\"li\",{parentName:\"ol\"},\"--- alpine2 ping statistics ---\"),mdx(\"li\",{parentName:\"ol\"},\"2 packets transmitted, 2 packets received, 0% packet loss\"),mdx(\"li\",{parentName:\"ol\"},\"round-trip min/avg/max = 0.085/0.087/0.090 ms\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"h1\",{parentName:\"li\"},\"ping -c 2 alpine4\")),mdx(\"li\",{parentName:\"ol\"},\"PING alpine4 (172.18.0.4): 56 data bytes\"),mdx(\"li\",{parentName:\"ol\"},\"64 bytes from 172.18.0.4: seq=0 ttl=64 time=0.076 ms\"),mdx(\"li\",{parentName:\"ol\"},\"64 bytes from 172.18.0.4: seq=1 ttl=64 time=0.091 ms\"),mdx(\"li\",{parentName:\"ol\"},\"--- alpine4 ping statistics ---\"),mdx(\"li\",{parentName:\"ol\"},\"2 packets transmitted, 2 packets received, 0% packet loss\"),mdx(\"li\",{parentName:\"ol\"},\"round-trip min/avg/max = 0.076/0.083/0.091 ms\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"h1\",{parentName:\"li\"},\"ping -c 2 alpine1\")),mdx(\"li\",{parentName:\"ol\"},\"PING alpine1 (172.18.0.2): 56 data bytes\"),mdx(\"li\",{parentName:\"ol\"},\"64 bytes from 172.18.0.2: seq=0 ttl=64 time=0.026 ms\"),mdx(\"li\",{parentName:\"ol\"},\"64 bytes from 172.18.0.2: seq=1 ttl=64 time=0.054 ms\"),mdx(\"li\",{parentName:\"ol\"},\"--- alpine1 ping statistics ---\"),mdx(\"li\",{parentName:\"ol\"},\"2 packets transmitted, 2 packets received, 0% packet loss\"),mdx(\"li\",{parentName:\"ol\"},\"round-trip min/avg/max = 0.026/0.040/0.054 ms\"),mdx(\"li\",{parentName:\"ol\"},\"From\\xA0alpine1, you should not be able to connect to\\xA0alpine3\\xA0at all, since it is not on the\\xA0alpine-net\\xA0network.\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"h1\",{parentName:\"li\"},\"ping -c 2 alpine3\")),mdx(\"li\",{parentName:\"ol\"},\"ping: bad address \\\\'alpine3\\\\'\")),mdx(\"p\",null,\"Not only that, but you can't connect to\\xA0alpine3\\xA0from\\xA0alpine1\\xA0by its IP address either. Look back at the\\xA0docker network inspect\\xA0output for the\\xA0bridge\\xA0network and find\\xA0alpine3's IP address:\\xA0172.17.0.2\\xA0Try to ping it.\"),mdx(\"h1\",null,\"ping -c 2 172.17.0.2\"),mdx(\"p\",null,\"PING 172.17.0.2 (172.17.0.2): 56 data bytes\"),mdx(\"p\",null,\"--- 172.17.0.2 ping statistics ---\"),mdx(\"p\",null,\"2 packets transmitted, 0 packets received, 100% packet loss\"),mdx(\"p\",null,\"Detach from\\xA0alpine1\\xA0using detach sequence,\\xA0CTRL\\xA0+\\xA0p\\xA0CTRL\\xA0+\\xA0q\\xA0(hold down\\xA0CTRL\\xA0and type\\xA0p\\xA0followed by\\xA0q).\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Remember that\\xA0alpine4\\xA0is connected to both the default\\xA0bridge\\xA0network and\\xA0alpine-net. It should be able to reach all of the other containers. However, you will need to address\\xA0alpine3by its IP address. Attach to it and run the tests.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker container attach alpine4\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"h1\",{parentName:\"li\"},\"ping -c 2 alpine1\")),mdx(\"li\",{parentName:\"ol\"},\"PING alpine1 (172.18.0.2): 56 data bytes\"),mdx(\"li\",{parentName:\"ol\"},\"64 bytes from 172.18.0.2: seq=0 ttl=64 time=0.074 ms\"),mdx(\"li\",{parentName:\"ol\"},\"64 bytes from 172.18.0.2: seq=1 ttl=64 time=0.082 ms\"),mdx(\"li\",{parentName:\"ol\"},\"--- alpine1 ping statistics ---\"),mdx(\"li\",{parentName:\"ol\"},\"2 packets transmitted, 2 packets received, 0% packet loss\"),mdx(\"li\",{parentName:\"ol\"},\"round-trip min/avg/max = 0.074/0.078/0.082 ms\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"h1\",{parentName:\"li\"},\"ping -c 2 alpine2\")),mdx(\"li\",{parentName:\"ol\"},\"PING alpine2 (172.18.0.3): 56 data bytes\"),mdx(\"li\",{parentName:\"ol\"},\"64 bytes from 172.18.0.3: seq=0 ttl=64 time=0.075 ms\"),mdx(\"li\",{parentName:\"ol\"},\"64 bytes from 172.18.0.3: seq=1 ttl=64 time=0.080 ms\"),mdx(\"li\",{parentName:\"ol\"},\"--- alpine2 ping statistics ---\"),mdx(\"li\",{parentName:\"ol\"},\"2 packets transmitted, 2 packets received, 0% packet loss\"),mdx(\"li\",{parentName:\"ol\"},\"round-trip min/avg/max = 0.075/0.077/0.080 ms\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"h1\",{parentName:\"li\"},\"ping -c 2 alpine3\")),mdx(\"li\",{parentName:\"ol\"},\"ping: bad address \\\\'alpine3\\\\'\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"h1\",{parentName:\"li\"},\"ping -c 2 172.17.0.2\")),mdx(\"li\",{parentName:\"ol\"},\"PING 172.17.0.2 (172.17.0.2): 56 data bytes\"),mdx(\"li\",{parentName:\"ol\"},\"64 bytes from 172.17.0.2: seq=0 ttl=64 time=0.089 ms\"),mdx(\"li\",{parentName:\"ol\"},\"64 bytes from 172.17.0.2: seq=1 ttl=64 time=0.075 ms\"),mdx(\"li\",{parentName:\"ol\"},\"--- 172.17.0.2 ping statistics ---\"),mdx(\"li\",{parentName:\"ol\"},\"2 packets transmitted, 2 packets received, 0% packet loss\"),mdx(\"li\",{parentName:\"ol\"},\"round-trip min/avg/max = 0.075/0.082/0.089 ms\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"h1\",{parentName:\"li\"},\"ping -c 2 alpine4\")),mdx(\"li\",{parentName:\"ol\"},\"PING alpine4 (172.18.0.4): 56 data bytes\"),mdx(\"li\",{parentName:\"ol\"},\"64 bytes from 172.18.0.4: seq=0 ttl=64 time=0.033 ms\"),mdx(\"li\",{parentName:\"ol\"},\"64 bytes from 172.18.0.4: seq=1 ttl=64 time=0.064 ms\"),mdx(\"li\",{parentName:\"ol\"},\"--- alpine4 ping statistics ---\"),mdx(\"li\",{parentName:\"ol\"},\"2 packets transmitted, 2 packets received, 0% packet loss\"),mdx(\"li\",{parentName:\"ol\"},\"round-trip min/avg/max = 0.033/0.048/0.064 ms\"),mdx(\"li\",{parentName:\"ol\"},\"As a final test, make sure your containers can all connect to the internet by pinging\\xA0google.com. You are already attached to\\xA0alpine4\\xA0so start by trying from there. Next, detach from\\xA0alpine4and connect to\\xA0alpine3\\xA0(which is only attached to the\\xA0bridge\\xA0network) and try again. Finally, connect to\\xA0alpine1\\xA0(which is only connected to the\\xA0alpine-net\\xA0network) and try again.\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"h1\",{parentName:\"li\"},\"ping -c 2 google.com\")),mdx(\"li\",{parentName:\"ol\"},\"PING google.com (172.217.3.174): 56 data bytes\"),mdx(\"li\",{parentName:\"ol\"},\"64 bytes from 172.217.3.174: seq=0 ttl=41 time=9.778 ms\"),mdx(\"li\",{parentName:\"ol\"},\"64 bytes from 172.217.3.174: seq=1 ttl=41 time=9.634 ms\"),mdx(\"li\",{parentName:\"ol\"},\"--- google.com ping statistics ---\"),mdx(\"li\",{parentName:\"ol\"},\"2 packets transmitted, 2 packets received, 0% packet loss\"),mdx(\"li\",{parentName:\"ol\"},\"round-trip min/avg/max = 9.634/9.706/9.778 ms\"),mdx(\"li\",{parentName:\"ol\"},\"CTRL+p CTRL+q\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker container attach alpine3\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"h1\",{parentName:\"li\"},\"ping -c 2 google.com\")),mdx(\"li\",{parentName:\"ol\"},\"PING google.com (172.217.3.174): 56 data bytes\"),mdx(\"li\",{parentName:\"ol\"},\"64 bytes from 172.217.3.174: seq=0 ttl=41 time=9.706 ms\"),mdx(\"li\",{parentName:\"ol\"},\"64 bytes from 172.217.3.174: seq=1 ttl=41 time=9.851 ms\"),mdx(\"li\",{parentName:\"ol\"},\"--- google.com ping statistics ---\"),mdx(\"li\",{parentName:\"ol\"},\"2 packets transmitted, 2 packets received, 0% packet loss\"),mdx(\"li\",{parentName:\"ol\"},\"round-trip min/avg/max = 9.706/9.778/9.851 ms\"),mdx(\"li\",{parentName:\"ol\"},\"CTRL+p CTRL+q\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker container attach alpine1\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"h1\",{parentName:\"li\"},\"ping -c 2 google.com\")),mdx(\"li\",{parentName:\"ol\"},\"PING google.com (172.217.3.174): 56 data bytes\"),mdx(\"li\",{parentName:\"ol\"},\"64 bytes from 172.217.3.174: seq=0 ttl=41 time=9.606 ms\"),mdx(\"li\",{parentName:\"ol\"},\"64 bytes from 172.217.3.174: seq=1 ttl=41 time=9.603 ms\"),mdx(\"li\",{parentName:\"ol\"},\"--- google.com ping statistics ---\"),mdx(\"li\",{parentName:\"ol\"},\"2 packets transmitted, 2 packets received, 0% packet loss\"),mdx(\"li\",{parentName:\"ol\"},\"round-trip min/avg/max = 9.603/9.604/9.606 ms\"),mdx(\"li\",{parentName:\"ol\"},\"CTRL+p CTRL+q\"),mdx(\"li\",{parentName:\"ol\"},\"Stop and remove all containers and the\\xA0alpine-net\\xA0network.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker container stop alpine1 alpine2 alpine3 alpine4\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker container rm alpine1 alpine2 alpine3 alpine4\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker network rm alpine-net\")),mdx(\"h4\",null,\"Other networking tutorials\"),mdx(\"p\",null,\"Now that you have completed the networking tutorials for standalone containers, you might want to run through these other networking tutorials:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/network-tutorial-host/\"}),\"Host networking tutorial\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/network-tutorial-overlay/\"}),\"Overlay networking tutorial\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/network-tutorial-macvlan/\"}),\"Macvlan networking tutorial\"))),mdx(\"h3\",null,\"Networking using the host network\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA02 minutes\")),mdx(\"p\",null,\"This series of tutorials deals with networking standalone containers which bind directly to the Docker host's network, with no network isolation. For other networking topics, see the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/network/\"}),\"overview\"),\".\"),mdx(\"h4\",null,\"Goal\"),mdx(\"p\",null,\"The goal of this tutorial is to start a\\xA0nginx\\xA0container which binds directly to port 80 on the Docker host. From a networking point of view, this is the same level of isolation as if the\\xA0nginx\\xA0process were running directly on the Docker host and not in a container. However, in all other ways, such as storage, process namespace, and user namespace, the\\xA0nginx\\xA0process is isolated from the host.\"),mdx(\"h4\",null,\"Prerequisites\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"This procedure requires port 80 to be available on the Docker host. To make Nginx listen on a different port, see the\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://hub.docker.com/_/nginx/\"}),\"documentation for the\\xA0nginx\\xA0image\")),mdx(\"li\",{parentName:\"ul\"},\"The\\xA0host\\xA0networking driver only works on Linux hosts, and is not supported on Docker for Mac, Docker for Windows, or Docker EE for Windows Server.\")),mdx(\"h4\",null,\"Procedure\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Create and start the container as a detached process.\"),mdx(\"li\",{parentName:\"ol\"},\"docker run --rm -itd --network host --name my_nginx nginx\"),mdx(\"li\",{parentName:\"ol\"},\"Access Nginx by browsing to\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"http://localhost/\"}),\"http://localhost:80/\"),\".\"),mdx(\"li\",{parentName:\"ol\"},\"Examine your network stack using the following commands:\",mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},\"Examine all network interfaces and verify that a new one was not created.\"),mdx(\"li\",{parentName:\"ul\"},\"ip addr show\"),mdx(\"li\",{parentName:\"ul\"},\"Verify which process is bound to port 80, using the\\xA0netstat\\xA0command. You need to use\\xA0sudo\\xA0because the process is owned by the Docker daemon user and you otherwise won't be able to see its name or PID.\"),mdx(\"li\",{parentName:\"ul\"},\"sudo netstat -tulpn | grep :80\"))),mdx(\"li\",{parentName:\"ol\"},\"Stop the container.\"),mdx(\"li\",{parentName:\"ol\"},\"docker container stop my_nginx\"),mdx(\"li\",{parentName:\"ol\"},\"docker container rm my_nginx\")),mdx(\"h4\",null,\"Other networking tutorials\"),mdx(\"p\",null,\"Now that you have completed the networking tutorials for standalone containers, you might want to run through these other networking tutorials:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/network-tutorial-standalone/\"}),\"Standalone networking tutorial\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/network-tutorial-overlay/\"}),\"Overlay networking tutorial\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/network-tutorial-macvlan/\"}),\"Macvlan networking tutorial\"))),mdx(\"h3\",null,\"Networking with overlay networks\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA021 minutes\")),mdx(\"p\",null,\"This series of tutorials deals with networking for swarm services. For networking with standalone containers, see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/network/network-tutorial-standalone/\"}),\"Networking with standalone containers\"),\". If you need to learn more about Docker networking in general, see the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/network/\"}),\"overview\"),\".\"),mdx(\"p\",null,\"This topic includes four different tutorials. You can run each of them on Linux, Windows, or a Mac, but for the last two, you need a second Docker host running elsewhere.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/network-tutorial-overlay/#use-the-default-overlay-network\"}),\"Use the default overlay network\"),\"\\xA0demonstrates how to use the default overlay network that Docker sets up for you automatically when you initialize or join a swarm. This network is not the best choice for production systems.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/network-tutorial-overlay/#use-a-user-defined-overlay-network\"}),\"Use user-defined overlay networks\"),\"\\xA0shows how to create and use your own custom overlay networks, to connect services. This is recommended for services running in production.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/network-tutorial-overlay/#use-an-overlay-network-for-standalone-containers\"}),\"Use an overlay network for standalone containers\"),\"\\xA0shows how to communicate between standalone containers on different Docker daemons using an overlay network.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/network-tutorial-overlay/#communicate-between-a-container-and-a-swarm-service\"}),\"Communicate between a container and a swarm service\"),\"\\xA0sets up communication between a standalone container and a swarm service, using an attachable overlay network. This is supported in Docker 17.06 and higher.\")),mdx(\"h4\",null,\"Prerequisites\"),mdx(\"p\",null,\"These requires you to have at least a single-node swarm, which means that you have started Docker and run\\xA0docker swarm init\\xA0on the host. You can run the examples on a multi-node swarm as well.\"),mdx(\"p\",null,\"The last example requires Docker 17.06 or higher.\"),mdx(\"h4\",null,\"Use the default overlay network\"),mdx(\"p\",null,\"In this example, you start an\\xA0alpine\\xA0service and examine the characteristics of the network from the point of view of the individual service containers.\"),mdx(\"p\",null,\"This tutorial does not go into operation-system-specific details about how overlay networks are implemented, but focuses on how the overlay functions from the point of view of a service.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Prerequisites\")),mdx(\"p\",null,\"This tutorial requires three physical or virtual Docker hosts which can all communicate with one another, all running new installations of Docker 17.03 or higher. This tutorial assumes that the three hosts are running on the same network with no firewall involved.\"),mdx(\"p\",null,\"These hosts will be referred to as\\xA0manager,\\xA0worker-1, and\\xA0worker-2. The\\xA0manager\\xA0host will function as both a manager and a worker, which means it can both run service tasks and manage the swarm.\\xA0worker-1\\xA0and\\xA0worker-2\\xA0will function as workers only,\"),mdx(\"p\",null,\"If you don't have three hosts handy, an easy solution is to set up three Ubuntu hosts on a cloud provider such as Amazon EC2, all on the same network with all communications allowed to all hosts on that network (using a mechanism such as EC2 security groups), and then to follow the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/installation/linux/docker-ce/ubuntu/\"}),\"installation instructions for Docker CE on Ubuntu\"),\".\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Walkthrough\")),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"CREATE THE SWARM\")),mdx(\"p\",null,\"At the end of this procedure, all three Docker hosts will be joined to the swarm and will be connected together using an overlay network called\\xA0ingress.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"On\\xA0master. initialize the swarm. If the host only has one network interface, the\\xA0--advertise-addr\\xA0flag is optional.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker swarm init --advertise-addr=\",mdx(\"inlineCode\",{parentName:\"li\"},\"<IP-ADDRESS-OF-MANAGER>\"))),mdx(\"p\",null,\"Make a note of the text that is printed, as this contains the token that you will use to join\\xA0worker-1\\xA0and\\xA0worker-2\\xA0to the swarm. It is a good idea to store the token in a password manager.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"On\\xA0worker-1, join the swarm. If the host only has one network interface, the\\xA0--advertise-addrflag is optional.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker swarm --join --token \",mdx(\"inlineCode\",{parentName:\"li\"},\"<TOKEN>\"),\" \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--advertise-addr \",mdx(\"inlineCode\",{parentName:\"li\"},\"<IP-ADDRESS-OF-WORKER-1>\"),\" \\\\\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<IP-ADDRESS-OF-MANAGER>\"),\":2377\"),mdx(\"li\",{parentName:\"ol\"},\"On\\xA0worker-2, join the swarm. If the host only has one network interface, the\\xA0--advertise-addrflag is optional.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker swarm --join --token \",mdx(\"inlineCode\",{parentName:\"li\"},\"<TOKEN>\"),\" \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--advertise-addr \",mdx(\"inlineCode\",{parentName:\"li\"},\"<IP-ADDRESS-OF-WORKER-2>\"),\" \\\\\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<IP-ADDRESS-OF-MANAGER>\"),\":2377\"),mdx(\"li\",{parentName:\"ol\"},\"On\\xA0manager, list all the nodes. This command can only be done from a manager.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker node ls\"),mdx(\"li\",{parentName:\"ol\"},\"ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS\"),mdx(\"li\",{parentName:\"ol\"},\"d68ace5iraw6whp7llvgjpu48 * ip-172-31-34-146 Ready Active Leader\"),mdx(\"li\",{parentName:\"ol\"},\"nvp5rwavvb8lhdggo8fcf7plg ip-172-31-35-151 Ready Active\"),mdx(\"li\",{parentName:\"ol\"},\"ouvx2l7qfcxisoyms8mtkgahw ip-172-31-36-89 Ready Active\")),mdx(\"p\",null,\"You can also use the\\xA0--filter\\xA0flag to filter by role:\"),mdx(\"p\",null,\"$ docker node ls --filter role=manager\"),mdx(\"p\",null,\"ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS\"),mdx(\"p\",null,\"d68ace5iraw6whp7llvgjpu48 * ip-172-31-34-146 Ready Active Leader\"),mdx(\"p\",null,\"$ docker node ls --filter role=worker\"),mdx(\"p\",null,\"ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS\"),mdx(\"p\",null,\"nvp5rwavvb8lhdggo8fcf7plg ip-172-31-35-151 Ready Active\"),mdx(\"p\",null,\"ouvx2l7qfcxisoyms8mtkgahw ip-172-31-36-89 Ready Active\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"List the Docker networks on\\xA0manager,\\xA0worker-1, and\\xA0worker-2\\xA0and notice that each of them now has an overlay network called\\xA0ingress\\xA0and a bridge network called\\xA0docker_gwbridge. Only the listing for\\xA0manager\\xA0is shown here:\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker network ls\"),mdx(\"li\",{parentName:\"ol\"},\"NETWORK ID NAME DRIVER SCOPE\"),mdx(\"li\",{parentName:\"ol\"},\"495c570066be bridge bridge local\"),mdx(\"li\",{parentName:\"ol\"},\"961c6cae9945 docker_gwbridge bridge local\"),mdx(\"li\",{parentName:\"ol\"},\"ff35ceda3643 host host local\"),mdx(\"li\",{parentName:\"ol\"},\"trtnl4tqnc3n ingress overlay swarm\"),mdx(\"li\",{parentName:\"ol\"},\"c8357deec9cb none null local\")),mdx(\"p\",null,\"The\\xA0docker_gwbridge\\xA0connects the\\xA0ingress\\xA0network to the Docker host's network interface so that traffic can flow to and from swarm managers and workers. If you create swarm services and do not specify a network, they are connected to the\\xA0ingress\\xA0network. It is recommended that you use separate overlay networks for each application or group of applications which will work together. In the next procedure, you will create two overlay networks and connect a service to each of them.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"CREATE THE SERVICES\")),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"On\\xA0manager, create a new overlay network called\\xA0nginx-net:\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker network create -d overlay nginx-net\")),mdx(\"p\",null,\"You don't need to create the overlay network on the other nodes, beacause it will be automatically created when one of those nodes starts running a service task which requires it.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"On\\xA0manager, create a 5-replica Nginx service connected to\\xA0nginx-net. The service will publish port 80 to the outside world. All of the service task containers can communicate with each other without opening any ports.\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": Services can only be created on a manager.\"),mdx(\"p\",null,\"$ docker service create \\\\\"),mdx(\"p\",null,\"--name my-nginx \\\\\"),mdx(\"p\",null,\"--publish target=80,published=80 \\\\\"),mdx(\"p\",null,\"--replicas=5 \\\\\"),mdx(\"p\",null,\"--network nginx-net \\\\\"),mdx(\"p\",null,\"nginx\"),mdx(\"p\",null,\"The default publish mode of\\xA0ingress, which is used when you do not specify a\\xA0mode\\xA0for the\\xA0--publish\\xA0flag, means that if you browse to port 80 on\\xA0manager,\\xA0worker-1, or\\xA0worker-2, you will be connected to port 80 on one of the 5 service tasks, even if no tasks are currently running on the node you browse to. If you want to publish the port using\\xA0host\\xA0mode, you can add\\xA0mode=host\\xA0to the\\xA0--publish\\xA0output. However, you should also use\\xA0--mode global\\xA0instead of\\xA0--replicas=5\\xA0in this case, since only one service task can bind a given port on a given node.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Run\\xA0docker service ls\\xA0to monitor the progress of service bring-up, which may take a few seconds.\"),mdx(\"li\",{parentName:\"ol\"},\"Inspect the\\xA0nginx-net\\xA0network on\\xA0master,\\xA0worker-1, and\\xA0worker-2. Remember that you did not need to create it manually on\\xA0worker-1\\xA0and\\xA0worker-2\\xA0because Docker created it for you. The output will be long, but notice the\\xA0Containers\\xA0and\\xA0Peers\\xA0sections.\\xA0Containers\\xA0lists all service tasks (or standalone containers) connected to the overlay network from that host.\"),mdx(\"li\",{parentName:\"ol\"},\"From\\xA0manager, inspect the service using\\xA0docker service inspect my-nginx\\xA0and notice the information about the ports and endpoints used by the service.\"),mdx(\"li\",{parentName:\"ol\"},\"Create a new network\\xA0nginx-net-2, then update the service to use this network instead of\\xA0nginx-net:\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker network create -d overlay nginx-net-2\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker service update \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--network-add nginx-net-2 \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--network-rm nginx-net \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"my-nginx\"),mdx(\"li\",{parentName:\"ol\"},\"Run\\xA0docker service ls\\xA0to verify that the service has been updated and all tasks have been redeployed. Run\\xA0docker network inspect nginx-net\\xA0to verify that no containers are connected to it. Run the same command for\\xA0nginx-net-2\\xA0and notice that all the service task containers are connected to it.\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": Even though overlay networks are automatically created on swarm worker nodes as needed, they are not automatically removed.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Clean up the service and the networks. From\\xA0manager, run the following commands. The manager will direct the workers to remove the networks automatically.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker service rm my-nginx\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker network rm nginx-net nginx-net-2\")),mdx(\"h4\",null,\"Use a user-defined overlay network\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Prerequisites\")),mdx(\"p\",null,\"This tutorial assumes the swarm is already set up and you are on a manager.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Walkthrough\")),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Create the user-defined overlay network.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker network create -d overlay my-overlay\"),mdx(\"li\",{parentName:\"ol\"},\"Start a service using the overlay network and publishing port 80 to port 8080 on the Docker host.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker service create \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--name my-nginx \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--network my-overlay \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--replicas 1 \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--publish published=8080,target=80 \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"nginx:latest\"),mdx(\"li\",{parentName:\"ol\"},\"Run\\xA0docker network inspect my-overlay\\xA0and verify that the\\xA0my-nginx\\xA0service task is connected to it, by looking at the\\xA0Containers\\xA0section.\"),mdx(\"li\",{parentName:\"ol\"},\"Remove the service and the network.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker service rm my-nginx\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker network rm my-overlay\")),mdx(\"h4\",null,\"Use an overlay network for standalone containers\"),mdx(\"p\",null,\"This example does the following:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"initializes a swarm on\\xA0host1\"),mdx(\"li\",{parentName:\"ul\"},\"joins\\xA0host2\\xA0to the swarm\"),mdx(\"li\",{parentName:\"ul\"},\"creates an attachable overlay network\"),mdx(\"li\",{parentName:\"ul\"},\"creates an\\xA0alpine\\xA0service with 3 replicas, connected to the overlay network\"),mdx(\"li\",{parentName:\"ul\"},\"creates a single\\xA0alpine\\xA0container on\\xA0host2, which is also attached to the overlay network\"),mdx(\"li\",{parentName:\"ul\"},\"proves that the standalone container can communicate with the service tasks, and vice versa.\")),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Prerequisites\")),mdx(\"p\",null,\"For this test, you need two different Docker hosts, which can communicate with each other. Each host needs to be running Docker 17.06 or higher. The following ports must be open between the two Docker hosts:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"TCP port 2377\"),mdx(\"li\",{parentName:\"ul\"},\"TCP and UDP port 7946\"),mdx(\"li\",{parentName:\"ul\"},\"UDP port 4789\")),mdx(\"p\",null,\"One easy way to set this is up is to have two VMs (either local or on a cloud provider like AWS), each with Docker installed and running. If you're using AWS or a similar cloud computing platform, the easiest configuration is to use a security group which opens all incoming ports between the two hosts and the SSH port from your client's IP address.\"),mdx(\"p\",null,\"This example will refer to the hosts as\\xA0host1\\xA0and\\xA0host2, and the command prompts will be labelled accordingly.\"),mdx(\"p\",null,\"The example uses Linux hosts, but the same commands work on Windows.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Walk-through\")),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Set up the swarm.\",mdx(\"ol\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ol\"},\"On\\xA0host1, run\\xA0docker swarm init, specifying the IP address for the interface which will communicate with the other host (for instance, the private IP address on AWS).\"),mdx(\"li\",{parentName:\"ol\"},\"(host1) $ docker swarm init --advertise-addr 192.0.2.1\"),mdx(\"li\",{parentName:\"ol\"},\"Swarm initialized: current node (l9ozqg3m6gysdnemmhoychk9p) is now a manager.\"),mdx(\"li\",{parentName:\"ol\"},\"To add a worker to this swarm, run the following command:\"),mdx(\"li\",{parentName:\"ol\"},\"docker swarm join \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--token SWMTKN-1-3mtj3k6tkuts4cpecpgjdvgj1u5jre5zwgiapox0tcjs1trqim-bfwb0ve6kf42go1rznrn0lycx \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"192.0.2.1:2377\"),mdx(\"li\",{parentName:\"ol\"},\"To add a manager to this swarm, run \\\\'docker swarm join-token manager\\\\' and follow the instructions.\")))),mdx(\"p\",null,\"The swarm is initialized and\\xA0host1\\xA0runs both manager and worker roles.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"ol\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ol\"},\"Copy the\\xA0docker swarm join\\xA0command. Open a new terminal, connect to\\xA0host2, and execute the command. Add the\\xA0--advertise-addr\\xA0flag, specifying the IP address for the interface that will communicate with the other host (for instance, the private IP address on AWS). The last argument is the IP address of\\xA0host1.\"),mdx(\"li\",{parentName:\"ol\"},\"(host2) $ docker swarm join \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--token SWMTKN-1-3mtj3k6tkuts4cpecpgjdvgj1u5jre5zwgiapox0tcjs1trqim-bfwb0ve6kf42go1rznrn0lycx \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--advertise-addr 192.0.2.2:2377 \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"192.0.2.1:2377\")))),mdx(\"p\",null,\"If the command succeeds, the following message is shown:\"),mdx(\"p\",null,\"This node joined a swarm as a worker.\"),mdx(\"p\",null,\"Otherwise, the\\xA0docker swarm join\\xA0command will time out. In this case, run\\xA0docker swarm leave --force\\xA0on\\xA0node2, verify your network and firewall settings, and try again.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Create an attachable overlay network called\\xA0test-net\\xA0on\\xA0host1.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker network create --driver=overlay --attachable test-net\")),mdx(\"p\",null,\"You don't need to manually create the overlay on\\xA0host2\\xA0because it will be created when a container or service tries to connect to it from\\xA0host2.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"On\\xA0host1, start a container that connects to\\xA0test-net:\"),mdx(\"li\",{parentName:\"ol\"},\"(host1) $ docker run -dit \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--name alpine1 \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--network test-net \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"alpine\"),mdx(\"li\",{parentName:\"ol\"},\"On\\xA0host2, start a container that connects to\\xA0test-net:\"),mdx(\"li\",{parentName:\"ol\"},\"(host2) $ docker run -dit \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--name alpine2 \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--network test-net \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"alpine\")),mdx(\"p\",null,\"The\\xA0-dit\\xA0flags mean to start the container detached (in the background), interactive (with the ability to type into it), and with a TTY (so you can see the input and output).\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": There is nothing to prevent you from using the same container name on multiple hosts, but automatic service discovery will not work if you do, and you will need to refer to the containers by IP address.\"),mdx(\"p\",null,\"Verify that\\xA0test-net\\xA0was created on\\xA0host2:\"),mdx(\"p\",null,\"(host2) $ docker network ls\"),mdx(\"p\",null,\"NETWORK ID NAME DRIVER SCOPE\"),mdx(\"p\",null,\"6e327b25443d bridge bridge local\"),mdx(\"p\",null,\"10eda0b42471 docker_gwbridge bridge local\"),mdx(\"p\",null,\"1b16b7e2a72c host host local\"),mdx(\"p\",null,\"lgsov6d3c6hh ingress overlay swarm\"),mdx(\"p\",null,\"6af747d9ae1e none null local\"),mdx(\"p\",null,\"uw9etrdymism test-net overlay swarm\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Remember that you created\\xA0alpine1\\xA0from\\xA0host1\\xA0and\\xA0alpine2\\xA0from\\xA0host2. Now, attach to\\xA0alpine2\\xA0from\\xA0host1:\"),mdx(\"li\",{parentName:\"ol\"},\"(host1) $ docker container attach alpine2\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"h1\",{parentName:\"li\"}))),mdx(\"p\",null,\"Automatic service discovery worked between two containers across the overlay network!\"),mdx(\"p\",null,\"Within the attached session, try pinging\\xA0alpine1\\xA0from\\xA0alpine2:\"),mdx(\"h1\",null,\"ping -c 2 alpine1\"),mdx(\"p\",null,\"PING alpine1 (10.0.0.2): 56 data bytes\"),mdx(\"p\",null,\"64 bytes from 10.0.0.2: seq=0 ttl=64 time=0.523 ms\"),mdx(\"p\",null,\"64 bytes from 10.0.0.2: seq=1 ttl=64 time=0.547 ms\"),mdx(\"p\",null,\"--- alpine1 ping statistics ---\"),mdx(\"p\",null,\"2 packets transmitted, 2 packets received, 0% packet loss\"),mdx(\"p\",null,\"round-trip min/avg/max = 0.523/0.535/0.547 ms\"),mdx(\"p\",null,\"This proves that the two containers can communicate with each other using the overlay network which is connecting\\xA0host1\\xA0and\\xA0host2.\"),mdx(\"p\",null,\"Detach from\\xA0alpine2\\xA0using the\\xA0CTRL\\xA0+\\xA0P\\xA0CTRL\\xA0+\\xA0Q\\xA0sequence.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Stop the containers and remove\\xA0test-net\\xA0from each host. Because the Docker daemons are operating independently and these are standalone containers, you need to run the commands on the individual hosts.\"),mdx(\"li\",{parentName:\"ol\"},\"(host1) $ docker container stop alpine1\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker container rm alpine1\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker network rm test-net\"),mdx(\"li\",{parentName:\"ol\"},\"(host2) $ docker container stop alpine2\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker container rm alpine2\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker network rm test-net\")),mdx(\"h4\",null,\"Communicate between a container and a swarm service\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Prerequisites\")),mdx(\"p\",null,\"You need Docker 17.06 or higher for this example.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Walkthrough\")),mdx(\"p\",null,\"In this example, you start two different\\xA0alpine\\xA0containers on the same Docker host and do some tests to understand how they communicate with each other. You need to have Docker installed and running.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Open a terminal window. List current networks before you do anything else. Here's what you should see if you've never added a network or initialized a swarm on this Docker daemon. You may see different networks, but you should at least see these (the network IDs will be different):\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker network ls\"),mdx(\"li\",{parentName:\"ol\"},\"NETWORK ID NAME DRIVER SCOPE\"),mdx(\"li\",{parentName:\"ol\"},\"17e324f45964 bridge bridge local\"),mdx(\"li\",{parentName:\"ol\"},\"6ed54d316334 host host local\"),mdx(\"li\",{parentName:\"ol\"},\"7092879f2cc8 none null local\")),mdx(\"p\",null,\"The default\\xA0bridge\\xA0network is listed, along with\\xA0host\\xA0and\\xA0none. The latter two are not fully-fledged networks, but are used to start a container connected directly to the Docker daemon host's networking stack, or to start a container with no network devices.\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"This tutorial will connect two containers to the\\xA0bridge\\xA0network.\")),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Start two\\xA0alpine\\xA0containers running\\xA0ash, which is Alpine's default shell rather than\\xA0bash. The\\xA0-dit\\xA0flags mean to start the container detached (in the background), interactive (with the ability to type into it), and with a TTY (so you can see the input and output). Since you are starting it detached, you won't be connected to the container right away. Instead, the container's ID will be printed. Because you have not specified any\\xA0--network\\xA0flags, the containers connect to the default\\xA0bridge\\xA0network.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker run -dit --name alpine1 alpine ash\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker run -dit --name alpine2 alpine ash\")),mdx(\"p\",null,\"Check that both containers are actually started:\"),mdx(\"p\",null,\"$ docker container ls\"),mdx(\"p\",null,\"CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES\"),mdx(\"p\",null,\"602dbf1edc81 alpine \\\"ash\\\" 4 seconds ago Up 3 seconds alpine2\"),mdx(\"p\",null,\"da33b7aa74b0 alpine \\\"ash\\\" 17 seconds ago Up 16 seconds alpine1\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Inspect the\\xA0bridge\\xA0network to see what containers are connected to it.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker network inspect bridge\"),mdx(\"li\",{parentName:\"ol\"},\"[\"),mdx(\"li\",{parentName:\"ol\"},\"{\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Name\\\": \\\"bridge\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Id\\\": \\\"17e324f459648a9baaea32b248d3884da102dde19396c25b30ec800068ce6b10\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Created\\\": \\\"2017-06-22T20:27:43.826654485Z\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Scope\\\": \\\"local\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Driver\\\": \\\"bridge\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"EnableIPv6\\\": false,\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"IPAM\\\": {\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Driver\\\": \\\"default\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Options\\\": null,\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Config\\\": [\"),mdx(\"li\",{parentName:\"ol\"},\"{\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Subnet\\\": \\\"172.17.0.0/16\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Gateway\\\": \\\"172.17.0.1\\\"\"),mdx(\"li\",{parentName:\"ol\"},\"}\"),mdx(\"li\",{parentName:\"ol\"},\"]\"),mdx(\"li\",{parentName:\"ol\"},\"},\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Internal\\\": false,\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Attachable\\\": false,\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Containers\\\": {\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"602dbf1edc81813304b6cf0a647e65333dc6fe6ee6ed572dc0f686a3307c6a2c\\\": {\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Name\\\": \\\"alpine2\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"EndpointID\\\": \\\"03b6aafb7ca4d7e531e292901b43719c0e34cc7eef565b38a6bf84acf50f38cd\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"MacAddress\\\": \\\"02:42:ac:11:00:03\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"IPv4Address\\\": \\\"172.17.0.3/16\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"IPv6Address\\\": \\\"\\\"\"),mdx(\"li\",{parentName:\"ol\"},\"},\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"da33b7aa74b0bf3bda3ebd502d404320ca112a268aafe05b4851d1e3312ed168\\\": {\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Name\\\": \\\"alpine1\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"EndpointID\\\": \\\"46c044a645d6afc42ddd7857d19e9dcfb89ad790afb5c239a35ac0af5e8a5bc5\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"MacAddress\\\": \\\"02:42:ac:11:00:02\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"IPv4Address\\\": \\\"172.17.0.2/16\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"IPv6Address\\\": \\\"\\\"\"),mdx(\"li\",{parentName:\"ol\"},\"}\"),mdx(\"li\",{parentName:\"ol\"},\"},\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Options\\\": {\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"com.docker.network.bridge.default_bridge\\\": \\\"true\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"com.docker.network.bridge.enable_icc\\\": \\\"true\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"com.docker.network.bridge.enable_ip_masquerade\\\": \\\"true\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"com.docker.network.bridge.host_binding_ipv4\\\": \\\"0.0.0.0\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"com.docker.network.bridge.name\\\": \\\"docker0\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"com.docker.network.driver.mtu\\\": \\\"1500\\\"\"),mdx(\"li\",{parentName:\"ol\"},\"},\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Labels\\\": {}\"),mdx(\"li\",{parentName:\"ol\"},\"}\"),mdx(\"li\",{parentName:\"ol\"},\"]\")),mdx(\"p\",null,\"Near the top, information about the\\xA0bridge\\xA0network is listed, including the IP address of the gateway between the Docker host and the\\xA0bridge\\xA0network (172.17.0.1). Under the\\xA0Containers\\xA0key, each connected container is listed, along with information about its IP address (172.17.0.2\\xA0for\\xA0alpine1\\xA0and\\xA0172.17.0.3\\xA0for\\xA0alpine2).\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"The containers are running in the background. Use the\\xA0docker attach\\xA0command to connect to\\xA0alpine1.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker attach alpine1\"),mdx(\"li\",{parentName:\"ol\"},\"/ #\")),mdx(\"p\",null,\"The prompt changes to\\xA0#\\xA0to indicate that you are the\\xA0root\\xA0user within the container. Use the\\xA0ip addr show\\xA0command to show the network interfaces for\\xA0alpine1\\xA0as they look from within the container:\"),mdx(\"h1\",null,\"ip addr show\"),mdx(\"p\",null,\"1: lo: \",mdx(\"inlineCode\",{parentName:\"p\"},\"<LOOPBACK,UP,LOWER_UP>\"),\" mtu 65536 qdisc noqueue state UNKNOWN qlen 1\"),mdx(\"p\",null,\"link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\"),mdx(\"p\",null,\"inet 127.0.0.1/8 scope host lo\"),mdx(\"p\",null,\"valid_lft forever preferred_lft forever\"),mdx(\"p\",null,\"inet6 ::1/128 scope host\"),mdx(\"p\",null,\"valid_lft forever preferred_lft forever\"),mdx(\"p\",null,\"27: eth0\\\\@if28: \",mdx(\"inlineCode\",{parentName:\"p\"},\"<BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN>\"),\" mtu 1500 qdisc noqueue state UP\"),mdx(\"p\",null,\"link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff\"),mdx(\"p\",null,\"inet 172.17.0.2/16 scope global eth0\"),mdx(\"p\",null,\"valid_lft forever preferred_lft forever\"),mdx(\"p\",null,\"inet6 fe80::42:acff:fe11:2/64 scope link\"),mdx(\"p\",null,\"valid_lft forever preferred_lft forever\"),mdx(\"p\",null,\"The first interface is the loopback device. Ignore it for now. Notice that the second interface has the IP address\\xA0172.17.0.2, which is the same address shown for\\xA0alpine1\\xA0in the previous step.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"From within\\xA0alpine1, make sure you can connect to the internet by pinging\\xA0google.com. The\\xA0-c 2\\xA0flag limits the command two two\\xA0ping\\xA0attempts.\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"h1\",{parentName:\"li\"},\"ping -c 2 google.com\")),mdx(\"li\",{parentName:\"ol\"},\"PING google.com (172.217.3.174): 56 data bytes\"),mdx(\"li\",{parentName:\"ol\"},\"64 bytes from 172.217.3.174: seq=0 ttl=41 time=9.841 ms\"),mdx(\"li\",{parentName:\"ol\"},\"64 bytes from 172.217.3.174: seq=1 ttl=41 time=9.897 ms\"),mdx(\"li\",{parentName:\"ol\"},\"--- google.com ping statistics ---\"),mdx(\"li\",{parentName:\"ol\"},\"2 packets transmitted, 2 packets received, 0% packet loss\"),mdx(\"li\",{parentName:\"ol\"},\"round-trip min/avg/max = 9.841/9.869/9.897 ms\"),mdx(\"li\",{parentName:\"ol\"},\"Now try to ping the second container. First, ping it by its IP address,\\xA0172.17.0.3:\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"h1\",{parentName:\"li\"},\"ping -c 2 172.17.0.3\")),mdx(\"li\",{parentName:\"ol\"},\"PING 172.17.0.3 (172.17.0.3): 56 data bytes\"),mdx(\"li\",{parentName:\"ol\"},\"64 bytes from 172.17.0.3: seq=0 ttl=64 time=0.086 ms\"),mdx(\"li\",{parentName:\"ol\"},\"64 bytes from 172.17.0.3: seq=1 ttl=64 time=0.094 ms\"),mdx(\"li\",{parentName:\"ol\"},\"--- 172.17.0.3 ping statistics ---\"),mdx(\"li\",{parentName:\"ol\"},\"2 packets transmitted, 2 packets received, 0% packet loss\"),mdx(\"li\",{parentName:\"ol\"},\"round-trip min/avg/max = 0.086/0.090/0.094 ms\")),mdx(\"p\",null,\"This succeeds. Next, try pinging the\\xA0alpine2\\xA0container by container name. This will fail.\"),mdx(\"h1\",null,\"ping -c 2 alpine2\"),mdx(\"p\",null,\"ping: bad address \\\\'alpine2\\\\'\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Detach from\\xA0alpine2\\xA0without stopping it by using the detach sequence,\\xA0CTRL\\xA0+\\xA0p\\xA0CTRL\\xA0+\\xA0q\\xA0(hold down\\xA0CTRL\\xA0and type\\xA0p\\xA0followed by\\xA0q). If you wish, attach to\\xA0alpine2\\xA0and repeat steps 4, 5, and 6 there, substituting\\xA0alpine1\\xA0for\\xA0alpine2.\"),mdx(\"li\",{parentName:\"ol\"},\"Stop and remove both containers.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker container stop alpine1 alpine2\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker container rm alpine1 alpine2\")),mdx(\"p\",null,\"Remember, the default\\xA0bridge\\xA0network is not recommended for production. To learn about user-defined bridge networks, continue to the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/network/network-tutorial-overlay/#use-user-defined-bridge-networks\"}),\"next tutorial\"),\".\"),mdx(\"h4\",null,\"Other networking tutorials\"),mdx(\"p\",null,\"Now that you have completed the networking tutorials for overlay networks, you might want to run through these other networking tutorials:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/network-tutorial-host/\"}),\"Host networking tutorial\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/network-tutorial-standalone/\"}),\"Standalone networking tutorial\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/network-tutorial-macvlan/\"}),\"Macvlan networking tutorial\"))),mdx(\"h3\",null,\"Networking using a macvlan network\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA05 minutes\")),mdx(\"p\",null,\"This series of tutorials deals with networking standalone containers which connect to\\xA0macvlannetworks. In this type of network, the Docker host accepts requests for multiple MAC addresses at its IP address, and routes those requests to the appropriate container. For other networking topics, see the\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/network/\"}),\"overview\"),\".\"),mdx(\"h4\",null,\"Goal\"),mdx(\"p\",null,\"The goal of these tutorials is to set up a bridged\\xA0macvlan\\xA0network and attach a container to it, then set up an 802.1q trunked\\xA0macvlan\\xA0network and attach a container to it.\"),mdx(\"h4\",null,\"Prerequisites\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Most cloud providers block\\xA0macvlan\\xA0networking. You may need physical access to your networking equipment.\"),mdx(\"li\",{parentName:\"ul\"},\"The\\xA0macvlan\\xA0networking driver only works on Linux hosts, and is not supported on Docker for Mac, Docker for Windows, or Docker EE for Windows Server.\"),mdx(\"li\",{parentName:\"ul\"},\"You need at least version 3.9 of the Linux kernel, and version 4.0 or higher is recommended.\"),mdx(\"li\",{parentName:\"ul\"},\"The examples assume your ethernet interface is\\xA0eth0. If your device has a different name, use that instead.\")),mdx(\"h4\",null,\"Bridge example\"),mdx(\"p\",null,\"In the simple bridge example, your traffic flows through\\xA0eth0\\xA0and Docker routes traffic to your container using its MAC address. To network devices on your network, your container appears to be physically attached to the network.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Create a\\xA0macvlan\\xA0network called\\xA0my-macvlan-net. Modify the\\xA0subnet,\\xA0gateway, and\\xA0parentvalues to values that make sense in your environment.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker network create -d macvlan \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--subnet=172.16.86.0/24 \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--gateway=172.16.86.1 \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"-o parent=eth0 \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"my-macvlan-net\")),mdx(\"p\",null,\"You can use\\xA0docker network ls\\xA0and\\xA0docker network inspect pub_net\\xA0commands to verify that the network exists and is a\\xA0macvlan\\xA0network.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Start an\\xA0alpine\\xA0container and attach it to the\\xA0my-macvlan-net\\xA0network. The\\xA0-dit\\xA0flags start the container in the background but allow you to attach to it. The\\xA0--rm\\xA0flag means the container is removed when it is stopped.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker run --rm -itd \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--network my-macvlan-net \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--name my-macvlan-alpine \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"alpine:latest \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"ash\"),mdx(\"li\",{parentName:\"ol\"},\"Inspect the\\xA0my-macvlan-alpine\\xA0container and notice the\\xA0MacAddress\\xA0key within the\\xA0Networkskey:\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker container inspect my-macvlan-alpine\"),mdx(\"li\",{parentName:\"ol\"},\"...truncated...\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Networks\\\": {\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"my-macvlan-net\\\": {\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"IPAMConfig\\\": null,\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Links\\\": null,\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Aliases\\\": [\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"bec64291cd4c\\\"\"),mdx(\"li\",{parentName:\"ol\"},\"],\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"NetworkID\\\": \\\"5e3ec79625d388dbcc03dcf4a6dc4548644eb99d58864cf8eee2252dcfc0cc9f\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"EndpointID\\\": \\\"8caf93c862b22f379b60515975acf96f7b54b7cf0ba0fb4a33cf18ae9e5c1d89\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Gateway\\\": \\\"172.16.86.1\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"IPAddress\\\": \\\"172.16.86.2\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"IPPrefixLen\\\": 24,\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"IPv6Gateway\\\": \\\"\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"GlobalIPv6Address\\\": \\\"\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"GlobalIPv6PrefixLen\\\": 0,\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"MacAddress\\\": \\\"02:42:ac:10:56:02\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"DriverOpts\\\": null\"),mdx(\"li\",{parentName:\"ol\"},\"}\"),mdx(\"li\",{parentName:\"ol\"},\"}\"),mdx(\"li\",{parentName:\"ol\"},\"...truncated\"),mdx(\"li\",{parentName:\"ol\"},\"Check out how the container sees its own network interfaces by running a couple of\\xA0docker exec\\xA0commands.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker exec my-macvlan-alpine ip addr show eth0\"),mdx(\"li\",{parentName:\"ol\"},\"9: eth0\\\\@tunl0: \",mdx(\"inlineCode\",{parentName:\"li\"},\"<BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN>\"),\" mtu 1500 qdisc noqueue state UP\"),mdx(\"li\",{parentName:\"ol\"},\"link/ether 02:42:ac:10:56:02 brd ff:ff:ff:ff:ff:ff\"),mdx(\"li\",{parentName:\"ol\"},\"inet 172.16.86.2/24 brd 172.16.86.255 scope global eth0\"),mdx(\"li\",{parentName:\"ol\"},\"valid_lft forever preferred_lft forever\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker exec my-macvlan-alpine ip route\"),mdx(\"li\",{parentName:\"ol\"},\"default via 172.16.86.1 dev eth0\"),mdx(\"li\",{parentName:\"ol\"},\"172.16.86.0/24 dev eth0 scope link src 172.16.86.2\"),mdx(\"li\",{parentName:\"ol\"},\"Stop the container (Docker removes it because of the\\xA0--rm\\xA0flag), and remove the network.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker container stop my-macvlan-alpine\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker network rm my-macvlan-net\")),mdx(\"h4\",null,\"802.1q trunked bridge example\"),mdx(\"p\",null,\"In the 802.1q trunked bridge example, your traffic flows through a sub-interface of\\xA0eth0\\xA0(called\\xA0eth0.10) and Docker routes traffic to your container using its MAC address. To network devices on your network, your container appears to be physically attached to the network.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Create a\\xA0macvlan\\xA0network called\\xA0my-8021q-macvlan-net. Modify the\\xA0subnet,\\xA0gateway, and\\xA0parent\\xA0values to values that make sense in your environment.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker network create -d macvlan \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--subnet=172.16.86.0/24 \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--gateway=172.16.86.1 \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"-o parent=eth0.10 \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"my-8021q-macvlan-net\")),mdx(\"p\",null,\"You can use\\xA0docker network ls\\xA0and\\xA0docker network inspect pub_net\\xA0commands to verify that the network exists, is a\\xA0macvlan\\xA0network, and has parent\\xA0eth0.10. You can use\\xA0ip addr showon the Docker host to verify that the interface\\xA0eth0.10\\xA0exists and has a separate IP address\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Start an\\xA0alpine\\xA0container and attach it to the\\xA0my-8021q-macvlan-net\\xA0network. The\\xA0-dit\\xA0flags start the container in the background but allow you to attach to it. The\\xA0--rm\\xA0flag means the container is removed when it is stopped.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker run --rm -itd \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--network my-8021q-macvlan-net \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--name my-second-macvlan-alpine \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"alpine:latest \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"ash\"),mdx(\"li\",{parentName:\"ol\"},\"Inspect the\\xA0my-second-macvlan-alpine\\xA0container and notice the\\xA0MacAddress\\xA0key within the\\xA0Networks\\xA0key:\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker container inspect my-second-macvlan-alpine\"),mdx(\"li\",{parentName:\"ol\"},\"...truncated...\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Networks\\\": {\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"my-8021q-macvlan-net\\\": {\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"IPAMConfig\\\": null,\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Links\\\": null,\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Aliases\\\": [\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"12f5c3c9ba5c\\\"\"),mdx(\"li\",{parentName:\"ol\"},\"],\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"NetworkID\\\": \\\"c6203997842e654dd5086abb1133b7e6df627784fec063afcbee5893b2bb64db\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"EndpointID\\\": \\\"aa08d9aa2353c68e8d2ae0bf0e11ed426ea31ed0dd71c868d22ed0dcf9fc8ae6\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"Gateway\\\": \\\"172.16.86.1\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"IPAddress\\\": \\\"172.16.86.2\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"IPPrefixLen\\\": 24,\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"IPv6Gateway\\\": \\\"\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"GlobalIPv6Address\\\": \\\"\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"GlobalIPv6PrefixLen\\\": 0,\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"MacAddress\\\": \\\"02:42:ac:10:56:02\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"DriverOpts\\\": null\"),mdx(\"li\",{parentName:\"ol\"},\"}\"),mdx(\"li\",{parentName:\"ol\"},\"}\"),mdx(\"li\",{parentName:\"ol\"},\"...truncated\"),mdx(\"li\",{parentName:\"ol\"},\"Check out how the container sees its own network interfaces by running a couple of\\xA0docker exec\\xA0commands.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker exec my-second-macvlan-alpine ip addr show eth0\"),mdx(\"li\",{parentName:\"ol\"},\"11: eth0\\\\@if10: \",mdx(\"inlineCode\",{parentName:\"li\"},\"<BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN>\"),\" mtu 1500 qdisc noqueue state UP\"),mdx(\"li\",{parentName:\"ol\"},\"link/ether 02:42:ac:10:56:02 brd ff:ff:ff:ff:ff:ff\"),mdx(\"li\",{parentName:\"ol\"},\"inet 172.16.86.2/24 brd 172.16.86.255 scope global eth0\"),mdx(\"li\",{parentName:\"ol\"},\"valid_lft forever preferred_lft forever\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker exec my-second-macvlan-alpine ip route\"),mdx(\"li\",{parentName:\"ol\"},\"default via 172.16.86.1 dev eth0\"),mdx(\"li\",{parentName:\"ol\"},\"172.16.86.0/24 dev eth0 scope link src 172.16.86.2\"),mdx(\"li\",{parentName:\"ol\"},\"Stop the container (Docker removes it because of the\\xA0--rm\\xA0flag), and remove the network.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker container stop my-second-macvlan-alpin\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker network rm my-8021q-macvlan-net\")),mdx(\"h4\",null,\"Other networking tutorials\"),mdx(\"p\",null,\"Now that you have completed the networking tutorial for\\xA0macvlan\\xA0networks, you might want to run through these other networking tutorials:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/network-tutorial-standalone/\"}),\"Standalone networking tutorial\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/network-tutorial-overlay/\"}),\"Overlay networking tutorial\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/network-tutorial-host/\"}),\"Host networking tutorial\"))),mdx(\"h3\",null,\"Configure the Daemon and the Containers\"),mdx(\"h4\",null,\"Enable IPv6 support\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA01 minute\")),mdx(\"p\",null,\"Before you can use IPv6 in Docker containers or swarm services, you need to enable IPv6 support in the Docker daemon. Afterward, you can choose to use either IPv4 or IPv6 (or both) with any container, service, or network.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": IPv6 networking is only supported on Docker daemons running on Linux hosts.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Edit\\xA0/etc/docker/daemon.json\\xA0and set the\\xA0ipv6\\xA0key to\\xA0true.\"),mdx(\"li\",{parentName:\"ol\"},\"{\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"ipv6\\\": true\"),mdx(\"li\",{parentName:\"ol\"},\"}\")),mdx(\"p\",null,\"Save the file.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Reload the Docker configuration file.\"),mdx(\"li\",{parentName:\"ol\"},\"$ systemctl reload docker\")),mdx(\"p\",null,\"You can now create networks with the\\xA0--ipv6\\xA0flag and assign containers IPv6 addresses using the\\xA0--ip6\\xA0flag.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Next steps\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/\"}),\"Networking overview\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/config/containers/container-networking/\"}),\"Container networking\"))),mdx(\"h4\",null,\"Docker and iptables\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA02 minutes\")),mdx(\"p\",null,\"On Linux, Docker manipulates\\xA0iptables\\xA0rules to provide network isolation. This is an implementation detail, and you should not modify the rules Docker inserts into your\\xA0iptables\\xA0policies.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Add iptables policies before Docker's rules\")),mdx(\"p\",null,\"All of Docker's\\xA0iptables\\xA0rules are added to the\\xA0DOCKER\\xA0chain. Do not manipulate this table manually. If you need to add rules which load before Docker's rules, add them to the\\xA0DOCKER-USER\\xA0chain. These rules are loaded before any rules Docker creates automatically.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Restrict connections to the Docker daemon\")),mdx(\"p\",null,\"By default, all external source IPs are allowed to connect to the Docker daemon. To allow only a specific IP or network to access the containers, insert a negated rule at the top of the DOCKER filter chain. For example, the following rule restricts external access to all IP addresses except 192.168.1.1:\"),mdx(\"p\",null,\"$ iptables -I DOCKER-USER -i ext_if ! -s 192.168.1.1 -j DROP\"),mdx(\"p\",null,\"You could instead allow connections from a source subnet. The following rule only allows access from the subnet 192.168.1.0/24:\"),mdx(\"p\",null,\"$ iptables -I DOCKER-USER -i ext_if ! -s 192.168.1.0/24 -j DROP\"),mdx(\"p\",null,\"Finally, you can specify a range of IP addresses to accept using\\xA0--src-range\\xA0(Remember to also add\\xA0-m iprange\\xA0when using\\xA0--src-range\\xA0or\\xA0--dst-range):\"),mdx(\"p\",null,\"$ iptables -I DOCKER-USER -m iprange -i ext_if ! --src-range 192.168.1.1-192.168.1.3 -j DROP\"),mdx(\"p\",null,\"You can combine\\xA0-s\\xA0or\\xA0--src-range\\xA0with\\xA0-d\\xA0or\\xA0--dst-range\\xA0to control both the source and destination. For instance, if the Docker daemon listens on both 192.168.1.99 and 10.1.2.3, you can make rules specific to\\xA010.1.2.3\\xA0and leave\\xA0192.168.1.99\\xA0open.\"),mdx(\"p\",null,\"iptables\\xA0is complicated and more complicated rule are out of scope for this topic. See the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://www.netfilter.org/documentation/HOWTO/NAT-HOWTO.html\"}),\"Netfilter.org HOWTO\"),\"\\xA0for a lot more information.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Prevent Docker from manipulating iptables\")),mdx(\"p\",null,\"To prevent Docker from manipulating the\\xA0iptables\\xA0policies at all, set the\\xA0iptables\\xA0key to\\xA0false\\xA0in\\xA0/etc/docker/daemon.json. This is inappropriate for most users, because the\\xA0iptables\\xA0policies then need to be managed by hand.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Next steps\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Read\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://success.docker.com/Architecture/Docker_Reference_Architecture%3A_Designing_Scalable%2C_Portable_Docker_Container_Networks\"}),\"Docker Reference Architecture: Designing Scalable, Portable Docker Container Networks\"))),mdx(\"h4\",null,\"Container networking\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA03 minutes\")),mdx(\"p\",null,\"The type of network a container uses, whether it is a\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/containers/bridges/\"}),\"bridge\"),\", an\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/containers/overlay/\"}),\"overlay\"),\", a\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/containers/macvlan/\"}),\"macvlan network\"),\", or a custom network plugin, is transparent from within the container. From the container's point of view, it has a network interface with an IP address, a gateway, a routing table, DNS services, and other networking details (assuming the container is not using the\\xA0none\\xA0network driver). This topic is about networking concerns from the point of view of the container.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Published ports\")),mdx(\"p\",null,\"By default, when you create a container, it does not publish any of its ports to the outside world. To make a port available to services outside of Docker, or to Docker containers which are not connected to the container's network, use the\\xA0--publish\\xA0or\\xA0-p\\xA0flag. This creates a firewall rule which maps a container port to a port on the Docker host. Here are some examples.\"),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Flag value\"),\"                  \",mdx(\"strong\",{parentName:\"p\"},\"Description\")),mdx(\"hr\",null),mdx(\"p\",null,\"  -p 8080:80                      Map TCP port 80 in the container to port 8080 on the Docker host.\\n-p 8080:80/udp                  Map UDP port 80 in the container to port 8080 on the Docker host.\\n-p 8080:80/tcp -p 8080:80/udp   Map TCP port 80 in the container to TCP port 8080 on the Docker host, and map UDP port 80 in the container to UDP port 8080 on the Docker host.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"IP address and hostname\")),mdx(\"p\",null,\"By default, the container is assigned an IP address for every Docker network it connects to. The IP address is assigned from the pool assigned to the network, so the Docker daemon effectively acts as a DHCP server for each container. Each network also has a default subnet mask and gateway.\"),mdx(\"p\",null,\"When the container starts, it can only be connected to a single network, using\\xA0--network. However, you can connect a running container to multiple networks using\\xA0docker network connect. When you start a container using the\\xA0--network\\xA0flag, you can specify the IP address assigned to the container on that network using the\\xA0--ip\\xA0or\\xA0--ip6\\xA0flags.\"),mdx(\"p\",null,\"When you connect an existing container to a different network using\\xA0docker network connect, you can use the\\xA0--ip\\xA0or\\xA0--ip6\\xA0flags on that command to specify the container's IP address on the additional network.\"),mdx(\"p\",null,\"In the same way, a container's hostname defaults to be the container's name in Docker. You can override the hostname using\\xA0--hostname. When connecting to an existing network using\\xA0docker network connect, you can use the\\xA0--alias\\xA0flag to specify an additional network alias for the container on that network.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"DNS services\")),mdx(\"p\",null,\"By default, a container inherits the DNS settings of the Docker daemon, including the\\xA0/etc/hosts\\xA0and\\xA0/etc/resolv.conf.You can override these settings on a per-container basis.\"),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Flag\"),\"        \",mdx(\"strong\",{parentName:\"p\"},\"Description\")),mdx(\"hr\",null),mdx(\"p\",null,\"  --dns          The IP address of a DNS server. To specify multiple DNS servers, use multiple\\xA0--dns\\xA0flags. If the container cannot reach any of the IP addresses you specify, Google's public DNS server\\xA08.8.8.8\\xA0is added, so that your container can resolve internet domains.\\n--dns-search   A DNS search domain to search non-fully-qualified hostnames. To specify multiple DNS search prefixes, use multiple\\xA0--dns-search\\xA0flags.\\n--dns-opt      A key-value pair representing a DNS option and its value. See your operating system's documentation for\\xA0resolv.conf\\xA0for valid options.\\n--hostname     The hostname a container uses for itself. Defaults to the container's name if not specified.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Proxy server\")),mdx(\"p\",null,\"If your container needs to use a proxy server, see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/network/proxy/\"}),\"Use a proxy server\"),\".\"),mdx(\"h4\",null,\"Configure Docker to use a proxy server\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA02 minutes\")),mdx(\"p\",null,\"If your container needs to use an HTTP, HTTPS, or FTP proxy server, you can configure it in different ways:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"In Docker 17.07 and higher, you can\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/proxy/#configure-the-docker-client\"}),\"configure the Docker client\"),\"\\xA0to pass proxy information to containers automatically.\"),mdx(\"li\",{parentName:\"ul\"},\"In Docker 17.06 and lower, you must\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/proxy/#use-environment-variables\"}),\"set appropriate environment variables\"),\"\\xA0within the container. You can do this when you build the image (which makes the image less portable) or when you create or run the container.\")),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Configure the Docker client\")),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"On the Docker client, create or edit the file\\xA0\",\"~\",\"/.docker/config.json\\xA0in the home directory of the user which starts containers. Add JSON such as the following, substituting the type of proxy with\\xA0httpsProxy\\xA0or\\xA0ftpProxy\\xA0if necessary, and substituting the address and port of the proxy server. You can configure multiple proxy servers at the same time.\")),mdx(\"p\",null,\"You can optionally exclude hosts or ranges from going through the proxy server by setting a\\xA0noProxy\\xA0key to one or more comma-separated IP addresses or hosts. Using the\\xA0*\\xA0character as a wildcard is supported, as shown in this example.\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"proxies\\\":\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"default\\\":\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"httpProxy\\\": \\\"\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://127.0.0.1:3001%22\"}),\"http://127.0.0.1:3001\\\"\"),\",\"),mdx(\"p\",null,\"\\\"noProxy\\\": \\\"*.test.example.com,.example2.com\\\"\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"Save the file.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"When you create or start new containers, the environment variables are set automatically within the container.\")),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Use environment variables\")),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Set the environment variables manually\")),mdx(\"p\",null,\"When you build the image, or using the\\xA0--env\\xA0flag when you create or run the container, you can set one or more of the following variables to the appropriate value. This method makes the image less portable, so if you have Docker 17.07 or higher, you should\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/network/proxy/#configure-the-docker-client\"}),\"configure the Docker client\"),\"\\xA0instead.\"),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Variable\"),\"   \",mdx(\"strong\",{parentName:\"p\"},\"Dockerfile example\"),\"                               \",mdx(\"strong\",{parentName:\"p\"},\"docker run\\xA0Example\")),mdx(\"hr\",null),mdx(\"p\",null,\"  HTTP_PROXY     ENV HTTP_PROXY \\\"\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://127.0.0.1:3001%22\"}),\"http://127.0.0.1:3001\\\"\"),\"             --env HTTP_PROXY \\\"\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://127.0.0.1:3001%22\"}),\"http://127.0.0.1:3001\\\"\"),\"\\nHTTPS_PROXY    ENV HTTPS_PROXY \\\"\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://127.0.0.1:3001%22\"}),\"https://127.0.0.1:3001\\\"\"),\"           --env HTTPS_PROXY \\\"\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://127.0.0.1:3001%22\"}),\"https://127.0.0.1:3001\\\"\"),\"\\nFTP_PROXY      ENV FTP_PROXY \\\"ftp://127.0.0.1:3001\\\"               --env FTP_PROXY \\\"ftp://127.0.0.1:3001\\\"\\nNO_PROXY       ENV NO_PROXY \\\"\",mdx(\"em\",{parentName:\"p\"},\".test.example.com,.example2.com\\\"   --env NO_PROXY \\\"\"),\".test.example.com,.e\"),mdx(\"h2\",null,\"Legacy Networing Content\"),mdx(\"h3\",null,\"Legacy container links\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA014 minutes\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Warning: The\\xA0--link\\xA0flag is a legacy feature of Docker. It may eventually be removed. Unless you absolutely need to continue using it, we recommend that you use user-defined networks to facilitate communication between two containers instead of using\\xA0--link. One feature that user-defined networks do not support that you can do with\\xA0--link\\xA0is sharing environmental variables between containers. However, you can use other mechanisms such as volumes to share environment variables between containers in a more controlled way.\")),mdx(\"p\",null,\"See\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/network/bridge/##differences-between-user-defined-bridges-and-the-default-bridge\"}),\"Differences between user-defined bridges and the default bridge\"),\"\\xA0for some alternatives to using\\xA0--link.\"),mdx(\"p\",null,\"The information in this section explains legacy container links within the Docker default\\xA0bridgenetwork which is created automatically when you install Docker.\"),mdx(\"p\",null,\"Before the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/userguide/networking/\"}),\"Docker networks feature\"),\", you could use the Docker link feature to allow containers to discover each other and securely transfer information about one container to another container. With the introduction of the Docker networks feature, you can still create links but they behave differently between default\\xA0bridge\\xA0network and\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/userguide/networking/work-with-networks/#linking-containers-in-user-defined-networks\"}),\"user defined networks\"),\".\"),mdx(\"p\",null,\"This section briefly discusses connecting via a network port and then goes into detail on container linking in default\\xA0bridge\\xA0network.\"),mdx(\"h4\",null,\"Connect using network port mapping\"),mdx(\"p\",null,\"Let's say you used this command to run a simple Python Flask application:\"),mdx(\"p\",null,\"$ docker run -d -P training/webapp python app.py\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": Containers have an internal network and an IP address. Docker can have a variety of network configurations. You can see more information on Docker networking\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/userguide/networking/\"}),\"here\"),\".\"),mdx(\"p\",null,\"When that container was created, the\\xA0-P\\xA0flag was used to automatically map any network port inside it to a random high port within an\\xA0ephemeral port range\\xA0on your Docker host. Next, when\\xA0docker pswas run, you saw that port 5000 in the container was bound to port 49155 on the host.\"),mdx(\"p\",null,\"$ docker ps nostalgic_morse\"),mdx(\"p\",null,\"CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES\"),mdx(\"p\",null,\"bc533791f3f5 training/webapp:latest python app.py 5 seconds ago Up 2 seconds 0.0.0.0:49155->5000/tcp nostalgic_morse\"),mdx(\"p\",null,\"You also saw how you can bind a container's ports to a specific port using the\\xA0-p\\xA0flag. Here port 80 of the host is mapped to port 5000 of the container:\"),mdx(\"p\",null,\"$ docker run -d -p 80:5000 training/webapp python app.py\"),mdx(\"p\",null,\"And you saw why this isn't such a great idea because it constrains you to only one container on that specific port.\"),mdx(\"p\",null,\"Instead, you may specify a range of host ports to bind a container port to that is different than the default\\xA0ephemeral port range:\"),mdx(\"p\",null,\"$ docker run -d -p 8000-9000:5000 training/webapp python app.py\"),mdx(\"p\",null,\"This would bind port 5000 in the container to a randomly available port between 8000 and 9000 on the host.\"),mdx(\"p\",null,\"There are also a few other ways you can configure the\\xA0-p\\xA0flag. By default the\\xA0-p\\xA0flag binds the specified port to all interfaces on the host machine. But you can also specify a binding to a specific interface, for example only to the\\xA0localhost.\"),mdx(\"p\",null,\"$ docker run -d -p 127.0.0.1:80:5000 training/webapp python app.py\"),mdx(\"p\",null,\"This would bind port 5000 inside the container to port 80 on the\\xA0localhost\\xA0or\\xA0127.0.0.1\\xA0interface on the host machine.\"),mdx(\"p\",null,\"Or, to bind port 5000 of the container to a dynamic port but only on the\\xA0localhost, you could use:\"),mdx(\"p\",null,\"$ docker run -d -p 127.0.0.1::5000 training/webapp python app.py\"),mdx(\"p\",null,\"You can also bind UDP ports by adding a trailing\\xA0/udp. For example:\"),mdx(\"p\",null,\"$ docker run -d -p 127.0.0.1:80:5000/udp training/webapp python app.py\"),mdx(\"p\",null,\"You also learned about the useful\\xA0docker port\\xA0shortcut which showed us the current port bindings. This is also useful for showing you specific port configurations. For example, if you've bound the container port to the\\xA0localhost\\xA0on the host machine, then the\\xA0docker port\\xA0output reflects that.\"),mdx(\"p\",null,\"$ docker port nostalgic_morse 5000\"),mdx(\"p\",null,\"127.0.0.1:49155\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": The\\xA0-p\\xA0flag can be used multiple times to configure multiple ports.\"),mdx(\"h4\",null,\"Connect with the linking system\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": This section covers the legacy link feature in the default\\xA0bridge\\xA0network. Refer to\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/userguide/networking/work-with-networks/#linking-containers-in-user-defined-networks\"}),\"linking containers in user-defined networks\"),\"\\xA0for more information on links in user-defined networks.\"),mdx(\"p\",null,\"Network port mappings are not the only way Docker containers can connect to one another. Docker also has a linking system that allows you to link multiple containers together and send connection information from one to another. When containers are linked, information about a source container can be sent to a recipient container. This allows the recipient to see selected data describing aspects of the source container.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"The importance of naming\")),mdx(\"p\",null,\"To establish links, Docker relies on the names of your containers. You've already seen that each container you create has an automatically created name; indeed you've become familiar with our old friend\\xA0nostalgic_morse\\xA0during this guide. You can also name containers yourself. This naming provides two useful functions:\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"It can be useful to name containers that do specific functions in a way that makes it easier for you to remember them, for example naming a container containing a web application\\xA0web.\"),mdx(\"li\",{parentName:\"ol\"},\"It provides Docker with a reference point that allows it to refer to other containers, for example, you can specify to link the container\\xA0web\\xA0to container\\xA0db.\")),mdx(\"p\",null,\"You can name your container by using the\\xA0--name\\xA0flag, for example:\"),mdx(\"p\",null,\"$ docker run -d -P --name web training/webapp python app.py\"),mdx(\"p\",null,\"This launches a new container and uses the\\xA0--name\\xA0flag to name the container\\xA0web. You can see the container's name using the\\xA0docker ps\\xA0command.\"),mdx(\"p\",null,\"$ docker ps -l\"),mdx(\"p\",null,\"CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES\"),mdx(\"p\",null,\"aed84ee21bde training/webapp:latest python app.py 12 hours ago Up 2 seconds 0.0.0.0:49154->5000/tcp web\"),mdx(\"p\",null,\"You can also use\\xA0docker inspect\\xA0to return the container's name.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": Container names must be unique. That means you can only call one container\\xA0web. If you want to re-use a container name you must delete the old container (with\\xA0docker container rm) before you can create a new container with the same name. As an alternative you can use the\\xA0--rm\\xA0flag with the\\xA0docker run\\xA0command. This deletes the container immediately after it is stopped.\"),mdx(\"h4\",null,\"Communication across links\"),mdx(\"p\",null,\"Links allow containers to discover each other and securely transfer information about one container to another container. When you set up a link, you create a conduit between a source container and a recipient container. The recipient can then access select data about the source. To create a link, you use the\\xA0--link\\xA0flag. First, create a new container, this time one containing a database.\"),mdx(\"p\",null,\"$ docker run -d --name db training/postgres\"),mdx(\"p\",null,\"This creates a new container called\\xA0db\\xA0from the\\xA0training/postgres\\xA0image, which contains a PostgreSQL database.\"),mdx(\"p\",null,\"Now, you need to delete the\\xA0web\\xA0container you created previously so you can replace it with a linked one:\"),mdx(\"p\",null,\"$ docker container rm -f web\"),mdx(\"p\",null,\"Now, create a new\\xA0web\\xA0container and link it with your\\xA0db\\xA0container.\"),mdx(\"p\",null,\"$ docker run -d -P --name web --link db:db training/webapp python app.py\"),mdx(\"p\",null,\"This links the new\\xA0web\\xA0container with the\\xA0db\\xA0container you created earlier. The\\xA0--link\\xA0flag takes the form:\"),mdx(\"p\",null,\"--link \",mdx(\"inlineCode\",{parentName:\"p\"},\"<name or id>\"),\":alias\"),mdx(\"p\",null,\"Where\\xA0name\\xA0is the name of the container we're linking to and\\xA0alias\\xA0is an alias for the link name. That alias is used shortly. The\\xA0--link\\xA0flag also takes the form:\"),mdx(\"p\",null,\"--link \",mdx(\"inlineCode\",{parentName:\"p\"},\"<name or id>\")),mdx(\"p\",null,\"In this case the alias matches the name. You could write the previous example as:\"),mdx(\"p\",null,\"$ docker run -d -P --name web --link db training/webapp python app.py\"),mdx(\"p\",null,\"Next, inspect your linked containers with\\xA0docker inspect:\"),mdx(\"p\",null,\"$ docker inspect -f \\\"{{ .HostConfig.Links }}\\\" web\"),mdx(\"p\",null,\"[/db:/web/db]\"),mdx(\"p\",null,\"You can see that the\\xA0web\\xA0container is now linked to the\\xA0db\\xA0container\\xA0web/db. Which allows it to access information about the\\xA0db\\xA0container.\"),mdx(\"p\",null,\"So what does linking the containers actually do? You've learned that a link allows a source container to provide information about itself to a recipient container. In our example, the recipient,\\xA0web, can access information about the source\\xA0db. To do this, Docker creates a secure tunnel between the containers that doesn't need to expose any ports externally on the container; when we started the\\xA0db\\xA0container we did not use either the\\xA0-P\\xA0or\\xA0-p\\xA0flags. That's a big benefit of linking: we don't need to expose the source container, here the PostgreSQL database, to the network.\"),mdx(\"p\",null,\"Docker exposes connectivity information for the source container to the recipient container in two ways:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Environment variables,\"),mdx(\"li\",{parentName:\"ul\"},\"Updating the\\xA0/etc/hosts\\xA0file.\")),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Environment variables\")),mdx(\"p\",null,\"Docker creates several environment variables when you link containers. Docker automatically creates environment variables in the target container based on the\\xA0--link\\xA0parameters. It also exposes all environment variables originating from Docker from the source container. These include variables from:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"the\\xA0ENV\\xA0commands in the source container's Dockerfile\"),mdx(\"li\",{parentName:\"ul\"},\"the\\xA0-e,\\xA0--env, and\\xA0--env-file\\xA0options on the\\xA0docker run\\xA0command when the source container is started\")),mdx(\"p\",null,\"These environment variables enable programmatic discovery from within the target container of information related to the source container.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Warning\"),\": It is important to understand that\\xA0all\\xA0environment variables originating from Docker within a container are made available to\\xA0any\\xA0container that links to it. This could have serious security implications if sensitive data is stored in them.\"),mdx(\"p\",null,\"Docker sets an\\xA0\",mdx(\"inlineCode\",{parentName:\"p\"},\"<alias>\"),\"_NAME\\xA0environment variable for each target container listed in the\\xA0--linkparameter. For example, if a new container called\\xA0web\\xA0is linked to a database container called\\xA0db\\xA0via\\xA0--link db:webdb, then Docker creates a\\xA0WEBDB_NAME=/web/webdb\\xA0variable in the\\xA0web\\xA0container.\"),mdx(\"p\",null,\"Docker also defines a set of environment variables for each port exposed by the source container. Each variable has a unique prefix in the form:\"),mdx(\"p\",null,mdx(\"inlineCode\",{parentName:\"p\"},\"<name>_PORT_<port>_<protocol>\")),mdx(\"p\",null,\"The components in this prefix are:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"the alias\\xA0\",mdx(\"inlineCode\",{parentName:\"li\"},\"<name>\"),\"\\xA0specified in the\\xA0--link\\xA0parameter (for example,\\xA0webdb)\"),mdx(\"li\",{parentName:\"ul\"},\"the\\xA0\",mdx(\"inlineCode\",{parentName:\"li\"},\"<port>\"),\"\\xA0number exposed\"),mdx(\"li\",{parentName:\"ul\"},\"a\\xA0\",mdx(\"inlineCode\",{parentName:\"li\"},\"<protocol>\"),\"\\xA0which is either TCP or UDP\")),mdx(\"p\",null,\"Docker uses this prefix format to define three distinct environment variables:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"The\\xA0prefix_ADDR\\xA0variable contains the IP Address from the URL, for example\\xA0WEBDB_PORT_5432_TCP_ADDR=172.17.0.82.\"),mdx(\"li\",{parentName:\"ul\"},\"The\\xA0prefix_PORT\\xA0variable contains just the port number from the URL for example\\xA0WEBDB_PORT_5432_TCP_PORT=5432.\"),mdx(\"li\",{parentName:\"ul\"},\"The\\xA0prefix_PROTO\\xA0variable contains just the protocol from the URL for example\\xA0WEBDB_PORT_5432_TCP_PROTO=tcp.\")),mdx(\"p\",null,\"If the container exposes multiple ports, an environment variable set is defined for each one. This means, for example, if a container exposes 4 ports that Docker creates 12 environment variables, 3 for each port.\"),mdx(\"p\",null,\"Additionally, Docker creates an environment variable called\\xA0\",mdx(\"inlineCode\",{parentName:\"p\"},\"<alias>\"),\"_PORT. This variable contains the URL of the source container's first exposed port. The 'first' port is defined as the exposed port with the lowest number. For example, consider the\\xA0WEBDB_PORT=tcp://172.17.0.82:5432\\xA0variable. If that port is used for both tcp and udp, then the tcp one is specified.\"),mdx(\"p\",null,\"Finally, Docker also exposes each Docker originated environment variable from the source container as an environment variable in the target. For each variable Docker creates an\\xA0\",mdx(\"inlineCode\",{parentName:\"p\"},\"<alias>_ENV_<name>\"),\"variable in the target container. The variable's value is set to the value Docker used when it started the source container.\"),mdx(\"p\",null,\"Returning back to our database example, you can run the\\xA0env\\xA0command to list the specified container's environment variables.\"),mdx(\"p\",null,\"$ docker run --rm --name web2 --link db:db training/webapp env\"),mdx(\"p\",null,\". . .\"),mdx(\"p\",null,\"DB_NAME=/web2/db\"),mdx(\"p\",null,\"DB_PORT=tcp://172.17.0.5:5432\"),mdx(\"p\",null,\"DB_PORT_5432_TCP=tcp://172.17.0.5:5432\"),mdx(\"p\",null,\"DB_PORT_5432_TCP_PROTO=tcp\"),mdx(\"p\",null,\"DB_PORT_5432_TCP_PORT=5432\"),mdx(\"p\",null,\"DB_PORT_5432_TCP_ADDR=172.17.0.5\"),mdx(\"p\",null,\". . .\"),mdx(\"p\",null,\"You can see that Docker has created a series of environment variables with useful information about the source\\xA0db\\xA0container. Each variable is prefixed with\\xA0DB\",mdx(\"em\",{parentName:\"p\"},\", which is populated from the\\xA0alias\\xA0you specified above. If the\\xA0alias\\xA0were\\xA0db1, the variables would be prefixed with\\xA0DB1\"),\". You can use these environment variables to configure your applications to connect to the database on the\\xA0dbcontainer. The connection is secure and private; only the linked\\xA0web\\xA0container can communicate with the\\xA0db\\xA0container.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Important notes on Docker environment variables\")),mdx(\"p\",null,\"Unlike host entries in the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/network/links/#updating-the-etchosts-file\"}),\"/etc/hosts\\xA0file\"),\", IP addresses stored in the environment variables are not automatically updated if the source container is restarted. We recommend using the host entries in/etc/hosts\\xA0to resolve the IP address of linked containers.\"),mdx(\"p\",null,\"These environment variables are only set for the first process in the container. Some daemons, such as\\xA0sshd, scrub them when spawning shells for connection.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Updating the\\xA0/etc/hosts\\xA0file\")),mdx(\"p\",null,\"In addition to the environment variables, Docker adds a host entry for the source container to the\\xA0/etc/hosts\\xA0file. Here's an entry for the\\xA0web\\xA0container:\"),mdx(\"p\",null,\"$ docker run -t -i --rm --link db:webdb training/webapp /bin/bash\"),mdx(\"p\",null,\"root\\\\@aed84ee21bde:/opt/webapp# cat /etc/hosts\"),mdx(\"p\",null,\"172.17.0.7 aed84ee21bde\"),mdx(\"p\",null,\". . .\"),mdx(\"p\",null,\"172.17.0.5 webdb 6e5cdeb2d300 db\"),mdx(\"p\",null,\"You can see two relevant host entries. The first is an entry for the\\xA0web\\xA0container that uses the Container ID as a host name. The second entry uses the link alias to reference the IP address of the\\xA0dbcontainer. In addition to the alias you provide, the linked container's name, if unique from the alias provided to the\\xA0--link\\xA0parameter, and the linked container's hostname are also added to\\xA0/etc/hosts\\xA0for the linked container's IP address. You can ping that host via any of these entries:\"),mdx(\"p\",null,\"root\\\\@aed84ee21bde:/opt/webapp# apt-get install -yqq inetutils-ping\"),mdx(\"p\",null,\"root\\\\@aed84ee21bde:/opt/webapp# ping webdb\"),mdx(\"p\",null,\"PING webdb (172.17.0.5): 48 data bytes\"),mdx(\"p\",null,\"56 bytes from 172.17.0.5: icmp_seq=0 ttl=64 time=0.267 ms\"),mdx(\"p\",null,\"56 bytes from 172.17.0.5: icmp_seq=1 ttl=64 time=0.250 ms\"),mdx(\"p\",null,\"56 bytes from 172.17.0.5: icmp_seq=2 ttl=64 time=0.256 ms\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": In the example, you had to install\\xA0ping\\xA0because it was not included in the container initially.\"),mdx(\"p\",null,\"Here, you used the\\xA0ping\\xA0command to ping the\\xA0db\\xA0container using its host entry, which resolves to\\xA0172.17.0.5. You can use this host entry to configure an application to make use of your\\xA0dbcontainer.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": You can link multiple recipient containers to a single source. For example, you could have multiple (differently named) web containers attached to your\\xA0db\\xA0container.\"),mdx(\"p\",null,\"If you restart the source container, the\\xA0/etc/hosts\\xA0files on the linked containers are automatically updated with the source container's new IP address, allowing linked communication to continue.\"),mdx(\"p\",null,\"$ docker restart db\"),mdx(\"p\",null,\"db\"),mdx(\"p\",null,\"$ docker run -t -i --rm --link db:db training/webapp /bin/bash\"),mdx(\"p\",null,\"root\\\\@aed84ee21bde:/opt/webapp# cat /etc/hosts\"),mdx(\"p\",null,\"172.17.0.7 aed84ee21bde\"),mdx(\"p\",null,\". . .\"),mdx(\"p\",null,\"172.17.0.9 db\"),mdx(\"h3\",null,\"Multi-host networking with standalone swarms\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA012 minutes\")),mdx(\"h4\",null,\"Standalone swarm only!\"),mdx(\"p\",null,\"This article only applies to users who need to use a standalone swarm with Docker, as opposed to swarm mode. Standalone swarms (sometimes known as Swarm Classic) rely on an external key-value store to store networking information. Docker swarm mode stores networking information in the Raft logs on the swarm managers. If you use swarm mode, see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/networking/\"}),\"swarm mode networking\"),\"\\xA0instead of this article.\"),mdx(\"p\",null,\"Users of Universal Control Plane\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"do\"),\"\\xA0use an external key-value store, but UCP manages it for you, and you do not need to manually intervene. If you run into issues with the key-value store, see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/datacenter/ucp/2.2/guides/admin/monitor-and-troubleshoot/troubleshoot-configurations/#troubleshoot-the-etcd-key-value-store\"}),\"Troubleshoot the etcd key-value store\")),mdx(\"p\",null,\"If you are using standalone swarms and not using UCP, this article may be useful to you. This article uses an example to explain the basics of creating a multi-host network using a standalone swarm and the\\xA0overlay\\xA0network driver. Unlike\\xA0bridge\\xA0networks, overlay networks require some pre-existing conditions before you can create one:\"),mdx(\"h4\",null,\"Overlay networking with an external key-value store\"),mdx(\"p\",null,\"To use Docker with an external key-value store, you need the following:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Access to the key-value store. Docker supports Consul, Etcd, and ZooKeeper (Distributed store) key-value stores. This example uses Consul.\"),mdx(\"li\",{parentName:\"ul\"},\"A cluster of hosts with connectivity to the key-value store.\"),mdx(\"li\",{parentName:\"ul\"},\"Docker running on each host in the cluster.\"),mdx(\"li\",{parentName:\"ul\"},\"Hosts within the cluster must have unique hostnames because the key-value store uses the hostnames to identify cluster members.\")),mdx(\"p\",null,\"Docker Machine and Docker Swarm are not mandatory to experience Docker multi-host networking with a key-value store. However, this example uses them to illustrate how they are integrated. You use Machine to create both the key-value store server and the host cluster using a standalone swarm.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": These examples are not relevant to Docker running in swarm mode and do not work in such a configuration.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Prerequisites\")),mdx(\"p\",null,\"Before you begin, make sure you have a system on your network with the latest version of Docker and Docker Machine installed. The example also relies on VirtualBox. If you installed on a Mac or Windows with Docker Toolbox, you have all of these installed already.\"),mdx(\"p\",null,\"If you have not already done so, make sure you upgrade Docker and Docker Machine to the latest versions.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Set up a key-value store\")),mdx(\"p\",null,\"An overlay network requires a key-value store. The key-value store holds information about the network state which includes discovery, networks, endpoints, IP addresses, and more. Docker supports Consul, Etcd, and ZooKeeper key-value stores. This example uses Consul.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Log into a system prepared with Docker and Docker Machine installed.\"),mdx(\"li\",{parentName:\"ol\"},\"Provision a VirtualBox machine called\\xA0mh-keystore.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker-machine create -d virtualbox mh-keystore\")),mdx(\"p\",null,\"When you provision a new machine, the process adds Docker to the host. This means rather than installing Consul manually, you can create an instance using the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://hub.docker.com/_/consul/\"}),\"consul image from Docker Hub\"),\". You do this in the next step.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Set your local environment to the\\xA0mh-keystore\\xA0machine.\"),mdx(\"li\",{parentName:\"ol\"},\"$ eval \\\"$(docker-machine env mh-keystore)\\\"\"),mdx(\"li\",{parentName:\"ol\"},\"Start a\\xA0consul\\xA0container running on the\\xA0mh-keystore\\xA0Docker machine.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker run -d \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--name consul \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"-p \\\"8500:8500\\\" \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"-h \\\"consul\\\" \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"consul agent -server -bootstrap -client \\\"0.0.0.0\\\"\")),mdx(\"p\",null,\"The client starts a\\xA0consul\\xA0image running in the\\xA0mh-keystore\\xA0Docker machine. The server is called\\xA0consul\\xA0and is listening on port\\xA08500.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Run the\\xA0docker ps\\xA0command to see the\\xA0consul\\xA0container.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker ps\"),mdx(\"li\",{parentName:\"ol\"},\"CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES\"),mdx(\"li\",{parentName:\"ol\"},\"a47492d6c4d1 consul \\\"docker-entrypoint...\\\" 2 seconds ago Up 1 second 8300-8302/tcp, 8301-8302/udp, 8600/tcp, 8600/udp, 0.0.0.0:8500->8500/tcp consul\")),mdx(\"p\",null,\"Keep your terminal open and move on to\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/network/overlay-standalone.swarm/#create-a-swarm-cluster\"}),\"Create a swarm cluster\"),\".\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Create a swarm cluster\")),mdx(\"p\",null,\"In this step, you use\\xA0docker-machine\\xA0to provision the hosts for your network. You don't actually create the network yet. You create several Docker machines in VirtualBox. One of the machines acts as the swarm manager and you create that first. As you create each host, you pass the Docker daemon on that machine options that are needed by the\\xA0overlay\\xA0network driver.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": This creates a standalone swarm cluster, rather than using Docker in swarm mode. These examples are not relevant to Docker running in swarm mode and do not work in such a configuration.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Create a swarm manager.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker-machine create \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"-d virtualbox \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--swarm --swarm-master \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--swarm-discovery=\\\"consul://$(docker-machine ip mh-keystore):8500\\\" \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--engine-opt=\\\"cluster-store=consul://$(docker-machine ip mh-keystore):8500\\\" \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--engine-opt=\\\"cluster-advertise=eth1:2376\\\" \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"mhs-demo0\")),mdx(\"p\",null,\"At creation time, you supply the Docker daemon with the\\xA0--cluster-store\\xA0option. This option tells the Engine the location of the key-value store for the\\xA0overlay\\xA0network. The bash expansion\\xA0$(docker-machine ip mh-keystore)\\xA0resolves to the IP address of the Consul server you created in \\\"STEP 1\\\". The\\xA0--cluster-advertise\\xA0option advertises the machine on the network.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Create another host and add it to the swarm.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker-machine create -d virtualbox \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--swarm \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--swarm-discovery=\\\"consul://$(docker-machine ip mh-keystore):8500\\\" \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--engine-opt=\\\"cluster-store=consul://$(docker-machine ip mh-keystore):8500\\\" \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--engine-opt=\\\"cluster-advertise=eth1:2376\\\" \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"mhs-demo1\"),mdx(\"li\",{parentName:\"ol\"},\"List your Docker machines to confirm they are all up and running.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker-machine ls\"),mdx(\"li\",{parentName:\"ol\"},\"NAME ACTIVE DRIVER STATE URL SWARM\"),mdx(\"li\",{parentName:\"ol\"},\"default - virtualbox Running tcp://192.168.99.100:2376\"),mdx(\"li\",{parentName:\"ol\"},\"mh-keystore * virtualbox Running tcp://192.168.99.103:2376\"),mdx(\"li\",{parentName:\"ol\"},\"mhs-demo0 - virtualbox Running tcp://192.168.99.104:2376 mhs-demo0 (master)\"),mdx(\"li\",{parentName:\"ol\"},\"mhs-demo1 - virtualbox Running tcp://192.168.99.105:2376 mhs-demo0\")),mdx(\"p\",null,\"At this point you have a set of hosts running on your network. You are ready to create a multi-host network for containers using these hosts.\"),mdx(\"p\",null,\"Leave your terminal open and go on to\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/network/overlay-standalone.swarm/#create-the-overlay-network\"}),\"Create the overlay network\"),\".\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Create the overlay network\")),mdx(\"p\",null,\"To create an overlay network:\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Set your docker environment to the swarm manager.\"),mdx(\"li\",{parentName:\"ol\"},\"$ eval $(docker-machine env --swarm mhs-demo0)\")),mdx(\"p\",null,\"Using the\\xA0--swarm\\xA0flag with\\xA0docker-machine\\xA0restricts the\\xA0docker\\xA0commands to swarm information alone.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Use the\\xA0docker info\\xA0command to view the swarm.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker info\"),mdx(\"li\",{parentName:\"ol\"},\"Containers: 3\"),mdx(\"li\",{parentName:\"ol\"},\"Images: 2\"),mdx(\"li\",{parentName:\"ol\"},\"Role: primary\"),mdx(\"li\",{parentName:\"ol\"},\"Strategy: spread\"),mdx(\"li\",{parentName:\"ol\"},\"Filters: affinity, health, constraint, port, dependency\"),mdx(\"li\",{parentName:\"ol\"},\"Nodes: 2\"),mdx(\"li\",{parentName:\"ol\"},\"mhs-demo0: 192.168.99.104:2376\"),mdx(\"li\",{parentName:\"ol\"},\"\\u2514 Containers: 2\"),mdx(\"li\",{parentName:\"ol\"},\"\\u2514 Reserved CPUs: 0 / 1\"),mdx(\"li\",{parentName:\"ol\"},\"\\u2514 Reserved Memory: 0 B / 1.021 GiB\"),mdx(\"li\",{parentName:\"ol\"},\"\\u2514 Labels: executiondriver=native-0.2, kernelversion=4.1.10-boot2docker, operatingsystem=Boot2Docker 1.9.0 (TCL 6.4); master : 4187d2c - Wed Oct 14 14:00:28 UTC 2015, provider=virtualbox, storagedriver=aufs\"),mdx(\"li\",{parentName:\"ol\"},\"mhs-demo1: 192.168.99.105:2376\"),mdx(\"li\",{parentName:\"ol\"},\"\\u2514 Containers: 1\"),mdx(\"li\",{parentName:\"ol\"},\"\\u2514 Reserved CPUs: 0 / 1\"),mdx(\"li\",{parentName:\"ol\"},\"\\u2514 Reserved Memory: 0 B / 1.021 GiB\"),mdx(\"li\",{parentName:\"ol\"},\"\\u2514 Labels: executiondriver=native-0.2, kernelversion=4.1.10-boot2docker, operatingsystem=Boot2Docker 1.9.0 (TCL 6.4); master : 4187d2c - Wed Oct 14 14:00:28 UTC 2015, provider=virtualbox, storagedriver=aufs\"),mdx(\"li\",{parentName:\"ol\"},\"CPUs: 2\"),mdx(\"li\",{parentName:\"ol\"},\"Total Memory: 2.043 GiB\"),mdx(\"li\",{parentName:\"ol\"},\"Name: 30438ece0915\")),mdx(\"p\",null,\"This output shows that you are running three containers and two images on the manager.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Create your\\xA0overlay\\xA0network.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker network create --driver overlay --subnet=10.0.9.0/24 my-net\")),mdx(\"p\",null,\"You only need to create the network on a single host in the cluster. In this case, you used the swarm manager but you could easily have run it on any host in the swarm.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": It is highly recommended to use the\\xA0--subnet\\xA0option when creating a network. If the\\xA0--subnet\\xA0is not specified, Docker automatically chooses and assigns a subnet for the network and it could overlap with another subnet in your infrastructure that is not managed by Docker. Such overlaps can cause connectivity issues or failures when containers are connected to that network.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Check that the network exists:\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker network ls\"),mdx(\"li\",{parentName:\"ol\"},\"NETWORK ID NAME DRIVER\"),mdx(\"li\",{parentName:\"ol\"},\"412c2496d0eb mhs-demo1/host host\"),mdx(\"li\",{parentName:\"ol\"},\"dd51763e6dd2 mhs-demo0/bridge bridge\"),mdx(\"li\",{parentName:\"ol\"},\"6b07d0be843f my-net overlay\"),mdx(\"li\",{parentName:\"ol\"},\"b4234109bd9b mhs-demo0/none null\"),mdx(\"li\",{parentName:\"ol\"},\"1aeead6dd890 mhs-demo0/host host\"),mdx(\"li\",{parentName:\"ol\"},\"d0bb78cbe7bd mhs-demo1/bridge bridge\"),mdx(\"li\",{parentName:\"ol\"},\"1c0eb8f69ebb mhs-demo1/none null\")),mdx(\"p\",null,\"Since you are in the swarm manager environment, you see all the networks on all the swarm participants: the default networks on each Docker daemon and the single overlay network. Each network has a unique ID and a namespaced name.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Switch to each swarm agent in turn and list the networks.\"),mdx(\"li\",{parentName:\"ol\"},\"$ eval $(docker-machine env mhs-demo0)\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker network ls\"),mdx(\"li\",{parentName:\"ol\"},\"NETWORK ID NAME DRIVER\"),mdx(\"li\",{parentName:\"ol\"},\"6b07d0be843f my-net overlay\"),mdx(\"li\",{parentName:\"ol\"},\"dd51763e6dd2 bridge bridge\"),mdx(\"li\",{parentName:\"ol\"},\"b4234109bd9b none null\"),mdx(\"li\",{parentName:\"ol\"},\"1aeead6dd890 host host\"),mdx(\"li\",{parentName:\"ol\"},\"$ eval $(docker-machine env mhs-demo1)\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker network ls\"),mdx(\"li\",{parentName:\"ol\"},\"NETWORK ID NAME DRIVER\"),mdx(\"li\",{parentName:\"ol\"},\"d0bb78cbe7bd bridge bridge\"),mdx(\"li\",{parentName:\"ol\"},\"1c0eb8f69ebb none null\"),mdx(\"li\",{parentName:\"ol\"},\"412c2496d0eb host host\"),mdx(\"li\",{parentName:\"ol\"},\"6b07d0be843f my-net overlay\")),mdx(\"p\",null,\"Both agents report they have the\\xA0my-net\\xA0network with the\\xA06b07d0be843f\\xA0ID. You now have a multi-host container network running!\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Run an application on your network\")),mdx(\"p\",null,\"Once your network is created, you can start a container on any of the hosts and it automatically is part of the network.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Set your environment to the swarm manager.\"),mdx(\"li\",{parentName:\"ol\"},\"$ eval $(docker-machine env --swarm mhs-demo0)\"),mdx(\"li\",{parentName:\"ol\"},\"Start an Nginx web server on the\\xA0mhs-demo0\\xA0instance.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker run -itd \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--name=web \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--network=my-net \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--env=\\\"constraint:node==mhs-demo0\\\" \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"nginx:alpine\"),mdx(\"li\",{parentName:\"ol\"},\"Run a\\xA0busybox\\xA0instance on the\\xA0mhs-demo1\\xA0instance and get the contents of the Nginx server's home page.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker run -it --rm \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--network=my-net \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--env=\\\"constraint:node==mhs-demo1\\\" \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"busybox wget -O- http://web\"),mdx(\"li\",{parentName:\"ol\"},\"Unable to find image \\\\'busybox:latest\\\\' locally\"),mdx(\"li\",{parentName:\"ol\"},\"latest: Pulling from library/busybox\"),mdx(\"li\",{parentName:\"ol\"},\"ab2b8a86ca6c: Pull complete\"),mdx(\"li\",{parentName:\"ol\"},\"2c5ac3f849df: Pull complete\"),mdx(\"li\",{parentName:\"ol\"},\"Digest: sha256:5551dbdfc48d66734d0f01cafee0952cb6e8eeecd1e2492240bf2fd9640c2279\"),mdx(\"li\",{parentName:\"ol\"},\"Status: Downloaded newer image for busybox:latest\"),mdx(\"li\",{parentName:\"ol\"},\"Connecting to web (10.0.9.2:80)\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<!DOCTYPE html>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<html>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<head>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<title>Welcome to nginx!</title>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<style>\")),mdx(\"li\",{parentName:\"ol\"},\"body {\"),mdx(\"li\",{parentName:\"ol\"},\"width: 35em;\"),mdx(\"li\",{parentName:\"ol\"},\"margin: 0 auto;\"),mdx(\"li\",{parentName:\"ol\"},\"font-family: Tahoma, Verdana, Arial, sans-serif;\"),mdx(\"li\",{parentName:\"ol\"},\"}\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"</style>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"</head>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<body>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<h1>Welcome to nginx!</h1>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<p>\"),\"If you see this page, the nginx web server is successfully installed and\"),mdx(\"li\",{parentName:\"ol\"},\"working. Further configuration is required.\",mdx(\"inlineCode\",{parentName:\"li\"},\"</p>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<p>\"),\"For online documentation and support, refer to\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<a href=\\\"http://nginx.org/\\\">nginx.org</a>.<br/>\")),mdx(\"li\",{parentName:\"ol\"},\"Commercial support is available at\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<a href=\\\"http://nginx.com/\\\">nginx.com</a>.</p>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<p><em>Thank you for using nginx.</em></p>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"</body>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"</html>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},\"100% |\",mdx(\"strong\",{parentName:\"li\"},mdx(\"strong\",{parentName:\"strong\"},mdx(\"strong\",{parentName:\"strong\"},mdx(\"strong\",{parentName:\"strong\"},mdx(\"strong\",{parentName:\"strong\"},mdx(\"strong\",{parentName:\"strong\"},mdx(\"strong\",{parentName:\"strong\"},\"***\"))))))),\"| 612 0:00:00 ETA\")))),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Check external connectivity\")),mdx(\"p\",null,\"As you've seen, Docker's built-in overlay network driver provides out-of-the-box connectivity between the containers on multiple hosts within the same network. Additionally, containers connected to the multi-host network are automatically connected to the\\xA0docker_gwbridge\\xA0network. This network allows the containers to have external connectivity outside of their cluster.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Change your environment to the swarm agent.\"),mdx(\"li\",{parentName:\"ol\"},\"$ eval $(docker-machine env mhs-demo1)\"),mdx(\"li\",{parentName:\"ol\"},\"View the\\xA0docker_gwbridge\\xA0network, by listing the networks.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker network ls\"),mdx(\"li\",{parentName:\"ol\"},\"NETWORK ID NAME DRIVER\"),mdx(\"li\",{parentName:\"ol\"},\"6b07d0be843f my-net overlay\"),mdx(\"li\",{parentName:\"ol\"},\"dd51763e6dd2 bridge bridge\"),mdx(\"li\",{parentName:\"ol\"},\"b4234109bd9b none null\"),mdx(\"li\",{parentName:\"ol\"},\"1aeead6dd890 host host\"),mdx(\"li\",{parentName:\"ol\"},\"e1dbd5dff8be docker_gwbridge bridge\"),mdx(\"li\",{parentName:\"ol\"},\"Repeat steps 1 and 2 on the swarm manager.\"),mdx(\"li\",{parentName:\"ol\"},\"$ eval $(docker-machine env mhs-demo0)\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker network ls\"),mdx(\"li\",{parentName:\"ol\"},\"NETWORK ID NAME DRIVER\"),mdx(\"li\",{parentName:\"ol\"},\"6b07d0be843f my-net overlay\"),mdx(\"li\",{parentName:\"ol\"},\"d0bb78cbe7bd bridge bridge\"),mdx(\"li\",{parentName:\"ol\"},\"1c0eb8f69ebb none null\"),mdx(\"li\",{parentName:\"ol\"},\"412c2496d0eb host host\"),mdx(\"li\",{parentName:\"ol\"},\"97102a22e8d2 docker_gwbridge bridge\"),mdx(\"li\",{parentName:\"ol\"},\"Check the Nginx container's network interfaces.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker container exec web ip addr\"),mdx(\"li\",{parentName:\"ol\"},\"1: lo: \",mdx(\"inlineCode\",{parentName:\"li\"},\"<LOOPBACK,UP,LOWER_UP>\"),\" mtu 65536 qdisc noqueue state UNKNOWN group default\"),mdx(\"li\",{parentName:\"ol\"},\"link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\"),mdx(\"li\",{parentName:\"ol\"},\"inet 127.0.0.1/8 scope host lo\"),mdx(\"li\",{parentName:\"ol\"},\"valid_lft forever preferred_lft forever\"),mdx(\"li\",{parentName:\"ol\"},\"inet6 ::1/128 scope host\"),mdx(\"li\",{parentName:\"ol\"},\"valid_lft forever preferred_lft forever\"),mdx(\"li\",{parentName:\"ol\"},\"22: eth0: \",mdx(\"inlineCode\",{parentName:\"li\"},\"<BROADCAST,MULTICAST,UP,LOWER_UP>\"),\" mtu 1450 qdisc noqueue state UP group default\"),mdx(\"li\",{parentName:\"ol\"},\"link/ether 02:42:0a:00:09:03 brd ff:ff:ff:ff:ff:ff\"),mdx(\"li\",{parentName:\"ol\"},\"inet 10.0.9.2/24 scope global eth0\"),mdx(\"li\",{parentName:\"ol\"},\"valid_lft forever preferred_lft forever\"),mdx(\"li\",{parentName:\"ol\"},\"inet6 fe80::42:aff:fe00:903/64 scope link\"),mdx(\"li\",{parentName:\"ol\"},\"valid_lft forever preferred_lft forever\"),mdx(\"li\",{parentName:\"ol\"},\"24: eth1: \",mdx(\"inlineCode\",{parentName:\"li\"},\"<BROADCAST,MULTICAST,UP,LOWER_UP>\"),\" mtu 1500 qdisc noqueue state UP group default\"),mdx(\"li\",{parentName:\"ol\"},\"link/ether 02:42:ac:12:00:02 brd ff:ff:ff:ff:ff:ff\"),mdx(\"li\",{parentName:\"ol\"},\"inet 172.18.0.2/16 scope global eth1\"),mdx(\"li\",{parentName:\"ol\"},\"valid_lft forever preferred_lft forever\"),mdx(\"li\",{parentName:\"ol\"},\"inet6 fe80::42:acff:fe12:2/64 scope link\"),mdx(\"li\",{parentName:\"ol\"},\"valid_lft forever preferred_lft forever\")),mdx(\"p\",null,\"The\\xA0eth0\\xA0interface represents the container interface that is connected to the\\xA0my-net\\xA0overlay network. While the\\xA0eth1\\xA0interface represents the container interface that is connected to the\\xA0docker_gwbridge\\xA0network.\"),mdx(\"h4\",null,\"Use Docker Compose with swarm classic\"),mdx(\"p\",null,\"Refer to the Networking feature introduced in\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/compose/networking/\"}),\"Compose V2 format\"),\"\\xA0and execute the multi-host networking scenario in the swarm cluster used above.\"),mdx(\"h4\",null,\"Next steps\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/\"}),\"Networking overview\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/network/overlay/\"}),\"Overlay networks\"))),mdx(\"p\",null,\"Manage Application Data\"),mdx(\"h1\",null,\"Manage data in Docker\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA08 minutes\")),mdx(\"p\",null,\"It is possible to store data within the writable layer of a container, but there are some downsides:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"The data doesn't persist when that container is no longer running, and it can be difficult to get the data out of the container if another process needs it.\"),mdx(\"li\",{parentName:\"ul\"},\"A container's writable layer is tightly coupled to the host machine where the container is running. You can't easily move the data somewhere else.\"),mdx(\"li\",{parentName:\"ul\"},\"Writing into a container's writable layer requires a\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/\"}),\"storage driver\"),\"\\xA0to manage the filesystem. The storage driver provides a union filesystem, using the Linux kernel. This extra abstraction reduces performance as compared to using\\xA0data volumes, which write directly to the host filesystem.\")),mdx(\"p\",null,\"Docker offers three different ways to mount data into a container from the Docker host:\\xA0volumes,\\xA0bind mounts, or\\xA0\",mdx(\"em\",{parentName:\"p\"},\"tmpfs\"),\"\\xA0volumes. When in doubt, volumes are almost always the right choice. Keep reading for more information about each mechanism for mounting data into containers.\"),mdx(\"h2\",null,\"Choose the right type of mount\"),mdx(\"p\",null,\"No matter which type of mount you choose to use, the data looks the same from within the container. It is exposed as either a directory or an individual file in the container's filesystem.\"),mdx(\"p\",null,\"An easy way to visualize the difference among volumes, bind mounts, and\\xA0tmpfs\\xA0mounts is to think about where the data lives on the Docker host.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Volumes\"),\"\\xA0are stored in a part of the host filesystem which is\\xA0managed by Docker(/var/lib/docker/volumes/\\xA0on Linux). Non-Docker processes should not modify this part of the filesystem. Volumes are the best way to persist data in Docker.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Bind mounts\"),\"\\xA0may be stored\\xA0anywhere\\xA0on the host system. They may even be important system files or directories. Non-Docker processes on the Docker host or a Docker container can modify them at any time.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"tmpfs\\xA0mounts\"),\"\\xA0are stored in the host system's memory only, and are never written to the host system's filesystem.\")),mdx(\"h3\",null,\"More details about mount types\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/volumes/\"}),mdx(\"strong\",{parentName:\"a\"},\"Volumes\")),\": Created and managed by Docker. You can create a volume explicitly using the\\xA0docker volume create\\xA0command, or Docker can create a volume during container or service creation.\")),mdx(\"p\",null,\"When you create a volume, it is stored within a directory on the Docker host. When you mount the volume into a container, this directory is what is mounted into the container. This is similar to the way that bind mounts work, except that volumes are managed by Docker and are isolated from the core functionality of the host machine.\"),mdx(\"p\",null,\"A given volume can be mounted into multiple containers simultaneously. When no running container is using a volume, the volume is still available to Docker and is not removed automatically. You can remove unused volumes using\\xA0docker volume prune.\"),mdx(\"p\",null,\"When you mount a volume, it may be\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"named\"),\"\\xA0or\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"anonymous\"),\". Anonymous volumes are not given an explicit name when they are first mounted into a container, so Docker gives them a random name that is guaranteed to be unique within a given Docker host. Besides the name, named and anonymous volumes behave in the same ways.\"),mdx(\"p\",null,\"Volumes also support the use of\\xA0volume drivers, which allow you to store your data on remote hosts or cloud providers, among other possibilities.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/bind-mounts/\"}),mdx(\"strong\",{parentName:\"a\"},\"Bind mounts\")),\": Available since the early days of Docker. Bind mounts have limited functionality compared to volumes. When you use a bind mount, a file or directory on the\\xA0host machine\\xA0is mounted into a container. The file or directory is referenced by its full path on the host machine. The file or directory does not need to exist on the Docker host already. It is created on demand if it does not yet exist. Bind mounts are very performant, but they rely on the host machine's filesystem having a specific directory structure available. If you are developing new Docker applications, consider using named volumes instead. You can't use Docker CLI commands to directly manage bind mounts.\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Warning\"),\": One side effect of using bind mounts, for better or for worse, is that you can change the\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"host\"),\"\\xA0filesystem via processes running in a\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"container\"),\", including creating, modifying, or deleting important system files or directories. This is a powerful ability which can have security implications, including impacting non-Docker processes on the host system.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/tmpfs/\"}),mdx(\"strong\",{parentName:\"a\"},\"tmpfs mounts\")),\": A\\xA0tmpfs\\xA0mount is not persisted on disk, either on the Docker host or within a container. It can be used by a container during the lifetime of the container, to store non-persistent state or sensitive information. For instance, internally, swarm services use\\xA0tmpfsmounts to mount\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/secrets/\"}),\"secrets\"),\"\\xA0into a service's containers.\")),mdx(\"p\",null,\"Bind mounts and volumes can both mounted into containers using the\\xA0-v\\xA0or\\xA0--volume\\xA0flag, but the syntax for each is slightly different. For\\xA0tmpfs\\xA0mounts, you can use the\\xA0--tmpfs\\xA0flag. However, in Docker 17.06 and higher, we recommend using the\\xA0--mount\\xA0flag for both containers and services, for bind mounts, volumes, or\\xA0tmpfs\\xA0mounts, as the syntax is more clear.\"),mdx(\"h3\",null,\"Good use cases for volumes\"),mdx(\"p\",null,\"Volumes are the preferred way to persist data in Docker containers and services. Some use cases for volumes include:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Sharing data among multiple running containers. If you don't explicitly create it, a volume is created the first time it is mounted into a container. When that container stops or is removed, the volume still exists. Multiple containers can mount the same volume simultaneously, either read-write or read-only. Volumes are only removed when you explicitly remove them.\"),mdx(\"li\",{parentName:\"ul\"},\"When the Docker host is not guaranteed to have a given directory or file structure. Volumes help you decouple the configuration of the Docker host from the container runtime.\"),mdx(\"li\",{parentName:\"ul\"},\"When you want to store your container's data on a remote host or a cloud provider, rather than locally.\"),mdx(\"li\",{parentName:\"ul\"},\"When you need to back up, restore, or migrate data from one Docker host to another, volumes are a better choice. You can stop containers using the volume, then back up the volume's directory (such as\\xA0/var/lib/docker/volumes/\",mdx(\"inlineCode\",{parentName:\"li\"},\"<volume-name>\"),\").\")),mdx(\"h3\",null,\"Good use cases for bind mounts\"),mdx(\"p\",null,\"In general, you should use volumes where possible. Bind mounts are appropriate for the following types of use case:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Sharing configuration files from the host machine to containers. This is how Docker provides DNS resolution to containers by default, by mounting\\xA0/etc/resolv.conf\\xA0from the host machine into each container.\"),mdx(\"li\",{parentName:\"ul\"},\"Sharing source code or build artifacts between a development environment on the Docker host and a container. For instance, you may mount a Maven\\xA0target/\\xA0directory into a container, and each time you build the Maven project on the Docker host, the container gets access to the rebuilt artifacts.\")),mdx(\"p\",null,\"If you use Docker for development this way, your production Dockerfile would copy the production-ready artifacts directly into the image, rather than relying on a bind mount.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"When the file or directory structure of the Docker host is guaranteed to be consistent with the bind mounts the containers require.\")),mdx(\"h3\",null,\"Good use cases for tmpfs mounts\"),mdx(\"p\",null,\"tmpfs\\xA0mounts are best used for cases when you do not want the data to persist either on the host machine or within the container. This may be for security reasons or to protect the performance of the container when your application needs to write a large volume of non-persistent state data.\"),mdx(\"h3\",null,\"Tips for using bind mounts or volumes\"),mdx(\"p\",null,\"If you use either bind mounts or volumes, keep the following in mind:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"If you mount an\\xA0\",mdx(\"strong\",{parentName:\"li\"},\"empty volume\"),\"\\xA0into a directory in the container in which files or directories exist, these files or directories are propagated (copied) into the volume. Similarly, if you start a container and specify a volume which does not already exist, an empty volume is created for you. This is a good way to pre-populate data that another container needs.\"),mdx(\"li\",{parentName:\"ul\"},\"If you mount a\\xA0\",mdx(\"strong\",{parentName:\"li\"},\"bind mount or non-empty volume\"),\"\\xA0into a directory in the container in which some files or directories exist, these files or directories are obscured by the mount, just as if you saved files into\\xA0/mnt\\xA0on a Linux host and then mounted a USB drive into\\xA0/mnt. The contents of\\xA0/mnt\\xA0would be obscured by the contents of the USB drive until the USB drive were unmounted. The obscured files are not removed or altered, but are not accessible while the bind mount or volume is mounted.\")),mdx(\"h3\",null,\"Next steps\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Learn more about\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/volumes/\"}),\"volumes\"),\".\"),mdx(\"li\",{parentName:\"ul\"},\"Learn more about\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/bind-mounts/\"}),\"bind mounts\"),\".\"),mdx(\"li\",{parentName:\"ul\"},\"Learn more about\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/tmpfs/\"}),\"tmpfs mounts\"),\".\"),mdx(\"li\",{parentName:\"ul\"},\"Learn more about\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/\"}),\"storage drivers\"),\", which are not related to bind mounts or volumes, but allow you to store data in a container's writable layer.\")),mdx(\"h2\",null,\"Use volumes\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA012 minutes\")),mdx(\"p\",null,\"Volumes are the preferred mechanism for persisting data generated by and used by Docker containers. While\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/storage/bind-mounts/\"}),\"bind mounts\"),\"\\xA0are dependent on the directory structure of the host machine, volumes are completely managed by Docker. Volumes have several advantages over bind mounts:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Volumes are easier to back up or migrate than bind mounts.\"),mdx(\"li\",{parentName:\"ul\"},\"You can manage volumes using Docker CLI commands or the Docker API.\"),mdx(\"li\",{parentName:\"ul\"},\"Volumes work on both Linux and Windows containers.\"),mdx(\"li\",{parentName:\"ul\"},\"Volumes can be more safely shared among multiple containers.\"),mdx(\"li\",{parentName:\"ul\"},\"Volume drivers allow you to store volumes on remote hosts or cloud providers, to encrypt the contents of volumes, or to add other functionality.\"),mdx(\"li\",{parentName:\"ul\"},\"A new volume's contents can be pre-populated by a container.\")),mdx(\"p\",null,\"In addition, volumes are often a better choice than persisting data in a container's writable layer, because using a volume does not increase the size of containers using it, and the volume's contents exist outside the lifecycle of a given container.\"),mdx(\"p\",null,\"If your container generates non-persistent state data, consider using a\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/storage/tmpfs/\"}),\"tmpfs mount\"),\"\\xA0to avoid storing the data anywhere permanently, and to increase the container's performance by avoiding writing into the container's writable layer.\"),mdx(\"p\",null,\"Volumes use\\xA0rprivate\\xA0bind propagation, and bind propagation is not configurable for volumes.\"),mdx(\"h3\",null,\"Choose the -v or --mount flag\"),mdx(\"p\",null,\"Originally, the\\xA0-v\\xA0or\\xA0--volume\\xA0flag was used for standalone containers and the\\xA0--mount\\xA0flag was used for swarm services. However, starting with Docker 17.06, you can also use\\xA0--mount\\xA0with standalone containers. In general,\\xA0--mount\\xA0is more explicit and verbose. The biggest difference is that the\\xA0-v\\xA0syntax combines all the options together in one field, while the\\xA0--mount\\xA0syntax separates them. Here is a comparison of the syntax for each flag.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Tip\"),\": New users should use the\\xA0--mount\\xA0syntax. Experienced users may be more familiar with the\\xA0-v\\xA0or\\xA0--volume\\xA0syntax, but are encouraged to use\\xA0--mount, because research has shown it to be easier to use.\"),mdx(\"p\",null,\"If you need to specify volume driver options, you must use\\xA0--mount.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"-v\\xA0or\\xA0--volume\"),\": Consists of three fields, separated by colon characters (:). The fields must be in the correct order, and the meaning of each field is not immediately obvious.\",mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},\"In the case of named volumes, the first field is the name of the volume, and is unique on a given host machine. For anonymous volumes, the first field is omitted.\"),mdx(\"li\",{parentName:\"ul\"},\"The second field is the path where the file or directory are mounted in the container.\"),mdx(\"li\",{parentName:\"ul\"},\"The third field is optional, and is a comma-separated list of options, such as\\xA0ro. These options are discussed below.\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"--mount\"),\": Consists of multiple key-value pairs, separated by commas and each consisting of a\\xA0\",mdx(\"inlineCode\",{parentName:\"li\"},\"<key>=<value>\"),\"\\xA0tuple. The\\xA0--mount\\xA0syntax is more verbose than\\xA0-v\\xA0or\\xA0--volume, but the order of the keys is not significant, and the value of the flag is easier to understand.\",mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},\"The\\xA0type\\xA0of the mount, which can be\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/bind-mounts/\"}),\"bind\"),\",\\xA0volume, or\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/tmpfs/\"}),\"tmpfs\"),\". This topic discusses volumes, so the type is always\\xA0volume.\"),mdx(\"li\",{parentName:\"ul\"},\"The\\xA0source\\xA0of the mount. For named volumes, this is the name of the volume. For anonymous volumes, this field is omitted. May be specified as\\xA0source\\xA0or\\xA0src.\"),mdx(\"li\",{parentName:\"ul\"},\"The\\xA0destination\\xA0takes as its value the path where the file or directory is mounted in the container. May be specified as\\xA0destination,\\xA0dst, or\\xA0target.\"),mdx(\"li\",{parentName:\"ul\"},\"The\\xA0readonly\\xA0option, if present, causes the bind mount to be\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/volumes/#use-a-read-only-volume\"}),\"mounted into the container as read-only\"),\".\"),mdx(\"li\",{parentName:\"ul\"},\"The\\xA0volume-opt\\xA0option, which can be specified more than once, takes a key-value pair consisting of the option name and its value.\")))),mdx(\"p\",null,\"The examples below show both the\\xA0--mount\\xA0and\\xA0-v\\xA0syntax where possible, and\\xA0--mount\\xA0is presented first.\"),mdx(\"h4\",null,\"Differences between\\xA0-v\\xA0and\\xA0--mount\\xA0behavior\"),mdx(\"p\",null,\"As opposed to bind mounts, all options for volumes are available for both\\xA0--mount\\xA0and\\xA0-v\\xA0flags.\"),mdx(\"p\",null,\"When using volumes with services, only\\xA0--mount\\xA0is supported.\"),mdx(\"h3\",null,\"Create and manage volumes\"),mdx(\"p\",null,\"Unlike a bind mount, you can create and manage volumes outside the scope of any container.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Create a volume\"),\":\"),mdx(\"p\",null,\"$ docker volume create my-vol\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"List volumes\"),\":\"),mdx(\"p\",null,\"$ docker volume ls\"),mdx(\"p\",null,\"local my-vol\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Inspect a volume\"),\":\"),mdx(\"p\",null,\"$ docker volume inspect my-vol\"),mdx(\"p\",null,\"[\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"Driver\\\": \\\"local\\\",\"),mdx(\"p\",null,\"\\\"Labels\\\": {},\"),mdx(\"p\",null,\"\\\"Mountpoint\\\": \\\"/var/lib/docker/volumes/my-vol/_data\\\",\"),mdx(\"p\",null,\"\\\"Name\\\": \\\"my-vol\\\",\"),mdx(\"p\",null,\"\\\"Options\\\": {},\"),mdx(\"p\",null,\"\\\"Scope\\\": \\\"local\\\"\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"]\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Remove a volume\"),\":\"),mdx(\"p\",null,\"$ docker volume rm my-vol\"),mdx(\"h3\",null,\"Start a container with a volume\"),mdx(\"p\",null,\"If you start a container with a volume that does not yet exist, Docker creates the volume for you. The following example mounts the volume\\xA0myvol2\\xA0into\\xA0/app/\\xA0in the container.\"),mdx(\"p\",null,\"The\\xA0-v\\xA0and\\xA0--mount\\xA0examples below produce the same result. You can't run them both unless you remove the\\xA0devtest\\xA0container and the\\xA0myvol2\\xA0volume after running the first one.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"--mount\"),mdx(\"li\",{parentName:\"ul\"},\"-v\")),mdx(\"p\",null,\"$ docker run -d \\\\\"),mdx(\"p\",null,\"--name devtest \\\\\"),mdx(\"p\",null,\"-v myvol2:/app \\\\\"),mdx(\"p\",null,\"nginx:latest\"),mdx(\"p\",null,\"Use\\xA0docker inspect devtest\\xA0to verify that the volume was created and mounted correctly. Look for the\\xA0Mounts\\xA0section:\"),mdx(\"p\",null,\"\\\"Mounts\\\": [\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"Type\\\": \\\"volume\\\",\"),mdx(\"p\",null,\"\\\"Name\\\": \\\"myvol2\\\",\"),mdx(\"p\",null,\"\\\"Source\\\": \\\"/var/lib/docker/volumes/myvol2/_data\\\",\"),mdx(\"p\",null,\"\\\"Destination\\\": \\\"/app\\\",\"),mdx(\"p\",null,\"\\\"Driver\\\": \\\"local\\\",\"),mdx(\"p\",null,\"\\\"Mode\\\": \\\"\\\",\"),mdx(\"p\",null,\"\\\"RW\\\": true,\"),mdx(\"p\",null,\"\\\"Propagation\\\": \\\"\\\"\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"],\"),mdx(\"p\",null,\"This shows that the mount is a volume, it shows the correct source and destination, and that the mount is read-write.\"),mdx(\"p\",null,\"Stop the container and remove the volume.\"),mdx(\"p\",null,\"$ docker container stop devtest\"),mdx(\"p\",null,\"$ docker container rm devtest\"),mdx(\"p\",null,\"$ docker volume rm myvol2\"),mdx(\"h4\",null,\"Start a service with volumes\"),mdx(\"p\",null,\"When you start a service and define a volume, each service container uses its own local volume. None of the containers can share this data if you use the\\xA0local\\xA0volume driver, but some volume drivers do support shared storage. Docker for AWS and Docker for Azure both support persistent storage using the Cloudstor plugin.\"),mdx(\"p\",null,\"The following example starts a\\xA0nginx\\xA0service with four replicas, each of which uses a local volume called\\xA0myvol2.\"),mdx(\"p\",null,\"$ docker service create -d \\\\\"),mdx(\"p\",null,\"--replicas=4 \\\\\"),mdx(\"p\",null,\"--name devtest-service \\\\\"),mdx(\"p\",null,\"--mount source=myvol2,target=/app \\\\\"),mdx(\"p\",null,\"nginx:latest\"),mdx(\"p\",null,\"Use\\xA0docker service ps devtest-service\\xA0to verify that the service is running:\"),mdx(\"p\",null,\"$ docker service ps devtest-service\"),mdx(\"p\",null,\"ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS\"),mdx(\"p\",null,\"4d7oz1j85wwn devtest-service.1 nginx:latest moby Running Running 14 seconds ago\"),mdx(\"p\",null,\"Remove the service, which stops all its tasks:\"),mdx(\"p\",null,\"$ docker service rm devtest-service\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"SYNTAX DIFFERENCES FOR SERVICES\")),mdx(\"p\",null,\"The\\xA0docker service create\\xA0command does not support the\\xA0-v\\xA0or\\xA0--volume\\xA0flag. When mounting a volume into a service's containers, you must use the\\xA0--mount\\xA0flag.\"),mdx(\"h4\",null,\"Populate a volume using a container\"),mdx(\"p\",null,\"If you start a container which creates a new volume, as above, and the container has files or directories in the directory to be mounted (such as\\xA0/app/\\xA0above), the directory's contents are copied into the volume. The container then mounts and uses the volume, and other containers which use the volume also have access to the pre-populated content.\"),mdx(\"p\",null,\"To illustrate this, this example starts an\\xA0nginx\\xA0container and populates the new volume\\xA0nginx-volwith the contents of the container's\\xA0/usr/share/nginx/html\\xA0directory, which is where Nginx stores its default HTML content.\"),mdx(\"p\",null,\"The\\xA0--mount\\xA0and\\xA0-v\\xA0examples have the same end result.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"--mount\"),mdx(\"li\",{parentName:\"ul\"},\"-v\")),mdx(\"p\",null,\"$ docker run -d \\\\\"),mdx(\"p\",null,\"--name=nginxtest \\\\\"),mdx(\"p\",null,\"-v nginx-vol:/usr/share/nginx/html \\\\\"),mdx(\"p\",null,\"nginx:latest\"),mdx(\"p\",null,\"After running either of these examples, run the following commands to clean up the containers and volumes.\"),mdx(\"p\",null,\"$ docker container stop nginxtest\"),mdx(\"p\",null,\"$ docker container rm nginxtest\"),mdx(\"p\",null,\"$ docker volume rm nginx-vol\"),mdx(\"h3\",null,\"Use a read-only volume\"),mdx(\"p\",null,\"For some development applications, the container needs to write into the bind mount so that changes are propagated back to the Docker host. At other times, the container only needs read access to the data. Remember that multiple containers can mount the same volume, and it can be mounted read-write for some of them and read-only for others, at the same time.\"),mdx(\"p\",null,\"This example modifies the one above but mounts the directory as a read-only volume, by adding\\xA0ro\\xA0to the (empty by default) list of options, after the mount point within the container. Where multiple options are present, separate them by commas.\"),mdx(\"p\",null,\"The\\xA0--mount\\xA0and\\xA0-v\\xA0examples have the same result.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"--mount\"),mdx(\"li\",{parentName:\"ul\"},\"-v\")),mdx(\"p\",null,\"$ docker run -d \\\\\"),mdx(\"p\",null,\"--name=nginxtest \\\\\"),mdx(\"p\",null,\"-v nginx-vol:/usr/share/nginx/html:ro \\\\\"),mdx(\"p\",null,\"nginx:latest\"),mdx(\"p\",null,\"Use\\xA0docker inspect nginxtest\\xA0to verify that the bind mount was created correctly. Look for the\\xA0Mounts\\xA0section:\"),mdx(\"p\",null,\"\\\"Mounts\\\": [\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"Type\\\": \\\"volume\\\",\"),mdx(\"p\",null,\"\\\"Name\\\": \\\"nginx-vol\\\",\"),mdx(\"p\",null,\"\\\"Source\\\": \\\"/var/lib/docker/volumes/nginx-vol/_data\\\",\"),mdx(\"p\",null,\"\\\"Destination\\\": \\\"/usr/share/nginx/html\\\",\"),mdx(\"p\",null,\"\\\"Driver\\\": \\\"local\\\",\"),mdx(\"p\",null,\"\\\"Mode\\\": \\\"\\\",\"),mdx(\"p\",null,\"\\\"RW\\\": false,\"),mdx(\"p\",null,\"\\\"Propagation\\\": \\\"\\\"\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"],\"),mdx(\"p\",null,\"Stop and remove the container, and remove the volume:\"),mdx(\"p\",null,\"$ docker container stop nginxtest\"),mdx(\"p\",null,\"$ docker container rm nginxtest\"),mdx(\"p\",null,\"$ docker volume rm nginx-vol\"),mdx(\"h3\",null,\"Use a volume driver\"),mdx(\"p\",null,\"When you create a volume using\\xA0docker volume create, or when you start a container which uses a not-yet-created volume, you can specify a volume driver. The following examples use the\\xA0vieux/sshfsvolume driver, first when creating a standalone volume, and then when starting a container which creates a new volume.\"),mdx(\"h4\",null,\"Initial set-up\"),mdx(\"p\",null,\"This example assumes that you have two nodes, the first of which is a Docker host and can connect to the second using SSH.\"),mdx(\"p\",null,\"On the Docker host, install the\\xA0vieux/sshfs\\xA0plugin:\"),mdx(\"p\",null,\"$ docker plugin install --grant-all-permissions vieux/sshfs\"),mdx(\"h4\",null,\"Create a volume using a volume driver\"),mdx(\"p\",null,\"This example specifies a SSH password, but if the two hosts have shared keys configured, you can omit the password. Each volume driver may have zero or more configurable options, each of which is specified using an\\xA0-o\\xA0flag.\"),mdx(\"p\",null,\"$ docker volume create --driver vieux/sshfs \\\\\"),mdx(\"p\",null,\"-o sshcmd=test\\\\@node2:/home/test \\\\\"),mdx(\"p\",null,\"-o password=testpassword \\\\\"),mdx(\"p\",null,\"sshvolume\"),mdx(\"h4\",null,\"Start a container which creates a volume using a volume driver\"),mdx(\"p\",null,\"This example specifies a SSH password, but if the two hosts have shared keys configured, you can omit the password. Each volume driver may have zero or more configurable options.\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"If the volume driver requires you to pass options, you must use the\\xA0--mount\\xA0flag to mount the volume, rather than\\xA0-v.\")),mdx(\"p\",null,\"$ docker run -d \\\\\"),mdx(\"p\",null,\"--name sshfs-container \\\\\"),mdx(\"p\",null,\"--volume-driver vieux/sshfs \\\\\"),mdx(\"p\",null,\"--mount src=sshvolume,target=/app,volume-opt=sshcmd=test\\\\@node2:/home/test,volume-opt=password=testpassword \\\\\"),mdx(\"p\",null,\"nginx:latest\"),mdx(\"h3\",null,\"Next steps\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Learn about\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/bind-mounts/\"}),\"bind mounts\"),\".\"),mdx(\"li\",{parentName:\"ul\"},\"Learn about\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/tmpfs/\"}),\"tmpfs mounts\"),\".\"),mdx(\"li\",{parentName:\"ul\"},\"Learn about\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/\"}),\"storage drivers\"),\".\")),mdx(\"h2\",null,\"Use bind mounts\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA015 minutes\")),mdx(\"p\",null,\"Bind mounts have been around since the early days of Docker. Bind mounts have limited functionality compared to\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/storage/volumes/\"}),\"volumes\"),\". When you use a bind mount, a file or directory on the\\xA0host machine\\xA0is mounted into a container. The file or directory is referenced by its full or relative path on the host machine. By contrast, when you use a volume, a new directory is created within Docker's storage directory on the host machine, and Docker manages that directory's contents.\"),mdx(\"p\",null,\"The file or directory does not need to exist on the Docker host already. It is created on demand if it does not yet exist. Bind mounts are very performant, but they rely on the host machine's filesystem having a specific directory structure available. If you are developing new Docker applications, consider using\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/storage/volumes/\"}),\"named volumes\"),\"\\xA0instead. You can't use Docker CLI commands to directly manage bind mounts.\"),mdx(\"h3\",null,\"Choosing the -v or --mount flag\"),mdx(\"p\",null,\"Originally, the\\xA0-v\\xA0or\\xA0--volume\\xA0flag was used for standalone containers and the\\xA0--mount\\xA0flag was used for swarm services. However, starting with Docker 17.06, you can also use\\xA0--mount\\xA0with standalone containers. In general,\\xA0--mount\\xA0is more explicit and verbose. The biggest difference is that the\\xA0-v\\xA0syntax combines all the options together in one field, while the\\xA0--mount\\xA0syntax separates them. Here is a comparison of the syntax for each flag.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Tip\"),\": New users should use the\\xA0--mount\\xA0syntax. Experienced users may be more familiar with the\\xA0-v\\xA0or\\xA0--volume\\xA0syntax, but are encouraged to use\\xA0--mount, because research has shown it to be easier to use.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"-v\\xA0or\\xA0--volume\"),\": Consists of three fields, separated by colon characters (:). The fields must be in the correct order, and the meaning of each field is not immediately obvious.\",mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},\"In the case of bind mounts, the first field is the path to the file or directory on the\\xA0\",mdx(\"strong\",{parentName:\"li\"},\"host machine\"),\".\"),mdx(\"li\",{parentName:\"ul\"},\"The second field is the path where the file or directory is mounted in the container.\"),mdx(\"li\",{parentName:\"ul\"},\"The third field is optional, and is a comma-separated list of options, such as\\xA0ro,\\xA0consistent,\\xA0delegated,\\xA0cached,\\xA0z, and\\xA0Z. These options are discussed below.\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"--mount\"),\": Consists of multiple key-value pairs, separated by commas and each consisting of a\\xA0\",mdx(\"inlineCode\",{parentName:\"li\"},\"<key>=<value>\"),\"\\xA0tuple. The\\xA0--mount\\xA0syntax is more verbose than\\xA0-v\\xA0or\\xA0--volume, but the order of the keys is not significant, and the value of the flag is easier to understand.\",mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},\"The\\xA0type\\xA0of the mount, which can be\\xA0bind,\\xA0volume, or\\xA0tmpfs. This topic discusses bind mounts, so the type is always\\xA0bind.\"),mdx(\"li\",{parentName:\"ul\"},\"The\\xA0source\\xA0of the mount. For bind mounts, this is the path to the file or directory on the Docker daemon host. May be specified as\\xA0source\\xA0or\\xA0src.\"),mdx(\"li\",{parentName:\"ul\"},\"The\\xA0destination\\xA0takes as its value the path where the file or directory is mounted in the container. May be specified as\\xA0destination,\\xA0dst, or\\xA0target.\"),mdx(\"li\",{parentName:\"ul\"},\"The\\xA0readonly\\xA0option, if present, causes the bind mount to be\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/bind-mounts/#use-a-read-only-bind-mount\"}),\"mounted into the container as read-only\"),\".\"),mdx(\"li\",{parentName:\"ul\"},\"The\\xA0bind-propagation\\xA0option, if present, changes the\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/bind-mounts/#configure-bind-propagation\"}),\"bind propagation\"),\". May be one of\\xA0rprivate,\\xA0private,\\xA0rshared,\\xA0shared,\\xA0rslave,\\xA0slave.\"),mdx(\"li\",{parentName:\"ul\"},\"The\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/bind-mounts/#configure-mount-consistency-for-macos\"}),\"consistency\"),\"\\xA0option, if present, may be one of\\xA0consistent,\\xA0delegated, or\\xA0cached. This setting only applies to Docker for Mac, and is ignored on all other platforms.\"),mdx(\"li\",{parentName:\"ul\"},\"The\\xA0--mount\\xA0flag does not support\\xA0z\\xA0or\\xA0Z\\xA0options for modifying selinux labels.\")))),mdx(\"p\",null,\"The examples below show both the\\xA0--mount\\xA0and\\xA0-v\\xA0syntax where possible, and\\xA0--mount\\xA0is presented first.\"),mdx(\"h4\",null,\"Differences between\\xA0-v\\xA0and\\xA0--mount\\xA0behavior\"),mdx(\"p\",null,\"Because the\\xA0-v\\xA0and\\xA0--volume\\xA0flags have been a part of Docker for a long time, their behavior cannot be changed. This means that\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"there is one behavior that is different between\\xA0-v\\xA0and\\xA0--mount.\")),mdx(\"p\",null,\"If you use\\xA0-v\\xA0or\\xA0--volume\\xA0to bind-mount a file or directory that does not yet exist on the Docker host,\\xA0-v\\xA0creates the endpoint for you.\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"It is always created as a directory.\")),mdx(\"p\",null,\"If you use\\xA0--mount\\xA0to bind-mount a file or directory that does not yet exist on the Docker host, Docker does\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"not\"),\"\\xA0automatically create it for you, but generates an error.\"),mdx(\"h3\",null,\"Start a container with a bind mount\"),mdx(\"p\",null,\"Consider a case where you have a directory\\xA0source\\xA0and that when you build the source code, the artifacts are saved into another directory\\xA0source/target/. You want the artifacts to be available to the container at\\xA0/app/, and you want the container to get access to a new build each time you build the source on your development host. Use the following command to bind-mount the\\xA0target/\\xA0directory into your container at\\xA0/app/. Run the command from within the\\xA0source\\xA0directory. The\\xA0$(pwd)\\xA0sub-command expands to the current working directory on Linux or macOS hosts.\"),mdx(\"p\",null,\"The\\xA0--mount\\xA0and\\xA0-v\\xA0examples below produce the same result. You can't run them both unless you remove the\\xA0devtest\\xA0container after running the first one.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"--mount\"),mdx(\"li\",{parentName:\"ul\"},\"-v\")),mdx(\"p\",null,\"$ docker run -d \\\\\"),mdx(\"p\",null,\"-it \\\\\"),mdx(\"p\",null,\"--name devtest \\\\\"),mdx(\"p\",null,\"--mount type=bind,source=\\\"$(pwd)\\\"/target,target=/app \\\\\"),mdx(\"p\",null,\"nginx:latest\"),mdx(\"p\",null,\"Use\\xA0docker inspect devtest\\xA0to verify that the bind mount was created correctly. Look for the\\xA0Mountssection:\"),mdx(\"p\",null,\"\\\"Mounts\\\": [\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"Type\\\": \\\"bind\\\",\"),mdx(\"p\",null,\"\\\"Source\\\": \\\"/tmp/source/target\\\",\"),mdx(\"p\",null,\"\\\"Destination\\\": \\\"/app\\\",\"),mdx(\"p\",null,\"\\\"Mode\\\": \\\"\\\",\"),mdx(\"p\",null,\"\\\"RW\\\": true,\"),mdx(\"p\",null,\"\\\"Propagation\\\": \\\"rprivate\\\"\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"],\"),mdx(\"p\",null,\"This shows that the mount is a\\xA0bind\\xA0mount, it shows the correct source and destination, it shows that the mount is read-write, and that the propagation is set to\\xA0rprivate.\"),mdx(\"p\",null,\"Stop the container:\"),mdx(\"p\",null,\"$ docker container stop devtest\"),mdx(\"p\",null,\"$ docker container rm devtest\"),mdx(\"h4\",null,\"Mounting into a non-empty directory on the container\"),mdx(\"p\",null,\"If you bind-mount into a non-empty directory on the container, the directory's existing contents are obscured by the bind mount. This can be beneficial, such as when you want to test a new version of your application without building a new image. However, it can also be surprising and this behavior differs from that of\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/storage/volumes/\"}),\"docker volumes\"),\".\"),mdx(\"p\",null,\"This example is contrived to be extreme, but replaces the contents of the container's\\xA0/usr/\\xA0directory with the\\xA0/tmp/\\xA0directory on the host machine. In most cases, this would result in a non-functioning container.\"),mdx(\"p\",null,\"The\\xA0--mount\\xA0and\\xA0-v\\xA0examples have the same end result.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"--mount\"),mdx(\"li\",{parentName:\"ul\"},\"-v\")),mdx(\"p\",null,\"$ docker run -d \\\\\"),mdx(\"p\",null,\"-it \\\\\"),mdx(\"p\",null,\"--name broken-container \\\\\"),mdx(\"p\",null,\"--mount type=bind,source=/tmp,target=/usr \\\\\"),mdx(\"p\",null,\"nginx:latest\"),mdx(\"p\",null,\"docker: Error response from daemon: oci runtime error: container_linux.go:262:\"),mdx(\"p\",null,\"starting container process caused \\\"exec: \\\\\\\"nginx\\\\\\\": executable file not found in $PATH\\\".\"),mdx(\"p\",null,\"The container is created but does not start. Remove it:\"),mdx(\"p\",null,\"$ docker container rm broken-container\"),mdx(\"h3\",null,\"Use a read-only bind mount\"),mdx(\"p\",null,\"For some development applications, the container needs to write into the bind mount, so changes are propagated back to the Docker host. At other times, the container only needs read access.\"),mdx(\"p\",null,\"This example modifies the one above but mounts the directory as a read-only bind mount, by adding\\xA0ro\\xA0to the (empty by default) list of options, after the mount point within the container. Where multiple options are present, separate them by commas.\"),mdx(\"p\",null,\"The\\xA0--mount\\xA0and\\xA0-v\\xA0examples have the same result.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"--mount\"),mdx(\"li\",{parentName:\"ul\"},\"-v\")),mdx(\"p\",null,\"$ docker run -d \\\\\"),mdx(\"p\",null,\"-it \\\\\"),mdx(\"p\",null,\"--name devtest \\\\\"),mdx(\"p\",null,\"--mount type=bind,source=\\\"$(pwd)\\\"/target,target=/app,readonly \\\\\"),mdx(\"p\",null,\"nginx:latest\"),mdx(\"p\",null,\"Use\\xA0docker inspect devtest\\xA0to verify that the bind mount was created correctly. Look for the\\xA0Mountssection:\"),mdx(\"p\",null,\"\\\"Mounts\\\": [\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"Type\\\": \\\"bind\\\",\"),mdx(\"p\",null,\"\\\"Source\\\": \\\"/tmp/source/target\\\",\"),mdx(\"p\",null,\"\\\"Destination\\\": \\\"/app\\\",\"),mdx(\"p\",null,\"\\\"Mode\\\": \\\"ro\\\",\"),mdx(\"p\",null,\"\\\"RW\\\": false,\"),mdx(\"p\",null,\"\\\"Propagation\\\": \\\"rprivate\\\"\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"],\"),mdx(\"p\",null,\"Stop the container:\"),mdx(\"p\",null,\"$ docker container stop devtest\"),mdx(\"p\",null,\"$ docker container rm devtest\"),mdx(\"h3\",null,\"Configure bind propagation\"),mdx(\"p\",null,\"Bind propagation defaults to\\xA0rprivate\\xA0for both bind mounts and volumes. It is only configurable for bind mounts, and only on Linux host machines. Bind propagation is an advanced topic and many users never need to configure it.\"),mdx(\"p\",null,\"Bind propagation refers to whether or not mounts created within a given bind-mount or named volume can be propagated to replicas of that mount. Consider a mount point\\xA0/mnt, which is also mounted on\\xA0/tmp. The propagation settings control whether a mount on\\xA0/tmp/a\\xA0would also be available on\\xA0/mnt/a. Each propagation setting has a recursive counterpoint. In the case of recursion, consider that\\xA0/tmp/a\\xA0is also mounted as\\xA0/foo. The propagation settings control whether\\xA0/mnt/a\\xA0and/or\\xA0/tmp/awould exist.\"),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Propagation setting\"),\"   \",mdx(\"strong\",{parentName:\"p\"},\"Description\")),mdx(\"hr\",null),mdx(\"p\",null,\"  shared                    Sub-mounts of the original mount are exposed to replica mounts, and sub-mounts of replica mounts are also propagated to the original mount.\\nslave                     similar to a shared mount, but only in one direction. If the original mount exposes a sub-mount, the replica mount can see it. However, if the replica mount exposes a sub-mount, the original mount cannot see it.\\nprivate                   The mount is private. Sub-mounts within it are not exposed to replica mounts, and sub-mounts of replica mounts are not exposed to the original mount.\\nrshared                   The same as shared, but the propagation also extends to and from mount points nested within any of the original or replica mount points.\\nrslave                    The same as slave, but the propagation also extends to and from mount points nested within any of the original or replica mount points.\\nrprivate                  The default. The same as private, meaning that no mount points anywhere within the original or replica mount points propagate in either direction.\"),mdx(\"p\",null,\"Before you can set bind propagation on a mount point, the host filesystem needs to already support bind propagation.\"),mdx(\"p\",null,\"For more information about bind propagation, see the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://www.kernel.org/doc/Documentation/filesystems/sharedsubtree.txt\"}),\"Linux kernel documentation for shared subtree\"),\".\"),mdx(\"p\",null,\"The following example mounts the\\xA0target/\\xA0directory into the container twice, and the second mount sets both the\\xA0ro\\xA0option and the\\xA0rslave\\xA0bind propagation option.\"),mdx(\"p\",null,\"The\\xA0--mount\\xA0and\\xA0-v\\xA0examples have the same result.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"--mount\"),mdx(\"li\",{parentName:\"ul\"},\"-v\")),mdx(\"p\",null,\"$ docker run -d \\\\\"),mdx(\"p\",null,\"-it \\\\\"),mdx(\"p\",null,\"--name devtest \\\\\"),mdx(\"p\",null,\"--mount type=bind,source=\\\"$(pwd)\\\"/target,target=/app \\\\\"),mdx(\"p\",null,\"--mount type=bind,source=\\\"$(pwd)\\\"/target,target=/app2,readonly,bind-propagation=rslave \\\\\"),mdx(\"p\",null,\"nginx:latest\"),mdx(\"p\",null,\"Now if you create\\xA0/app/foo/,\\xA0/app2/foo/\\xA0also exists.\"),mdx(\"h3\",null,\"Configure the selinux label\"),mdx(\"p\",null,\"If you use\\xA0selinux\\xA0you can add the\\xA0z\\xA0or\\xA0Z\\xA0options to modify the selinux label of the\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"host file or directory\"),\"\\xA0being mounted into the container. This affects the file or directory on the host machine itself and can have consequences outside of the scope of Docker.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"The\\xA0z\\xA0option indicates that the bind mount content is shared among multiple containers.\"),mdx(\"li\",{parentName:\"ul\"},\"The\\xA0Z\\xA0option indicates that the bind mount content is private and unshared.\")),mdx(\"p\",null,\"Use\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"extreme\"),\"\\xA0caution with these options. Bind-mounting a system directory such as\\xA0/home\\xA0or\\xA0/usrwith the\\xA0Z\\xA0option renders your host machine inoperable and you may need to relabel the host machine files by hand.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Important\"),\": When using bind mounts with services, selinux labels (:Z\\xA0and\\xA0:z), as well as\\xA0:ro\\xA0are ignored. See\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/moby/moby/issues/32579\"}),\"moby/moby #32579\"),\"\\xA0for details.\"),mdx(\"p\",null,\"This example sets the\\xA0z\\xA0option to specify that multiple containers can share the bind mount's contents:\"),mdx(\"p\",null,\"It is not possible to modify the selinux label using the\\xA0--mount\\xA0flag.\"),mdx(\"p\",null,\"$ docker run -d \\\\\"),mdx(\"p\",null,\"-it \\\\\"),mdx(\"p\",null,\"--name devtest \\\\\"),mdx(\"p\",null,\"-v \\\"$(pwd)\\\"/target:/app:z \\\\\"),mdx(\"p\",null,\"nginx:latest\"),mdx(\"h3\",null,\"Configure mount consistency for macOS\"),mdx(\"p\",null,\"Docker for Mac uses\\xA0osxfs\\xA0to propagate directories and files shared from macOS to the Linux VM. This propagation makes these directories and files available to Docker containers running on Docker for Mac.\"),mdx(\"p\",null,\"By default, these shares are fully-consistent, meaning that every time a write happens on the macOS host or through a mount in a container, the changes are flushed to disk so that all participants in the share have a fully-consistent view. Full consistency can severely impact performance in some cases. Docker 17.05 and higher introduce options to tune the consistency setting on a per-mount, per-container basis. The following options are available:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"consistent\\xA0or\\xA0default: The default setting with full consistency, as described above.\"),mdx(\"li\",{parentName:\"ul\"},\"delegated: The container runtime's view of the mount is authoritative. There may be delays before updates made in a container are visible on the host.\"),mdx(\"li\",{parentName:\"ul\"},\"cached: The macOS host's view of the mount is authoritative. There may be delays before updates made on the host are visible within a container.\")),mdx(\"p\",null,\"These options are completely ignored on all host operating systems except macOS.\"),mdx(\"p\",null,\"The\\xA0--mount\\xA0and\\xA0-v\\xA0examples have the same result.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"--mount\"),mdx(\"li\",{parentName:\"ul\"},\"-v\")),mdx(\"p\",null,\"$ docker run -d \\\\\"),mdx(\"p\",null,\"-it \\\\\"),mdx(\"p\",null,\"--name devtest \\\\\"),mdx(\"p\",null,\"--mount type=bind,source=\\\"$(pwd)\\\"/target,destination=/app,consistency=cached \\\\\"),mdx(\"p\",null,\"nginx:latest\"),mdx(\"h3\",null,\"Next steps\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Learn about\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/volumes/\"}),\"volumes\"),\".\"),mdx(\"li\",{parentName:\"ul\"},\"Learn about\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/tmpfs/\"}),\"tmpfs mounts\"),\".\"),mdx(\"li\",{parentName:\"ul\"},\"Learn about\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/\"}),\"storage drivers\"),\".\")),mdx(\"h2\",null,\"Use tmpfs mounts\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA04 minutes\")),mdx(\"p\",null,mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/storage/volumes/\"}),\"Volumes\"),\"\\xA0and\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/storage/bind-mounts/\"}),\"bind mounts\"),\"\\xA0are mounted into the container's filesystem by default, and their contents are stored on the host machine.\"),mdx(\"p\",null,\"There may be cases where you do not want to store a container's data on the host machine, but you also don't want to write the data into the container's writable layer, for performance or security reasons, or if the data relates to non-persistent application state. An example might be a temporary one-time password that the container's application creates and uses as-needed.\"),mdx(\"p\",null,\"To give the container access to the data without writing it anywhere permanently, you can use a\\xA0tmpfsmount, which is only stored in the host machine's memory (or swap, if memory is low). When the container stops, the\\xA0tmpfs\\xA0mount is removed. If a container is committed, the\\xA0tmpfs\\xA0mount is not saved.\"),mdx(\"h3\",null,\"Choosing the --tmpfs or --mount flag\"),mdx(\"p\",null,\"Originally, the\\xA0--tmpfs\\xA0flag was used for standalone containers and the\\xA0--mount\\xA0flag was used for swarm services. However, starting with Docker 17.06, you can also use\\xA0--mount\\xA0with standalone containers. In general,\\xA0--mount\\xA0is more explicit and verbose. The biggest difference is that the--tmpfs\\xA0flag does not support any configurable options.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Tip\"),\": New users should use the\\xA0--mount\\xA0syntax. Experienced users may be more familiar with the\\xA0--tmpfs\\xA0syntax, but are encouraged to use\\xA0--mount, because research has shown it to be easier to use.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"--tmpfs\"),\": Mounts a\\xA0tmpfs\\xA0mount without allowing you to specify any configurable options, and can only be used with standalone containers.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"--mount\"),\": Consists of multiple key-value pairs, separated by commas and each consisting of a\\xA0\",mdx(\"inlineCode\",{parentName:\"li\"},\"<key>=<value>\"),\"\\xA0tuple. The\\xA0--mount\\xA0syntax is more verbose than\\xA0-v\\xA0or\\xA0--volume, but the order of the keys is not significant, and the value of the flag is easier to understand.\",mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},\"The\\xA0type\\xA0of the mount, which can be\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/bind-mounts-md\"}),\"bind\"),\",\\xA0volume, or\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/tmpfs/\"}),\"tmpfs\"),\". This topic discusses\\xA0tmpfs, so the type is always\\xA0tmpfs.\"),mdx(\"li\",{parentName:\"ul\"},\"The\\xA0destination\\xA0takes as its value the path where the\\xA0tmpfs\\xA0mount is mounted in the container. May be specified as\\xA0destination,\\xA0dst, or\\xA0target.\"),mdx(\"li\",{parentName:\"ul\"},\"The\\xA0tmpfs-type\\xA0and\\xA0tmpfs-mode\\xA0options. See\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/tmpfs/#tmpfs-options\"}),\"tmpfs options\"),\".\")))),mdx(\"p\",null,\"The examples below show both the\\xA0--mount\\xA0and\\xA0--tmpfs\\xA0syntax where possible, and\\xA0--mount\\xA0is presented first.\"),mdx(\"h4\",null,\"Differences between\\xA0--tmpfs\\xA0and\\xA0--mount\\xA0behavior\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"The\\xA0--tmpfs\\xA0flag does not allow you to specify any configurable options.\"),mdx(\"li\",{parentName:\"ul\"},\"The\\xA0--tmpfs\\xA0flag cannot be used with swarm services. You must use\\xA0--mount.\")),mdx(\"h3\",null,\"Limitations of tmpfs containers\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"tmpfs\\xA0mounts cannot be shared among containers.\"),mdx(\"li\",{parentName:\"ul\"},\"tmpfs\\xA0mounts only work on Linux containers, and not on Windows containers.\")),mdx(\"h3\",null,\"Use a tmpfs mount in a container\"),mdx(\"p\",null,\"To use a\\xA0tmpfs\\xA0mount in a container, use the\\xA0--tmpfs\\xA0flag, or use the\\xA0--mount\\xA0flag with\\xA0type=tmpfs\\xA0and\\xA0destination\\xA0options. There is no\\xA0source\\xA0for\\xA0tmpfs\\xA0mounts. The following example creates a\\xA0tmpfs\\xA0mount at\\xA0/app\\xA0in a Nginx container. The first example uses the\\xA0--mountflag and the second uses the\\xA0--tmpfs\\xA0flag.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"--mount\"),mdx(\"li\",{parentName:\"ul\"},\"--tmpfs\")),mdx(\"p\",null,\"$ docker run -d \\\\\"),mdx(\"p\",null,\"-it \\\\\"),mdx(\"p\",null,\"--name tmptest \\\\\"),mdx(\"p\",null,\"--mount type=tmpfs,destination=/app \\\\\"),mdx(\"p\",null,\"nginx:latest\"),mdx(\"p\",null,\"Verify that the mount is a\\xA0tmpfs\\xA0mount by running\\xA0docker container inspect tmptest\\xA0and looking for the\\xA0Mounts\\xA0section:\"),mdx(\"p\",null,\"\\\"Tmpfs\\\": {\"),mdx(\"p\",null,\"\\\"/app\\\": \\\"\\\"\"),mdx(\"p\",null,\"},\"),mdx(\"p\",null,\"Remove the container:\"),mdx(\"p\",null,\"$ docker container stop tmptest\"),mdx(\"p\",null,\"$ Docker container rm tmptest\"),mdx(\"h4\",null,\"Specify tmpfs options\"),mdx(\"p\",null,\"tmpfs\\xA0mounts allow for two configuration options, neither of which is required. If you need to specify these options, you must use the\\xA0--mount\\xA0flag, as the\\xA0--tmpfs\\xA0flag does not support them.\"),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Option\"),\"   \",mdx(\"strong\",{parentName:\"p\"},\"Description\")),mdx(\"hr\",null),mdx(\"p\",null,\"  tmpfs-size   Size of the tmpfs mount in bytes. Unlimited by default.\\ntmpfs-mode   File mode of the tmpfs in octal. For instance,\\xA0700\\xA0or\\xA00770. Defaults to\\xA01777\\xA0or world-writable.\"),mdx(\"p\",null,\"The following example sets the\\xA0tmpfs-mode\\xA0to\\xA01770, so that it is not world-readable within the container.\"),mdx(\"p\",null,\"docker run -d \\\\\"),mdx(\"p\",null,\"-it \\\\\"),mdx(\"p\",null,\"--name tmptest \\\\\"),mdx(\"p\",null,\"--mount type=tmpfs,destination=/app,tmpfs-mode=1770 \\\\\"),mdx(\"p\",null,\"nginx:latest\"),mdx(\"h3\",null,\"Next steps\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Learn about\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/volumes/\"}),\"volumes\")),mdx(\"li\",{parentName:\"ul\"},\"Learn about\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/bind-mounts/\"}),\"bind mounts\")),mdx(\"li\",{parentName:\"ul\"},\"Learn about\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/\"}),\"storage drivers\"))),mdx(\"h2\",null,\"Troubleshoot volume errors\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA01 minute\")),mdx(\"p\",null,\"This topic discusses errors which may occur when you use Docker volumes or bind mounts.\"),mdx(\"h3\",null,\"Error: Unable to remove filesystem\"),mdx(\"p\",null,\"Some container-based utilities, such as\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/google/cadvisor\"}),\"Google cAdvisor\"),\", mount Docker system directories, such as\\xA0/var/lib/docker/, into a container. For instance, the documentation for\\xA0cadvisor\\xA0instructs you to run the\\xA0cadvisor\\xA0container as follows:\"),mdx(\"p\",null,\"$ sudo docker run \\\\\"),mdx(\"p\",null,\"--volume=/:/rootfs:ro \\\\\"),mdx(\"p\",null,\"--volume=/var/run:/var/run:rw \\\\\"),mdx(\"p\",null,\"--volume=/sys:/sys:ro \\\\\"),mdx(\"p\",null,\"--volume=/var/lib/docker/:/var/lib/docker:ro \\\\\"),mdx(\"p\",null,\"--publish=8080:8080 \\\\\"),mdx(\"p\",null,\"--detach=true \\\\\"),mdx(\"p\",null,\"--name=cadvisor \\\\\"),mdx(\"p\",null,\"google/cadvisor:latest\"),mdx(\"p\",null,\"When you bind-mount\\xA0/var/lib/docker/, this effectively mounts all resources of all other running containers as filesystems within the container which mounts\\xA0/var/lib/docker/. When you attempt to remove any of these containers, the removal attempt may fail with an error like the following:\"),mdx(\"p\",null,\"Error: Unable to remove filesystem for\"),mdx(\"p\",null,\"74bef250361c7817bee19349c93139621b272bc8f654ae112dd4eb9652af9515:\"),mdx(\"p\",null,\"remove /var/lib/docker/containers/74bef250361c7817bee19349c93139621b272bc8f654ae112dd4eb9652af9515/shm:\"),mdx(\"p\",null,\"Device or resource busy\"),mdx(\"p\",null,\"The problem occurs if the container which bind-mounts\\xA0/var/lib/docker/\\xA0uses\\xA0statfs\\xA0or\\xA0fstatfson filesystem handles within\\xA0/var/lib/docker/\\xA0and does not close them.\"),mdx(\"p\",null,\"Typically, we would advise against bind-mounting\\xA0/var/lib/docker\\xA0in this way. However,\\xA0cAdvisorrequires this bind-mount for core functionality.\"),mdx(\"p\",null,\"If you are unsure which process is causing the path mentioned in the error to be busy and preventing it from being removed, you can use the\\xA0lsof\\xA0command to find its process. For instance, for the error above:\"),mdx(\"p\",null,\"$ sudo lsof /var/lib/docker/containers/74bef250361c7817bee19349c93139621b272bc8f654ae112dd4eb9652af9515/shm\"),mdx(\"p\",null,\"To work around this problem, stop the container which bind-mounts\\xA0/var/lib/docker\\xA0and try again to remove the other container.\"),mdx(\"h2\",null,\"Store Data within Containers\"),mdx(\"h3\",null,\"About storage drivers\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA016 minutes\")),mdx(\"p\",null,\"To use storage drivers effectively, it's important to know how Docker builds and stores images, how these images are used by containers. You can use this information to make informed choices about the best way to persist data from your applications and avoid performance problems along the way.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": Storage drivers allow you to persist data in the writable layer of your container. This is the least efficient way to persist data.\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/storage/volumes/\"}),\"Volumes\"),\"\\xA0or\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/storage/bind-mounts/\"}),\"bind mounts\"),\"\\xA0provide much better read and write performance, and volumes provide more security and isolation than either storage drivers or bind mounts. Neither volumes nor bind mounts use most of the concepts described in this topic.\"),mdx(\"h4\",null,\"Images and layers\"),mdx(\"p\",null,\"A Docker image is built up from a series of layers. Each layer represents an instruction in the image's Dockerfile. Each layer except the very last one is read-only. Consider the following Dockerfile:\"),mdx(\"p\",null,\"FROM ubuntu:15.04\"),mdx(\"p\",null,\"COPY . /app\"),mdx(\"p\",null,\"RUN make /app\"),mdx(\"p\",null,\"CMD python /app/app.py\"),mdx(\"p\",null,\"This Dockerfile contains four commands, each of which creates a layer. The\\xA0FROM\\xA0statement starts out by creating a layer from the\\xA0ubuntu:15.04\\xA0image. The\\xA0COPY\\xA0command adds some files from your Docker client's current directory. The\\xA0RUN\\xA0command builds your application using the\\xA0makecommand. Finally, the last layer specifies what command to run within the container.\"),mdx(\"p\",null,\"Each layer is only a set of differences from the layer before it. The layers are stacked on top of each other. When you create a new container, you add a new writable layer on top of the underlying layers. This layer is often called the \\\"container layer\\\". All changes made to the running container, such as writing new files, modifying existing files, and deleting files, are written to this thin writable container layer. The diagram below shows a container based on the Ubuntu 15.04 image.\"),mdx(\"p\",null,\"A\\xA0storage driver\\xA0handles the details about the way these layers interact with each other. Different storage drivers are available, which have advantages and disadvantages in different situations.\"),mdx(\"h4\",null,\"Container and layers\"),mdx(\"p\",null,\"The major difference between a container and an image is the top writable layer. All writes to the container that add new or modify existing data are stored in this writable layer. When the container is deleted, the writable layer is also deleted. The underlying image remains unchanged.\"),mdx(\"p\",null,\"Because each container has its own writable container layer, and all changes are stored in this container layer, multiple containers can share access to the same underlying image and yet have their own data state. The diagram below shows multiple containers sharing the same Ubuntu 15.04 image.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": If you need multiple images to have shared access to the exact same data, store this data in a Docker volume and mount it into your containers.\"),mdx(\"p\",null,\"Docker uses storage drivers to manage the contents of the image layers and the writable container layer. Each storage driver handles the implementation differently, but all drivers use stackable image layers and the copy-on-write (CoW) strategy.\"),mdx(\"h4\",null,\"Container size on disk\"),mdx(\"p\",null,\"To view the approximate size of a running container, you can use the\\xA0docker ps -s\\xA0command. Two different columns relate to size.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"size: the amount of data (on disk) that is used for the writable layer of each container\"),mdx(\"li\",{parentName:\"ul\"},\"virtual size: the amount of data used for the read-only image data used by the container plus the container's writable layer\\xA0size. Multiple containers may share some or all read-only image data. Two containers started from the same image share 100% of the read-only data, while two containers with different images which have layers in common share those common layers. Therefore, you can't just total the virtual sizes. This over-estimates the total disk usage by a potentially non-trivial amount.\")),mdx(\"p\",null,\"The total disk space used by all of the running containers on disk is some combination of each container's\\xA0size\\xA0and the\\xA0virtual size\\xA0values. If multiple containers started from the same exact image, the total size on disk for these containers would be SUM (size\\xA0of containers) plus one container's (virtual size-\\xA0size).\"),mdx(\"p\",null,\"This also does not count the following additional ways a container can take up disk space:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Disk space used for log files if you use the\\xA0json-file\\xA0logging driver. This can be non-trivial if your container generates a large amount of logging data and log rotation is not configured.\"),mdx(\"li\",{parentName:\"ul\"},\"Volumes and bind mounts used by the container.\"),mdx(\"li\",{parentName:\"ul\"},\"Disk space used for the container's configuration files, which are typically small.\"),mdx(\"li\",{parentName:\"ul\"},\"Memory written to disk (if swapping is enabled).\"),mdx(\"li\",{parentName:\"ul\"},\"Checkpoints, if you're using the experimental checkpoint/restore feature.\")),mdx(\"h4\",null,\"The copy-on-write (CoW) strategy\"),mdx(\"p\",null,\"Copy-on-write is a strategy of sharing and copying files for maximum efficiency. If a file or directory exists in a lower layer within the image, and another layer (including the writable layer) needs read access to it, it just uses the existing file. The first time another layer needs to modify the file (when building the image or running the container), the file is copied into that layer and modified. This minimizes I/O and the size of each of the subsequent layers. These advantages are explained in more depth below.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Sharing promotes smaller images\")),mdx(\"p\",null,\"When you use\\xA0docker pull\\xA0to pull down an image from a repository, or when you create a container from an image that does not yet exist locally, each layer is pulled down separately, and stored in Docker's local storage area, which is usually\\xA0/var/lib/docker/\\xA0on Linux hosts. You can see these layers being pulled in this example:\"),mdx(\"p\",null,\"$ docker pull ubuntu:15.04\"),mdx(\"p\",null,\"15.04: Pulling from library/ubuntu\"),mdx(\"p\",null,\"1ba8ac955b97: Pull complete\"),mdx(\"p\",null,\"f157c4e5ede7: Pull complete\"),mdx(\"p\",null,\"0b7e98f84c4c: Pull complete\"),mdx(\"p\",null,\"a3ed95caeb02: Pull complete\"),mdx(\"p\",null,\"Digest: sha256:5e279a9df07990286cce22e1b0f5b0490629ca6d187698746ae5e28e604a640e\"),mdx(\"p\",null,\"Status: Downloaded newer image for ubuntu:15.04\"),mdx(\"p\",null,\"Each of these layers is stored in its own directory inside the Docker host's local storage area. To examine the layers on the filesystem, list the contents of\\xA0/var/lib/docker/\",mdx(\"inlineCode\",{parentName:\"p\"},\"<storage-driver>\"),\"/layers/. This example uses\\xA0aufs, which is the default storage driver:\"),mdx(\"p\",null,\"$ ls /var/lib/docker/aufs/layers\"),mdx(\"p\",null,\"1d6674ff835b10f76e354806e16b950f91a191d3b471236609ab13a930275e24\"),mdx(\"p\",null,\"5dbb0cbe0148cf447b9464a358c1587be586058d9a4c9ce079320265e2bb94e7\"),mdx(\"p\",null,\"bef7199f2ed8e86fa4ada1309cfad3089e0542fec8894690529e4c04a7ca2d73\"),mdx(\"p\",null,\"ebf814eccfe98f2704660ca1d844e4348db3b5ccc637eb905d4818fbfb00a06a\"),mdx(\"p\",null,\"The directory names do not correspond to the layer IDs (this has been true since Docker 1.10).\"),mdx(\"p\",null,\"Now imagine that you have two different Dockerfiles. You use the first one to create an image called\\xA0acme/my-base-image:1.0.\"),mdx(\"p\",null,\"FROM ubuntu:16.10\"),mdx(\"p\",null,\"COPY . /app\"),mdx(\"p\",null,\"The second one is based on\\xA0acme/my-base-image:1.0, but has some additional layers:\"),mdx(\"p\",null,\"FROM acme/my-base-image:1.0\"),mdx(\"p\",null,\"CMD /app/hello.sh\"),mdx(\"p\",null,\"The second image contains all the layers from the first image, plus a new layer with the\\xA0CMDinstruction, and a read-write container layer. Docker already has all the layers from the first image, so it does not need to pull them again. The two images share any layers they have in common.\"),mdx(\"p\",null,\"If you build images from the two Dockerfiles, you can use\\xA0docker image ls\\xA0and\\xA0docker historycommands to verify that the cryptographic IDs of the shared layers are the same.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Make a new directory\\xA0cow-test/\\xA0and change into it.\"),mdx(\"li\",{parentName:\"ol\"},\"Within\\xA0cow-test/, create a new file with the following contents:\"),mdx(\"li\",{parentName:\"ol\"},\"#!/bin/sh\"),mdx(\"li\",{parentName:\"ol\"},\"echo \\\"Hello world\\\"\")),mdx(\"p\",null,\"Save the file, and make it executable:\"),mdx(\"p\",null,\"chmod +x hello.sh\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Copy the contents of the first Dockerfile above into a new file called\\xA0Dockerfile.base.\"),mdx(\"li\",{parentName:\"ol\"},\"Copy the contents of the second Dockerfile above into a new file called\\xA0Dockerfile.\"),mdx(\"li\",{parentName:\"ol\"},\"Within the\\xA0cow-test/\\xA0directory, build the first image. Don't forget to include the final\\xA0.\\xA0in the command. That sets the\\xA0PATH, which tells Docker where to look for any files that need to be added to the image.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker build -t acme/my-base-image:1.0 -f Dockerfile.base .\"),mdx(\"li\",{parentName:\"ol\"},\"Sending build context to Docker daemon 4.096kB\"),mdx(\"li\",{parentName:\"ol\"},\"Step 1/2 : FROM ubuntu:16.10\"),mdx(\"li\",{parentName:\"ol\"},\"---> 31005225a745\"),mdx(\"li\",{parentName:\"ol\"},\"Step 2/2 : COPY . /app\"),mdx(\"li\",{parentName:\"ol\"},\"---> Using cache\"),mdx(\"li\",{parentName:\"ol\"},\"---> bd09118bcef6\"),mdx(\"li\",{parentName:\"ol\"},\"Successfully built bd09118bcef6\"),mdx(\"li\",{parentName:\"ol\"},\"Successfully tagged acme/my-base-image:1.0\"),mdx(\"li\",{parentName:\"ol\"},\"Build the second image.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker build -t acme/my-final-image:1.0 -f Dockerfile .\"),mdx(\"li\",{parentName:\"ol\"},\"Sending build context to Docker daemon 4.096kB\"),mdx(\"li\",{parentName:\"ol\"},\"Step 1/2 : FROM acme/my-base-image:1.0\"),mdx(\"li\",{parentName:\"ol\"},\"---> bd09118bcef6\"),mdx(\"li\",{parentName:\"ol\"},\"Step 2/2 : CMD /app/hello.sh\"),mdx(\"li\",{parentName:\"ol\"},\"---> Running in a07b694759ba\"),mdx(\"li\",{parentName:\"ol\"},\"---> dbf995fc07ff\"),mdx(\"li\",{parentName:\"ol\"},\"Removing intermediate container a07b694759ba\"),mdx(\"li\",{parentName:\"ol\"},\"Successfully built dbf995fc07ff\"),mdx(\"li\",{parentName:\"ol\"},\"Successfully tagged acme/my-final-image:1.0\"),mdx(\"li\",{parentName:\"ol\"},\"Check out the sizes of the images:\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker image ls\"),mdx(\"li\",{parentName:\"ol\"},\"REPOSITORY TAG IMAGE ID CREATED SIZE\"),mdx(\"li\",{parentName:\"ol\"},\"acme/my-final-image 1.0 dbf995fc07ff 58 seconds ago 103MB\"),mdx(\"li\",{parentName:\"ol\"},\"acme/my-base-image 1.0 bd09118bcef6 3 minutes ago 103MB\"),mdx(\"li\",{parentName:\"ol\"},\"Check out the layers that comprise each image:\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker history bd09118bcef6\"),mdx(\"li\",{parentName:\"ol\"},\"IMAGE CREATED CREATED BY SIZE COMMENT\"),mdx(\"li\",{parentName:\"ol\"},\"bd09118bcef6 4 minutes ago /bin/sh -c #(nop) COPY dir:35a7eb158c1504e... 100B\"),mdx(\"li\",{parentName:\"ol\"},\"31005225a745 3 months ago /bin/sh -c #(nop) CMD \",\"[\\\"/bin/bash\\\"]\",\" 0B\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<missing>\"),\" 3 months ago /bin/sh -c mkdir -p /run/systemd && echo \\\\'... 7B\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<missing>\"),\" 3 months ago /bin/sh -c sed -i \\\\'s/\\\\^#\\\\s\",mdx(\"em\",{parentName:\"li\"},\"(\",\"deb.\"),\"universe\",\".\",\".. 2.78kB\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<missing>\"),\" 3 months ago /bin/sh -c rm -rf /var/lib/apt/lists/* 0B\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<missing> 3 months ago /bin/sh -c set -xe && echo \\\\'#!/bin/sh\\\\' >\"),\"... 745B\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<missing>\"),\" 3 months ago /bin/sh -c #(nop) ADD file:eef57983bd66e3a... 103MB\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker history dbf995fc07ff\"),mdx(\"li\",{parentName:\"ol\"},\"IMAGE CREATED CREATED BY SIZE COMMENT\"),mdx(\"li\",{parentName:\"ol\"},\"dbf995fc07ff 3 minutes ago /bin/sh -c #(nop) CMD [\\\"/bin/sh\\\" \\\"-c\\\" \\\"/a... 0B\"),mdx(\"li\",{parentName:\"ol\"},\"bd09118bcef6 5 minutes ago /bin/sh -c #(nop) COPY dir:35a7eb158c1504e... 100B\"),mdx(\"li\",{parentName:\"ol\"},\"31005225a745 3 months ago /bin/sh -c #(nop) CMD \",\"[\\\"/bin/bash\\\"]\",\" 0B\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<missing>\"),\" 3 months ago /bin/sh -c mkdir -p /run/systemd && echo \\\\'... 7B\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<missing>\"),\" 3 months ago /bin/sh -c sed -i \\\\'s/\\\\^#\\\\s\",mdx(\"em\",{parentName:\"li\"},\"(\",\"deb.\"),\"universe\",\".\",\".. 2.78kB\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<missing>\"),\" 3 months ago /bin/sh -c rm -rf /var/lib/apt/lists/* 0B\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<missing> 3 months ago /bin/sh -c set -xe && echo \\\\'#!/bin/sh\\\\' >\"),\"... 745B\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<missing>\"),\" 3 months ago /bin/sh -c #(nop) ADD file:eef57983bd66e3a... 103MB\")),mdx(\"p\",null,\"Notice that all the layers are identical except the top layer of the second image. All the other layers are shared between the two images, and are only stored once in\\xA0/var/lib/docker/. The new layer actually doesn't take any room at all, because it is not changing any files, but only running a command.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": The\\xA0\",mdx(\"inlineCode\",{parentName:\"p\"},\"<missing>\"),\"\\xA0lines in the\\xA0docker history\\xA0output indicate that those layers were built on another system and are not available locally. This can be ignored.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Copying makes containers efficient\")),mdx(\"p\",null,\"When you start a container, a thin writable container layer is added on top of the other layers. Any changes the container makes to the filesystem are stored here. Any files the container does not change do not get copied to this writable layer. This means that the writable layer is as small as possible.\"),mdx(\"p\",null,\"When an existing file in a container is modified, the storage driver performs a copy-on-write operation. The specifics steps involved depend on the specific storage driver. For the default\\xA0aufs\\xA0driver and the\\xA0overlay\\xA0and\\xA0overlay2\\xA0drivers, the copy-on-write operation follows this rough sequence:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Search through the image layers for the file to update. The process starts at the newest layer and works down to the base layer one layer at a time. When results are found, they are added to a cache to speed future operations.\"),mdx(\"li\",{parentName:\"ul\"},\"Perform a\\xA0copy_up\\xA0operation on the first copy of the file that is found, to copy the file to the container's writable layer.\"),mdx(\"li\",{parentName:\"ul\"},\"Any modifications are made to this copy of the file, and the container cannot see the read-only copy of the file that exists in the lower layer.\")),mdx(\"p\",null,\"Btrfs, ZFS, and other drivers handle the copy-on-write differently. You can read more about the methods of these drivers later in their detailed descriptions.\"),mdx(\"p\",null,\"Containers that write a lot of data consume more space than containers that do not. This is because most write operations consume new space in the container's thin writable top layer.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": for write-heavy applications, you should not store the data in the container. Instead, use Docker volumes, which are independent of the running container and are designed to be efficient for I/O. In addition, volumes can be shared among containers and do not increase the size of your container's writable layer.\"),mdx(\"p\",null,\"A\\xA0copy_up\\xA0operation can incur a noticeable performance overhead. This overhead is different depending on which storage driver is in use. Large files, lots of layers, and deep directory trees can make the impact more noticeable. This is mitigated by the fact that each\\xA0copy_up\\xA0operation only occurs the first time a given file is modified.\"),mdx(\"p\",null,\"To verify the way that copy-on-write works, the following procedures spins up 5 containers based on the\\xA0acme/my-final-image:1.0\\xA0image we built earlier and examines how much room they take up.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": This procedure doesn't work on Docker for Mac or Docker for Windows.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"From a terminal on your Docker host, run the following\\xA0docker run\\xA0commands. The strings at the end are the IDs of each container.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker run -dit --name my_container_1 acme/my-final-image:1.0 bash \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"&& docker run -dit --name my_container_2 acme/my-final-image:1.0 bash \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"&& docker run -dit --name my_container_3 acme/my-final-image:1.0 bash \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"&& docker run -dit --name my_container_4 acme/my-final-image:1.0 bash \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"&& docker run -dit --name my_container_5 acme/my-final-image:1.0 bash\"),mdx(\"li\",{parentName:\"ol\"},\"c36785c423ec7e0422b2af7364a7ba4da6146cbba7981a0951fcc3fa0430c409\"),mdx(\"li\",{parentName:\"ol\"},\"dcad7101795e4206e637d9358a818e5c32e13b349e62b00bf05cd5a4343ea513\"),mdx(\"li\",{parentName:\"ol\"},\"1e7264576d78a3134fbaf7829bc24b1d96017cf2bc046b7cd8b08b5775c33d0c\"),mdx(\"li\",{parentName:\"ol\"},\"38fa94212a419a082e6a6b87a8e2ec4a44dd327d7069b85892a707e3fc818544\"),mdx(\"li\",{parentName:\"ol\"},\"1a174fc216cccf18ec7d4fe14e008e30130b11ede0f0f94a87982e310cf2e765\"),mdx(\"li\",{parentName:\"ol\"},\"Run the\\xA0docker ps\\xA0command to verify the 5 containers are running.\"),mdx(\"li\",{parentName:\"ol\"},\"CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES\"),mdx(\"li\",{parentName:\"ol\"},\"1a174fc216cc acme/my-final-image:1.0 \\\"bash\\\" About a minute ago Up About a minute my_container_5\"),mdx(\"li\",{parentName:\"ol\"},\"38fa94212a41 acme/my-final-image:1.0 \\\"bash\\\" About a minute ago Up About a minute my_container_4\"),mdx(\"li\",{parentName:\"ol\"},\"1e7264576d78 acme/my-final-image:1.0 \\\"bash\\\" About a minute ago Up About a minute my_container_3\"),mdx(\"li\",{parentName:\"ol\"},\"dcad7101795e acme/my-final-image:1.0 \\\"bash\\\" About a minute ago Up About a minute my_container_2\"),mdx(\"li\",{parentName:\"ol\"},\"c36785c423ec acme/my-final-image:1.0 \\\"bash\\\" About a minute ago Up About a minute my_container_1\"),mdx(\"li\",{parentName:\"ol\"},\"List the contents of the local storage area.\"),mdx(\"li\",{parentName:\"ol\"},\"$ sudo ls /var/lib/docker/containers\"),mdx(\"li\",{parentName:\"ol\"},\"1a174fc216cccf18ec7d4fe14e008e30130b11ede0f0f94a87982e310cf2e765\"),mdx(\"li\",{parentName:\"ol\"},\"1e7264576d78a3134fbaf7829bc24b1d96017cf2bc046b7cd8b08b5775c33d0c\"),mdx(\"li\",{parentName:\"ol\"},\"38fa94212a419a082e6a6b87a8e2ec4a44dd327d7069b85892a707e3fc818544\"),mdx(\"li\",{parentName:\"ol\"},\"c36785c423ec7e0422b2af7364a7ba4da6146cbba7981a0951fcc3fa0430c409\"),mdx(\"li\",{parentName:\"ol\"},\"dcad7101795e4206e637d9358a818e5c32e13b349e62b00bf05cd5a4343ea513\"),mdx(\"li\",{parentName:\"ol\"},\"Now check out their sizes:\"),mdx(\"li\",{parentName:\"ol\"},\"$ sudo du -sh /var/lib/docker/containers/*\"),mdx(\"li\",{parentName:\"ol\"},\"32K /var/lib/docker/containers/1a174fc216cccf18ec7d4fe14e008e30130b11ede0f0f94a87982e310cf2e765\"),mdx(\"li\",{parentName:\"ol\"},\"32K /var/lib/docker/containers/1e7264576d78a3134fbaf7829bc24b1d96017cf2bc046b7cd8b08b5775c33d0c\"),mdx(\"li\",{parentName:\"ol\"},\"32K /var/lib/docker/containers/38fa94212a419a082e6a6b87a8e2ec4a44dd327d7069b85892a707e3fc818544\"),mdx(\"li\",{parentName:\"ol\"},\"32K /var/lib/docker/containers/c36785c423ec7e0422b2af7364a7ba4da6146cbba7981a0951fcc3fa0430c409\"),mdx(\"li\",{parentName:\"ol\"},\"32K /var/lib/docker/containers/dcad7101795e4206e637d9358a818e5c32e13b349e62b00bf05cd5a4343ea513\")),mdx(\"p\",null,\"Each of these containers only takes up 32k of space on the filesystem.\"),mdx(\"p\",null,\"Not only does copy-on-write save space, but it also reduces start-up time. When you start a container (or multiple containers from the same image), Docker only needs to create the thin writable container layer.\"),mdx(\"p\",null,\"If Docker had to make an entire copy of the underlying image stack each time it started a new container, container start times and disk space used would be significantly increased. This would be similar to the way that virtual machines work, with one or more virtual disks per virtual machine.\"),mdx(\"h4\",null,\"Data volumes and the storage driver\"),mdx(\"p\",null,\"When a container is deleted, any data written to the container that is not stored in a\\xA0data volume\\xA0is deleted along with the container.\"),mdx(\"p\",null,\"A data volume is a directory or file in the Docker host's filesystem that is mounted directly into a container. Data volumes are not controlled by the storage driver. Reads and writes to data volumes bypass the storage driver and operate at native host speeds. You can mount any number of data volumes into a container. Multiple containers can also share one or more data volumes.\"),mdx(\"p\",null,\"The diagram below shows a single Docker host running two containers. Each container exists inside of its own address space within the Docker host's local storage area (/var/lib/docker/...). There is also a single shared data volume located at\\xA0/data\\xA0on the Docker host. This is mounted directly into both containers.\"),mdx(\"p\",null,\"Data volumes reside outside of the local storage area on the Docker host, further reinforcing their independence from the storage driver's control. When a container is deleted, any data stored in data volumes persists on the Docker host.\"),mdx(\"p\",null,\"For detailed information about data volumes, see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/tutorials/dockervolumes/\"}),\"Managing data in containers\"),\".\"),mdx(\"h4\",null,\"Related information\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/volumes/\"}),\"Volumes\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/select-storage-driver/\"}),\"Select a storage driver\"))),mdx(\"h3\",null,\"Docker storage drivers\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA09 minutes\")),mdx(\"p\",null,\"Ideally, very little data is written to a container's writable layer, and you use Docker volumes to write data. However, some workloads require you to be able to write to the container's writable layer. This is where storage drivers come in.\"),mdx(\"p\",null,\"Docker supports several different storage drivers, using a pluggable architecture. The storage driver controls how images and containers are stored and managed on your Docker host.\"),mdx(\"p\",null,\"After you have read the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/\"}),\"storage driver overview\"),\", the next step is to choose the best storage driver for your workloads. In making this decision, there are three high-level factors to consider:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"If multiple storage drivers are supported in your kernel, Docker has a prioritized list of which storage driver to use if no storage driver is explicitly configured, assuming that the prerequisites for that storage driver are met:\",mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},\"If possible, the storage driver with the least amount of configuration is used, such as\\xA0btrfs\\xA0or\\xA0zfs. Each of these relies on the backing filesystem being configured correctly.\"),mdx(\"li\",{parentName:\"ul\"},\"Otherwise, try to use the storage driver with the best overall performance and stability in the most usual scenarios.\",mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},\"overlay2\\xA0is preferred, followed by\\xA0overlay. Neither of these requires extra configuration.\\xA0overlay2\\xA0is the default choice for Docker CE.\"),mdx(\"li\",{parentName:\"ul\"},\"devicemapper\\xA0is next, but requires\\xA0direct-lvm\\xA0for production environments, because\\xA0loopback-lvm, while zero-configuration, has very poor performance.\")))))),mdx(\"p\",null,\"The selection order is defined in Docker's source code. You can see the order by looking at\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/docker/docker-ce/blob/18.03/components/engine/daemon/graphdriver/driver_linux.go#L50\"}),\"the source code for Docker CE 18.03\"),\"\\xA0You can use the branch selector at the top of the file viewer to choose a different branch, if you run a different version of Docker.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Your choice may be limited by your Docker edition, operating system, and distribution. For instance,\\xA0aufs\\xA0is only supported on Ubuntu and Debian, and may require extra packages to be installed, while\\xA0btrfs\\xA0is only supported on SLES, which is only supported with Docker EE. See\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/select-storage-driver/#supported-storage-drivers-per-linux-distribution\"}),\"Support storage drivers per Linux distribution\"),\".\"),mdx(\"li\",{parentName:\"ul\"},\"Some storage drivers require you to use a specific format for the backing filesystem. If you have external requirements to use a specific backing filesystem, this may limit your choices. See\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/select-storage-driver/#supported-backing-filesystems\"}),\"Supported backing filesystems\"),\".\"),mdx(\"li\",{parentName:\"ul\"},\"After you have narrowed down which storage drivers you can choose from, your choice are determined by the characteristics of your workload and the level of stability you need. See\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/select-storage-driver/#other-considerations\"}),\"Other considerations\"),\"\\xA0for help making the final decision.\")),mdx(\"h4\",null,\"Supported storage drivers per Linux distribution\"),mdx(\"p\",null,\"At a high level, the storage drivers you can use is partially determined by the Docker edition you use.\"),mdx(\"p\",null,\"In addition, Docker does not recommend any configuration that requires you to disable security features of your operating system, such as the need to disable\\xA0selinux\\xA0if you use the\\xA0overlay\\xA0or\\xA0overlay2\\xA0driver on CentOS.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Docker EE and CS-Engine\")),mdx(\"p\",null,\"For Docker EE and CS-Engine, the definitive resource for which storage drivers are supported is the\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://success.docker.com/Policies/Compatibility_Matrix\"}),\"Product compatibility matrix\"),\". To get commercial support from Docker, you must use a supported configuration.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Docker CE\")),mdx(\"p\",null,\"For Docker CE, only some configurations are tested, and your operating system's kernel may not support every storage driver. In general, the following configurations work on recent versions of the Linux distribution:\"),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Linux distribution\"),\"   \",mdx(\"strong\",{parentName:\"p\"},\"Recommended storage drivers\")),mdx(\"hr\",null),mdx(\"p\",null,\"  Docker CE on Ubuntu      aufs,\\xA0devicemapper,\\xA0overlay2\\xA0(Ubuntu 14.04.4 or later, 16.04 or later),\\xA0overlay,\\xA0zfs,\\xA0vfs\\nDocker CE on Debian      aufs,\\xA0devicemapper,\\xA0overlay2\\xA0(Debian Stretch),\\xA0overlay,\\xA0vfs\\nDocker CE on CentOS      devicemapper,\\xA0vfs\\nDocker CE on Fedora      devicemapper,\\xA0overlay2\\xA0(Fedora 26 or later, experimental),\\xA0overlay(experimental),\\xA0vfs\"),mdx(\"p\",null,\"When possible,\\xA0overlay2\\xA0is the recommended storage driver. When installing Docker for the first time,\\xA0overlay2\\xA0is used by default. Previously,\\xA0aufs\\xA0was used by default when available, but this is no longer the case. If you want to use\\xA0aufs\\xA0on new installations going forward, you need to explicitly configure it, and you may need to install extra packages, such as\\xA0linux-image-extra. See\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/aufs-driver/\"}),\"aufs\"),\".\"),mdx(\"p\",null,\"On existing installations using\\xA0aufs, it is still used.\"),mdx(\"p\",null,\"When in doubt, the best all-around configuration is to use a modern Linux distribution with a kernel that supports the\\xA0overlay2\\xA0storage driver, and to use Docker volumes for write-heavy workloads instead of relying on writing data to the container's writable layer.\"),mdx(\"p\",null,\"The\\xA0vfs\\xA0storage driver is usually not the best choice. Before using the\\xA0vfs\\xA0storage driver, be sure to read about\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/vfs-driver/\"}),\"its performance and storage characteristics and limitations\"),\".\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Expectations for non-recommended storage drivers: Commercial support is not available for Docker CE, and you can technically use any storage driver that is available for your platform. For instance, you can use\\xA0btrfs\\xA0with Docker CE, even though it is not recommended on any platform for Docker CE, and you do so at your own risk.\")),mdx(\"p\",null,\"The recommendations in the table above are based on automated regression testing and the configurations that are known to work for a large number of users. If you use a recommended configuration and find a reproducible issue, it is likely to be fixed very quickly. If the driver that you want to use is not recommended according to this table, you can run it at your own risk. You can and should still report any issues you run into. However, such issues have a lower priority than issues encountered when using a recommended configuration.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Docker for Mac and Docker for Windows\")),mdx(\"p\",null,\"Docker for Mac and Docker for Windows are intended for development, rather than production. Modifying the storage driver on these platforms is not possible.\"),mdx(\"h4\",null,\"Supported backing filesystems\"),mdx(\"p\",null,\"With regard to Docker, the backing filesystem is the filesystem where\\xA0/var/lib/docker/\\xA0is located. Some storage drivers only work with specific backing filesystems.\"),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Storage driver\"),\"   \",mdx(\"strong\",{parentName:\"p\"},\"Supported backing filesystems\")),mdx(\"hr\",null),mdx(\"p\",null,\"  overlay,\\xA0overlay2    ext4,\\xA0xfs\\naufs                 ext4,\\xA0xfs\\ndevicemapper         direct-lvm\\nbtrfs                btrfs\\nzfs                  zfs\"),mdx(\"h4\",null,\"Other considerations\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Suitability for your workload\")),mdx(\"p\",null,\"Among other things, each storage driver has its own performance characteristics that make it more or less suitable for different workloads. Consider the following generalizations:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"aufs,\\xA0overlay, and\\xA0overlay2\\xA0all operate at the file level rather than the block level. This uses memory more efficiently, but the container's writable layer may grow quite large in write-heavy workloads.\"),mdx(\"li\",{parentName:\"ul\"},\"Block-level storage drivers such as\\xA0devicemapper,\\xA0btrfs, and\\xA0zfs\\xA0perform better for write-heavy workloads (though not as well as Docker volumes).\"),mdx(\"li\",{parentName:\"ul\"},\"For lots of small writes or containers with many layers or deep filesystems,\\xA0overlay\\xA0may perform better than\\xA0overlay2.\"),mdx(\"li\",{parentName:\"ul\"},\"btrfs\\xA0and\\xA0zfs\\xA0require a lot of memory.\"),mdx(\"li\",{parentName:\"ul\"},\"zfs\\xA0is a good choice for high-density workloads such as PaaS.\")),mdx(\"p\",null,\"More information about performance, suitability, and best practices is available in the documentation for each storage driver.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Shared storage systems and the storage driver\")),mdx(\"p\",null,\"If your enterprise uses SAN, NAS, hardware RAID, or other shared storage systems, they may provide high availability, increased performance, thin provisioning, deduplication, and compression. In many cases, Docker can work on top of these storage systems, but Docker does not closely integrate with them.\"),mdx(\"p\",null,\"Each Docker storage driver is based on a Linux filesystem or volume manager. Be sure to follow existing best practices for operating your storage driver (filesystem or volume manager) on top of your shared storage system. For example, if using the ZFS storage driver on top of a shared storage system, be sure to follow best practices for operating ZFS filesystems on top of that specific shared storage system.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Stability\")),mdx(\"p\",null,\"For some users, stability is more important than performance. Though Docker considers all of the storage drivers mentioned here to be stable, some are newer and are still under active development. In general,\\xA0aufs,\\xA0overlay, and\\xA0devicemapper\\xA0are the choices with the highest stability.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Experience and expertise\")),mdx(\"p\",null,\"Choose a storage driver that your organization is comfortable maintaining. For example, if you use RHEL or one of its downstream forks, you may already have experience with LVM and Device Mapper. If so, the\\xA0devicemapper\\xA0driver might be the best choice.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Test with your own workloads\")),mdx(\"p\",null,\"You can test Docker's performance when running your own workloads on different storage drivers. Make sure to use equivalent hardware and workloads to match production conditions, so you can see which storage driver offers the best overall performance.\"),mdx(\"h4\",null,\"Check your current storage driver\"),mdx(\"p\",null,\"The detailed documentation for each individual storage driver details all of the set-up steps to use a given storage driver.\"),mdx(\"p\",null,\"To see what storage driver Docker is currently using, use\\xA0docker info\\xA0and look for the\\xA0Storage Driver\\xA0line:\"),mdx(\"p\",null,\"$ docker info\"),mdx(\"p\",null,\"Containers: 0\"),mdx(\"p\",null,\"Images: 0\"),mdx(\"p\",null,\"Storage Driver: overlay\"),mdx(\"p\",null,\"Backing Filesystem: extfs\"),mdx(\"p\",null,mdx(\"inlineCode\",{parentName:\"p\"},\"<output truncated>\")),mdx(\"p\",null,\"To change the storage driver, see the specific instructions for the new storage driver. Some drivers require additional configuration, including configuration to physical or logical disks on the Docker host.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Important\"),\": When you change the storage driver, any existing images and containers become inaccessible. This is because their layers cannot be used by the new storage driver. If you revert your changes, you can access the old images and containers again, but any that you pulled or created using the new driver are then inaccessible.\"),mdx(\"h4\",null,\"Related information\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/\"}),\"About images, containers, and storage drivers\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/aufs-driver/\"}),\"aufs\\xA0storage driver in practice\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/device-mapper-driver/\"}),\"devicemapper\\xA0storage driver in practice\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/overlayfs-driver/\"}),\"overlay\\xA0and\\xA0overlay2\\xA0storage drivers in practice\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/btrfs-driver/\"}),\"btrfs\\xA0storage driver in practice\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/zfs-driver/\"}),\"zfs\\xA0storage driver in practice\"))),mdx(\"h3\",null,\"Use the AUFS storage driver\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA08 minutes\")),mdx(\"p\",null,\"AUFS is a\\xA0union filesystem. The\\xA0aufs\\xA0storage driver was previously the default storage driver used for managing images and layers on Docker for Ubuntu, and for Debian versions prior to Stretch. If your Linux kernel is version 4.0 or higher, and you use Docker CE, consider using the newer\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/overlayfs-driver/\"}),\"overlay2\"),\", which has potential performance advantages over the\\xA0aufs\\xA0storage driver.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": AUFS is not supported on some distributions and Docker editions. See\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/aufs-driver/#prerequisites\"}),\"Prerequisites\"),\"\\xA0> for more information about supported platforms, and see also\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/selectadriver/#storage-driver-order\"}),\"the order of preferences for storage drivers\"),\".\"),mdx(\"h4\",null,\"Prerequisites\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"For Docker CE, AUFS is supported on Ubuntu, and on Debian versions prior to Stretch.\"),mdx(\"li\",{parentName:\"ul\"},\"For Docker EE, AUFS is supported on Ubuntu.\"),mdx(\"li\",{parentName:\"ul\"},\"If you use Ubuntu, you need to\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/install/linux/ubuntu/#recommended-extra-packages-for-trusty-1404\"}),\"install extra packages\"),\"\\xA0to add the AUFS module to the kernel. If you do not install these packages, you need to use\\xA0devicemapper\\xA0on Ubuntu 14.04 (which is not recommended), or\\xA0overlay2\\xA0on Ubuntu 16.04 and higher, which is also supported.\"),mdx(\"li\",{parentName:\"ul\"},\"AUFS cannot use the following backing filesystems:\\xA0aufs,\\xA0btrfs, or\\xA0ecryptfs. This means that the filesystem which contains\\xA0/var/lib/docker/aufs\\xA0cannot be one of these filesystem types.\")),mdx(\"h4\",null,\"Configure Docker with the\\xA0aufs\\xA0storage driver\"),mdx(\"p\",null,\"If the AUFS driver is loaded into the kernel when you start Docker, and no other storage driver is configured, Docker uses it by default.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Use the following command to verify that your kernel supports AUFS.\"),mdx(\"li\",{parentName:\"ol\"},\"$ grep aufs /proc/filesystems\"),mdx(\"li\",{parentName:\"ol\"},\"nodev aufs\"),mdx(\"li\",{parentName:\"ol\"},\"Check which storage driver Docker is using.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker info\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<truncated output>\")),mdx(\"li\",{parentName:\"ol\"},\"Storage Driver: aufs\"),mdx(\"li\",{parentName:\"ol\"},\"Root Dir: /var/lib/docker/aufs\"),mdx(\"li\",{parentName:\"ol\"},\"Backing Filesystem: extfs\"),mdx(\"li\",{parentName:\"ol\"},\"Dirs: 0\"),mdx(\"li\",{parentName:\"ol\"},\"Dirperm1 Supported: true\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<truncated output>\")),mdx(\"li\",{parentName:\"ol\"},\"If you are using a different storage driver, either AUFS is not included in the kernel (in which case a different default driver is used) or that Docker has been explicitly configured to use a different driver. Check\\xA0/etc/docker/daemon.json\\xA0or the output of\\xA0ps auxw | grep dockerd\\xA0to see if Docker has been started with the\\xA0--storage-driver\\xA0flag.\")),mdx(\"h4\",null,\"How the\\xA0aufs\\xA0storage driver works\"),mdx(\"p\",null,\"AUFS is a\\xA0union filesystem, which means that it layers multiple directories on a single Linux host and presents them as a single directory. These directories are called\\xA0branches\\xA0in AUFS terminology, and\\xA0layers\\xA0in Docker terminology. The unification process is referred to a a\\xA0union mount.\"),mdx(\"p\",null,\"The diagram below shows a Docker container based on the\\xA0ubuntu:latest\\xA0image.\"),mdx(\"p\",null,\"Each image layer, and the container layer, are represented on the Docker host as subdirectories within\\xA0/var/lib/docker/. The union mount provides the unified view of all layers. The directory names do not directly correspond to the IDs of the layers themselves.\"),mdx(\"p\",null,\"AUFS uses the Copy-on-Write (CoW) strategy to maximize storage efficiency and minimize overhead.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Example: Image and container on-disk constructs\")),mdx(\"p\",null,\"The following\\xA0docker pull\\xA0command shows a Docker host downloading a Docker image comprising five layers.\"),mdx(\"p\",null,\"$ docker pull ubuntu\"),mdx(\"p\",null,\"Using default tag: latest\"),mdx(\"p\",null,\"latest: Pulling from library/ubuntu\"),mdx(\"p\",null,\"b6f892c0043b: Pull complete\"),mdx(\"p\",null,\"55010f332b04: Pull complete\"),mdx(\"p\",null,\"2955fb827c94: Pull complete\"),mdx(\"p\",null,\"3deef3fcbd30: Pull complete\"),mdx(\"p\",null,\"cf9722e506aa: Pull complete\"),mdx(\"p\",null,\"Digest: sha256:382452f82a8bbd34443b2c727650af46aced0f94a44463c62a9848133ecb1aa8\"),mdx(\"p\",null,\"Status: Downloaded newer image for ubuntu:latest\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"THE IMAGE LAYERS\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Warning\"),\": Do not directly manipulate any files or directories within\\xA0/var/lib/docker/. These files and directories are managed by Docker.\"),mdx(\"p\",null,\"All of the information about the image and container layers is stored in subdirectories of\\xA0/var/lib/docker/aufs/.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"diff/: the\\xA0\",mdx(\"strong\",{parentName:\"li\"},\"contents\"),\"\\xA0of each layer, each stored in a separate subdirectory\"),mdx(\"li\",{parentName:\"ul\"},\"layers/: metadata about how image layers are stacked. This directory contains one file for each image or container layer on the Docker host. Each file contains the IDs of all the layers below it in the stack (its parents).\"),mdx(\"li\",{parentName:\"ul\"},\"mnt/: Mount points, one per image or container layer, which are used to assemble and mount the unified filesystem for a container. For images, which are read-only, these directories are always empty.\")),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"THE CONTAINER LAYER\")),mdx(\"p\",null,\"If a container is running, the contents of\\xA0/var/lib/docker/aufs/\\xA0change in the following ways:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"diff/: Differences introduced in the writable container layer, such as new or modified files.\"),mdx(\"li\",{parentName:\"ul\"},\"layers/: Metadata about the writable container layer's parent layers.\"),mdx(\"li\",{parentName:\"ul\"},\"mnt/: A mount point for each running container's unified filesystem, exactly as it appears from within the container.\")),mdx(\"h4\",null,\"How container reads and writes work with\\xA0aufs\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Reading files\")),mdx(\"p\",null,\"Consider three scenarios where a container opens a file for read access with overlay.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"The file does not exist in the container layer\"),\": If a container opens a file for read access and the file does not already exist in the container layer, the storage driver searches for the file in the image layers, starting with the layer just below the container layer. It is read from the layer where it is found.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"The file only exists in the container layer\"),\": If a container opens a file for read access and the file exists in the container layer, it is read from there.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"The file exists in both the container layer and the image layer\"),\": If a container opens a file for read access and the file exists in the container layer and one or more image layers, the file is read from the container layer. Files in the container layer obscure files with the same name in the image layers.\")),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Modifying files or directories\")),mdx(\"p\",null,\"Consider some scenarios where files in a container are modified.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Writing to a file for the first time\"),\": The first time a container writes to an existing file, that file does not exist in the container (upperdir). The\\xA0aufs\\xA0driver performs a\\xA0copy_up\\xA0operation to copy the file from the image layer where it exists to the writable container layer. The container then writes the changes to the new copy of the file in the container layer.\")),mdx(\"p\",null,\"However, AUFS works at the file level rather than the block level. This means that all copy_up operations copy the entire file, even if the file is very large and only a small part of it is being modified. This can have a noticeable impact on container write performance. AUFS, which can suffer noticeable latencies when searching for files in images with many layers. However, it is worth noting that the copy_up operation only occurs the first time a given file is written to. Subsequent writes to the same file operate against the copy of the file already copied up to the container.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Deleting files and directories\"),\":\",mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},\"When a\\xA0file\\xA0is deleted within a container, a\\xA0whiteout\\xA0file is created in the container layer. The version of the file in the image layer is not deleted (because the image layers are read-only). However, the whiteout file prevents it from being available to the container.\"),mdx(\"li\",{parentName:\"ul\"},\"When a\\xA0directory\\xA0is deleted within a container, an\\xA0opaque file\\xA0is created in the container layer. This works in the same way as a whiteout file and effectively prevents the directory from being accessed, even though it still exists in the image layer.\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Renaming directories\"),\": Calling\\xA0rename(2)\\xA0for a directory is not fully supported on AUFS. It returns\\xA0EXDEV\\xA0(\\\"cross-device link not permitted\\\"), even when both of the source and the destination path are on a same AUFS layer, unless the directory has no children. Your application needs to be designed to handle\\xA0EXDEV\\xA0and fall back to a \\\"copy and unlink\\\" strategy.\")),mdx(\"h4\",null,\"AUFS and Docker performance\"),mdx(\"p\",null,\"To summarize some of the performance related aspects already mentioned:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"The AUFS storage driver is less performant than the\\xA0overlay2\\xA0driver, but is a good choice for PaaS and other similar use-cases where container density is important. This is because AUFS efficiently shares images between multiple running containers, enabling fast container start times and minimal use of disk space.\"),mdx(\"li\",{parentName:\"ul\"},\"The underlying mechanics of how AUFS shares files between image layers and containers uses the page cache very efficiently.\"),mdx(\"li\",{parentName:\"ul\"},\"The AUFS storage driver can introduce significant latencies into container write performance. This is because the first time a container writes to any file, the file needs to be located and copied into the containers top writable layer. These latencies increase and are compounded when these files exist below many image layers and the files themselves are large.\")),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Performance best practices\")),mdx(\"p\",null,\"The following generic performance best practices also apply to AUFS.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Solid State Devices (SSD)\"),\"\\xA0provide faster reads and writes than spinning disks.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Use volumes for write-heavy workloads\"),\": Volumes provide the best and most predictable performance for write-heavy workloads. This is because they bypass the storage driver and do not incur any of the potential overheads introduced by thin provisioning and copy-on-write. Volumes have other benefits, such as allowing you to share data among containers and persisting even when no running container is using them.\")),mdx(\"h4\",null,\"Related information\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/volumes/\"}),\"Volumes\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/imagesandcontainers/\"}),\"Understand images, containers, and storage drivers\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/selectadriver/\"}),\"Select a storage driver\"))),mdx(\"h3\",null,\"Use the BTRFS storage driver\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA011 minutes\")),mdx(\"p\",null,\"Btrfs is a next generation copy-on-write filesystem that supports many advanced storage technologies that make it a good fit for Docker. Btrfs is included in the mainline Linux kernel.\"),mdx(\"p\",null,\"Docker's\\xA0btrfs\\xA0storage driver leverages many Btrfs features for image and container management. Among these features are block-level operations, thin provisioning, copy-on-write snapshots, and ease of administration. You can easily combine multiple physical block devices into a single Btrfs filesystem.\"),mdx(\"p\",null,\"This article refers to Docker's Btrfs storage driver as\\xA0btrfs\\xA0and the overall Btrfs Filesystem as Btrfs.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": The\\xA0btrfs\\xA0storage driver is only supported on Docker CE on Ubuntu or Debian, and Docker EE / CS Engine on SLES.\"),mdx(\"h4\",null,\"Prerequisites\"),mdx(\"p\",null,\"btrfs\\xA0is supported if you meet the following prerequisites:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Docker CE\"),\": For Docker CE,\\xA0btrfs\\xA0is only recommended on Ubuntu or Debian.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Docker EE\"),\": For Docker EE and CS-Engine,\\xA0btrfs\\xA0is only supported on SLES. See the\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://success.docker.com/Policies/Compatibility_Matrix\"}),\"Product compatibility matrix\"),\"\\xA0for all supported configurations for commercially-supported Docker.\"),mdx(\"li\",{parentName:\"ul\"},\"Changing the storage driver makes any containers you have already created inaccessible on the local system. Use\\xA0docker save\\xA0to save containers, and push existing images to Docker Hub or a private repository, so that you not need to re-create them later.\"),mdx(\"li\",{parentName:\"ul\"},\"btrfs\\xA0requires a dedicated block storage device such as a physical disk. This block device must be formatted for Btrfs and mounted into\\xA0/var/lib/docker/. The configuration instructions below walk you through this procedure. By default, the SLES\\xA0/\\xA0filesystem is formatted with BTRFS, so for SLES, you do not need to use a separate block device, but you can choose to do so for performance reasons.\"),mdx(\"li\",{parentName:\"ul\"},\"btrfs\\xA0support must exist in your kernel. To check this, run the following command:\"),mdx(\"li\",{parentName:\"ul\"},\"$ sudo cat /proc/filesystems | grep btrfs\"),mdx(\"li\",{parentName:\"ul\"},\"btrfs\"),mdx(\"li\",{parentName:\"ul\"},\"To manage BTRFS filesystems at the level of the operating system, you need the\\xA0btrfscommand. If you do not have this command, install the\\xA0btrfsprogs\\xA0package (SLES) or\\xA0btrfs-tools\\xA0package (Ubuntu).\")),mdx(\"h4\",null,\"Configure Docker to use the btrfs storage driver\"),mdx(\"p\",null,\"This procedure is essentially identical on SLES and Ubuntu.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Stop Docker.\"),mdx(\"li\",{parentName:\"ol\"},\"Copy the contents of\\xA0/var/lib/docker/\\xA0to a backup location, then empty the contents of\\xA0/var/lib/docker/:\"),mdx(\"li\",{parentName:\"ol\"},\"$ sudo cp -au /var/lib/docker /var/lib/docker.bk\"),mdx(\"li\",{parentName:\"ol\"},\"$ sudo rm -rf /var/lib/docker/*\"),mdx(\"li\",{parentName:\"ol\"},\"Format your dedicated block device or devices as a Btrfs filesystem. This example assumes that you are using two block devices called\\xA0/dev/xvdf\\xA0and\\xA0/dev/xvdg. Double-check the block device names because this is a destructive operation.\"),mdx(\"li\",{parentName:\"ol\"},\"$ sudo mkfs.btrfs -f /dev/xvdf /dev/xvdg\")),mdx(\"p\",null,\"There are many more options for Btrfs, including striping and RAID. See the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://btrfs.wiki.kernel.org/index.php/Using_Btrfs_with_Multiple_Devices\"}),\"Btrfs documentation\"),\".\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Mount the new Btrfs filesystem on the\\xA0/var/lib/docker/\\xA0mount point. You can specify any of the block devices used to create the Btrfs filesystem.\"),mdx(\"li\",{parentName:\"ol\"},\"$ sudo mount -t btrfs /dev/xvdf /var/lib/docker\")),mdx(\"p\",null,\"Don't forget to make the change permanent across reboots by adding an entry to\\xA0/etc/fstab.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Copy the contents of\\xA0/var/lib/docker.bk\\xA0to\\xA0/var/lib/docker/.\"),mdx(\"li\",{parentName:\"ol\"},\"$ sudo cp -au /var/lib/docker.bk/* /var/lib/docker/\"),mdx(\"li\",{parentName:\"ol\"},\"Configure Docker to use the\\xA0btrfs\\xA0storage driver. This is required even though\\xA0/var/lib/docker/\\xA0is now using a Btrfs filesystem. Edit or create the file\\xA0/etc/docker/daemon.json. If it is a new file, add the following contents. If it is an existing file, add the key and value only, being careful to end the line with a comma if it is not the final line before an ending curly bracket (}).\"),mdx(\"li\",{parentName:\"ol\"},\"{\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"storage-driver\\\": \\\"btrfs\\\"\"),mdx(\"li\",{parentName:\"ol\"},\"}\")),mdx(\"p\",null,\"See all storage options for each storage driver:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/dockerd/#storage-driver-options\"}),\"Stable\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/edge/engine/reference/commandline/dockerd/#storage-driver-options\"}),\"Edge\"))))),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Start Docker. After it is running, verify that\\xA0btrfs\\xA0is being used as the storage driver.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker info\"),mdx(\"li\",{parentName:\"ol\"},\"Containers: 0\"),mdx(\"li\",{parentName:\"ol\"},\"Running: 0\"),mdx(\"li\",{parentName:\"ol\"},\"Paused: 0\"),mdx(\"li\",{parentName:\"ol\"},\"Stopped: 0\"),mdx(\"li\",{parentName:\"ol\"},\"Images: 0\"),mdx(\"li\",{parentName:\"ol\"},\"Server Version: 17.03.1-ce\"),mdx(\"li\",{parentName:\"ol\"},\"Storage Driver: btrfs\"),mdx(\"li\",{parentName:\"ol\"},\"Build Version: Btrfs v4.4\"),mdx(\"li\",{parentName:\"ol\"},\"Library Version: 101\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<output truncated>\")),mdx(\"li\",{parentName:\"ol\"},\"When you are ready, remove the\\xA0/var/lib/docker.bk\\xA0directory.\")),mdx(\"h4\",null,\"Manage a Btrfs volume\"),mdx(\"p\",null,\"One of the benefits of Btrfs is the ease of managing Btrfs filesystems without the need to unmount the filesystem or restart Docker.\"),mdx(\"p\",null,\"When space gets low, Btrfs automatically expands the volume in\\xA0chunks\\xA0of roughly 1 GB.\"),mdx(\"p\",null,\"To add a block device to a Btrfs volume, use the\\xA0btrfs device add\\xA0and\\xA0btrfs filesystem balancecommands.\"),mdx(\"p\",null,\"$ sudo btrfs device add /dev/svdh /var/lib/docker\"),mdx(\"p\",null,\"$ sudo btrfs filesystem balance /var/lib/docker\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": While you can do these operations with Docker running, performance suffers. It might be best to plan an outage window to balance the Btrfs filesystem.\"),mdx(\"h4\",null,\"How the\\xA0btrfs\\xA0storage driver works\"),mdx(\"p\",null,\"The\\xA0btrfs\\xA0storage driver works differently from\\xA0devicemapper\\xA0or other storage drivers in that your entire\\xA0/var/lib/docker/\\xA0directory is stored on a Btrfs volume.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Image and container layers on-disk\")),mdx(\"p\",null,\"Information about image layers and writable container layers is stored in/var/lib/docker/btrfs/subvolumes/. This subdirectory contains one directory per image or container layer, with the unified filesystem built from a layer plus all its parent layers. Subvolumes are natively copy-on-write and have space allocated to them on-demand from an underlying storage pool. They can also be nested and snapshotted. The diagram below shows 4 subvolumes. 'Subvolume 2' and 'Subvolume 3' are nested, whereas 'Subvolume 4' shows its own internal directory tree.\"),mdx(\"p\",null,\"Only the base layer of an image is stored as a true subvolume. All the other layers are stored as snapshots, which only contain the differences introduced in that layer. You can create snapshots of snapshots as shown in the diagram below.\"),mdx(\"p\",null,\"On disk, snapshots look and feel just like subvolumes, but in reality they are much smaller and more space-efficient. Copy-on-write is used to maximize storage efficiency and minimize layer size, and writes in the container's writable layer are managed at the block level. The following image shows a subvolume and its snapshot sharing data.\"),mdx(\"p\",null,\"For maximum efficiency, when a container needs more space, it is allocated in\\xA0chunks\\xA0of roughly 1 GB in size.\"),mdx(\"p\",null,\"Docker's\\xA0btrfs\\xA0storage driver stores every image layer and container in its own Btrfs subvolume or snapshot. The base layer of an image is stored as a subvolume whereas child image layers and containers are stored as snapshots. This is shown in the diagram below.\"),mdx(\"p\",null,\"The high level process for creating images and containers on Docker hosts running the\\xA0btrfs\\xA0driver is as follows:\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"The image's base layer is stored in a Btrfs\\xA0subvolume\\xA0under\\xA0/var/lib/docker/btrfs/subvolumes.\"),mdx(\"li\",{parentName:\"ol\"},\"Subsequent image layers are stored as a Btrfs\\xA0snapshot\\xA0of the parent layer's subvolume or snapshot, but with the changes introduced by this layer. These differences are stored at the block level.\"),mdx(\"li\",{parentName:\"ol\"},\"The container's writable layer is a Btrfs snapshot of the final image layer, with the differences introduced by the running container. These differences are stored at the block level.\")),mdx(\"h4\",null,\"How container reads and writes work with\\xA0btrfs\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Reading files\")),mdx(\"p\",null,\"A container is a space-efficient snapshot of an image. Metadata in the snapshot points to the actual data blocks in the storage pool. This is the same as with a subvolume. Therefore, reads performed against a snapshot are essentially the same as reads performed against a subvolume.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Writing files\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Writing new files\"),\": Writing a new file to a container invokes an allocate-on-demand operation to allocate new data block to the container's snapshot. The file is then written to this new space. The allocate-on-demand operation is native to all writes with Btrfs and is the same as writing new data to a subvolume. As a result, writing new files to a container's snapshot operates at native Btrfs speeds.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Modifying existing files\"),\": Updating an existing file in a container is a copy-on-write operation (redirect-on-write\\xA0is the Btrfs terminology). The original data is read from the layer where the file currently exists, and only the modified blocks are written into the container's writable layer. Next, the Btrfs driver updates the filesystem metadata in the snapshot to point to this new data. This behavior incurs very little overhead.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Deleting files or directories\"),\": If a container deletes a file or directory that exists in a lower layer, Btrfs masks the existence of the file or directory in the lower layer. If a container creates a file and then deletes it, this operation is performed in the Btrfs filesystem itself and the space is reclaimed.\")),mdx(\"p\",null,\"With Btrfs, writing and updating lots of small files can result in slow performance.\"),mdx(\"h4\",null,\"Btrfs and Docker performance\"),mdx(\"p\",null,\"There are several factors that influence Docker's performance under the\\xA0btrfs\\xA0storage driver.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": Many of these factors are mitigated by using Docker volumes for write-heavy workloads, rather than relying on storing data in the container's writable layer. However, in the case of Btrfs, Docker volumes still suffer from these draw-backs unless\\xA0/var/lib/docker/volumes/\\xA0is\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"not\"),\"backed by Btrfs.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Page caching\"),\". Btrfs does not support page cache sharing. This means that each process accessing the same file copies the file into the Docker hosts's memory. As a result, the\\xA0btrfs\\xA0driver may not be the best choice high-density use cases such as PaaS.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Small writes\"),\". Containers performing lots of small writes (this usage pattern matches what happens when you start and stop many containers in a short period of time, as well) can lead to poor use of Btrfs chunks. This can prematurely fill the Btrfs filesystem and lead to out-of-space conditions on your Docker host. Use\\xA0btrfs filesys show\\xA0to closely monitor the amount of free space on your Btrfs device.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Sequential writes\"),\". Btrfs uses a journaling technique when writing to disk. This can impact the performance of sequential writes, reducing performance by up to 50%.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Fragmentation\"),\". Fragmentation is a natural byproduct of copy-on-write filesystems like Btrfs. Many small random writes can compound this issue. Fragmentation can manifest as CPU spikes when using SSDs or head thrashing when using spinning disks. Either of these issues can harm performance.\")),mdx(\"p\",null,\"If your Linux kernel version is 3.9 or higher, you can enable the\\xA0autodefrag\\xA0feature when mounting a Btrfs volume. Test this feature on your own workloads before deploying it into production, as some tests have shown a negative impact on performance.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"SSD performance\"),\": Btrfs includes native optimizations for SSD media. To enable these features, mount the Btrfs filesystem with the\\xA0-o ssd\\xA0mount option. These optimizations include enhanced SSD write performance by avoiding optimization such as\\xA0seek optimizations\\xA0which do not apply to solid-state media.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Balance Btrfs filesystems often\"),\": Use operating system utilities such as a\\xA0cron\\xA0job to balance the Btrfs filesystem regularly, during non-peak hours. This reclaims unallocated blocks and helps to prevent the filesystem from filling up unnecessarily. You cannot rebalance a totally full Btrfs filesystem unless you add additional physical block devices to the filesystem. See the\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://btrfs.wiki.kernel.org/index.php/Balance_Filters#Balancing_to_fix_filesystem_full_errors\"}),\"BTRFS Wiki\"),\".\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Use fast storage\"),\": Solid-state drives (SSDs) provide faster reads and writes than spinning disks.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Use volumes for write-heavy workloads\"),\": Volumes provide the best and most predictable performance for write-heavy workloads. This is because they bypass the storage driver and do not incur any of the potential overheads introduced by thin provisioning and copy-on-write. Volumes have other benefits, such as allowing you to share data among containers and persisting even when no running container is using them.\")),mdx(\"h4\",null,\"Related Information\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/volumes/\"}),\"Volumes\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/imagesandcontainers/\"}),\"Understand images, containers, and storage drivers\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/selectadriver/\"}),\"Select a storage driver\"))),mdx(\"h3\",null,\"Use the Device Mapper storage driver\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA026 minutes\")),mdx(\"p\",null,\"Device Mapper is a kernel-based framework that underpins many advanced volume management technologies on Linux. Docker's\\xA0devicemapper\\xA0storage driver leverages the thin provisioning and snapshotting capabilities of this framework for image and container management. This article refers to the Device Mapper storage driver as\\xA0devicemapper, and the kernel framework as\\xA0Device Mapper.\"),mdx(\"p\",null,\"For the systems where it is supported,\\xA0devicemapper\\xA0support is included in the Linux kernel. However, specific configuration is required to use it with Docker. For instance, on a stock installation of RHEL or CentOS, Docker defaults to\\xA0overlay, which is not a supported configuration.\"),mdx(\"p\",null,\"The\\xA0devicemapper\\xA0driver uses block devices dedicated to Docker and operates at the block level, rather than the file level. These devices can be extended by adding physical storage to your Docker host, and they perform better than using a filesystem at the level of the operating system.\"),mdx(\"h4\",null,\"Prerequisites\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"devicemapper\\xA0storage driver is the only supported storage driver for Docker EE and Commercially Supported Docker Engine (CS-Engine) on RHEL, CentOS, and Oracle Linux. See the\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://success.docker.com/Policies/Compatibility_Matrix\"}),\"Product compatibility matrix\"),\".\"),mdx(\"li\",{parentName:\"ul\"},\"devicemapper\\xA0is also supported on Docker CE running on CentOS, Fedora, Ubuntu, or Debian.\"),mdx(\"li\",{parentName:\"ul\"},\"Changing the storage driver makes any containers you have already created inaccessible on the local system. Use\\xA0docker save\\xA0to save containers, and push existing images to Docker Hub or a private repository, so that you not need to re-create them later.\")),mdx(\"h4\",null,\"Configure Docker with the\\xA0devicemapper\\xA0storage driver\"),mdx(\"p\",null,\"Before following these procedures, you must first meet all the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/device-mapper-driver/#prerequisites\"}),\"prerequisites\"),\".\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Configure\\xA0loop-lvm\\xA0mode for testing\")),mdx(\"p\",null,\"This configuration is only appropriate for testing. Loopback devices are slow and resource-intensive, and require you to create file on disk at specific sizes. They can also introduce race conditions. They are supposed for testing because the set-up is easier.\"),mdx(\"p\",null,\"For production systems, see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/device-mapper-driver/#configure-direct-lvm-mode-for-production\"}),\"Configure direct-lvm mode for production\"),\".\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Stop Docker.\"),mdx(\"li\",{parentName:\"ol\"},\"$ sudo systemctl stop docker\"),mdx(\"li\",{parentName:\"ol\"},\"Edit\\xA0/etc/docker/daemon.json. If it does not yet exist, create it. Assuming that the file was empty, add the following contents.\"),mdx(\"li\",{parentName:\"ol\"},\"{\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"storage-driver\\\": \\\"devicemapper\\\"\"),mdx(\"li\",{parentName:\"ol\"},\"}\")),mdx(\"p\",null,\"See all storage options for each storage driver:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/dockerd/#storage-driver-options\"}),\"Stable\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/edge/engine/reference/commandline/dockerd/#storage-driver-options\"}),\"Edge\"))))),mdx(\"p\",null,\"Docker does not start if the\\xA0daemon.json\\xA0file contains badly-formed JSON.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Start Docker.\"),mdx(\"li\",{parentName:\"ol\"},\"$ sudo systemctl start docker\"),mdx(\"li\",{parentName:\"ol\"},\"Verify that the daemon is using the\\xA0devicemapper\\xA0storage driver. Use the\\xA0docker infocommand and look for\\xA0Storage Driver.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker info\"),mdx(\"li\",{parentName:\"ol\"},\"Containers: 0\"),mdx(\"li\",{parentName:\"ol\"},\"Running: 0\"),mdx(\"li\",{parentName:\"ol\"},\"Paused: 0\"),mdx(\"li\",{parentName:\"ol\"},\"Stopped: 0\"),mdx(\"li\",{parentName:\"ol\"},\"Images: 0\"),mdx(\"li\",{parentName:\"ol\"},\"Server Version: 17.03.1-ce\"),mdx(\"li\",{parentName:\"ol\"},\"Storage Driver: devicemapper\"),mdx(\"li\",{parentName:\"ol\"},\"Pool Name: docker-202:1-8413957-pool\"),mdx(\"li\",{parentName:\"ol\"},\"Pool Blocksize: 65.54 kB\"),mdx(\"li\",{parentName:\"ol\"},\"Base Device Size: 10.74 GB\"),mdx(\"li\",{parentName:\"ol\"},\"Backing Filesystem: xfs\"),mdx(\"li\",{parentName:\"ol\"},\"Data file: /dev/loop0\"),mdx(\"li\",{parentName:\"ol\"},\"Metadata file: /dev/loop1\"),mdx(\"li\",{parentName:\"ol\"},\"Data Space Used: 11.8 MB\"),mdx(\"li\",{parentName:\"ol\"},\"Data Space Total: 107.4 GB\"),mdx(\"li\",{parentName:\"ol\"},\"Data Space Available: 7.44 GB\"),mdx(\"li\",{parentName:\"ol\"},\"Metadata Space Used: 581.6 kB\"),mdx(\"li\",{parentName:\"ol\"},\"Metadata Space Total: 2.147 GB\"),mdx(\"li\",{parentName:\"ol\"},\"Metadata Space Available: 2.147 GB\"),mdx(\"li\",{parentName:\"ol\"},\"Thin Pool Minimum Free Space: 10.74 GB\"),mdx(\"li\",{parentName:\"ol\"},\"Udev Sync Supported: true\"),mdx(\"li\",{parentName:\"ol\"},\"Deferred Removal Enabled: false\"),mdx(\"li\",{parentName:\"ol\"},\"Deferred Deletion Enabled: false\"),mdx(\"li\",{parentName:\"ol\"},\"Deferred Deleted Device Count: 0\"),mdx(\"li\",{parentName:\"ol\"},\"Data loop file: /var/lib/docker/devicemapper/data\"),mdx(\"li\",{parentName:\"ol\"},\"Metadata loop file: /var/lib/docker/devicemapper/metadata\"),mdx(\"li\",{parentName:\"ol\"},\"Library Version: 1.02.135-RHEL7 (2016-11-16)\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<output truncated>\"))),mdx(\"p\",null,\"This host is running in\\xA0loop-lvm\\xA0mode, which is\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"not\"),\"\\xA0supported on production systems. This is indicated by the fact that the\\xA0Data loop file\\xA0and a\\xA0Metadata loop file\\xA0are on files under/var/lib/docker/devicemapper. These are loopback-mounted sparse files. For production systems, see\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/device-mapper-driver/#configure-direct-lvm-mode-for-production\"}),\"Configure direct-lvm mode for production\"),\".\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Configure direct-lvm mode for production\")),mdx(\"p\",null,\"Production hosts using the\\xA0devicemapper\\xA0storage driver must use\\xA0direct-lvm\\xA0mode. This mode uses block devices to create the thin pool. This is faster than using loopback devices, uses system resources more efficiently, and block devices can grow as needed. However, more set-up is required than\\xA0loop-lvm\\xA0mode.\"),mdx(\"p\",null,\"After you have satisfied the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/device-mapper-driver/#prerequisites\"}),\"prerequisites\"),\", follow the steps below to configure Docker to use the\\xA0devicemapper\\xA0storage driver in\\xA0direct-lvm\\xA0mode.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Warning\"),\": Changing the storage driver makes any containers you have already created inaccessible on the local system. Use\\xA0docker save\\xA0to save containers, and push existing images to Docker Hub or a private repository, so that you don't need to recreate them later.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"ALLOW DOCKER TO CONFIGURE DIRECT-LVM MODE\")),mdx(\"p\",null,\"In Docker 17.06 and higher, Docker can manage the block device for you, simplifying configuration of\\xA0direct-lvm\\xA0mode.\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"This is appropriate for fresh Docker set-ups only.\"),\"\\xA0You can only use a single block device. If you need to use multiple block devices,\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/device-mapper-driver/#configure-direct-lvm-mode-manually\"}),\"configure direct-lvm mode manually\"),\"\\xA0instead. The following new configuration options have been added:\"),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Option\"),\"                      \",mdx(\"strong\",{parentName:\"p\"},\"Description\"),\"                                                                                                                                                                    \",mdx(\"strong\",{parentName:\"p\"},\"Required?\"),\"   \",mdx(\"strong\",{parentName:\"p\"},\"Default\"),\"   \",mdx(\"strong\",{parentName:\"p\"},\"Example\")),mdx(\"hr\",null),mdx(\"p\",null,\"  dm.directlvm_device             The path to the block device to configure for\\xA0direct-lvm.                                                                                                                          Yes             \\xA0             dm.directlvm_device=\\\"/dev/xvdf\\\"\\ndm.thinp_percent                The percentage of space to use for storage from the passed in block device.                                                                                                        No              95            dm.thinp_percent=95\\ndm.thinp_metapercent            The percentage of space to for metadata storage from the passed-in block device.                                                                                                   No              1             dm.thinp_metapercent=1\\ndm.thinp_autoextend_threshold   The threshold for when lvm should automatically extend the thin pool as a percentage of the total storage space.                                                                   No              80            dm.thinp_autoextend_threshold=80\\ndm.thinp_autoextend_percent     The percentage to increase the thin pool by when an autoextend is triggered.                                                                                                       No              20            dm.thinp_autoextend_percent=20\\ndm.directlvm_device_force       Whether to format the block device even if a filesystem already exists on it. If set to\\xA0false\\xA0and a filesystem is present, an error is logged and the filesystem is left intact.   No              false         dm.directlvm_device_force=true\"),mdx(\"p\",null,\"Edit the\\xA0daemon.json\\xA0file and set the appropriate options, then restart Docker for the changes to take effect. The following\\xA0daemon.json\\xA0sets all of the options in the table above.\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"storage-driver\\\": \\\"devicemapper\\\",\"),mdx(\"p\",null,\"\\\"storage-opts\\\": [\"),mdx(\"p\",null,\"\\\"dm.directlvm_device=/dev/xdf\\\",\"),mdx(\"p\",null,\"\\\"dm.thinp_percent=95\\\",\"),mdx(\"p\",null,\"\\\"dm.thinp_metapercent=1\\\",\"),mdx(\"p\",null,\"\\\"dm.thinp_autoextend_threshold=80\\\",\"),mdx(\"p\",null,\"\\\"dm.thinp_autoextend_percent=20\\\",\"),mdx(\"p\",null,\"\\\"dm.directlvm_device_force=false\\\"\"),mdx(\"p\",null,\"]\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"See all storage options for each storage driver:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/dockerd/#storage-driver-options\"}),\"Stable\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/edge/engine/reference/commandline/dockerd/#storage-driver-options\"}),\"Edge\"))),mdx(\"p\",null,\"Restart Docker for the changes to take effect. Docker invokes the commands to configure the block device for you.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Warning\"),\": Changing these values after Docker has prepared the block device for you is not supported and causes an error.\"),mdx(\"p\",null,\"You still need to\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/device-mapper-driver/#manage-devicemapper\"}),\"perform periodic maintenance tasks\"),\".\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"CONFIGURE DIRECT-LVM MODE MANUALLY\")),mdx(\"p\",null,\"The procedure below creates a logical volume configured as a thin pool to use as backing for the storage pool. It assumes that you have a spare block device at\\xA0/dev/xvdf\\xA0with enough free space to complete the task. The device identifier and volume sizes may be different in your environment and you should substitute your own values throughout the procedure. The procedure also assumes that the Docker daemon is in the\\xA0stopped\\xA0state.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Identify the block device you want to use. The device is located under\\xA0/dev/\\xA0(such as\\xA0/dev/xvdf) and needs enough free space to store the images and container layers for the workloads that host runs. A solid state drive is ideal.\"),mdx(\"li\",{parentName:\"ol\"},\"Stop Docker.\"),mdx(\"li\",{parentName:\"ol\"},\"$ sudo systemctl stop docker\"),mdx(\"li\",{parentName:\"ol\"},\"Install the following packages:\",mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"RHEL / CentOS\"),\":\\xA0device-mapper-persistent-data,\\xA0lvm2, and all dependencies\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Ubuntu / Debian\"),\":\\xA0thin-provisioning-tools,\\xA0lvm2, and all dependencies\"))),mdx(\"li\",{parentName:\"ol\"},\"Create a physical volume on your block device from step 1, using the\\xA0pvcreate\\xA0command. Substitute your device name for\\xA0/dev/xvdf.\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Warning\"),\": The next few steps are destructive, so be sure that you have specified the correct device!\"),mdx(\"p\",null,\"$ sudo pvcreate /dev/xvdf\"),mdx(\"p\",null,\"Physical volume \\\"/dev/xvdf\\\" successfully created.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Create a\\xA0docker\\xA0volume group on the same device, using the\\xA0vgcreate\\xA0command.\"),mdx(\"li\",{parentName:\"ol\"},\"$ sudo vgcreate docker /dev/xvdf\"),mdx(\"li\",{parentName:\"ol\"},\"Volume group \\\"docker\\\" successfully created\"),mdx(\"li\",{parentName:\"ol\"},\"Create two logical volumes named\\xA0thinpool\\xA0and\\xA0thinpoolmeta\\xA0using the\\xA0lvcreate\\xA0command. The last parameter specifies the amount of free space to allow for automatic expanding of the data or metadata if space runs low, as a temporary stop-gap. These are the recommended values.\"),mdx(\"li\",{parentName:\"ol\"},\"$ sudo lvcreate --wipesignatures y -n thinpool docker -l 95%VG\"),mdx(\"li\",{parentName:\"ol\"},\"Logical volume \\\"thinpool\\\" created.\"),mdx(\"li\",{parentName:\"ol\"},\"$ sudo lvcreate --wipesignatures y -n thinpoolmeta docker -l 1%VG\"),mdx(\"li\",{parentName:\"ol\"},\"Logical volume \\\"thinpoolmeta\\\" created.\"),mdx(\"li\",{parentName:\"ol\"},\"Convert the volumes to a thin pool and a storage location for metadata for the thin pool, using the\\xA0lvconvert\\xA0command.\"),mdx(\"li\",{parentName:\"ol\"},\"$ sudo lvconvert -y \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--zero n \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"-c 512K \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--thinpool docker/thinpool \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--poolmetadata docker/thinpoolmeta\"),mdx(\"li\",{parentName:\"ol\"},\"WARNING: Converting logical volume docker/thinpool and docker/thinpoolmeta to\"),mdx(\"li\",{parentName:\"ol\"},\"thin pool\\\\'s data and metadata volumes with metadata wiping.\"),mdx(\"li\",{parentName:\"ol\"},\"THIS WILL DESTROY CONTENT OF LOGICAL VOLUME (filesystem etc.)\"),mdx(\"li\",{parentName:\"ol\"},\"Converted docker/thinpool to thin pool.\"),mdx(\"li\",{parentName:\"ol\"},\"Configure autoextension of thin pools via an\\xA0lvm\\xA0profile.\"),mdx(\"li\",{parentName:\"ol\"},\"$ sudo vi /etc/lvm/profile/docker-thinpool.profile\"),mdx(\"li\",{parentName:\"ol\"},\"Specify\\xA0thin_pool_autoextend_threshold\\xA0and\\xA0thin_pool_autoextend_percent\\xA0values.\")),mdx(\"p\",null,\"thin_pool_autoextend_threshold\\xA0is the percentage of space used before\\xA0lvm\\xA0attempts to autoextend the available space (100 = disabled, not recommended).\"),mdx(\"p\",null,\"thin_pool_autoextend_percent\\xA0is the amount of space to add to the device when automatically extending (0 = disabled).\"),mdx(\"p\",null,\"The example below adds 20% more capacity when the disk usage reaches 80%.\"),mdx(\"p\",null,\"activation {\"),mdx(\"p\",null,\"thin_pool_autoextend_threshold=80\"),mdx(\"p\",null,\"thin_pool_autoextend_percent=20\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"Save the file.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Apply the LVM profile, using the\\xA0lvchange\\xA0command.\"),mdx(\"li\",{parentName:\"ol\"},\"$ sudo lvchange --metadataprofile docker-thinpool docker/thinpool\"),mdx(\"li\",{parentName:\"ol\"},\"Logical volume docker/thinpool changed.\"),mdx(\"li\",{parentName:\"ol\"},\"Enable monitoring for logical volumes on your host. Without this step, automatic extension does not occur even in the presence of the LVM profile.\"),mdx(\"li\",{parentName:\"ol\"},\"$ sudo lvs -o+seg_monitor\"),mdx(\"li\",{parentName:\"ol\"},\"LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert Monitor\"),mdx(\"li\",{parentName:\"ol\"},\"thinpool docker twi-a-t--- 95.00g 0.00 0.01 monitored\"),mdx(\"li\",{parentName:\"ol\"},\"If you have ever run Docker on this host before, or if\\xA0/var/lib/docker/\\xA0exists, move it out of the way so that Docker can use the new LVM pool to store the contents of image and containers.\"),mdx(\"li\",{parentName:\"ol\"},\"$ mkdir /var/lib/docker.bk\"),mdx(\"li\",{parentName:\"ol\"},\"$ mv /var/lib/docker/* /var/lib/docker.bk\")),mdx(\"p\",null,\"If any of the following steps fail and you need to restore, you can remove\\xA0/var/lib/docker\\xA0and replace it with\\xA0/var/lib/docker.bk.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Edit\\xA0/etc/docker/daemon.json\\xA0and configure the options needed for the\\xA0devicemapper\\xA0storage driver. If the file was previously empty, it should now contain the following contents:\"),mdx(\"li\",{parentName:\"ol\"},\"{\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"storage-driver\\\": \\\"devicemapper\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"storage-opts\\\": [\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"dm.thinpooldev=/dev/mapper/docker-thinpool\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"dm.use_deferred_removal=true\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"dm.use_deferred_deletion=true\\\"\"),mdx(\"li\",{parentName:\"ol\"},\"]\"),mdx(\"li\",{parentName:\"ol\"},\"}\"),mdx(\"li\",{parentName:\"ol\"},\"Start Docker.\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"systemd\"),\":\"),mdx(\"p\",null,\"$ sudo systemctl start docker\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"service\"),\":\"),mdx(\"p\",null,\"$ sudo service docker start\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Verify that Docker is using the new configuration using\\xA0docker info.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker info\"),mdx(\"li\",{parentName:\"ol\"},\"Containers: 0\"),mdx(\"li\",{parentName:\"ol\"},\"Running: 0\"),mdx(\"li\",{parentName:\"ol\"},\"Paused: 0\"),mdx(\"li\",{parentName:\"ol\"},\"Stopped: 0\"),mdx(\"li\",{parentName:\"ol\"},\"Images: 0\"),mdx(\"li\",{parentName:\"ol\"},\"Server Version: 17.03.1-ce\"),mdx(\"li\",{parentName:\"ol\"},\"Storage Driver: devicemapper\"),mdx(\"li\",{parentName:\"ol\"},\"Pool Name: docker-thinpool\"),mdx(\"li\",{parentName:\"ol\"},\"Pool Blocksize: 524.3 kB\"),mdx(\"li\",{parentName:\"ol\"},\"Base Device Size: 10.74 GB\"),mdx(\"li\",{parentName:\"ol\"},\"Backing Filesystem: xfs\"),mdx(\"li\",{parentName:\"ol\"},\"Data file:\"),mdx(\"li\",{parentName:\"ol\"},\"Metadata file:\"),mdx(\"li\",{parentName:\"ol\"},\"Data Space Used: 19.92 MB\"),mdx(\"li\",{parentName:\"ol\"},\"Data Space Total: 102 GB\"),mdx(\"li\",{parentName:\"ol\"},\"Data Space Available: 102 GB\"),mdx(\"li\",{parentName:\"ol\"},\"Metadata Space Used: 147.5 kB\"),mdx(\"li\",{parentName:\"ol\"},\"Metadata Space Total: 1.07 GB\"),mdx(\"li\",{parentName:\"ol\"},\"Metadata Space Available: 1.069 GB\"),mdx(\"li\",{parentName:\"ol\"},\"Thin Pool Minimum Free Space: 10.2 GB\"),mdx(\"li\",{parentName:\"ol\"},\"Udev Sync Supported: true\"),mdx(\"li\",{parentName:\"ol\"},\"Deferred Removal Enabled: true\"),mdx(\"li\",{parentName:\"ol\"},\"Deferred Deletion Enabled: true\"),mdx(\"li\",{parentName:\"ol\"},\"Deferred Deleted Device Count: 0\"),mdx(\"li\",{parentName:\"ol\"},\"Library Version: 1.02.135-RHEL7 (2016-11-16)\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<output truncated>\"))),mdx(\"p\",null,\"If Docker is configured correctly, the\\xA0Data file\\xA0and\\xA0Metadata file\\xA0is blank, and the pool name is\\xA0docker-thinpool.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"After you have verified that the configuration is correct, you can remove the\\xA0/var/lib/docker.bkdirectory which contains the previous configuration.\"),mdx(\"li\",{parentName:\"ol\"},\"$ rm -rf /var/lib/docker.bk\")),mdx(\"h4\",null,\"Manage devicemapper\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Monitor the thin pool\")),mdx(\"p\",null,\"Do not rely on LVM auto-extension alone. The volume group automatically extends, but the volume can still fill up. You can monitor free space on the volume using\\xA0lvs\\xA0or\\xA0lvs -a. Consider using a monitoring tool at the OS level, such a Nagios.\"),mdx(\"p\",null,\"To view the LVM logs, you can use\\xA0journalctl:\"),mdx(\"p\",null,\"$ journalctl -fu dm-event.service\"),mdx(\"p\",null,\"If you run into repeated problems with thin pool, you can set the storage option\\xA0dm.min_free_space\\xA0to a value (representing a percentage) in\\xA0/etc/docker.daemon.json. For instance, setting it to\\xA010ensures that operations fail with a warning when the free space is at or near 10%. See the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/dockerd/#storage-driver-options\"}),\"storage driver options in the Engine daemon reference\"),\".\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Increase capacity on a running device\")),mdx(\"p\",null,\"You can increase the capacity of the pool on a running thin-pool device. This is useful if the data's logical volume is full and the volume group is at full capacity. The specific procedure depends on whether you are using a\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/device-mapper-driver/#resize-a-loop-lvm-thin-pool\"}),\"loop-lvm thin pool\"),\"\\xA0or a\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/device-mapper-driver/#resize-a-direct-lvm-thin-pool\"}),\"direct-lvm thin pool\"),\".\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"RESIZE A LOOP-LVM THIN POOL\")),mdx(\"p\",null,\"The easiest way to resize a\\xA0loop-lvm\\xA0thin pool is to\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/device-mapper-driver/#use-the-device_tool-utility\"}),\"use the device_tool utility\"),\", but you can\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/device-mapper-driver/#use-operating-system-utilities\"}),\"use operating system utilities\"),\"\\xA0instead.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Use the device_tool utility\")),mdx(\"p\",null,\"A community-contributed script called\\xA0device_tool.go\\xA0is available in the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/moby/moby/tree/master/contrib/docker-device-tool\"}),\"moby/moby\"),\"\\xA0Github repository. You can use this tool to resize a\\xA0loop-lvm\\xA0thin pool, avoiding the long process above. This tool is not guaranteed to work, but you should only be using\\xA0loop-lvm\\xA0on non-production systems.\"),mdx(\"p\",null,\"If you do not want to use\\xA0device_tool, you can\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/device-mapper-driver/#use-operating-system-utilities\"}),\"resize the thin pool manually\"),\"\\xA0instead.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"To use the tool, clone the Github repository, change to the\\xA0contrib/docker-device-tool, and follow the instructions in the\\xA0README.md\\xA0to compile the tool.\"),mdx(\"li\",{parentName:\"ol\"},\"Use the tool. The following example resizes the thin pool to 200GB.\"),mdx(\"li\",{parentName:\"ol\"},\"$ ./device_tool resize 200GB\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Use operating system utilities\")),mdx(\"p\",null,\"If you do not want to\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/device-mapper-driver/#use-the-device_tool-utility\"}),\"use the device-tool utility\"),\", you can resize a\\xA0loop-lvm\\xA0thin pool manually using the following procedure.\"),mdx(\"p\",null,\"In\\xA0loop-lvm\\xA0mode, a loopback device is used to store the data, and another to store the metadata.\\xA0loop-lvm\\xA0mode is only supported for testing, because it has significant performance and stability drawbacks.\"),mdx(\"p\",null,\"If you are using\\xA0loop-lvm\\xA0mode, the output of\\xA0docker info\\xA0shows file paths for\\xA0Data loop file\\xA0and\\xA0Metadata loop file:\"),mdx(\"p\",null,\"$ docker info |grep \\\\'loop file\\\\'\"),mdx(\"p\",null,\"Data loop file: /var/lib/docker/devicemapper/data\"),mdx(\"p\",null,\"Metadata loop file: /var/lib/docker/devicemapper/metadata\"),mdx(\"p\",null,\"Follow these steps to increase the size of the thin pool. In this example, the thin pool is 100 GB, and is increased to 200 GB.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"List the sizes of the devices.\"),mdx(\"li\",{parentName:\"ol\"},\"$ sudo ls -lh /var/lib/docker/devicemapper/\"),mdx(\"li\",{parentName:\"ol\"},\"total 1175492\"),mdx(\"li\",{parentName:\"ol\"},\"-rw------- 1 root root 100G Mar 30 05:22 data\"),mdx(\"li\",{parentName:\"ol\"},\"-rw------- 1 root root 2.0G Mar 31 11:17 metadata\"),mdx(\"li\",{parentName:\"ol\"},\"Increase the size of the\\xA0data\\xA0file to 200 G using the\\xA0truncate\\xA0command, which is used to increase\\xA0\",mdx(\"strong\",{parentName:\"li\"},\"or\"),\"\\xA0decrease the size of a file. Note that decreasing the size is a destructive operation.\"),mdx(\"li\",{parentName:\"ol\"},\"$ sudo truncate -s 200G /var/lib/docker/devicemapper/data\"),mdx(\"li\",{parentName:\"ol\"},\"Verify the file size changed.\"),mdx(\"li\",{parentName:\"ol\"},\"$ sudo ls -lh /var/lib/docker/devicemapper/\"),mdx(\"li\",{parentName:\"ol\"},\"total 1.2G\"),mdx(\"li\",{parentName:\"ol\"},\"-rw------- 1 root root 200G Apr 14 08:47 data\"),mdx(\"li\",{parentName:\"ol\"},\"-rw------- 1 root root 2.0G Apr 19 13:27 metadata\"),mdx(\"li\",{parentName:\"ol\"},\"The loopback file has changed on disk but not in memory. List the size of the loopback device in memory, in GB. Reload it, then list the size again. After the reload, the size is 200 GB.\"),mdx(\"li\",{parentName:\"ol\"},\"$ echo $\",\"[ $(sudo blockdev --getsize64 /dev/loop0) / 1024 / 1024 / 1024 ]\"),mdx(\"li\",{parentName:\"ol\"},\"100\"),mdx(\"li\",{parentName:\"ol\"},\"$ sudo losetup -c /dev/loop0\"),mdx(\"li\",{parentName:\"ol\"},\"$ echo $\",\"[ $(sudo blockdev --getsize64 /dev/loop0) / 1024 / 1024 / 1024 ]\"),mdx(\"li\",{parentName:\"ol\"},\"200\"),mdx(\"li\",{parentName:\"ol\"},\"Reload the devicemapper thin pool.\")),mdx(\"p\",null,\"a. Get the pool name first. The pool name is the first field, delimited by \",mdx(\"inlineCode\",{parentName:\"p\"},\" :\"),\". This command extracts it.\"),mdx(\"p\",null,\"$ sudo dmsetup status | grep \\\\' thin-pool \\\\' | awk -F \\\\': \\\\' {\\\\'print $1\\\\'}\"),mdx(\"p\",null,\"docker-8:1-123141-pool\"),mdx(\"p\",null,\"b. Dump the device mapper table for the thin pool.\"),mdx(\"p\",null,\"$ sudo dmsetup table docker-8:1-123141-pool\"),mdx(\"p\",null,\"0 209715200 thin-pool 7:1 7:0 128 32768 1 skip_block_zeroing\"),mdx(\"p\",null,\"c. Calculate the total sectors of the thin pool using the second field of the output. The number is expressed in 512-k sectors. A 100G file has 209715200 512-k sectors. If you double this number to 200G, you get 419430400 512-k sectors.\"),mdx(\"p\",null,\"d. Reload the thin pool with the new sector number, using the following three\\xA0dmsetupcommands.\"),mdx(\"p\",null,\"$ sudo dmsetup suspend docker-8:1-123141-pool\"),mdx(\"p\",null,\"$ sudo dmsetup reload docker-8:1-123141-pool --table \\\\'0 419430400 thin-pool 7:1 7:0 128 32768 1 skip_block_zeroing\\\\'\"),mdx(\"p\",null,\"$ sudo dmsetup resume docker-8:1-123141-pool\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"RESIZE A DIRECT-LVM THIN POOL\")),mdx(\"p\",null,\"To extend a\\xA0direct-lvm\\xA0thin pool, you need to first attach a new block device to the Docker host, and make note of the name assigned to it by the kernel. In this example, the new block device is\\xA0/dev/xvdg.\"),mdx(\"p\",null,\"Follow this procedure to extend a\\xA0direct-lvm\\xA0thin pool, substituting your block device and other parameters to suit your situation.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Gather information about your volume group.\")),mdx(\"p\",null,\"Use the\\xA0pvdisplay\\xA0command to find the physical block devices currently in use by your thin pool, and the volume group's name.\"),mdx(\"p\",null,\"$ sudo pvdisplay |grep \\\\'VG Name\\\\'\"),mdx(\"p\",null,\"PV Name /dev/xvdf\"),mdx(\"p\",null,\"VG Name docker\"),mdx(\"p\",null,\"In the following steps, substitute your block device or volume group name as appropriate.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Extend the volume group, using the\\xA0vgextend\\xA0command with the\\xA0VG Name\\xA0from the previous step, and the name of your\\xA0\",mdx(\"strong\",{parentName:\"li\"},\"new\"),\"\\xA0block device.\"),mdx(\"li\",{parentName:\"ol\"},\"$ sudo vgextend docker /dev/xvdg\"),mdx(\"li\",{parentName:\"ol\"},\"Physical volume \\\"/dev/xvdg\\\" successfully created.\"),mdx(\"li\",{parentName:\"ol\"},\"Volume group \\\"docker\\\" successfully extended\"),mdx(\"li\",{parentName:\"ol\"},\"Extend the\\xA0docker/thinpool\\xA0logical volume. This command uses 100% of the volume right away, without auto-extend. To extend the metadata thinpool instead, use\\xA0docker/thinpool_tmeta.\"),mdx(\"li\",{parentName:\"ol\"},\"$ sudo lvextend -l+100%FREE -n docker/thinpool\"),mdx(\"li\",{parentName:\"ol\"},\"Size of logical volume docker/thinpool_tdata changed from 95.00 GiB (24319 extents) to 198.00 GiB (50688 extents).\"),mdx(\"li\",{parentName:\"ol\"},\"Logical volume docker/thinpool_tdata successfully resized.\"),mdx(\"li\",{parentName:\"ol\"},\"Verify the new thin pool size using the\\xA0Data Space Available\\xA0field in the output of\\xA0docker info. If you extended the\\xA0docker/thinpool_tmeta\\xA0logical volume instead, look for\\xA0Metadata Space Available.\"),mdx(\"li\",{parentName:\"ol\"},\"Storage Driver: devicemapper\"),mdx(\"li\",{parentName:\"ol\"},\"Pool Name: docker-thinpool\"),mdx(\"li\",{parentName:\"ol\"},\"Pool Blocksize: 524.3 kB\"),mdx(\"li\",{parentName:\"ol\"},\"Base Device Size: 10.74 GB\"),mdx(\"li\",{parentName:\"ol\"},\"Backing Filesystem: xfs\"),mdx(\"li\",{parentName:\"ol\"},\"Data file:\"),mdx(\"li\",{parentName:\"ol\"},\"Metadata file:\"),mdx(\"li\",{parentName:\"ol\"},\"Data Space Used: 212.3 MB\"),mdx(\"li\",{parentName:\"ol\"},\"Data Space Total: 212.6 GB\"),mdx(\"li\",{parentName:\"ol\"},\"Data Space Available: 212.4 GB\"),mdx(\"li\",{parentName:\"ol\"},\"Metadata Space Used: 286.7 kB\"),mdx(\"li\",{parentName:\"ol\"},\"Metadata Space Total: 1.07 GB\"),mdx(\"li\",{parentName:\"ol\"},\"Metadata Space Available: 1.069 GB\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<output truncated>\"))),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Activate the\\xA0devicemapper\\xA0after reboot\")),mdx(\"p\",null,\"If you reboot the host and find that the\\xA0docker\\xA0service failed to start, look for the error, \\\"Non existing device\\\". You need to re-activate the logical volumes with this command:\"),mdx(\"p\",null,\"sudo lvchange -ay docker/thinpool\"),mdx(\"h4\",null,\"How the\\xA0devicemapper\\xA0storage driver works\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Warning\"),\": Do not directly manipulate any files or directories within\\xA0/var/lib/docker/. These files and directories are managed by Docker.\"),mdx(\"p\",null,\"Use the\\xA0lsblk\\xA0command to see the devices and their pools, from the operating system's point of view:\"),mdx(\"p\",null,\"$ sudo lsblk\"),mdx(\"p\",null,\"NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT\"),mdx(\"p\",null,\"xvda 202:0 0 8G 0 disk\"),mdx(\"p\",null,\"\\u2514\\u2500xvda1 202:1 0 8G 0 part /\"),mdx(\"p\",null,\"xvdf 202:80 0 100G 0 disk\"),mdx(\"p\",null,\"\\u251C\\u2500docker-thinpool_tmeta 253:0 0 1020M 0 lvm\"),mdx(\"p\",null,\"\\u2502 \\u2514\\u2500docker-thinpool 253:2 0 95G 0 lvm\"),mdx(\"p\",null,\"\\u2514\\u2500docker-thinpool_tdata 253:1 0 95G 0 lvm\"),mdx(\"p\",null,\"\\u2514\\u2500docker-thinpool 253:2 0 95G 0 lvm\"),mdx(\"p\",null,\"Use the\\xA0mount\\xA0command to see the mount-point Docker is using:\"),mdx(\"p\",null,\"$ mount |grep devicemapper\"),mdx(\"p\",null,\"/dev/xvda1 on /var/lib/docker/devicemapper type xfs (rw,relatime,seclabel,attr2,inode64,noquota)\"),mdx(\"p\",null,\"When you use\\xA0devicemapper, Docker stores image and layer contents in the thinpool, and exposes them to containers by mounting them under subdirectories of\\xA0/var/lib/docker/devicemapper/.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Image and container layers on-disk\")),mdx(\"p\",null,\"The\\xA0/var/lib/docker/devicemapper/metadata/\\xA0directory contains metadata about the Devicemapper configuration itself and about each image and container layer that exist. The\\xA0devicemapper\\xA0storage driver uses snapshots, and this metadata include information about those snapshots. These files are in JSON format.\"),mdx(\"p\",null,\"The\\xA0/var/lib/devicemapper/mnt/\\xA0directory contains a mount point for each image and container layer that exists. Image layer mount points are empty, but a container's mount point shows the container's filesystem as it appears from within the container.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Image layering and sharing\")),mdx(\"p\",null,\"The\\xA0devicemapper\\xA0storage driver uses dedicated block devices rather than formatted filesystems, and operates on files at the block level for maximum performance during copy-on-write (CoW) operations.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"SNAPSHOTS\")),mdx(\"p\",null,\"Another feature of\\xA0devicemapper\\xA0is its use of snapshots (also sometimes called\\xA0thin devices\\xA0or\\xA0virtual devices), which store the differences introduced in each layer as very small, lightweight thin pools. Snapshots provide many benefits:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Layers which are shared in common between containers are only stored on disk once, unless they are writable. For instance, if you have 10 different images which are all based on\\xA0alpine, the\\xA0alpine\\xA0image and all its parent images are only stored once each on disk.\"),mdx(\"li\",{parentName:\"ul\"},\"Snapshots are an implementation of a copy-on-write (CoW) strategy. This means that a given file or directory is only copied to the container's writable layer when it is modified or deleted by that container.\"),mdx(\"li\",{parentName:\"ul\"},\"Because\\xA0devicemapper\\xA0operates at the block level, multiple blocks in a writable layer can be modified simultaneously.\"),mdx(\"li\",{parentName:\"ul\"},\"Snapshots can be backed up using standard OS-level backup utilities. Just make a copy of\\xA0/var/lib/docker/devicemapper/.\")),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"DEVICEMAPPER WORKFLOW\")),mdx(\"p\",null,\"When you start Docker with the\\xA0devicemapper\\xA0storage driver, all objects related to image and container layers are stored in\\xA0/var/lib/docker/devicemapper/, which is backed by one or more block-level devices, either loopback devices (testing only) or physical disks.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"The\\xA0base device\\xA0is the lowest-level object. This is the thin pool itself. You can examine it using\\xA0docker info. It contains a filesystem. This base device is the starting point for every image and container layer. The base device is a Device Mapper implementation detail, rather than a Docker layer.\"),mdx(\"li\",{parentName:\"ul\"},\"Metadata about the base device and each image or container layer is stored in/var/lib/docker/devicemapper/metadata/\\xA0in JSON format. These layers are copy-on-write snapshots, which means that they are empty until they diverge from their parent layers.\"),mdx(\"li\",{parentName:\"ul\"},\"Each container's writable layer is mounted on a mountpoint in/var/lib/docker/devicemapper/mnt/. An empty directory exists for each read-only image layer and each stopped container.\")),mdx(\"p\",null,\"Each image layer is a snapshot of the layer below it. The lowest layer of each image is a snapshot of the base device that exists in the pool. When you run a container, it is a snapshot of the image the container is based on. The following example shows a Docker host with two running containers. The first is a\\xA0ubuntu\\xA0container and the second is a\\xA0busybox\\xA0container.\"),mdx(\"h4\",null,\"How container reads and writes work with\\xA0devicemapper\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Reading files\")),mdx(\"p\",null,\"With\\xA0devicemapper, reads happen at the block level. The diagram below shows the high level process for reading a single block (0x44f) in an example container.\"),mdx(\"p\",null,\"An application makes a read request for block\\xA00x44f\\xA0in the container. Because the container is a thin snapshot of an image, it doesn't have the block, but it has a pointer to the block on the nearest parent image where it does exist, and it reads the block from there. The block now exists in the container's memory.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Writing files\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Writing a new file\"),\": With the\\xA0devicemapper\\xA0driver, writing new data to a container is accomplished by an\\xA0allocate-on-demand\\xA0operation. Each block of the new file is allocated in the container's writable layer and the block is written there.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Updating an existing file\"),\": The relevant block of the file is read from the nearest layer where it exists. When the container writes the file, only the modified blocks are written to the container's writable layer.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Deleting a file or directory\"),\": When you delete a file or directory in a container's writable layer, or when an image layer deletes a file that exists in its parent layer, the\\xA0devicemapper\\xA0storage driver intercepts further read attempts on that file or directory and responds that the file or directory does not exist.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Writing and then deleting a file\"),\": If a container writes to a file and later deletes the file, all of those operations happen in the container's writable layer. In that case, if you are using\\xA0direct-lvm, the blocks are freed. If you use\\xA0loop-lvm, the blocks may not be freed. This is another reason not to useloop-lvm\\xA0in production.\"),mdx(\"h4\",null,\"Device Mapper and Docker performance\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"allocate-on demand\\xA0performance impact\"),\":\")),mdx(\"p\",null,\"The\\xA0devicemapper\\xA0storage driver uses an\\xA0allocate-on-demand\\xA0operation to allocate new blocks from the thin pool into a container's writable layer. Each block is 64KB, so this is the minimum amount of space that is used for a write.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Copy-on-write performance impact\"),\": The first time a container modifies a specific block, that block is written to the container's writable layer. Because these writes happen at the level of the block rather than the file, performance impact is minimized. However, writing a large number of blocks can still negatively impact performance, and the\\xA0devicemapper\\xA0storage driver may actually perform worse than other storage drivers in this scenario. For write-heavy workloads, you should use data volumes, which bypass the storage driver completely.\")),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Performance best practices\")),mdx(\"p\",null,\"Keep these things in mind to maximize performance when using the\\xA0devicemapper\\xA0storage driver.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Use\\xA0direct-lvm\"),\": The\\xA0loop-lvm\\xA0mode is not performant and should never be used in production.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Use fast storage\"),\": Solid-state drives (SSDs) provide faster reads and writes than spinning disks.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Memory usage\"),\": the\\xA0devicemapper\\xA0uses more memory than some other storage drivers. Each launched container loads one or more copies of its files into memory, depending on how many blocks of the same file are being modified at the same time. Due to the memory pressure, the\\xA0devicemapper\\xA0storage driver may not be the right choice for certain workloads in high-density use cases.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Use volumes for write-heavy workloads\"),\": Volumes provide the best and most predictable performance for write-heavy workloads. This is because they bypass the storage driver and do not incur any of the potential overheads introduced by thin provisioning and copy-on-write. Volumes have other benefits, such as allowing you to share data among containers and persisting even when no running container is using them.\")),mdx(\"h4\",null,\"Related Information\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/volumes/\"}),\"Volumes\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/imagesandcontainers/\"}),\"Understand images, containers, and storage drivers\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/selectadriver/\"}),\"Select a storage driver\"))),mdx(\"h3\",null,\"Use the OverlayFS storage driver\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA019 minutes\")),mdx(\"p\",null,\"OverlayFS is a modern\\xA0union filesystem\\xA0that is similar to AUFS, but faster and with a simpler implementation. Docker provides two storage drivers for OverlayFS: the original\\xA0overlay, and the newer and more stable\\xA0overlay2.\"),mdx(\"p\",null,\"This topic refers to the Linux kernel driver as\\xA0OverlayFS\\xA0and to the Docker storage driver as\\xA0overlayor\\xA0overlay2.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note: If you use OverlayFS, use the\\xA0overlay2\\xA0driver rather than the\\xA0overlay\\xA0driver, because it is more efficient in terms of inode utilization. To use the new driver, you need version 4.0 or higher of the Linux kernel, unless you are a Docker EE user on RHEL or CentOS, in which case you need version 3.10.0-693 or higher of the kernel and to follow some extra steps.\")),mdx(\"p\",null,\"For more information about differences between\\xA0overlay\\xA0vs\\xA0overlay2, check\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/select-storage-driver/\"}),\"Docker storage drivers\"),\".\"),mdx(\"h4\",null,\"Prerequisites\"),mdx(\"p\",null,\"OverlayFS is supported if you meet the following prerequisites:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"The\\xA0overlay2\\xA0driver is supported for Docker EE and recommended for Docker CE.\"),mdx(\"li\",{parentName:\"ul\"},\"The\\xA0overlay\\xA0driver is allowed but not recommended for Docker CE.\"),mdx(\"li\",{parentName:\"ul\"},\"Version 4.0 or higher of the Linux kernel, or RHEL or CentOS using version 3.10.0-693 of the kernel or higher. Docker EE users using kernels older than 4.0 need to follow some extra steps, outlined below. If you use an older kernel, you need to use the\\xA0overlay\\xA0driver, which is not recommended.\"),mdx(\"li\",{parentName:\"ul\"},\"The following backing filesystems are supported:\",mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},\"ext4\\xA0(RHEL 7.1 only)\"),mdx(\"li\",{parentName:\"ul\"},\"xfs\\xA0(RHEL 7.2 and higher), but only with\\xA0d_type=true\\xA0enabled. Use\\xA0xfs_info\\xA0to verify that the\\xA0ftype\\xA0option is set to\\xA01. To format an\\xA0xfs\\xA0filesystem correctly, use the flag\\xA0-n ftype=1.\")))),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Warning\"),\": Running on XFS without d_type support now causes Docker to skip the attempt to use the\\xA0overlay\\xA0or\\xA0overlay2\\xA0driver. Existing installs will continue to run, but produce an error. This is to allow users to migrate their data. In a future version, this will be a fatal error, which will prevent Docker from starting.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Changing the storage driver makes any containers you have already created inaccessible on the local system. Use\\xA0docker save\\xA0to save containers, and push existing images to Docker Hub or a private repository, so that you not need to re-create them later.\")),mdx(\"h4\",null,\"Configure Docker with the\\xA0overlay\\xA0or\\xA0overlay2storage driver\"),mdx(\"p\",null,\"It is highly recommended that you use the\\xA0overlay2\\xA0driver if possible, rather than the\\xA0overlaydriver. The\\xA0overlay\\xA0driver is\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"not\"),\"\\xA0supported for Docker EE.\"),mdx(\"p\",null,\"To configure Docker to use the\\xA0overlay\\xA0storage driver your Docker host must be running version 3.18 of the Linux kernel (preferably newer) with the overlay kernel module loaded. For the\\xA0overlay2\\xA0driver, the version of your kernel must be 4.0 or newer.\"),mdx(\"p\",null,\"Before following this procedure, you must first meet all the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/overlayfs-driver/#prerequisites\"}),\"prerequisites\"),\".\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Stop Docker.\"),mdx(\"li\",{parentName:\"ol\"},\"$ sudo systemctl stop docker\"),mdx(\"li\",{parentName:\"ol\"},\"Copy the contents of\\xA0/var/lib/docker\\xA0to a temporary location.\"),mdx(\"li\",{parentName:\"ol\"},\"$ cp -au /var/lib/docker /var/lib/docker.bk\"),mdx(\"li\",{parentName:\"ol\"},\"If you want to use a separate backing filesystem from the one used by\\xA0/var/lib/, format the filesystem and mount it into\\xA0/var/lib/docker. Make sure add this mount to\\xA0/etc/fstab\\xA0to make it permanent.\"),mdx(\"li\",{parentName:\"ol\"},\"Edit\\xA0/etc/docker/daemon.json. If it does not yet exist, create it. Assuming that the file was empty, add the following contents.\"),mdx(\"li\",{parentName:\"ol\"},\"{\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"storage-driver\\\": \\\"overlay2\\\"\"),mdx(\"li\",{parentName:\"ol\"},\"}\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note: RHEL and CentOS users on Docker EE 17.06\")),mdx(\"p\",null,\"You need to add a second option to the\\xA0daemon.json\\xA0to disable the check for version 4.0 or higher of the Linux kernel. Your\\xA0daemon.json\\xA0should look like the following.\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"This is only needed for Docker EE users of RHEL or CentOS.\"),\"\\xA0Do not attempt to use\\xA0overlay2\\xA0with kernel versions older than 3.10.0-693.\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"storage-driver\\\": \\\"overlay2\\\",\"),mdx(\"p\",null,\"\\\"storage-opts\\\": [\"),mdx(\"p\",null,\"\\\"overlay2.override_kernel_check=true\\\"\"),mdx(\"p\",null,\"]\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"If you need to use the legacy\\xA0overlay\\xA0driver, specify it instead.\"),mdx(\"p\",null,\"More storage options are available. See all storage options for each storage driver:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/dockerd/#storage-driver-options\"}),\"Stable\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/edge/engine/reference/commandline/dockerd/#storage-driver-options\"}),\"Edge\"))))),mdx(\"p\",null,\"Docker does not start if the\\xA0daemon.json\\xA0file contains badly-formed JSON.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Start Docker.\"),mdx(\"li\",{parentName:\"ol\"},\"$ sudo systemctl start docker\"),mdx(\"li\",{parentName:\"ol\"},\"Verify that the daemon is using the\\xA0overlay/overlay2\\xA0storage driver. Use the\\xA0docker infocommand and look for\\xA0Storage Driver\\xA0and\\xA0Backing filesystem.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker info\"),mdx(\"li\",{parentName:\"ol\"},\"Containers: 0\"),mdx(\"li\",{parentName:\"ol\"},\"Images: 0\"),mdx(\"li\",{parentName:\"ol\"},\"Storage Driver: overlay\"),mdx(\"li\",{parentName:\"ol\"},\"Backing Filesystem: extfs\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<output truncated>\"))),mdx(\"p\",null,\"Docker is now using the\\xA0overlay2\\xA0storage driver. Docker has automatically created the\\xA0overlaymount with the required\\xA0lowerdir,\\xA0upperdir,\\xA0merged, and\\xA0workdir\\xA0constructs.\"),mdx(\"p\",null,\"Continue reading for details about how OverlayFS works within your Docker containers, as well as performance advice and information about limitations of its compatibility with different backing filesystems.\"),mdx(\"h4\",null,\"How the\\xA0overlay2\\xA0driver works\"),mdx(\"p\",null,\"If you are still using the\\xA0overlay\\xA0driver rather than\\xA0overlay2, see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/overlayfs-driver/#how-the-overlay-driver-works\"}),\"How the overlay driver works\"),\"instead.\"),mdx(\"p\",null,\"OverlayFS layers two directories on a single Linux host and presents them as a single directory. These directories are called\\xA0layers\\xA0and the unification process is referred to as a\\xA0union mount. OverlayFS refers to the lower directory as\\xA0lowerdir\\xA0and the upper directory a\\xA0upperdir. The unified view is exposed through its own directory called\\xA0merged.\"),mdx(\"p\",null,\"While the\\xA0overlay\\xA0driver only works with a single lower OverlayFS layer and hence requires hard links for implementation of multi-layered images, the\\xA0overlay2\\xA0driver natively supports up to 128 lower OverlayFS layers. This capability provides better performance for layer-related Docker commands such as\\xA0docker build\\xA0and\\xA0docker commit, and consumes fewer inodes on the backing filesystem.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Image and container layers on-disk\")),mdx(\"p\",null,\"After downloading a five-layer image using\\xA0docker pull ubuntu, you can see six directories under\\xA0/var/lib/docker/overlay2.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Warning\"),\": Do not directly manipulate any files or directories within\\xA0/var/lib/docker/. These files and directories are managed by Docker.\"),mdx(\"p\",null,\"$ ls -l /var/lib/docker/overlay2\"),mdx(\"p\",null,\"total 24\"),mdx(\"p\",null,\"drwx------ 5 root root 4096 Jun 20 07:36 223c2864175491657d238e2664251df13b63adb8d050924fd1bfcdb278b866f7\"),mdx(\"p\",null,\"drwx------ 3 root root 4096 Jun 20 07:36 3a36935c9df35472229c57f4a27105a136f5e4dbef0f87905b2e506e494e348b\"),mdx(\"p\",null,\"drwx------ 5 root root 4096 Jun 20 07:36 4e9fa83caff3e8f4cc83693fa407a4a9fac9573deaf481506c102d484dd1e6a1\"),mdx(\"p\",null,\"drwx------ 5 root root 4096 Jun 20 07:36 e8876a226237217ec61c4baf238a32992291d059fdac95ed6303bdff3f59cff5\"),mdx(\"p\",null,\"drwx------ 5 root root 4096 Jun 20 07:36 eca1e4e1694283e001f200a667bb3cb40853cf2d1b12c29feda7422fed78afed\"),mdx(\"p\",null,\"drwx------ 2 root root 4096 Jun 20 07:36 l\"),mdx(\"p\",null,\"The new\\xA0l\\xA0(lowercase\\xA0L) directory contains shortened layer identifiers as symbolic links. These identifiers are used to avoid hitting the page size limitation on arguments to the\\xA0mount\\xA0command.\"),mdx(\"p\",null,\"$ ls -l /var/lib/docker/overlay2/l\"),mdx(\"p\",null,\"total 20\"),mdx(\"p\",null,\"lrwxrwxrwx 1 root root 72 Jun 20 07:36 6Y5IM2XC7TSNIJZZFLJCS6I4I4 -> ../3a36935c9df35472229c57f4a27105a136f5e4dbef0f87905b2e506e494e348b/diff\"),mdx(\"p\",null,\"lrwxrwxrwx 1 root root 72 Jun 20 07:36 B3WWEFKBG3PLLV737KZFIASSW7 -> ../4e9fa83caff3e8f4cc83693fa407a4a9fac9573deaf481506c102d484dd1e6a1/diff\"),mdx(\"p\",null,\"lrwxrwxrwx 1 root root 72 Jun 20 07:36 JEYMODZYFCZFYSDABYXD5MF6YO -> ../eca1e4e1694283e001f200a667bb3cb40853cf2d1b12c29feda7422fed78afed/diff\"),mdx(\"p\",null,\"lrwxrwxrwx 1 root root 72 Jun 20 07:36 NFYKDW6APBCCUCTOUSYDH4DXAT -> ../223c2864175491657d238e2664251df13b63adb8d050924fd1bfcdb278b866f7/diff\"),mdx(\"p\",null,\"lrwxrwxrwx 1 root root 72 Jun 20 07:36 UL2MW33MSE3Q5VYIKBRN4ZAGQP -> ../e8876a226237217ec61c4baf238a32992291d059fdac95ed6303bdff3f59cff5/diff\"),mdx(\"p\",null,\"The lowest layer contains a file called\\xA0link, which contains the name of the shortened identifier, and a directory called\\xA0diff\\xA0which contains the layer's contents.\"),mdx(\"p\",null,\"$ ls /var/lib/docker/overlay2/3a36935c9df35472229c57f4a27105a136f5e4dbef0f87905b2e506e494e348b/\"),mdx(\"p\",null,\"diff link\"),mdx(\"p\",null,\"$ cat /var/lib/docker/overlay2/3a36935c9df35472229c57f4a27105a136f5e4dbef0f87905b2e506e494e348b/link\"),mdx(\"p\",null,\"6Y5IM2XC7TSNIJZZFLJCS6I4I4\"),mdx(\"p\",null,\"$ ls /var/lib/docker/overlay2/3a36935c9df35472229c57f4a27105a136f5e4dbef0f87905b2e506e494e348b/diff\"),mdx(\"p\",null,\"bin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var\"),mdx(\"p\",null,\"The second-lowest layer, and each higher layer, contain a file called\\xA0lower, which denotes its parent, and a directory called\\xA0diff\\xA0which contains its contents. It also contains a\\xA0merged\\xA0directory, which contains the unified contents of its parent layer and itself, and a\\xA0work\\xA0directory which is used internally by OverlayFS.\"),mdx(\"p\",null,\"$ ls /var/lib/docker/overlay2/223c2864175491657d238e2664251df13b63adb8d050924fd1bfcdb278b866f7\"),mdx(\"p\",null,\"diff link lower merged work\"),mdx(\"p\",null,\"$ cat /var/lib/docker/overlay2/223c2864175491657d238e2664251df13b63adb8d050924fd1bfcdb278b866f7/lower\"),mdx(\"p\",null,\"l/6Y5IM2XC7TSNIJZZFLJCS6I4I4\"),mdx(\"p\",null,\"$ ls /var/lib/docker/overlay2/223c2864175491657d238e2664251df13b63adb8d050924fd1bfcdb278b866f7/diff/\"),mdx(\"p\",null,\"etc sbin usr var\"),mdx(\"p\",null,\"To view the mounts which exist when you use the\\xA0overlay\\xA0storage driver with Docker, use the\\xA0mountcommand. The output below is truncated for readability.\"),mdx(\"p\",null,\"$ mount | grep overlay\"),mdx(\"p\",null,\"overlay on /var/lib/docker/overlay2/9186877cdf386d0a3b016149cf30c208f326dca307529e646afce5b3f83f5304/merged\"),mdx(\"p\",null,\"type overlay (rw,relatime,\"),mdx(\"p\",null,\"lowerdir=l/DJA75GUWHWG7EWICFYX54FIOVT:l/B3WWEFKBG3PLLV737KZFIASSW7:l/JEYMODZYFCZFYSDABYXD5MF6YO:l/UL2MW33MSE3Q5VYIKBRN4ZAGQP:l/NFYKDW6APBCCUCTOUSYDH4DXAT:l/6Y5IM2XC7TSNIJZZFLJCS6I4I4,\"),mdx(\"p\",null,\"upperdir=9186877cdf386d0a3b016149cf30c208f326dca307529e646afce5b3f83f5304/diff,\"),mdx(\"p\",null,\"workdir=9186877cdf386d0a3b016149cf30c208f326dca307529e646afce5b3f83f5304/work)\"),mdx(\"p\",null,\"The\\xA0rw\\xA0on the second line shows that the\\xA0overlay\\xA0mount is read-write.\"),mdx(\"h4\",null,\"How the\\xA0overlay\\xA0driver works\"),mdx(\"p\",null,\"This content applies to the\\xA0overlay\\xA0driver only. Docker recommends using the\\xA0overlay2\\xA0driver, which works differently. See\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/overlayfs-driver/#how-the-overlay2-driver-works\"}),\"How the overlay2 driver works\"),\"\\xA0for\\xA0overlay2.\"),mdx(\"p\",null,\"OverlayFS layers two directories on a single Linux host and presents them as a single directory. These directories are called\\xA0layers\\xA0and the unification process is referred to a a\\xA0union mount. OverlayFS refers to the lower directory as\\xA0lowerdir\\xA0and the upper directory a\\xA0upperdir. The unified view is exposed through its own directory called\\xA0merged.\"),mdx(\"p\",null,\"The diagram below shows how a Docker image and a Docker container are layered. The image layer is the\\xA0lowerdir\\xA0and the container layer is the\\xA0upperdir. The unified view is exposed through a directory called\\xA0merged\\xA0which is effectively the containers mount point. The diagram shows how Docker constructs map to OverlayFS constructs.\"),mdx(\"p\",null,\"Where the image layer and the container layer contain the same files, the container layer \\\"wins\\\" and obscures the existence of the same files in the image layer.\"),mdx(\"p\",null,\"The\\xA0overlay\\xA0driver only works with two layers. This means that multi-layered images cannot be implemented as multiple OverlayFS layers. Instead, each image layer is implemented as its own directory under\\xA0/var/lib/docker/overlay. Hard links are then used as a space-efficient way to reference data shared with lower layers. As of Docker 1.10, image layer IDs no longer correspond to directory names in\\xA0/var/lib/docker/.\"),mdx(\"p\",null,\"To create a container, the\\xA0overlay\\xA0driver combines the directory representing the image's top layer plus a new directory for the container. The image's top layer is the\\xA0lowerdir\\xA0in the overlay and is read-only. The new directory for the container is the\\xA0upperdir\\xA0and is writable.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Image and container layers on-disk\")),mdx(\"p\",null,\"The following\\xA0docker pull\\xA0command shows a Docker host downloading a Docker image comprising five layers.\"),mdx(\"p\",null,\"$ docker pull ubuntu\"),mdx(\"p\",null,\"Using default tag: latest\"),mdx(\"p\",null,\"latest: Pulling from library/ubuntu\"),mdx(\"p\",null,\"5ba4f30e5bea: Pull complete\"),mdx(\"p\",null,\"9d7d19c9dc56: Pull complete\"),mdx(\"p\",null,\"ac6ad7efd0f9: Pull complete\"),mdx(\"p\",null,\"e7491a747824: Pull complete\"),mdx(\"p\",null,\"a3ed95caeb02: Pull complete\"),mdx(\"p\",null,\"Digest: sha256:46fb5d001b88ad904c5c732b086b596b92cfb4a4840a3abd0e35dbb6870585e4\"),mdx(\"p\",null,\"Status: Downloaded newer image for ubuntu:latest\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"THE IMAGE LAYERS\")),mdx(\"p\",null,\"Each image layer has its own directory within\\xA0/var/lib/docker/overlay/, which contains its contents, as shown below. The image layer IDs do not correspond to the directory IDs.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Warning\"),\": Do not directly manipulate any files or directories within\\xA0/var/lib/docker/. These files and directories are managed by Docker.\"),mdx(\"p\",null,\"$ ls -l /var/lib/docker/overlay/\"),mdx(\"p\",null,\"total 20\"),mdx(\"p\",null,\"drwx------ 3 root root 4096 Jun 20 16:11 38f3ed2eac129654acef11c32670b534670c3a06e483fce313d72e3e0a15baa8\"),mdx(\"p\",null,\"drwx------ 3 root root 4096 Jun 20 16:11 55f1e14c361b90570df46371b20ce6d480c434981cbda5fd68c6ff61aa0a5358\"),mdx(\"p\",null,\"drwx------ 3 root root 4096 Jun 20 16:11 824c8a961a4f5e8fe4f4243dab57c5be798e7fd195f6d88ab06aea92ba931654\"),mdx(\"p\",null,\"drwx------ 3 root root 4096 Jun 20 16:11 ad0fe55125ebf599da124da175174a4b8c1878afe6907bf7c78570341f308461\"),mdx(\"p\",null,\"drwx------ 3 root root 4096 Jun 20 16:11 edab9b5e5bf73f2997524eebeac1de4cf9c8b904fa8ad3ec43b3504196aa3801\"),mdx(\"p\",null,\"The image layer directories contain the files unique to that layer as well as hard links to the data that is shared with lower layers. This allows for efficient use of disk space.\"),mdx(\"p\",null,\"$ ls -i /var/lib/docker/overlay/38f3ed2eac129654acef11c32670b534670c3a06e483fce313d72e3e0a15baa8/root/bin/ls\"),mdx(\"p\",null,\"19793696 /var/lib/docker/overlay/38f3ed2eac129654acef11c32670b534670c3a06e483fce313d72e3e0a15baa8/root/bin/ls\"),mdx(\"p\",null,\"$ ls -i /var/lib/docker/overlay/55f1e14c361b90570df46371b20ce6d480c434981cbda5fd68c6ff61aa0a5358/root/bin/ls\"),mdx(\"p\",null,\"19793696 /var/lib/docker/overlay/55f1e14c361b90570df46371b20ce6d480c434981cbda5fd68c6ff61aa0a5358/root/bin/ls\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"THE CONTAINER LAYER\")),mdx(\"p\",null,\"Containers also exist on-disk in the Docker host's filesystem under\\xA0/var/lib/docker/overlay/. If you list a running container's subdirectory using the\\xA0ls -l\\xA0command, three directories and one file exist:\"),mdx(\"p\",null,\"$ ls -l /var/lib/docker/overlay/\",mdx(\"inlineCode\",{parentName:\"p\"},\"<directory-of-running-container>\")),mdx(\"p\",null,\"total 16\"),mdx(\"p\",null,\"-rw-r--r-- 1 root root 64 Jun 20 16:39 lower-id\"),mdx(\"p\",null,\"drwxr-xr-x 1 root root 4096 Jun 20 16:39 merged\"),mdx(\"p\",null,\"drwxr-xr-x 4 root root 4096 Jun 20 16:39 upper\"),mdx(\"p\",null,\"drwx------ 3 root root 4096 Jun 20 16:39 work\"),mdx(\"p\",null,\"The\\xA0lower-id\\xA0file contains the ID of the top layer of the image the container is based on, which is the OverlayFS\\xA0lowerdir.\"),mdx(\"p\",null,\"$ cat /var/lib/docker/overlay/ec444863a55a9f1ca2df72223d459c5d940a721b2288ff86a3f27be28b53be6c/lower-id\"),mdx(\"p\",null,\"55f1e14c361b90570df46371b20ce6d480c434981cbda5fd68c6ff61aa0a5358\"),mdx(\"p\",null,\"The\\xA0upper\\xA0directory contains the contents of the container's read-write layer, which corresponds to the OverlayFS\\xA0upperdir.\"),mdx(\"p\",null,\"The\\xA0merged\\xA0directory is the union mount of the\\xA0lowerdir\\xA0and\\xA0upperdir, which comprises the view of the filesystem from within the running container.\"),mdx(\"p\",null,\"The\\xA0work\\xA0directory is internal to OverlayFS.\"),mdx(\"p\",null,\"To view the mounts which exist when you use the\\xA0overlay\\xA0storage driver with Docker, use the\\xA0mountcommand. The output below is truncated for readability.\"),mdx(\"p\",null,\"$ mount | grep overlay\"),mdx(\"p\",null,\"overlay on /var/lib/docker/overlay/ec444863a55a.../merged\"),mdx(\"p\",null,\"type overlay (rw,relatime,lowerdir=/var/lib/docker/overlay/55f1e14c361b.../root,\"),mdx(\"p\",null,\"upperdir=/var/lib/docker/overlay/ec444863a55a.../upper,\"),mdx(\"p\",null,\"workdir=/var/lib/docker/overlay/ec444863a55a.../work)\"),mdx(\"p\",null,\"The\\xA0rw\\xA0on the second line shows that the\\xA0overlay\\xA0mount is read-write.\"),mdx(\"h4\",null,\"How container reads and writes work with\\xA0overlayor\\xA0overlay2\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Reading files\")),mdx(\"p\",null,\"Consider three scenarios where a container opens a file for read access with overlay.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"The file does not exist in the container layer\"),\": If a container opens a file for read access and the file does not already exist in the container (upperdir) it is read from the image (lowerdir). This incurs very little performance overhead.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"The file only exists in the container layer\"),\": If a container opens a file for read access and the file exists in the container (upperdir) and not in the image (lowerdir), it is read directly from the container.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"The file exists in both the container layer and the image layer\"),\": If a container opens a file for read access and the file exists in the image layer and the container layer, the file's version in the container layer is read. Files in the container layer (upperdir) obscure files with the same name in the image layer (lowerdir).\")),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Modifying files or directories\")),mdx(\"p\",null,\"Consider some scenarios where files in a container are modified.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Writing to a file for the first time\"),\": The first time a container writes to an existing file, that file does not exist in the container (upperdir). The\\xA0overlay/overlay2\\xA0driver performs a\\xA0copy_upoperation to copy the file from the image (lowerdir) to the container (upperdir). The container then writes the changes to the new copy of the file in the container layer.\")),mdx(\"p\",null,\"However, OverlayFS works at the file level rather than the block level. This means that all OverlayFS copy_up operations copy the entire file, even if the\\\\ file is very large and only a small part of it is being modified. This can have a noticeable impact on container write performance. However, two things are worth noting:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},\"The copy_up operation only occurs the first time a given file is written to. Subsequent writes to the same file operate against the copy of the file already copied up to the container.\"),mdx(\"li\",{parentName:\"ul\"},\"OverlayFS only works with two layers. This means that performance should be better than AUFS, which can suffer noticeable latencies when searching for files in images with many layers. This advantage applies to both\\xA0overlay\\xA0and\\xA0overlay2\\xA0drivers.\\xA0overlayfs2\\xA0is slightly less performant than\\xA0overlayfs\\xA0on initial read, because it must look through more layers, but it caches the results so this is only a small penalty.\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},mdx(\"strong\",{parentName:\"p\"},\"Deleting files and directories\"),\":\"),mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},\"When a\\xA0file\\xA0is deleted within a container, a\\xA0whiteout\\xA0file is created in the container (upperdir). The version of the file in the image layer (lowerdir) is not deleted (because the\\xA0lowerdir\\xA0is read-only). However, the whiteout file prevents it from being available to the container.\"),mdx(\"li\",{parentName:\"ul\"},\"When a\\xA0directory\\xA0is deleted within a container, an\\xA0opaque directory\\xA0is created within the container (upperdir). This works in the same way as a whiteout file and effectively prevents the directory from being accessed, even though it still exists in the image (lowerdir).\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},mdx(\"strong\",{parentName:\"p\"},\"Renaming directories\"),\": Calling\\xA0rename(2)\\xA0for a directory is allowed only when both the source and the destination path are on the top layer. Otherwise, it returns\\xA0EXDEV\\xA0error (\\\"cross-device link not permitted\\\"). Your application needs to be designed to handle\\xA0EXDEV\\xA0and fall back to a \\\"copy and unlink\\\" strategy.\"))),mdx(\"h4\",null,\"OverlayFS and Docker Performance\"),mdx(\"p\",null,\"Both\\xA0overlay2\\xA0and\\xA0overlay\\xA0drivers are more performant than\\xA0aufs\\xA0and\\xA0devicemapper. In certain circumstances,\\xA0overlay2\\xA0may perform better than\\xA0btrfs\\xA0as well. However, be aware of the following details.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Page Caching\"),\". OverlayFS supports page cache sharing. Multiple containers accessing the same file share a single page cache entry for that file. This makes the\\xA0overlay\\xA0and\\xA0overlay2\\xA0drivers efficient with memory and a good option for high-density use cases such as PaaS.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"copy_up\"),\". As with AUFS, OverlayFS performs copy-up operations whenever a container writes to a file for the first time. This can add latency into the write operation, especially for large files. However, once the file has been copied up, all subsequent writes to that file occur in the upper layer, without the need for further copy-up operations.\")),mdx(\"p\",null,\"The OverlayFS\\xA0copy_up\\xA0operation is faster than the same operation with AUFS, because AUFS supports more layers than OverlayFS and it is possible to incur far larger latencies if searching through many AUFS layers.\\xA0overlay2\\xA0supports multiple layers as well, but mitigates any performance hit with caching.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Inode limits\"),\". Use of the\\xA0overlay\\xA0storage driver can cause excessive inode consumption. This is especially true in the presence of a large number of images and containers on the Docker host. The only way to increase the number of inodes available to a filesystem is to reformat it. To avoid running into this issue, it is highly recommended that you use\\xA0overlay2\\xA0if at all possible.\")),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Performance best practices\")),mdx(\"p\",null,\"The following generic performance best practices also apply to OverlayFS.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Use fast storage\"),\": Solid-state drives (SSDs) provide faster reads and writes than spinning disks.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Use volumes for write-heavy workloads\"),\": Volumes provide the best and most predictable performance for write-heavy workloads. This is because they bypass the storage driver and do not incur any of the potential overheads introduced by thin provisioning and copy-on-write. Volumes have other benefits, such as allowing you to share data among containers and persisting even when no running container is using them.\")),mdx(\"h4\",null,\"Limitations on OverlayFS compatibility\"),mdx(\"p\",null,\"To summarize the OverlayFS's aspect which is incompatible with other filesystems:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"open(2)\"),\": OverlayFS only implements a subset of the POSIX standards. This can result in certain OverlayFS operations breaking POSIX standards. One such operation is the\\xA0copy-up\\xA0operation. Suppose that your application calls\\xA0fd1=open(\\\"foo\\\", O_RDONLY)\\xA0and then\\xA0fd2=open(\\\"foo\\\", O_RDWR). In this case, your application expects\\xA0fd1\\xA0and\\xA0fd2\\xA0to refer to the same file. However, due to a copy-up operation that occurs after the second calling to\\xA0open(2), the descriptors refer to different files. The\\xA0fd1\\xA0continues to reference the file in the image (lowerdir) and the\\xA0fd2\\xA0references the file in the container (upperdir). A workaround for this is to\\xA0touch\\xA0the files which causes the copy-up operation to happen. All subsequent\\xA0open(2)operations regardless of read-only or read-write access mode reference the file in the container (upperdir).\")),mdx(\"p\",null,\"yum\\xA0is known to be affected unless the\\xA0yum-plugin-ovl\\xA0package is installed. If the\\xA0yum-plugin-ovl\\xA0package is not available in your distribution such as RHEL/CentOS prior to 6.8 or 7.2, you may need to run\\xA0touch /var/lib/rpm/*\\xA0before running\\xA0yum install. This package implements the\\xA0touch\\xA0workaround referenced above for\\xA0yum.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"rename(2)\"),\": OverlayFS does not fully support the\\xA0rename(2)\\xA0system call. Your application needs to detect its failure and fall back to a \\\"copy and unlink\\\" strategy.\")),mdx(\"h3\",null,\"Use the ZFS storage driver\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA09 minutes\")),mdx(\"p\",null,\"ZFS is a next generation filesystem that supports many advanced storage technologies such as volume management, snapshots, checksumming, compression and deduplication, replication and more.\"),mdx(\"p\",null,\"It was created by Sun Microsystems (now Oracle Corporation) and is open sourced under the CDDL license. Due to licensing incompatibilities between the CDDL and GPL, ZFS cannot be shipped as part of the mainline Linux kernel. However, the ZFS On Linux (ZoL) project provides an out-of-tree kernel module and userspace tools which can be installed separately.\"),mdx(\"p\",null,\"The ZFS on Linux (ZoL) port is healthy and maturing. However, at this point in time it is not recommended to use the\\xA0zfs\\xA0Docker storage driver for production use unless you have substantial experience with ZFS on Linux.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": There is also a FUSE implementation of ZFS on the Linux platform. This is not recommended. The native ZFS driver (ZoL) is more tested, more performant, and is more widely used. The remainder of this document refers to the native ZoL port.\"),mdx(\"h4\",null,\"Prerequisites\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"ZFS requires one or more dedicated block devices, preferrably solid-state drives (SSDs).\"),mdx(\"li\",{parentName:\"ul\"},\"ZFS is only supported on Docker CE with Ubuntu 14.04 or higher, with the\\xA0zfs\\xA0package (16.04 and higher) or\\xA0zfs-native\\xA0and\\xA0ubuntu-zfs\\xA0packages (14.04) installed.\",mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},\"For Ubuntu 14.04, you need to enable a supplemental package repositoryppa:zfs-native/stable\\xA0before you can install the package. See\\xA0\",mdx(\"inlineCode\",{parentName:\"li\"},\"<https://launchpad.net/~zfs-native/+archive/ubuntu/stable>\"),\"\\xA0for instructions.\"))),mdx(\"li\",{parentName:\"ul\"},\"ZFS is not supported on Docker EE or CS-Engine, or any other Linux platforms.\"),mdx(\"li\",{parentName:\"ul\"},\"The\\xA0/var/lib/docker/\\xA0directory must be mounted on a ZFS-formatted filesystem.\"),mdx(\"li\",{parentName:\"ul\"},\"Changing the storage driver makes any containers you have already created inaccessible on the local system. Use\\xA0docker save\\xA0to save containers, and push existing images to Docker Hub or a private repository, so that you not need to re-create them later.\")),mdx(\"h4\",null,\"Configure Docker with the\\xA0zfs\\xA0storage driver\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Stop Docker.\"),mdx(\"li\",{parentName:\"ol\"},\"Copy the contents of\\xA0/var/lib/docker/\\xA0to\\xA0/var/lib/docker.bk\\xA0and remove the contents of\\xA0/var/lib/docker/.\"),mdx(\"li\",{parentName:\"ol\"},\"$ sudo cp -au /var/lib/docker /var/lib/docker.bk\"),mdx(\"li\",{parentName:\"ol\"},\"$ sudo rm -rf /var/lib/docker/*\"),mdx(\"li\",{parentName:\"ol\"},\"Create a new\\xA0zpool\\xA0on your dedicated block device or devices, and mount it into\\xA0/var/lib/docker/. Be sure you have specified the correct devices, because this is a destructive operation. This example adds two devices to the pool.\"),mdx(\"li\",{parentName:\"ol\"},\"$ sudo zpool create -f zpool-docker -m /var/lib/docker /dev/xvdf /dev/xvdg\")),mdx(\"p\",null,\"The command creates the\\xA0zpool\\xA0and names it\\xA0zpool-docker. The name is for display purposes only, and you can use a different name. Check that the pool was created and mounted correctly using\\xA0zfs list.\"),mdx(\"p\",null,\"$ sudo zfs list\"),mdx(\"p\",null,\"NAME USED AVAIL REFER MOUNTPOINT\"),mdx(\"p\",null,\"zpool-docker 55K 96.4G 19K /var/lib/docker\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Configure Docker to use\\xA0zfs. Edit\\xA0/etc/docker/daemon.json\\xA0and set the\\xA0storage-driver\\xA0to\\xA0zfs. If the file was empty before, it should now look like this:\"),mdx(\"li\",{parentName:\"ol\"},\"{\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"storage-driver\\\": \\\"zfs\\\"\"),mdx(\"li\",{parentName:\"ol\"},\"}\")),mdx(\"p\",null,\"Save and close the file.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Start Docker. Use\\xA0docker info\\xA0to verify that the storage driver is\\xA0zfs.\"),mdx(\"li\",{parentName:\"ol\"},\"$ sudo docker info\"),mdx(\"li\",{parentName:\"ol\"},\"Containers: 0\"),mdx(\"li\",{parentName:\"ol\"},\"Running: 0\"),mdx(\"li\",{parentName:\"ol\"},\"Paused: 0\"),mdx(\"li\",{parentName:\"ol\"},\"Stopped: 0\"),mdx(\"li\",{parentName:\"ol\"},\"Images: 0\"),mdx(\"li\",{parentName:\"ol\"},\"Server Version: 17.03.1-ce\"),mdx(\"li\",{parentName:\"ol\"},\"Storage Driver: zfs\"),mdx(\"li\",{parentName:\"ol\"},\"Zpool: zpool-docker\"),mdx(\"li\",{parentName:\"ol\"},\"Zpool Health: ONLINE\"),mdx(\"li\",{parentName:\"ol\"},\"Parent Dataset: zpool-docker\"),mdx(\"li\",{parentName:\"ol\"},\"Space Used By Parent: 249856\"),mdx(\"li\",{parentName:\"ol\"},\"Space Available: 103498395648\"),mdx(\"li\",{parentName:\"ol\"},\"Parent Quota: no\"),mdx(\"li\",{parentName:\"ol\"},\"Compression: off\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<output truncated>\"))),mdx(\"h4\",null,\"Manage\\xA0zfs\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Increase capacity on a running device\")),mdx(\"p\",null,\"To increase the size of the\\xA0zpool, you need to add a dedicated block device to the Docker host, and then add it to the\\xA0zpool\\xA0using the\\xA0zpool add\\xA0command:\"),mdx(\"p\",null,\"$ sudo zpool add zpool-docker /dev/xvdh\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Limit a container's writable storage quota\")),mdx(\"p\",null,\"If you want to implement a quota on a per-image/dataset basis, you can set the\\xA0size\\xA0storage option to limit the amount of space a single container can use for its writable layer.\"),mdx(\"p\",null,\"Edit\\xA0/etc/docker/daemon.json\\xA0and add the following:\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"storage-driver\\\": \\\"zfs\\\",\"),mdx(\"p\",null,\"\\\"storage-opts\\\": \",\"[\\\"size=256M\\\"]\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"See all storage options for each storage driver:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/dockerd/#storage-driver-options\"}),\"Stable\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/edge/engine/reference/commandline/dockerd/#storage-driver-options\"}),\"Edge\"))),mdx(\"p\",null,\"Save and close the file, and restart Docker.\"),mdx(\"h4\",null,\"How the\\xA0zfs\\xA0storage driver works\"),mdx(\"p\",null,\"ZFS uses the following objects:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"filesystems\"),\": thinly provisioned, with space allocated from the\\xA0zpool\\xA0on demand.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"snapshots\"),\": read-only space-efficient point-in-time copies of filesystems.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"clones\"),\": Read-write copies of snapshots. Used for storing the differences from the previous layer.\")),mdx(\"p\",null,\"The process of creating a clone:\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"A read-only snapshot is created from the filesystem.\"),mdx(\"li\",{parentName:\"ol\"},\"A writable clone is created from the snapshot. This contains any differences from the parent layer.\")),mdx(\"p\",null,\"Filesystems, snapshots, and clones all allocate space from the underlying\\xA0zpool.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Image and container layers on-disk\")),mdx(\"p\",null,\"Each running container's unified filesystem is mounted on a mount point in/var/lib/docker/zfs/graph/. Continue reading for an explanation of how the unified filesystem is composed.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Image layering and sharing\")),mdx(\"p\",null,\"The base layer of an image is a ZFS filesystem. Each child layer is a ZFS clone based on a ZFS snapshot of the layer below it. A container is a ZFS clone based on a ZFS Snapshot of the top layer of the image it's created from.\"),mdx(\"p\",null,\"The diagram below shows how this is put together with a running container based on a two-layer image.\"),mdx(\"p\",null,\"When you start a container, the following steps happen in order:\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"The base layer of the image exists on the Docker host as a ZFS filesystem.\"),mdx(\"li\",{parentName:\"ol\"},\"Additional image layers are clones of the dataset hosting the image layer directly below it.\")),mdx(\"p\",null,\"In the diagram, \\\"Layer 1\\\" is added by taking a ZFS snapshot of the base layer and then creating a clone from that snapshot. The clone is writable and consumes space on-demand from the zpool. The snapshot is read-only, maintaining the base layer as an immutable object.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"When the container is launched, a writable layer is added above the image.\")),mdx(\"p\",null,\"In the diagram, the container's read-write layer is created by making a snapshot of the top layer of the image (Layer 1) and creating a clone from that snapshot.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"As the container modifies the contents of its writable layer, space is allocated for the blocks that are changed. By default, these blocks are 128k.\")),mdx(\"h4\",null,\"How container reads and writes work with\\xA0zfs\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Reading files\")),mdx(\"p\",null,\"Each container's writable layer is a ZFS clone which shares all its data with the dataset it was created from (the snapshots of its parent layers). Read operations are fasst, even if the data being read is from a deep layer. This diagram illustrates how block sharing works:\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Writing files\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Writing a new file\"),\": space is allocated on demand from the underlying\\xA0zpool\\xA0and the blocks are written directly into the container's writable layer.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Modifying an existing file\"),\": space is allocated only for the changed blocks, and those blocks are written into the container's writable layer using a copy-on-write (CoW) strategy. This minimizes the size of the layer and increases write performance.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Deleting a file or directory\"),\":\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"When you delete a file or directory that exists in a lower layer, the ZFS driver masks the existence of the file or directory in the container's writable layer, even though the file or directory still exists in the lower read-only layers.\"),mdx(\"li\",{parentName:\"ul\"},\"If you create and then delete a file or directory within the container's writable layer, the blocks are reclaimed by the\\xA0zpool.\")),mdx(\"h4\",null,\"ZFS and Docker performance\"),mdx(\"p\",null,\"There are several factors that influence the performance of Docker using the\\xA0zfs\\xA0storage driver.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Memory\"),\": Memory has a major impact on ZFS performance. ZFS was originally designed for large enterprise-grade servers with a large amount of memory.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"ZFS Features\"),\": ZFS includes a de-duplication feature. Using this feature may save disk space, but uses a large amount of memory. It is recommended that you disable this feature for the\\xA0zpoolyou are using with Docker, unless you are using SAN, NAS, or other hardware RAID technologies.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"ZFS Caching\"),\": ZFS caches disk blocks in a memory structure called the adaptive replacement cache (ARC). The\\xA0Single Copy ARC\\xA0feature of ZFS allows a single cached copy of a block to be shared by multiple clones of a With this feature, multiple running containers can share a single copy of a cached block. This feature makes ZFS a good option for PaaS and other high-density use cases.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Fragmentation\"),\": Fragmentation is a natural byproduct of copy-on-write filesystems like ZFS. ZFS mitigates this by using a small block size of 128k. The ZFS intent log (ZIL) and the coalescing of writes (delayed writes) also help to reduce fragmentation. You can monitor fragmentation usingzfs status. However, there is no way to defragment ZFS without reformatting and restoring the filesystem.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Use the native ZFS driver for Linux\"),\": The ZFS FUSE implementation is not recommended, due to poor performance.\")),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Performance best practices\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Use fast storage\"),\": Solid-state drives (SSDs) provide faster reads and writes than spinning disks.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Use volumes for write-heavy workloads\"),\": Volumes provide the best and most predictable performance for write-heavy workloads. This is because they bypass the storage driver and do not incur any of the potential overheads introduced by thin provisioning and copy-on-write. Volumes have other benefits, such as allowing you to share data among containers and persisting even when no running container is using them.\")),mdx(\"h3\",null,\"Use the VFS storage driver\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA03 minutes\")),mdx(\"p\",null,\"The VFS storage driver is not a union filesystem; instead, each layer is a directory on disk, and there is no copy-on-write support. To create a new layer, a \\\"deep copy\\\" is done of the previous layer. This leads to lower performance and more space used on disk than other storage drivers. However, it is robust, stable, and works in every environment. It can also be used as a mechanism to verify other storage back-ends against, in a testing environment.\"),mdx(\"p\",null,\"Docker 17.12 and higher include support for quotas when using the VFS driver.\"),mdx(\"h4\",null,\"Configure Docker with the\\xA0vfs\\xA0storage driver\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Stop Docker.\"),mdx(\"li\",{parentName:\"ol\"},\"$ sudo systemctl stop docker\"),mdx(\"li\",{parentName:\"ol\"},\"Edit\\xA0/etc/docker/daemon.json. If it does not yet exist, create it. Assuming that the file was empty, add the following contents.\"),mdx(\"li\",{parentName:\"ol\"},\"{\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"storage-driver\\\": \\\"vfs\\\"\"),mdx(\"li\",{parentName:\"ol\"},\"}\")),mdx(\"p\",null,\"If you want to set a quota to control the maximum size the VFS storage driver can use, set the\\xA0size\\xA0option on the\\xA0storage-drivers\\xA0key. Quotas are only supported in Docker 17.12 CE and higher.\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"storage-opts\\\": \",\"[\\\"size=256M\\\"]\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"Docker does not start if the\\xA0daemon.json\\xA0file contains badly-formed JSON.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Start Docker.\"),mdx(\"li\",{parentName:\"ol\"},\"$ sudo systemctl start docker\"),mdx(\"li\",{parentName:\"ol\"},\"Verify that the daemon is using the\\xA0vfs\\xA0storage driver. Use the\\xA0docker info\\xA0command and look for\\xA0Storage Driver\\xA0and\\xA0Backing filesystem.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker info\"),mdx(\"li\",{parentName:\"ol\"},\"Storage Driver: vfs\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<output truncated>\"))),mdx(\"p\",null,\"Docker is now using the\\xA0vfs\\xA0storage driver. Docker has automatically created the\\xA0/var/lib/docker/vfs/\\xA0directory, which contains all the layers used by running containers.\"),mdx(\"h4\",null,\"How the\\xA0vfs\\xA0storage driver works\"),mdx(\"p\",null,\"VFS is not a union filesystem. Instead, each image layer and the writable container layer are represented on the Docker host as subdirectories within\\xA0/var/lib/docker/. The union mount provides the unified view of all layers. The directory names do not directly correspond to the IDs of the layers themselves.\"),mdx(\"p\",null,\"VFS does not support copy-on-write (COW), so each time a new layer is created, it is a deep copy of its parent layer. These layers are all located under\\xA0/var/lib/docker/dir/.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Example: Image and container on-disk constructs\")),mdx(\"p\",null,\"The following\\xA0docker pull\\xA0command shows a Docker host downloading a Docker image comprising five layers.\"),mdx(\"p\",null,\"$ docker pull ubuntu\"),mdx(\"p\",null,\"Using default tag: latest\"),mdx(\"p\",null,\"latest: Pulling from library/ubuntu\"),mdx(\"p\",null,\"e0a742c2abfd: Pull complete\"),mdx(\"p\",null,\"486cb8339a27: Pull complete\"),mdx(\"p\",null,\"dc6f0d824617: Pull complete\"),mdx(\"p\",null,\"4f7a5649a30e: Pull complete\"),mdx(\"p\",null,\"672363445ad2: Pull complete\"),mdx(\"p\",null,\"Digest: sha256:84c334414e2bfdcae99509a6add166bbb4fa4041dc3fa6af08046a66fed3005f\"),mdx(\"p\",null,\"Status: Downloaded newer image for ubuntu:latest\"),mdx(\"p\",null,\"After pulling, each of these layers is represented as a subdirectory of\\xA0/var/lib/docker/vfs/dir/. The directory names do not correlate with the image layer IDs shown in the\\xA0docker pull\\xA0command. To see the size taken up on disk by each layer, you can use the\\xA0du -sh\\xA0command, which gives the size as a human-readable value.\"),mdx(\"p\",null,\"$ ls -l /var/lib/docker/vfs/dir/\"),mdx(\"p\",null,\"total 0\"),mdx(\"p\",null,\"drwxr-xr-x. 2 root root 19 Aug 2 18:19 3262dfbe53dac3e1ab7dcc8ad5d8c4d586a11d2ac3c4234892e34bff7f6b821e\"),mdx(\"p\",null,\"drwxr-xr-x. 21 root root 224 Aug 2 18:23 6af21814449345f55d88c403e66564faad965d6afa84b294ae6e740c9ded2561\"),mdx(\"p\",null,\"drwxr-xr-x. 21 root root 224 Aug 2 18:23 6d3be4585ba32f9f5cbff0110e8d07aea5f5b9fbb1439677c27e7dfee263171c\"),mdx(\"p\",null,\"drwxr-xr-x. 21 root root 224 Aug 2 18:23 9ecd2d88ca177413ab89f987e1507325285a7418fc76d0dcb4bc021447ba2bab\"),mdx(\"p\",null,\"drwxr-xr-x. 21 root root 224 Aug 2 18:23 a292ac6341a65bf3a5da7b7c251e19de1294bd2ec32828de621d41c7ad31f895\"),mdx(\"p\",null,\"drwxr-xr-x. 21 root root 224 Aug 2 18:23 e92be7a4a4e3ccbb7dd87695bca1a0ea373d4f673f455491b1342b33ed91446b\"),mdx(\"p\",null,\"$ du -sh /var/lib/docker/vfs/dir/*\"),mdx(\"p\",null,\"4.0K /var/lib/docker/vfs/dir/3262dfbe53dac3e1ab7dcc8ad5d8c4d586a11d2ac3c4234892e34bff7f6b821e\"),mdx(\"p\",null,\"125M /var/lib/docker/vfs/dir/6af21814449345f55d88c403e66564faad965d6afa84b294ae6e740c9ded2561\"),mdx(\"p\",null,\"104M /var/lib/docker/vfs/dir/6d3be4585ba32f9f5cbff0110e8d07aea5f5b9fbb1439677c27e7dfee263171c\"),mdx(\"p\",null,\"125M /var/lib/docker/vfs/dir/9ecd2d88ca177413ab89f987e1507325285a7418fc76d0dcb4bc021447ba2bab\"),mdx(\"p\",null,\"104M /var/lib/docker/vfs/dir/a292ac6341a65bf3a5da7b7c251e19de1294bd2ec32828de621d41c7ad31f895\"),mdx(\"p\",null,\"104M /var/lib/docker/vfs/dir/e92be7a4a4e3ccbb7dd87695bca1a0ea373d4f673f455491b1342b33ed91446b\"),mdx(\"p\",null,\"The above output shows that three layers each take 104M and two take 125M. These directories have only small differences from each other, but take up nearly the same amount of room on disk. This is one of the disadvantages of using the\\xA0vfs\\xA0storage driver.\"),mdx(\"h4\",null,\"Related information\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/volumes/\"}),\"Volumes\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/storage/storagedriver/imagesandcontainers/\"}),\"Understand images, containers, and storage drivers\"))),mdx(\"h4\",null,\"Run Your App in Production\"),mdx(\"h2\",null,\"Configure All Objects\"),mdx(\"h3\",null,\"Docker object labels\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA03 minutes\")),mdx(\"p\",null,\"Labels are a mechanism for applying metadata to Docker objects, including:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Images\"),mdx(\"li\",{parentName:\"ul\"},\"Containers\"),mdx(\"li\",{parentName:\"ul\"},\"Local daemons\"),mdx(\"li\",{parentName:\"ul\"},\"Volumes\"),mdx(\"li\",{parentName:\"ul\"},\"Networks\"),mdx(\"li\",{parentName:\"ul\"},\"Swarm nodes\"),mdx(\"li\",{parentName:\"ul\"},\"Swarm services\")),mdx(\"p\",null,\"You can use labels to organize your images, record licensing information, annotate relationships between containers, volumes, and networks, or in any way that makes sense for your business or application.\"),mdx(\"h4\",null,\"Label keys and values\"),mdx(\"p\",null,\"A label is a key-value pair, stored as a string. You can specify multiple labels for an object, but each key-value pair must be unique within an object. If the same key is given multiple values, the most-recently-written value overwrites all previous values.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Key format recommendations\")),mdx(\"p\",null,\"A label\\xA0key\\xA0is the left-hand side of the key-value pair. Keys are alphanumeric strings which may contain periods (.) and hyphens (-). Most Docker users use images created by other organizations, and the following guidelines help to prevent inadvertent duplication of labels across objects, especially if you plan to use labels as a mechanism for automation.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Authors of third-party tools should prefix each label key with the reverse DNS notation of a domain they own, such as\\xA0com.example.some-label.\"),mdx(\"li\",{parentName:\"ul\"},\"Do not use a domain in your label key without the domain owner's permission.\"),mdx(\"li\",{parentName:\"ul\"},\"The\\xA0com.docker.\",mdx(\"em\",{parentName:\"li\"},\",\\xA0io.docker.\"),\", and\\xA0org.dockerproject.*\\xA0namespaces are reserved by Docker for internal use.\"),mdx(\"li\",{parentName:\"ul\"},\"Label keys should begin and end with a lower-case letter and should only contain lower-case alphanumeric characters, the period character (.), and the hyphen character (-). Consecutive periods or hyphens are not allowed.\"),mdx(\"li\",{parentName:\"ul\"},\"The period character (.) separates namespace \\\"fields\\\". Label keys without namespaces are reserved for CLI use, allowing users of the CLI to interactively label Docker objects using shorter typing-friendly strings.\")),mdx(\"p\",null,\"These guidelines are not currently enforced and additional guidelines may apply to specific use cases.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Value guidelines\")),mdx(\"p\",null,\"Label values can contain any data type that can be represented as a string, including (but not limited to) JSON, XML, CSV, or YAML. The only requirement is that the value be serialized to a string first, using a mechanism specific to the type of structure. For instance, to serialize JSON into a string, you might use the\\xA0JSON.stringify()\\xA0JavaScript method.\"),mdx(\"p\",null,\"Since Docker does not deserialize the value, you cannot treat a JSON or XML document as a nested structure when querying or filtering by label value unless you build this functionality into third-party tooling.\"),mdx(\"h4\",null,\"Manage labels on objects\"),mdx(\"p\",null,\"Each type of object with support for labels has mechanisms for adding and managing them and using them as they relate to that type of object. These links provide a good place to start learning about how you can use labels in your Docker deployments.\"),mdx(\"p\",null,\"Labels on images, containers, local daemons, volumes, and networks are static for the lifetime of the object. To change these labels you must recreate the object. Labels on swarm nodes and services can be updated dynamically.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Images and containers\",mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/builder/#label\"}),\"Adding labels to images\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/run/#set-metadata-on-container--l---label---label-file\"}),\"Overriding a container's labels at runtime\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/inspect/\"}),\"Inspecting labels on images or containers\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/images/#filtering\"}),\"Filtering images by label\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/ps/#filtering\"}),\"Filtering containers by label\")))),mdx(\"li\",{parentName:\"ul\"},\"Local Docker daemons\",mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/dockerd/\"}),\"Adding labels to a Docker daemon at runtime\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/info/\"}),\"Inspecting a Docker daemon's labels\")))),mdx(\"li\",{parentName:\"ul\"},\"Volumes\",mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/volume_create/\"}),\"Adding labels to volumes\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/volume_inspect/\"}),\"Inspecting a volume's labels\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/volume_ls/#filtering\"}),\"Filtering volumes by label\")))),mdx(\"li\",{parentName:\"ul\"},\"Networks\",mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/network_create/\"}),\"Adding labels to a network\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/network_inspect/\"}),\"Inspecting a network's labels\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/network_ls/#filtering\"}),\"Filtering networks by label\")))),mdx(\"li\",{parentName:\"ul\"},\"Swarm nodes\",mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/node_update/#add-label-metadata-to-a-node\"}),\"Adding or updating a swarm node's labels\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/node_inspect/\"}),\"Inspecting a swarm node's labels\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/node_ls/#filtering\"}),\"Filtering swarm nodes by label\")))),mdx(\"li\",{parentName:\"ul\"},\"Swarm services\",mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/service_create/#set-metadata-on-a-service-l-label\"}),\"Adding labels when creating a swarm service\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/service_update/\"}),\"Updating a swarm service's labels\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/service_inspect/\"}),\"Inspecting a swarm service's labels\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/service_ls/#filtering\"}),\"Filtering swarm services by label\"))))),mdx(\"h3\",null,\"Prune unused Docker objects\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA05 minutes\")),mdx(\"p\",null,\"Docker takes a conservative approach to cleaning up unused objects (often referred to as \\\"garbage collection\\\"), such as images, containers, volumes, and networks: these objects are generally not removed unless you explicitly ask Docker to do so. This can cause Docker to use extra disk space. For each type of object, Docker provides a\\xA0prune\\xA0command. In addition, you can use\\xA0docker system prune\\xA0to clean up multiple types of objects at once. This topic shows how to use these\\xA0prune\\xA0commands.\"),mdx(\"h4\",null,\"Prune images\"),mdx(\"p\",null,\"The\\xA0docker image prune\\xA0command allows you to clean up unused images. By default,\\xA0docker image prune\\xA0only cleans up\\xA0dangling\\xA0images. A dangling image is one that is not tagged and is not referenced by any container. To remove dangling images:\"),mdx(\"p\",null,\"$ docker image prune\"),mdx(\"p\",null,\"WARNING! This will remove all dangling images.\"),mdx(\"p\",null,\"Are you sure you want to continue? \",\"[y/N]\",\" y\"),mdx(\"p\",null,\"To remove all images which are not used by existing containers, use the\\xA0-a\\xA0flag:\"),mdx(\"p\",null,\"$ docker image prune -a\"),mdx(\"p\",null,\"WARNING! This will remove all images without at least one container associated to them.\"),mdx(\"p\",null,\"Are you sure you want to continue? \",\"[y/N]\",\" y\"),mdx(\"p\",null,\"By default, you are prompted to continue. To bypass the prompt, use the\\xA0-f\\xA0or\\xA0--force\\xA0flag.\"),mdx(\"p\",null,\"You can limit which images are pruned using filtering expressions with the\\xA0--filter\\xA0flag. For example, to only consider images created more than 24 hours ago:\"),mdx(\"p\",null,\"$ docker image prune -a --filter \\\"until=24h\\\"\"),mdx(\"p\",null,\"Other filtering expressions are available. See the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/image_prune/\"}),\"docker image prune\\xA0reference\"),\"\\xA0for more examples.\"),mdx(\"h4\",null,\"Prune containers\"),mdx(\"p\",null,\"When you stop a container, it is not automatically removed unless you started it with the\\xA0--rm\\xA0flag. To see all containers on the Docker host, including stopped containers, use\\xA0docker ps -a. You may be surprised how many containers exist, especially on a development system! A stopped container's writable layers still take up disk space. To clean this up, you can use the\\xA0docker container prunecommand.\"),mdx(\"p\",null,\"$ docker container prune\"),mdx(\"p\",null,\"WARNING! This will remove all stopped containers.\"),mdx(\"p\",null,\"Are you sure you want to continue? \",\"[y/N]\",\" y\"),mdx(\"p\",null,\"By default, you are prompted to continue. To bypass the prompt, use the\\xA0-f\\xA0or\\xA0--force\\xA0flag.\"),mdx(\"p\",null,\"By default, all stopped containers are removed. You can limit the scope using the\\xA0--filter\\xA0flag. For instance, the following command only removes stopped containers older than 24 hours:\"),mdx(\"p\",null,\"$ docker container prune --filter \\\"until=24h\\\"\"),mdx(\"p\",null,\"Other filtering expressions are available. See the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/container_prune/\"}),\"docker container prune\\xA0reference\"),\"\\xA0for more examples.\"),mdx(\"h4\",null,\"Prune volumes\"),mdx(\"p\",null,\"Volumes can be used by one or more containers, and take up space on the Docker host. Volumes are never removed automatically, because to do so could destroy data.\"),mdx(\"p\",null,\"$ docker volume prune\"),mdx(\"p\",null,\"WARNING! This will remove all volumes not used by at least one container.\"),mdx(\"p\",null,\"Are you sure you want to continue? \",\"[y/N]\",\" y\"),mdx(\"p\",null,\"By default, you are prompted to continue. To bypass the prompt, use the\\xA0-f\\xA0or\\xA0--force\\xA0flag.\"),mdx(\"p\",null,\"By default, all unused volumes are removed. You can limit the scope using the\\xA0--filter\\xA0flag. For instance, the following command only removes volumes which are not labelled with the\\xA0keep\\xA0label:\"),mdx(\"p\",null,\"$ docker volume prune --filter \\\"label!=keep\\\"\"),mdx(\"p\",null,\"Other filtering expressions are available. See the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/volume_prune/\"}),\"docker volume prune\\xA0reference\"),\"\\xA0for more examples.\"),mdx(\"h4\",null,\"Prune networks\"),mdx(\"p\",null,\"Docker networks don't take up much disk space, but they do create\\xA0iptables\\xA0rules, bridge network devices, and routing table entries. To clean these things up, you can use\\xA0docker network prune\\xA0to clean up networks which aren't used by any containers.\"),mdx(\"p\",null,\"$ docker network prune\"),mdx(\"p\",null,\"WARNING! This will remove all networks not used by at least one container.\"),mdx(\"p\",null,\"Are you sure you want to continue? \",\"[y/N]\",\" y\"),mdx(\"p\",null,\"By default, you are prompted to continue. To bypass the prompt, use the\\xA0-f\\xA0or\\xA0--force\\xA0flag.\"),mdx(\"p\",null,\"By default, all unused networks are removed. You can limit the scope using the\\xA0--filter\\xA0flag. For instance, the following command only removes networks older than 24 hours:\"),mdx(\"p\",null,\"$ docker network prune --filter \\\"until=24h\\\"\"),mdx(\"p\",null,\"Other filtering expressions are available. See the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/network_prune/\"}),\"docker network prune\\xA0reference\"),\"\\xA0for more examples.\"),mdx(\"h4\",null,\"Prune everything\"),mdx(\"p\",null,\"The\\xA0docker system prune\\xA0command is a shortcut that prunes images, containers, and networks. In Docker 17.06.0 and earlier, volumes are also pruned. In Docker 17.06.1 and higher, you must specify the\\xA0--volumes\\xA0flag for\\xA0docker system prune\\xA0to prune volumes.\"),mdx(\"p\",null,\"$ docker system prune\"),mdx(\"p\",null,\"WARNING! This will remove:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},\"all stopped containers\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},\"all networks not used by at least one container\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},\"all dangling images\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},\"all build cache\"))),mdx(\"p\",null,\"Are you sure you want to continue? \",\"[y/N]\",\" y\"),mdx(\"p\",null,\"If you are on Docker 17.06.1 or higher and want to also prune volumes, add the\\xA0--volumes\\xA0flag:\"),mdx(\"p\",null,\"$ docker system prune --volumes\"),mdx(\"p\",null,\"WARNING! This will remove:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},\"all stopped containers\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},\"all networks not used by at least one container\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},\"all volumes not used by at least one container\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},\"all dangling images\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},\"all build cache\"))),mdx(\"p\",null,\"Are you sure you want to continue? \",\"[y/N]\",\" y\"),mdx(\"p\",null,\"By default, you are prompted to continue. To bypass the prompt, use the\\xA0-f\\xA0or\\xA0--force\\xA0flag.\"),mdx(\"h3\",null,\"Format command and log output\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA01 minute\")),mdx(\"p\",null,\"Docker uses\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://golang.org/pkg/text/template/\"}),\"Go templates\"),\"\\xA0which you can use to manipulate the output format of certain commands and log drivers.\"),mdx(\"p\",null,\"Docker provides a set of basic functions to manipulate template elements. All of these examples use the\\xA0docker inspect\\xA0command, but many other CLI commands have a\\xA0--format\\xA0flag, and many of the CLI command references include examples of customizing the output format.\"),mdx(\"h4\",null,\"join\"),mdx(\"p\",null,\"join\\xA0concatenates a list of strings to create a single string. It puts a separator between each element in the list.\"),mdx(\"p\",null,\"$ docker inspect --format \\\\'{{join .Args \\\" , \\\"}}\\\\' container\"),mdx(\"h4\",null,\"json\"),mdx(\"p\",null,\"json\\xA0encodes an element as a json string.\"),mdx(\"p\",null,\"$ docker inspect --format \\\\'{{json .Mounts}}\\\\' container\"),mdx(\"h4\",null,\"lower\"),mdx(\"p\",null,\"lower\\xA0transforms a string into its lowercase representation.\"),mdx(\"p\",null,\"$ docker inspect --format \\\"{{lower .Name}}\\\" container\"),mdx(\"h4\",null,\"split\"),mdx(\"p\",null,\"split\\xA0slices a string into a list of strings separated by a separator.\"),mdx(\"p\",null,\"$ docker inspect --format \\\\'{{split (join .Names \\\"/\\\") \\\"/\\\"}}\\\\' container\"),mdx(\"h4\",null,\"title\"),mdx(\"p\",null,\"title\\xA0capitalizes the first character of a string.\"),mdx(\"p\",null,\"$ docker inspect --format \\\"{{title .Name}}\\\" container\"),mdx(\"h4\",null,\"upper\"),mdx(\"p\",null,\"upper\\xA0transforms a string into its uppercase representation.\"),mdx(\"p\",null,\"$ docker inspect --format \\\"{{upper .Name}}\\\" container\"),mdx(\"h4\",null,\"println\"),mdx(\"p\",null,\"println\\xA0prints each value on a new line.\"),mdx(\"p\",null,\"$ docker inspect --format=\\\\'{{range .NetworkSettings.Networks}}{{println .IPAddress}}{{end}}\\\\' containe\"),mdx(\"h2\",null,\"Configure the Daemon\"),mdx(\"h3\",null,\"Configure and troubleshoot the Docker daemon\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA09 minutes\")),mdx(\"p\",null,\"After successfully installing and starting Docker, the\\xA0dockerd\\xA0daemon runs with its default configuration. This topic shows how to customize the configuration, start the daemon manually, and troubleshoot and debug the daemon if you run into issues.\"),mdx(\"h4\",null,\"Start the daemon using operating system utilities\"),mdx(\"p\",null,\"The command to start Docker depends on your operating system. Check the correct page under\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/install/\"}),\"Install Docker\"),\". To configure Docker to start automatically at system boot, see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/install/linux/linux-postinstall/#configure-docker-to-start-on-boot\"}),\"Configure Docker to start on boot\"),\".\"),mdx(\"h4\",null,\"Start the daemon manually\"),mdx(\"p\",null,\"Typically, you start Docker using operating system utilities. For debugging purposes, you can start Docker manually using the\\xA0dockerd\\xA0command. You may need to use\\xA0sudo, depending on your operating system configuration. When you start Docker this way, it runs in the foreground and sends its logs directly to your terminal.\"),mdx(\"p\",null,\"$ dockerd\"),mdx(\"p\",null,\"INFO\",\"[0000]\",\" +job init_networkdriver()\"),mdx(\"p\",null,\"INFO\",\"[0000]\",\" +job serveapi(unix:///var/run/docker.sock)\"),mdx(\"p\",null,\"INFO\",\"[0000]\",\" Listening for HTTP on unix (/var/run/docker.sock)\"),mdx(\"p\",null,\"...\"),mdx(\"p\",null,\"...\"),mdx(\"p\",null,\"To stop Docker when you have started it manually, issue a\\xA0Ctrl+C\\xA0in your terminal.\"),mdx(\"h4\",null,\"Configure the Docker daemon\"),mdx(\"p\",null,\"The daemon includes many configuration options, which you can pass as flags when starting Docker manually, or set in the\\xA0daemon.json\\xA0configuration file. The second method is recommended because those configuration changes persist when you restart Docker.\"),mdx(\"p\",null,\"See\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/dockerd/\"}),\"dockerd\"),\"\\xA0for a full list of configuration options.\"),mdx(\"p\",null,\"Here is an example of starting the Docker daemon manually with some configuration options:\"),mdx(\"p\",null,\"$ dockerd -D --tls=true --tlscert=/var/docker/server.pem --tlskey=/var/docker/serverkey.pem -H tcp://192.168.59.3:2376\"),mdx(\"p\",null,\"This command enables debugging (-D), enables TLS (-tls), specifies the server certificate and key (--tlscert\\xA0and\\xA0--tlskey), and specifies the network interface where the daemon listens for connections (-H).\"),mdx(\"p\",null,\"A better approach is to put these options into the\\xA0daemon.json\\xA0file and restart Docker. This method works for every Docker platform. The following\\xA0daemon.json\\xA0example sets all the same options as the above command:\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"debug\\\": true,\"),mdx(\"p\",null,\"\\\"tls\\\": true,\"),mdx(\"p\",null,\"\\\"tlscert\\\": \\\"/var/docker/server.pem\\\",\"),mdx(\"p\",null,\"\\\"tlskey\\\": \\\"/var/docker/serverkey.pem\\\",\"),mdx(\"p\",null,\"\\\"hosts\\\": \",\"[\\\"tcp://192.168.59.3:2376\\\"]\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"Many specific configuration options are discussed throughout the Docker documentation. Some places to go next include:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/admin/host_integration/\"}),\"Automatically start containers\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/admin/resource_constraints/\"}),\"Limit a container's resources\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/userguide/storagedriver/\"}),\"Configure storage drivers\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/security/\"}),\"Container security\"))),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Troubleshoot conflicts between the\\xA0daemon.json\\xA0and startup scripts\")),mdx(\"p\",null,\"If you use a\\xA0daemon.json\\xA0file and also pass options to the\\xA0dockerd\\xA0command manually or using start-up scripts, and these options conflict, Docker fails to start with an error such as:\"),mdx(\"p\",null,\"unable to configure the Docker daemon with file /etc/docker/daemon.json:\"),mdx(\"p\",null,\"the following directives are specified both as a flag and in the configuration\"),mdx(\"p\",null,\"file: hosts: (from flag: \",\"[unix:///var/run/docker.sock]\",\", from file: \",\"[tcp://127.0.0.1:2376]\",\")\"),mdx(\"p\",null,\"If you see an error similar to this one and you are starting the daemon manually with flags, you may need to adjust your flags or the\\xA0daemon.json\\xA0to remove the conflict.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": If you see this specific error, continue to the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/daemon/#use-the-hosts-key-in-daemon-json-with-systemd\"}),\"next section\"),\"\\xA0for a workaround.\"),mdx(\"p\",null,\"If you are starting Docker using your operating system's init scripts, you may need to override the defaults in these scripts in ways that are specific to the operating system.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"USE THE HOSTS KEY IN DAEMON.JSON WITH SYSTEMD\")),mdx(\"p\",null,\"One notable example of a configuration conflict that is difficult to troubleshoot is when you want to specify a different daemon address from the default. Docker listens on a socket by default. On Debian and Ubuntu systems using\\xA0systemd, this means that a host flag\\xA0-H\\xA0is always used when starting\\xA0dockerd. If you specify a\\xA0hosts\\xA0entry in the\\xA0daemon.json, this causes a configuration conflict (as in the above message) and Docker fails to start.\"),mdx(\"p\",null,\"To work around this problem, create a new file\\xA0/etc/systemd/system/docker.service.d/docker.confwith the following contents, to remove the\\xA0-H\\xA0argument that is used when starting the daemon by default.\"),mdx(\"p\",null,\"[Service]\"),mdx(\"p\",null,\"ExecStart=\"),mdx(\"p\",null,\"ExecStart=/usr/bin/dockerd\"),mdx(\"p\",null,\"There are other times when you might need to configure\\xA0systemd\\xA0with Docker, such as\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/admin/systemd/#httphttps-proxy\"}),\"configuring a HTTP or HTTPS proxy\"),\".\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": If you override this option and then do not specify a\\xA0hosts\\xA0entry in the\\xA0daemon.json\\xA0or a\\xA0-H\\xA0flag when starting Docker manually, Docker fails to start.\"),mdx(\"p\",null,\"Run\\xA0sudo systemctl daemon-reload\\xA0before attempting to start Docker. If Docker starts successfully, it is now listening on the IP address specified in the\\xA0hosts\\xA0key of the\\xA0daemon.json\\xA0instead of a socket.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Important\"),\": Setting\\xA0hosts\\xA0in the\\xA0daemon.json\\xA0is not supported on Docker for Windows or Docker for Mac.\"),mdx(\"h4\",null,\"Troubleshoot the daemon\"),mdx(\"p\",null,\"You can enable debugging on the daemon to learn about the runtime activity of the daemon and to aid in troubleshooting. If the daemon is completely non-responsive, you can also\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/daemon/#force-a-full-stack-trace-to-be-logged\"}),\"force a full stack trace\"),\"\\xA0of all threads to be added to the daemon log by sending the\\xA0SIGUSR\\xA0signal to the Docker daemon.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Out Of Memory Exceptions (OOME)\")),mdx(\"p\",null,\"If your containers attempt to use more memory than the system has available, you may experience an Out Of Memory Exception (OOME) and a container, or the Docker daemon, might be killed by the kernel OOM killer. To prevent this from happening, ensure that your application runs on hosts with adequate memory and see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/admin/resource_constraints/#understand-the-risks-of-running-out-of-memory\"}),\"Understand the risks of running out of memory\"),\".\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Read the logs\")),mdx(\"p\",null,\"The daemon logs may help you diagnose problems. The logs may be saved in one of a few locations, depending on the operating system configuration and the logging subsystem used:\"),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Operating system\"),\"     \",mdx(\"strong\",{parentName:\"p\"},\"Location\")),mdx(\"hr\",null),mdx(\"p\",null,\"  RHEL, Oracle Linux       /var/log/messages\\nDebian                   /var/log/daemon.log\\nUbuntu 16.04+, CentOS    Use the command\\xA0journalctl -u docker.service\\nUbuntu 14.10-            /var/log/upstart/docker.log\\nmacOS (Docker 18.01+)    \",\"~\",\"/Library/Containers/com.docker.docker/Data/vms/0/console-ring\\nmacOS (Docker <18.01)   \",\"~\",\"/Library/Containers/com.docker.docker/Data/com.docker.driver.amd64-linux/console-ring\\nWindows                  AppData\\\\Local\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Enable debugging\")),mdx(\"p\",null,\"There are two ways to enable debugging. The recommended approach is to set the\\xA0debug\\xA0key to\\xA0true\\xA0in the\\xA0daemon.json\\xA0file. This method works for every Docker platform.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Edit the\\xA0daemon.json\\xA0file, which is usually located in\\xA0/etc/docker/. You may need to create this file, if it does not yet exist. On macOS or Windows, do not edit the file directly. Instead, go to\",mdx(\"strong\",{parentName:\"li\"},\"Preferences\"),\"\\xA0/\\xA0\",mdx(\"strong\",{parentName:\"li\"},\"Daemon\"),\"\\xA0/\\xA0\",mdx(\"strong\",{parentName:\"li\"},\"Advanced\"),\".\"),mdx(\"li\",{parentName:\"ol\"},\"If the file is empty, add the following:\"),mdx(\"li\",{parentName:\"ol\"},\"{\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"debug\\\": true\"),mdx(\"li\",{parentName:\"ol\"},\"}\")),mdx(\"p\",null,\"If the file already contains JSON, just add the key\\xA0\\\"debug\\\": true, being careful to add a comma to the end of the line if it is not the last line before the closing bracket. Also verify that if the\\xA0log-level\\xA0key is set, it is set to either\\xA0info\\xA0or\\xA0debug.\\xA0info\\xA0is the default, and possible values are\\xA0debug,\\xA0info,\\xA0warn,\\xA0error,\\xA0fatal.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Send a\\xA0HUP\\xA0signal to the daemon to cause it to reload its configuration. On Linux hosts, use the following command.\"),mdx(\"li\",{parentName:\"ol\"},\"$ sudo kill -SIGHUP $(pidof dockerd)\")),mdx(\"p\",null,\"On Windows hosts, restart Docker.\"),mdx(\"p\",null,\"Instead of following this procedure, you can also stop the Docker daemon and restart it manually with the debug flag\\xA0-D. However, this may result in Docker restarting with a different environment than the one the hosts' startup scripts create, and this may make debugging more difficult.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Force a stack trace to be logged\")),mdx(\"p\",null,\"If the daemon is unresponsive, you can force a full stack trace to be logged by sending a\\xA0SIGUSR1signal to the daemon.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Linux\"),\":\"),mdx(\"li\",{parentName:\"ul\"},\"$ sudo kill -SIGUSR1 $(pidof dockerd)\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Windows Server\"),\":\")),mdx(\"p\",null,\"Download\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/jhowardmsft/docker-signal\"}),\"docker-signal\"),\".\"),mdx(\"p\",null,\"Run the executable with the flag\\xA0--pid=\",mdx(\"inlineCode\",{parentName:\"p\"},\"<PID of daemon>\"),\".\"),mdx(\"p\",null,\"This forces a stack trace to be logged but does not stop the daemon. Daemon logs show the stack trace or the path to a file containing the stack trace if it was logged to a file.\"),mdx(\"p\",null,\"The daemon continues operating after handling the\\xA0SIGUSR1\\xA0signal and dumping the stack traces to the log. The stack traces can be used to determine the state of all goroutines and threads within the daemon.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"View stack traces\")),mdx(\"p\",null,\"The Docker daemon log can be viewed by using one of the following methods:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"By running\\xA0journalctl -u docker.service\\xA0on Linux systems using\\xA0systemctl\"),mdx(\"li\",{parentName:\"ul\"},\"/var/log/messages,\\xA0/var/log/daemon.log, or\\xA0/var/log/docker.log\\xA0on older Linux systems\"),mdx(\"li\",{parentName:\"ul\"},\"By running\\xA0Get-EventLog -LogName Application -Source Docker -After (Get-Date).AddMinutes(-5) | Sort-Object Time | Export-CSV \",\"~\",\"/last5minutes.CSVon Docker EE for Windows Server\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": It is not possible to manually generate a stack trace on Docker for Mac or Docker for Windows. However, you can click the Docker taskbar icon and choose\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"Diagnose and feedback\"),\"\\xA0to send information to Docker if you run into issues.\"),mdx(\"p\",null,\"Look in the Docker logs for a message like the following:\"),mdx(\"p\",null,\"...goroutine stacks written to /var/run/docker/goroutine-stacks-2017-06-02T193336z.log\"),mdx(\"p\",null,\"...daemon datastructure dump written to /var/run/docker/daemon-data-2017-06-02T193336z.log\"),mdx(\"p\",null,\"The locations where Docker saves these stack traces and dumps depends on your operating system and configuration. You can sometimes get useful diagnostic information straight from the stack traces and dumps. Otherwise, you can provide this information to Docker for help diagnosing the problem.\"),mdx(\"h4\",null,\"Check whether Docker is running\"),mdx(\"p\",null,\"The operating-system independent way to check whether Docker is running is to ask Docker, using the\\xA0docker info\\xA0command.\"),mdx(\"p\",null,\"You can also use operating system utilities, such as\\xA0sudo systemctl is-active docker\\xA0or\\xA0sudo status docker\\xA0or\\xA0sudo service docker status, or checking the service status using Windows utilities.\"),mdx(\"p\",null,\"Finally, you can check in the process list for the\\xA0dockerd\\xA0process, using commands like\\xA0ps\\xA0or\\xA0top.\"),mdx(\"h3\",null,\"Control Docker with systemd\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA03 minutes\")),mdx(\"p\",null,\"Many Linux distributions use systemd to start the Docker daemon. This document shows a few examples of how to customize Docker's settings.\"),mdx(\"h4\",null,\"Start the Docker daemon\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Start manually\")),mdx(\"p\",null,\"Once Docker is installed, you need to start the Docker daemon. Most Linux distributions use\\xA0systemctl\\xA0to start services. If you do not have\\xA0systemctl, use the\\xA0service\\xA0command.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"systemctl\"),\":\"),mdx(\"li\",{parentName:\"ul\"},\"$ sudo systemctl start docker\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"service\"),\":\"),mdx(\"li\",{parentName:\"ul\"},\"$ sudo service docker start\")),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Start automatically at system boot\")),mdx(\"p\",null,\"If you want Docker to start at boot, see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/install/linux/linux-postinstall/#configure-docker-to-start-on-boot\"}),\"Configure Docker to start on boot\"),\".\"),mdx(\"h4\",null,\"Custom Docker daemon options\"),mdx(\"p\",null,\"There are a number of ways to configure the daemon flags and environment variables for your Docker daemon. The recommended way is to use the platform-independent\\xA0daemon.json\\xA0file, which is located in\\xA0/etc/docker/\\xA0on Linux by default. See\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-configuration-file\"}),\"Daemon configuration file\"),\".\"),mdx(\"p\",null,\"You can configure nearly all daemon configuration options using\\xA0daemon.json. The following example configures two options. One thing you cannot configure using\\xA0daemon.json\\xA0mechanism is a\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/daemon/#http-proxy\"}),\"HTTP proxy\"),\".\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Runtime directory and storage driver\")),mdx(\"p\",null,\"You may want to control the disk space used for Docker images, containers, and volumes by moving it to a separate partition.\"),mdx(\"p\",null,\"To accomplish this, set the following flags in the\\xA0daemon.json\\xA0file:\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"data-root\\\": \\\"/mnt/docker-data\\\",\"),mdx(\"p\",null,\"\\\"storage-driver\\\": \\\"overlay\\\"\"),mdx(\"p\",null,\"}\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"HTTP/HTTPS proxy\")),mdx(\"p\",null,\"The Docker daemon uses the\\xA0HTTP_PROXY,\\xA0HTTPS_PROXY, and\\xA0NO_PROXY\\xA0environmental variables in its start-up environment to configure HTTP or HTTPS proxy behavior. You cannot configure these environment variables using the\\xA0daemon.json\\xA0file.\"),mdx(\"p\",null,\"This example overrides the default\\xA0docker.service\\xA0file.\"),mdx(\"p\",null,\"If you are behind an HTTP or HTTPS proxy server, for example in corporate settings, you need to add this configuration in the Docker systemd service file.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Create a systemd drop-in directory for the docker service:\"),mdx(\"li\",{parentName:\"ol\"},\"$ sudo mkdir -p /etc/systemd/system/docker.service.d\"),mdx(\"li\",{parentName:\"ol\"},\"Create a file called\\xA0/etc/systemd/system/docker.service.d/http-proxy.conf\\xA0that adds the\\xA0HTTP_PROXY\\xA0environment variable:\"),mdx(\"li\",{parentName:\"ol\"},\"[Service]\"),mdx(\"li\",{parentName:\"ol\"},\"Environment=\\\"HTTP_PROXY=\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"http://proxy.example.com:80/%22\"}),\"http://proxy.example.com:80/\\\"\"))),mdx(\"p\",null,\"Or, if you are behind an HTTPS proxy server, create a file called/etc/systemd/system/docker.service.d/https-proxy.conf\\xA0that adds the\\xA0HTTPS_PROXYenvironment variable:\"),mdx(\"p\",null,\"[Service]\"),mdx(\"p\",null,\"Environment=\\\"HTTPS_PROXY=\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://proxy.example.com:443/%22\"}),\"https://proxy.example.com:443/\\\"\")),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"If you have internal Docker registries that you need to contact without proxying you can specify them via the\\xA0NO_PROXY\\xA0environment variable:\"),mdx(\"li\",{parentName:\"ol\"},\"[Service]\"),mdx(\"li\",{parentName:\"ol\"},\"Environment=\\\"HTTP_PROXY=\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"http://proxy.example.com:80/%22\"}),\"http://proxy.example.com:80/\\\"\"),\" \\\"NO_PROXY=localhost,127.0.0.1,docker-registry.somecorporation.com\\\"\")),mdx(\"p\",null,\"Or, if you are behind an HTTPS proxy server:\"),mdx(\"p\",null,\"[Service]\"),mdx(\"p\",null,\"Environment=\\\"HTTPS_PROXY=\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://proxy.example.com:443/%22\"}),\"https://proxy.example.com:443/\\\"\"),\" \\\"NO_PROXY=localhost,127.0.0.1,docker-registry.somecorporation.com\\\"\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Flush changes:\"),mdx(\"li\",{parentName:\"ol\"},\"$ sudo systemctl daemon-reload\"),mdx(\"li\",{parentName:\"ol\"},\"Restart Docker:\"),mdx(\"li\",{parentName:\"ol\"},\"$ sudo systemctl restart docker\"),mdx(\"li\",{parentName:\"ol\"},\"Verify that the configuration has been loaded:\"),mdx(\"li\",{parentName:\"ol\"},\"$ systemctl show --property=Environment docker\"),mdx(\"li\",{parentName:\"ol\"},\"Environment=HTTP_PROXY=\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"http://proxy.example.com:80/\"}),\"http://proxy.example.com:80/\"))),mdx(\"p\",null,\"Or, if you are behind an HTTPS proxy server:\"),mdx(\"p\",null,\"$ systemctl show --property=Environment docker\"),mdx(\"p\",null,\"Environment=HTTPS_PROXY=\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://proxy.example.com:443/\"}),\"https://proxy.example.com:443/\")),mdx(\"h4\",null,\"Configure where the Docker daemon listens for connections\"),mdx(\"p\",null,\"See\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/install/linux/linux-postinstall/#control-where-the-docker-daemon-listens-for-connections\"}),\"Configure where the Docker daemon listens for connections\"),\".\"),mdx(\"h4\",null,\"Manually create the systemd unit files\"),mdx(\"p\",null,\"When installing the binary without a package, you may want to integrate Docker with systemd. For this, install the two unit files (service\\xA0and\\xA0socket) from\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/moby/moby/tree/master/contrib/init/systemd\"}),\"the github repository\"),\"\\xA0to\\xA0/etc/systemd/system.\"),mdx(\"h3\",null,\"Collect Docker metrics with Prometheus\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA08 minutes\")),mdx(\"p\",null,mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://prometheus.io/\"}),\"Prometheus\"),\"\\xA0is an open-source systems monitoring and alerting toolkit. You can configure Docker as a Prometheus target. This topic shows you how to configure Docker, set up Prometheus to run as a Docker container, and monitor your Docker instance using Prometheus.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Warning\"),\": The available metrics and the names of those metrics are in active development and may change at any time.\"),mdx(\"p\",null,\"Currently, you can only monitor Docker itself. You cannot currently monitor your application using the Docker target.\"),mdx(\"h4\",null,\"Configure Docker\"),mdx(\"p\",null,\"To configure the Docker daemon as a Prometheus target, you need to specify themetrics-address. The best way to do this is via the\\xA0daemon.json, which is located at one of the following locations by default. If the file does not exist, create it.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Linux\"),\":\\xA0/etc/docker/daemon.json\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Windows Server\"),\":\\xA0C:\\\\ProgramData\\\\docker\\\\config\\\\daemon.json\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Docker for Mac / Docker for Windows\"),\": Click the Docker icon in the toolbar, select\\xA0\",mdx(\"strong\",{parentName:\"li\"},\"Preferences\"),\", then select\\xA0\",mdx(\"strong\",{parentName:\"li\"},\"Daemon\"),\". Click\\xA0\",mdx(\"strong\",{parentName:\"li\"},\"Advanced\"),\".\")),mdx(\"p\",null,\"If the file is currently empty, paste the following:\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"metrics-addr\\\" : \\\"127.0.0.1:9323\\\",\"),mdx(\"p\",null,\"\\\"experimental\\\" : true\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"If the file is not empty, add those two keys, making sure that the resulting file is valid JSON. Be careful that every line ends with a comma (,) except for the last line.\"),mdx(\"p\",null,\"Save the file, or in the case of Docker for Mac or Docker for Windows, save the configuration. Restart Docker.\"),mdx(\"p\",null,\"Docker now exposes Prometheus-compatible metrics on port 9323.\"),mdx(\"h4\",null,\"Configure and run Prometheus\"),mdx(\"p\",null,\"In this example, Prometheus runs as a Docker service on a Docker swarm.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Prerequisites\")),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"One or more Docker engines are joined into a Docker swarm, using\\xA0docker swarm init\\xA0on one manager and\\xA0docker swarm join\\xA0on other managers and worker nodes.\"),mdx(\"li\",{parentName:\"ol\"},\"You need an internet connection to pull the Prometheus image.\")),mdx(\"p\",null,\"Copy one of the following configuration files and save it to\\xA0/tmp/prometheus.yml\\xA0(Linux or Mac) or\\xA0C:\\\\tmp\\\\prometheus.yml\\xA0(Windows). This is a stock Prometheus configuration file, except for the addition of the Docker job definition at the bottom of the file. Docker for Mac and Docker for Windows need a slightly different configuration.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Docker for Linux\"),mdx(\"li\",{parentName:\"ul\"},\"Docker for Mac\"),mdx(\"li\",{parentName:\"ul\"},\"Docker for Windows\")),mdx(\"h1\",null,\"my global config\"),mdx(\"p\",null,\"global:\"),mdx(\"p\",null,\"scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.\"),mdx(\"p\",null,\"evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.\"),mdx(\"h1\",null,\"scrape_timeout is set to the global default (10s).\"),mdx(\"h1\",null,\"Attach these labels to any time series or alerts when communicating with\"),mdx(\"h1\",null,\"external systems (federation, remote storage, Alertmanager).\"),mdx(\"p\",null,\"external_labels:\"),mdx(\"p\",null,\"monitor: \\\\'codelab-monitor\\\\'\"),mdx(\"h1\",null,\"Load rules once and periodically evaluate them according to the global \\\\'evaluation_interval\\\\'.\"),mdx(\"p\",null,\"rule_files:\"),mdx(\"h1\",null,\"- \\\"first.rules\\\"\"),mdx(\"h1\",null,\"- \\\"second.rules\\\"\"),mdx(\"h1\",null,\"A scrape configuration containing exactly one endpoint to scrape:\"),mdx(\"h1\",null,\"Here it\\\\'s Prometheus itself.\"),mdx(\"p\",null,\"scrape_configs:\"),mdx(\"h1\",null,\"The job name is added as a label \",mdx(\"inlineCode\",{parentName:\"h1\"},\"job=\"),\"<job_name>`` to any timeseries scraped from this config.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"job_name: \\\\'prometheus\\\\'\")),mdx(\"h1\",null,\"metrics_path defaults to \\\\'/metrics\\\\'\"),mdx(\"h1\",null,\"scheme defaults to \\\\'http\\\\'.\"),mdx(\"p\",null,\"static_configs:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},\"targets: \",\"[\\\\'localhost:9090\\\\']\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},\"job_name: \\\\'docker\\\\'\"))),mdx(\"h1\",null,\"metrics_path defaults to \\\\'/metrics\\\\'\"),mdx(\"h1\",null,\"scheme defaults to \\\\'http\\\\'.\"),mdx(\"p\",null,\"static_configs:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"targets: \",\"[\\\\'localhost:9323\\\\']\")),mdx(\"p\",null,\"Next, start a single-replica Prometheus service using this configuration.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Docker for Linux\"),mdx(\"li\",{parentName:\"ul\"},\"Docker for Mac\"),mdx(\"li\",{parentName:\"ul\"},\"Docker for Windows or Windows Server\")),mdx(\"p\",null,\"$ docker service create --replicas 1 --name my-prometheus \\\\\"),mdx(\"p\",null,\"--mount type=bind,source=/tmp/prometheus.yml,destination=/etc/prometheus/prometheus.yml \\\\\"),mdx(\"p\",null,\"--publish published=9090,target=9090,protocol=tcp \\\\\"),mdx(\"p\",null,\"prom/prometheus\"),mdx(\"p\",null,\"Verify that the Docker target is listed at http://localhost:9090/targets/.\"),mdx(\"p\",null,\"You can't access the endpoint URLs directly if you use Docker for Mac or Docker for Windows.\"),mdx(\"h4\",null,\"Use Prometheus\"),mdx(\"p\",null,\"Create a graph. Click the\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"Graphs\"),\"\\xA0link in the Prometheus UI. Choose a metric from the combo box to the right of the\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"Execute\"),\"\\xA0button, and click\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"Execute\"),\". The screenshot below shows the graph forengine_daemon_network_actions_seconds_count.\"),mdx(\"p\",null,\"The above graph shows a pretty idle Docker instance. Your graph might look different if you are running active workloads.\"),mdx(\"p\",null,\"To make the graph more interesting, create some network actions by starting a service with 10 tasks that just ping Docker non-stop (you can change the ping target to anything you like):\"),mdx(\"p\",null,\"$ docker service create \\\\\"),mdx(\"p\",null,\"--replicas 10 \\\\\"),mdx(\"p\",null,\"--name ping_service \\\\\"),mdx(\"p\",null,\"alpine ping docker.com\"),mdx(\"p\",null,\"Wait a few minutes (the default scrape interval is 15 seconds) and reload your graph.\"),mdx(\"p\",null,\"When you are ready, stop and remove the\\xA0ping_service\\xA0service, so that you are not flooding a host with pings for no reason.\"),mdx(\"p\",null,\"$ docker service remove ping_service\"),mdx(\"p\",null,\"Wait a few minutes and you should see that the graph falls back to the idle level.\"),mdx(\"h4\",null,\"Next steps\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Read the\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://prometheus.io/docs/introduction/overview/\"}),\"Prometheus documentation\")),mdx(\"li\",{parentName:\"ul\"},\"Set up some\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://prometheus.io/docs/alerting/overview/\"}),\"alerts\"))),mdx(\"h2\",null,\"Configure Containers\"),mdx(\"h3\",null,\"Start containers automatically\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA02 minutes\")),mdx(\"p\",null,\"Docker provides\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/run/#restart-policies---restart\"}),\"restart policies\"),\"\\xA0to control whether your containers start automatically when they exit, or when Docker restarts. Restart policies ensure that linked containers are started in the correct order. Docker recommends that you use restart policies, and avoid using process managers to start containers.\"),mdx(\"p\",null,\"Restart policies are different from the\\xA0--live-restore\\xA0flag of the\\xA0dockerd\\xA0command. Using\\xA0--live-restore\\xA0allows you to keep your containers running during a Docker upgrade, though networking and user input are interrupted.\"),mdx(\"h4\",null,\"Use a restart policy\"),mdx(\"p\",null,\"To configure the restart policy for a container, use the\\xA0--restart\\xA0flag when using the\\xA0docker run\\xA0command. The value of the\\xA0--restart\\xA0flag can be any of the following:\"),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Flag\"),\"         \",mdx(\"strong\",{parentName:\"p\"},\"Description\")),mdx(\"hr\",null),mdx(\"p\",null,\"  no               Do not automatically restart the container. (the default)\\non-failure       Restart the container if it exits due to an error, which manifests as a non-zero exit code.\\nunless-stopped   Restart the container unless it is explicitly stopped or Docker itself is stopped or restarted.\\nalways           Always restart the container if it stops.\"),mdx(\"p\",null,\"The following example starts a Redis container and configures it to always restart unless it is explicitly stopped or Docker is restarted.\"),mdx(\"p\",null,\"$ docker run -dit --restart unless-stopped redis\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Restart policy details\")),mdx(\"p\",null,\"Keep the following in mind when using restart policies:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"A restart policy only takes effect after a container starts successfully. In this case, starting successfully means that the container is up for at least 10 seconds and Docker has started monitoring it. This prevents a container which does not start at all from going into a restart loop.\"),mdx(\"li\",{parentName:\"ul\"},\"If you manually stop a container, its restart policy is ignored until the Docker daemon restarts or the container is manually restarted. This is another attempt to prevent a restart loop.\"),mdx(\"li\",{parentName:\"ul\"},\"Restart policies only apply to\\xA0containers. Restart policies for swarm services are configured differently. See the\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/service_create/\"}),\"flags related to service restart\"),\".\")),mdx(\"h4\",null,\"Use a process manager\"),mdx(\"p\",null,\"If restart policies don't suit your needs, such as when processes outside Docker depend on Docker containers, you can use a process manager such as\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://upstart.ubuntu.com/\"}),\"upstart\"),\",\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://freedesktop.org/wiki/Software/systemd/\"}),\"systemd\"),\", or\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://supervisord.org/\"}),\"supervisor\"),\"instead.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Warning\"),\": Do not try to combine Docker restart policies with host-level process managers, because this creates conflicts.\"),mdx(\"p\",null,\"To use a process manager, configure it to start your container or service using the same\\xA0docker start\\xA0or\\xA0docker service\\xA0command you would normally use to start the container manually. Consult the documentation for the specific process manager for more details.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Using a process manager inside containers\")),mdx(\"p\",null,\"Process managers can also run within the container to check whether a process is running and starts/restart it if not.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Warning: These are not Docker-aware and just monitor operating system processes within the container.\")),mdx(\"p\",null,\"Docker does not recommend this approach, because it is platform-dependent and even differs within different versions of a given Linux distribution.\"),mdx(\"h3\",null,\"Keep containers alive during daemon downtime\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA02 minutes\")),mdx(\"p\",null,\"By default, when the Docker daemon terminates, it shuts down running containers. Starting with Docker Engine 1.12, you can configure the daemon so that containers remain running if the daemon becomes unavailable. This functionality is called\\xA0live restore. The live restore option helps reduce container downtime due to daemon crashes, planned outages, or upgrades.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": Live restore is not supported on Windows containers, but it does work for Linux containers running on Docker for Windows.\"),mdx(\"h4\",null,\"Enable live restore\"),mdx(\"p\",null,\"There are two ways to enable the live restore setting to keep containers alive when the daemon becomes unavailable.\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"Only do one of the following\"),\".\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Add the configuration to the daemon configuration file. On Linux, this defaults to\\xA0/etc/docker/daemon.json. On Docker for Mac or Docker for Windows, select the Docker icon from the task bar, then click\\xA0\",mdx(\"strong\",{parentName:\"li\"},\"Preferences\"),\"\\xA0->\\xA0\",mdx(\"strong\",{parentName:\"li\"},\"Daemon\"),\"\\xA0->\\xA0\",mdx(\"strong\",{parentName:\"li\"},\"Advanced\"),\".\",mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},\"Use the following JSON to enable\\xA0live-restore.\"),mdx(\"li\",{parentName:\"ul\"},\"{\"),mdx(\"li\",{parentName:\"ul\"},\"\\\"live-restore\\\": true\"),mdx(\"li\",{parentName:\"ul\"},\"}\"),mdx(\"li\",{parentName:\"ul\"},\"Restart the Docker daemon. On Linux, you can avoid a restart (and avoid any downtime for your containers) by reload the Docker daemon. If you use\\xA0systemd, then use the command\\xA0systemctl reload docker. Otherwise, send a\\xA0SIGHUP\\xA0signal to the\\xA0dockerd\\xA0process.\"))),mdx(\"li\",{parentName:\"ul\"},\"If you prefer, you can start the\\xA0dockerd\\xA0process manually with the\\xA0--live-restore\\xA0flag. This approach is not recommended because it does not set up the environment that\\xA0systemd\\xA0or another process manager would use when starting the Docker process. This can cause unexpected behavior.\")),mdx(\"h4\",null,\"Live restore during upgrades\"),mdx(\"p\",null,\"The live restore feature supports restoring containers to the daemon for upgrades from one minor release to the next, such as when upgrading from Docker 1.12.1 to 1.12.2.\"),mdx(\"p\",null,\"If you skip releases during an upgrade, the daemon may not restore its connection to the containers. If the daemon can't restore the connection, it cannot manage the running containers and you must stop them manually.\"),mdx(\"h4\",null,\"Live restore upon restart\"),mdx(\"p\",null,\"The live restore option only works to restore containers if the daemon options, such as bridge IP addresses and graph driver, did not change. If any of these daemon-level configuration options have changed, the live restore may not work and you may need to manually stop the containers.\"),mdx(\"h4\",null,\"Impact of live restore on running containers\"),mdx(\"p\",null,\"If the daemon is down for a long time, running containers may fill up the FIFO log the daemon normally reads. A full log blocks containers from logging more data. The default buffer size is 64K. If the buffers fill, you must restart the Docker daemon to flush them.\"),mdx(\"p\",null,\"On Linux, you can modify the kernel's buffer size by changing\\xA0/proc/sys/fs/pipe-max-size. You cannot modify the buffer size on Docker for Mac or Docker for Windows.\"),mdx(\"h4\",null,\"Live restore and swarm mode\"),mdx(\"p\",null,\"The live restore option only pertains to standalone containers, and not to swarm services. Swarm services are managed by swarm managers. If swarm managers are not available, swarm services continue to run on worker nodes but cannot be managed until enough swarm managers are available to maintain a quorum.\"),mdx(\"h3\",null,\"Run multiple services in a container\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA03 minutes\")),mdx(\"p\",null,\"A container's main running process is the\\xA0ENTRYPOINT\\xA0and/or\\xA0CMD\\xA0at the end of the\\xA0Dockerfile. It is generally recommended that you separate areas of concern by using one service per container. That service may fork into multiple processes (for example, Apache web server starts multiple worker processes). It's ok to have multiple processes, but to get the most benefit out of Docker, avoid one container being responsible for multiple aspects of your overall application. You can connect multiple containers using user-defined networks and shared volumes.\"),mdx(\"p\",null,\"The container's main process is responsible for managing all processes that it starts. In some cases, the main process isn't well-designed, and doesn't handle \\\"reaping\\\" (stopping) child processes gracefully when the container exits. If your process falls into this category, you can use the\\xA0--init\\xA0option when you run the container. The\\xA0--init\\xA0flag inserts a tiny init-process into the container as the main process, and handles reaping of all processes when the container exits. Handling such processes this way is superior to using a full-fledged init process such as\\xA0sysvinit,\\xA0upstart, or\\xA0systemd\\xA0to handle process lifecycle within your container.\"),mdx(\"p\",null,\"If you need to run more than one service within a container, you can accomplish this in a few different ways.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Put all of your commands in a wrapper script, complete with testing and debugging information. Run the wrapper script as your\\xA0CMD. This is a very naive example. First, the wrapper script:\"),mdx(\"li\",{parentName:\"ul\"},\"#!/bin/bash\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"h1\",{parentName:\"li\"},\"Start the first process\")),mdx(\"li\",{parentName:\"ul\"},\"./my_first_process -D\"),mdx(\"li\",{parentName:\"ul\"},\"status=$?\"),mdx(\"li\",{parentName:\"ul\"},\"if \",\"[ $status -ne 0 ]\",\"; then\"),mdx(\"li\",{parentName:\"ul\"},\"echo \\\"Failed to start my_first_process: $status\\\"\"),mdx(\"li\",{parentName:\"ul\"},\"exit $status\"),mdx(\"li\",{parentName:\"ul\"},\"fi\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"h1\",{parentName:\"li\"},\"Start the second process\")),mdx(\"li\",{parentName:\"ul\"},\"./my_second_process -D\"),mdx(\"li\",{parentName:\"ul\"},\"status=$?\"),mdx(\"li\",{parentName:\"ul\"},\"if \",\"[ $status -ne 0 ]\",\"; then\"),mdx(\"li\",{parentName:\"ul\"},\"echo \\\"Failed to start my_second_process: $status\\\"\"),mdx(\"li\",{parentName:\"ul\"},\"exit $status\"),mdx(\"li\",{parentName:\"ul\"},\"fi\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"h1\",{parentName:\"li\"},\"Naive check runs checks once a minute to see if either of the processes exited.\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"h1\",{parentName:\"li\"},\"This illustrates part of the heavy lifting you need to do if you want to run\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"h1\",{parentName:\"li\"},\"more than one service in a container. The container exits with an error\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"h1\",{parentName:\"li\"},\"if it detects that either of the processes has exited.\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"h1\",{parentName:\"li\"},\"Otherwise it loops forever, waking up every 60 seconds\")),mdx(\"li\",{parentName:\"ul\"},\"while sleep 60; do\"),mdx(\"li\",{parentName:\"ul\"},\"ps aux |grep my_first_process |grep -q -v grep\"),mdx(\"li\",{parentName:\"ul\"},\"PROCESS_1_STATUS=$?\"),mdx(\"li\",{parentName:\"ul\"},\"ps aux |grep my_second_process |grep -q -v grep\"),mdx(\"li\",{parentName:\"ul\"},\"PROCESS_2_STATUS=$?\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"h1\",{parentName:\"li\"},\"If the greps above find anything, they exit with 0 status\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"h1\",{parentName:\"li\"},\"If they are not both 0, then something is wrong\")),mdx(\"li\",{parentName:\"ul\"},\"if \",\"[ $PROCESS_1_STATUS -ne 0 -o $PROCESS_2_STATUS -ne 0 ]\",\"; then\"),mdx(\"li\",{parentName:\"ul\"},\"echo \\\"One of the processes has already exited.\\\"\"),mdx(\"li\",{parentName:\"ul\"},\"exit 1\"),mdx(\"li\",{parentName:\"ul\"},\"fi\"),mdx(\"li\",{parentName:\"ul\"},\"done\")),mdx(\"p\",null,\"Next, the Dockerfile:\"),mdx(\"p\",null,\"FROM ubuntu:latest\"),mdx(\"p\",null,\"COPY my_first_process my_first_process\"),mdx(\"p\",null,\"COPY my_second_process my_second_process\"),mdx(\"p\",null,\"COPY my_wrapper_script.sh my_wrapper_script.sh\"),mdx(\"p\",null,\"CMD ./my_wrapper_script.sh\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Use a process manager like\\xA0supervisord. This is a moderately heavy-weight approach that requires you to package\\xA0supervisord\\xA0and its configuration in your image (or base your image on one that includes\\xA0supervisord), along with the different applications it manages. Then you start\\xA0supervisord, which manages your processes for you. Here is an example Dockerfile using this approach, that assumes the pre-written\\xA0supervisord.conf,\\xA0my_first_process, and\\xA0my_second_process\\xA0files all exist in the same directory as your Dockerfile.\"),mdx(\"li\",{parentName:\"ul\"},\"FROM ubuntu:latest\"),mdx(\"li\",{parentName:\"ul\"},\"RUN apt-get update && apt-get install -y supervisor\"),mdx(\"li\",{parentName:\"ul\"},\"RUN mkdir -p /var/log/supervisor\"),mdx(\"li\",{parentName:\"ul\"},\"COPY supervisord.conf /etc/supervisor/conf.d/supervisord.conf\"),mdx(\"li\",{parentName:\"ul\"},\"COPY my_first_process my_first_process\"),mdx(\"li\",{parentName:\"ul\"},\"COPY my_second_process my_second_process\")),mdx(\"p\",null,\"CMD \",\"[\\\"/usr/bin/supervisord\\\"]\"),mdx(\"h3\",null,\"Runtime metrics\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA017 minutes\")),mdx(\"h4\",null,\"Docker stats\"),mdx(\"p\",null,\"You can use the\\xA0docker stats\\xA0command to live stream a container's runtime metrics. The command supports CPU, memory usage, memory limit, and network IO metrics.\"),mdx(\"p\",null,\"The following is a sample output from the\\xA0docker stats\\xA0command\"),mdx(\"p\",null,\"$ docker stats redis1 redis2\"),mdx(\"p\",null,\"CONTAINER CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O\"),mdx(\"p\",null,\"redis1 0.07% 796 KB / 64 MB 1.21% 788 B / 648 B 3.568 MB / 512 KB\"),mdx(\"p\",null,\"redis2 0.07% 2.746 MB / 64 MB 4.29% 1.266 KB / 648 B 12.4 MB / 0 B\"),mdx(\"p\",null,\"The\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/stats/\"}),\"docker stats\"),\"\\xA0reference page has more details about the\\xA0docker stats\\xA0command.\"),mdx(\"h4\",null,\"Control groups\"),mdx(\"p\",null,\"Linux Containers rely on\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://www.kernel.org/doc/Documentation/cgroup-v1/cgroups.txt\"}),\"control groups\"),\"\\xA0which not only track groups of processes, but also expose metrics about CPU, memory, and block I/O usage. You can access those metrics and obtain network usage metrics as well. This is relevant for \\\"pure\\\" LXC containers, as well as for Docker containers.\"),mdx(\"p\",null,\"Control groups are exposed through a pseudo-filesystem. In recent distros, you should find this filesystem under\\xA0/sys/fs/cgroup. Under that directory, you see multiple sub-directories, called devices, freezer, blkio, etc.; each sub-directory actually corresponds to a different cgroup hierarchy.\"),mdx(\"p\",null,\"On older systems, the control groups might be mounted on\\xA0/cgroup, without distinct hierarchies. In that case, instead of seeing the sub-directories, you see a bunch of files in that directory, and possibly some directories corresponding to existing containers.\"),mdx(\"p\",null,\"To figure out where your control groups are mounted, you can run:\"),mdx(\"p\",null,\"$ grep cgroup /proc/mounts\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Enumerate cgroups\")),mdx(\"p\",null,\"You can look into\\xA0/proc/cgroups\\xA0to see the different control group subsystems known to the system, the hierarchy they belong to, and how many groups they contain.\"),mdx(\"p\",null,\"You can also look at\\xA0/proc/\",mdx(\"inlineCode\",{parentName:\"p\"},\"<pid>\"),\"/cgroup\\xA0to see which control groups a process belongs to. The control group is shown as a path relative to the root of the hierarchy mountpoint.\\xA0/\\xA0means the process has not been assigned to a group, while\\xA0/lxc/pumpkin\\xA0indicates that the process is a member of a container named\\xA0pumpkin.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Find the cgroup for a given container\")),mdx(\"p\",null,\"For each container, one cgroup is created in each hierarchy. On older systems with older versions of the LXC userland tools, the name of the cgroup is the name of the container. With more recent versions of the LXC tools, the cgroup is\\xA0lxc/\",mdx(\"inlineCode\",{parentName:\"p\"},\"<container_name>\"),\".\"),mdx(\"p\",null,\"For Docker containers using cgroups, the container name is the full ID or long ID of the container. If a container shows up as ae836c95b4c3 in\\xA0docker ps, its long ID might be something likeae836c95b4c3c9e9179e0e91015512da89fdec91612f63cebae57df9a5444c79. You can look it up with\\xA0docker inspect\\xA0or\\xA0docker ps --no-trunc.\"),mdx(\"p\",null,\"Putting everything together to look at the memory metrics for a Docker container, take a look at\\xA0/sys/fs/cgroup/memory/docker/\",mdx(\"inlineCode\",{parentName:\"p\"},\"<longid>\"),\"/.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Metrics from cgroups: memory, CPU, block I/O\")),mdx(\"p\",null,\"For each subsystem (memory, CPU, and block I/O), one or more pseudo-files exist and contain statistics.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"MEMORY METRICS:\\xA0MEMORY.STAT\")),mdx(\"p\",null,\"Memory metrics are found in the \\\"memory\\\" cgroup. The memory control group adds a little overhead, because it does very fine-grained accounting of the memory usage on your host. Therefore, many distros chose to not enable it by default. Generally, to enable it, all you have to do is to add some kernel command-line parameters:\\xA0cgroup_enable=memory swapaccount=1.\"),mdx(\"p\",null,\"The metrics are in the pseudo-file\\xA0memory.stat. Here is what it looks like:\"),mdx(\"p\",null,\"cache 11492564992\"),mdx(\"p\",null,\"rss 1930993664\"),mdx(\"p\",null,\"mapped_file 306728960\"),mdx(\"p\",null,\"pgpgin 406632648\"),mdx(\"p\",null,\"pgpgout 403355412\"),mdx(\"p\",null,\"swap 0\"),mdx(\"p\",null,\"pgfault 728281223\"),mdx(\"p\",null,\"pgmajfault 1724\"),mdx(\"p\",null,\"inactive_anon 46608384\"),mdx(\"p\",null,\"active_anon 1884520448\"),mdx(\"p\",null,\"inactive_file 7003344896\"),mdx(\"p\",null,\"active_file 4489052160\"),mdx(\"p\",null,\"unevictable 32768\"),mdx(\"p\",null,\"hierarchical_memory_limit 9223372036854775807\"),mdx(\"p\",null,\"hierarchical_memsw_limit 9223372036854775807\"),mdx(\"p\",null,\"total_cache 11492564992\"),mdx(\"p\",null,\"total_rss 1930993664\"),mdx(\"p\",null,\"total_mapped_file 306728960\"),mdx(\"p\",null,\"total_pgpgin 406632648\"),mdx(\"p\",null,\"total_pgpgout 403355412\"),mdx(\"p\",null,\"total_swap 0\"),mdx(\"p\",null,\"total_pgfault 728281223\"),mdx(\"p\",null,\"total_pgmajfault 1724\"),mdx(\"p\",null,\"total_inactive_anon 46608384\"),mdx(\"p\",null,\"total_active_anon 1884520448\"),mdx(\"p\",null,\"total_inactive_file 7003344896\"),mdx(\"p\",null,\"total_active_file 4489052160\"),mdx(\"p\",null,\"total_unevictable 32768\"),mdx(\"p\",null,\"The first half (without the\\xA0total\",mdx(\"em\",{parentName:\"p\"},\"\\xA0prefix) contains statistics relevant to the processes within the cgroup, excluding sub-cgroups. The second half (with the\\xA0total\"),\"\\xA0prefix) includes sub-cgroups as well.\"),mdx(\"p\",null,\"Some metrics are \\\"gauges\\\", or values that can increase or decrease. For instance,\\xA0swap\\xA0isthe amount of swap space used by the members of the cgroup. Some others are \\\"counters\\\", or values that can only go up, because they represent occurrences of a specific event. For instance,\\xA0pgfault\\xA0indicates the number of page faults since the creation of the cgroup.\"),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Metric\"),\"                           \",mdx(\"strong\",{parentName:\"p\"},\"Description\")),mdx(\"hr\",null),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"cache\"),\"                            The amount of memory used by the processes of this control group that can be associated precisely with a block on a block device. When you read from and write to files on disk, this amount increases. This is the case if you use \\\"conventional\\\" I/O (open,\\xA0read,\\xA0write\\xA0syscalls) as well as mapped files (with\\xA0mmap). It also accounts for the memory used by\\xA0tmpfsmounts, though the reasons are unclear.\\n\",mdx(\"strong\",{parentName:\"p\"},\"rss\"),\"                              The amount of memory that\\xA0doesn't\\xA0correspond to anything on disk: stacks, heaps, and anonymous memory maps.\\n\",mdx(\"strong\",{parentName:\"p\"},\"mapped_file\"),\"                      Indicates the amount of memory mapped by the processes in the control group. It doesn't give you information about\\xA0how much\\xA0memory is used; it rather tells you\\xA0how\\xA0it is used.\\n\",mdx(\"strong\",{parentName:\"p\"},\"pgfault\"),\",\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"pgmajfault\"),\"          Indicate the number of times that a process of the cgroup triggered a \\\"page fault\\\" and a \\\"major fault\\\", respectively. A page fault happens when a process accesses a part of its virtual memory space which is nonexistent or protected. The former can happen if the process is buggy and tries to access an invalid address (it is sent a\\xA0SIGSEGV\\xA0signal, typically killing it with the famous\\xA0Segmentation fault\\xA0message). The latter can happen when the process reads from a memory zone which has been swapped out, or which corresponds to a mapped file: in that case, the kernel loads the page from disk, and let the CPU complete the memory access. It can also happen when the process writes to a copy-on-write memory zone: likewise, the kernel preempts the process, duplicate the memory page, and resume the write operation on the process` own copy of the page. \\\"Major\\\" faults happen when the kernel actually needs to read the data from disk. When it just duplicates an existing page, or allocate an empty page, it's a regular (or \\\"minor\\\") fault.\\n\",mdx(\"strong\",{parentName:\"p\"},\"swap\"),\"                             The amount of swap currently used by the processes in this cgroup.\\n\",mdx(\"strong\",{parentName:\"p\"},\"active_anon\"),\",\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"inactive_anon\"),\"   The amount of\\xA0anonymous\\xA0memory that has been identified has respectively\\xA0active\\xA0and\\xA0inactive\\xA0by the kernel. \\\"Anonymous\\\" memory is the memory that is\\xA0not\\xA0linked to disk pages. In other words, that's the equivalent of the rss counter described above. In fact, the very definition of the rss counter is\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"active_anon\"),\"\\xA0+\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"inactive_anon\"),\"\\xA0-\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"tmpfs\"),\"\\xA0(where tmpfs is the amount of memory used up by\\xA0tmpfs\\xA0filesystems mounted by this control group). Now, what's the difference between \\\"active\\\" and \\\"inactive\\\"? Pages are initially \\\"active\\\"; and at regular intervals, the kernel sweeps over the memory, and tags some pages as \\\"inactive\\\". Whenever they are accessed again, they are immediately retagged \\\"active\\\". When the kernel is almost out of memory, and time comes to swap out to disk, the kernel swaps \\\"inactive\\\" pages.\\n\",mdx(\"strong\",{parentName:\"p\"},\"active_file\"),\",\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"inactive_file\"),\"   Cache memory, with\\xA0active\\xA0and\\xA0inactive\\xA0similar to the\\xA0anonmemory above. The exact formula is\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"cache\"),\"\\xA0=\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"active_file\"),\"\\xA0+\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"inactive_file\"),\"\\xA0+\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"tmpfs\"),\". The exact rules used by the kernel to move memory pages between active and inactive sets are different from the ones used for anonymous memory, but the general principle is the same. When the kernel needs to reclaim memory, it is cheaper to reclaim a clean (=non modified) page from this pool, since it can be reclaimed immediately (while anonymous pages and dirty/modified pages need to be written to disk first).\\n\",mdx(\"strong\",{parentName:\"p\"},\"unevictable\"),\"                      The amount of memory that cannot be reclaimed; generally, it accounts for memory that has been \\\"locked\\\" with\\xA0mlock. It is often used by crypto frameworks to make sure that secret keys and other sensitive material never gets swapped out to disk.\\n\",mdx(\"strong\",{parentName:\"p\"},\"memory_limit\"),\",\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"memsw_limit\"),\"    These are not really metrics, but a reminder of the limits applied to this cgroup. The first one indicates the maximum amount of physical memory that can be used by the processes of this control group; the second one indicates the maximum amount of RAM+swap.\"),mdx(\"p\",null,\"Accounting for memory in the page cache is very complex. If two processes in different control groups both read the same file (ultimately relying on the same blocks on disk), the corresponding memory charge is split between the control groups. It's nice, but it also means that when a cgroup is terminated, it could increase the memory usage of another cgroup, because they are not splitting the cost anymore for those memory pages.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"CPU metrics:\\xA0cpuacct.stat\")),mdx(\"p\",null,\"Now that we've covered memory metrics, everything else is simple in comparison. CPU metrics are in the\\xA0cpuacct\\xA0controller.\"),mdx(\"p\",null,\"For each container, a pseudo-file\\xA0cpuacct.stat\\xA0contains the CPU usage accumulated by the processes of the container, broken down into\\xA0user\\xA0and\\xA0system\\xA0time. The distinction is:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"user\\xA0time is the amount of time a process has direct control of the CPU, executing process code.\"),mdx(\"li\",{parentName:\"ul\"},\"system\\xA0time is the time the kernel is executing system calls on behalf of the process.\")),mdx(\"p\",null,\"Those times are expressed in ticks of 1/100th of a second, also called \\\"user jiffies\\\". There are\\xA0USER_HZ\\xA0\\\"jiffies\\\"\\xA0per second, and on x86 systems,\\xA0USER_HZ\\xA0is 100. Historically, this mapped exactly to the number of scheduler \\\"ticks\\\" per second, but higher frequency scheduling and\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://lwn.net/Articles/549580/\"}),\"tickless kernels\"),\"\\xA0have made the number of ticks irrelevant.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"BLOCK I/O METRICS\")),mdx(\"p\",null,\"Block I/O is accounted in the\\xA0blkio\\xA0controller. Different metrics are scattered across different files. While you can find in-depth details in the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://www.kernel.org/doc/Documentation/cgroup-v1/blkio-controller.txt\"}),\"blkio-controller\"),\"\\xA0file in the kernel documentation, here is a short list of the most relevant ones:\"),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Metric\"),\"                   \",mdx(\"strong\",{parentName:\"p\"},\"Description\")),mdx(\"hr\",null),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"blkio.sectors\"),\"            Contains the number of 512-bytes sectors read and written by the processes member of the cgroup, device by device. Reads and writes are merged in a single counter.\\n\",mdx(\"strong\",{parentName:\"p\"},\"blkio.io_service_bytes\"),\"   Indicates the number of bytes read and written by the cgroup. It has 4 counters per device, because for each device, it differentiates between synchronous vs. asynchronous I/O, and reads vs. writes.\\n\",mdx(\"strong\",{parentName:\"p\"},\"blkio.io_serviced\"),\"        The number of I/O operations performed, regardless of their size. It also has 4 counters per device.\\n\",mdx(\"strong\",{parentName:\"p\"},\"blkio.io_queued\"),\"          Indicates the number of I/O operations currently queued for this cgroup. In other words, if the cgroup isn't doing any I/O, this is zero. The opposite is not true. In other words, if there is no I/O queued, it does not mean that the cgroup is idle (I/O-wise). It could be doing purely synchronous reads on an otherwise quiescent device, which can therefore handle them immediately, without queuing. Also, while it is helpful to figure out which cgroup is putting stress on the I/O subsystem, keep in mind that it is a relative quantity. Even if a process group does not perform more I/O, its queue size can increase just because the device load increases because of other devices.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Network metrics\")),mdx(\"p\",null,\"Network metrics are not exposed directly by control groups. There is a good explanation for that: network interfaces exist within the context of\\xA0network namespaces. The kernel could probably accumulate metrics about packets and bytes sent and received by a group of processes, but those metrics wouldn't be very useful. You want per-interface metrics (because traffic happening on the local\\xA0lo\\xA0interface doesn't really count). But since processes in a single cgroup can belong to multiple network namespaces, those metrics would be harder to interpret: multiple network namespaces means multiple\\xA0lo\\xA0interfaces, potentially multiple\\xA0eth0\\xA0interfaces, etc.; so this is why there is no easy way to gather network metrics with control groups.\"),mdx(\"p\",null,\"Instead we can gather network metrics from other sources:\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"IPTABLES\")),mdx(\"p\",null,\"IPtables (or rather, the netfilter framework for which iptables is just an interface) can do some serious accounting.\"),mdx(\"p\",null,\"For instance, you can setup a rule to account for the outbound HTTP traffic on a web server:\"),mdx(\"p\",null,\"$ iptables -I OUTPUT -p tcp --sport 80\"),mdx(\"p\",null,\"There is no\\xA0-j\\xA0or\\xA0-g\\xA0flag, so the rule just counts matched packets and goes to the following rule.\"),mdx(\"p\",null,\"Later, you can check the values of the counters, with:\"),mdx(\"p\",null,\"$ iptables -nxvL OUTPUT\"),mdx(\"p\",null,\"Technically,\\xA0-n\\xA0is not required, but it prevents iptables from doing DNS reverse lookups, which are probably useless in this scenario.\"),mdx(\"p\",null,\"Counters include packets and bytes. If you want to setup metrics for container traffic like this, you could execute a\\xA0for\\xA0loop to add two\\xA0iptables\\xA0rules per container IP address (one in each direction), in the\\xA0FORWARD\\xA0chain. This only meters traffic going through the NAT layer; you also need to add traffic going through the userland proxy.\"),mdx(\"p\",null,\"Then, you need to check those counters on a regular basis. If you happen to use\\xA0collectd, there is a\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://collectd.org/wiki/index.php/Table_of_Plugins\"}),\"nice plugin\"),\"\\xA0to automate iptables counters collection.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"INTERFACE-LEVEL COUNTERS\")),mdx(\"p\",null,\"Since each container has a virtual Ethernet interface, you might want to check directly the TX and RX counters of this interface. Each container is associated to a virtual Ethernet interface in your host, with a name like\\xA0vethKk8Zqi. Figuring out which interface corresponds to which container is, unfortunately, difficult.\"),mdx(\"p\",null,\"But for now, the best way is to check the metrics\\xA0from within the containers. To accomplish this, you can run an executable from the host environment within the network namespace of a container using\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"ip-netns magic\"),\".\"),mdx(\"p\",null,\"The\\xA0ip-netns exec\\xA0command allows you to execute any program (present in the host system) within any network namespace visible to the current process. This means that your host can enter the network namespace of your containers, but your containers can't access the host or other peer containers. Containers can interact with their sub-containers, though.\"),mdx(\"p\",null,\"The exact format of the command is:\"),mdx(\"p\",null,\"$ ip netns exec \",mdx(\"inlineCode\",{parentName:\"p\"},\"<nsname> <command...>\")),mdx(\"p\",null,\"For example:\"),mdx(\"p\",null,\"$ ip netns exec mycontainer netstat -i\"),mdx(\"p\",null,\"ip netns\\xA0finds the \\\"mycontainer\\\" container by using namespaces pseudo-files. Each process belongs to one network namespace, one PID namespace, one\\xA0mnt\\xA0namespace, etc., and those namespaces are materialized under\\xA0/proc/\",mdx(\"inlineCode\",{parentName:\"p\"},\"<pid>\"),\"/ns/. For example, the network namespace of PID 42 is materialized by the pseudo-file\\xA0/proc/42/ns/net.\"),mdx(\"p\",null,\"When you run\\xA0ip netns exec mycontainer ..., it expects\\xA0/var/run/netns/mycontainer\\xA0to be one of those pseudo-files. (Symlinks are accepted.)\"),mdx(\"p\",null,\"In other words, to execute a command within the network namespace of a container, we need to:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Find out the PID of any process within the container that we want to investigate;\"),mdx(\"li\",{parentName:\"ul\"},\"Create a symlink from\\xA0/var/run/netns/\",mdx(\"inlineCode\",{parentName:\"li\"},\"<somename>\\xA0to\\xA0/proc/<thepid>\"),\"/ns/net\"),mdx(\"li\",{parentName:\"ul\"},\"Execute\\xA0ip netns exec \",mdx(\"inlineCode\",{parentName:\"li\"},\"<somename>\"),\" ....\")),mdx(\"p\",null,\"Review\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/containers/runmetrics/#enumerate-cgroups\"}),\"Enumerate Cgroups\"),\"\\xA0for how to find the cgroup of an in-container process whose network usage you want to measure. From there, you can examine the pseudo-file named\\xA0tasks, which contains all the PIDs in the cgroup (and thus, in the container). Pick any one of the PIDs.\"),mdx(\"p\",null,\"Putting everything together, if the \\\"short ID\\\" of a container is held in the environment variable\\xA0$CID, then you can do this:\"),mdx(\"p\",null,\"$ TASKS=/sys/fs/cgroup/devices/docker/$CID*/tasks\"),mdx(\"p\",null,\"$ PID=$(head -n 1 $TASKS)\"),mdx(\"p\",null,\"$ mkdir -p /var/run/netns\"),mdx(\"p\",null,\"$ ln -sf /proc/$PID/ns/net /var/run/netns/$CID\"),mdx(\"p\",null,\"$ ip netns exec $CID netstat -i\"),mdx(\"h4\",null,\"Tips for high-performance metric collection\"),mdx(\"p\",null,\"Running a new process each time you want to update metrics is (relatively) expensive. If you want to collect metrics at high resolutions, and/or over a large number of containers (think 1000 containers on a single host), you do not want to fork a new process each time.\"),mdx(\"p\",null,\"Here is how to collect metrics from a single process. You need to write your metric collector in C (or any language that lets you do low-level system calls). You need to use a special system call,setns(), which lets the current process enter any arbitrary namespace. It requires, however, an open file descriptor to the namespace pseudo-file (remember: that's the pseudo-file in/proc/\",mdx(\"inlineCode\",{parentName:\"p\"},\"<pid>\"),\"/ns/net).\"),mdx(\"p\",null,\"However, there is a catch: you must not keep this file descriptor open. If you do, when the last process of the control group exits, the namespace is not destroyed, and its network resources (like the virtual interface of the container) stays around forever (or until you close that file descriptor).\"),mdx(\"p\",null,\"The right approach would be to keep track of the first PID of each container, and re-open the namespace pseudo-file each time.\"),mdx(\"h4\",null,\"Collect metrics when a container exits\"),mdx(\"p\",null,\"Sometimes, you do not care about real time metric collection, but when a container exits, you want to know how much CPU, memory, etc. it has used.\"),mdx(\"p\",null,\"Docker makes this difficult because it relies on\\xA0lxc-start, which carefully cleans up after itself. It is usually easier to collect metrics at regular intervals, and this is the way the\\xA0collectd\\xA0LXC plugin works.\"),mdx(\"p\",null,\"But, if you'd still like to gather the stats when a container stops, here is how:\"),mdx(\"p\",null,\"For each container, start a collection process, and move it to the control groups that you want to monitor by writing its PID to the tasks file of the cgroup. The collection process should periodically re-read the tasks file to check if it's the last process of the control group. (If you also want to collect network statistics as explained in the previous section, you should also move the process to the appropriate network namespace.)\"),mdx(\"p\",null,\"When the container exits,\\xA0lxc-start\\xA0attempts to delete the control groups. It fails, since the control group is still in use; but that's fine. Your process should now detect that it is the only one remaining in the group. Now is the right time to collect all the metrics you need!\"),mdx(\"p\",null,\"Finally, your process should move itself back to the root control group, and remove the container control group. To remove a control group, just\\xA0rmdir\\xA0its directory. It's counter-intuitive tormdir\\xA0a directory as it still contains files; but remember that this is a pseudo-filesystem, so usual rules don't apply. After the cleanup is done, the collection process can exit safely.\"),mdx(\"h3\",null,\"Limit a container\\\\'s resources\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA013 minutes\")),mdx(\"p\",null,\"By default, a container has no resource constraints and can use as much of a given resource as the host's kernel scheduler allows. Docker provides ways to control how much memory, CPU, or block IO a container can use, setting runtime configuration flags of the\\xA0docker run\\xA0command. This section provides details on when you should set such limits and the possible implications of setting them.\"),mdx(\"p\",null,\"Many of these features require your kernel to support Linux capabilities. To check for support, you can use the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/info/\"}),\"docker info\"),\"\\xA0command. If a capability is disabled in your kernel, you may see a warning at the end of the output like the following:\"),mdx(\"p\",null,\"WARNING: No swap limit support\"),mdx(\"p\",null,\"Consult your operating system's documentation for enabling them.\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/install/linux/linux-postinstall/#your-kernel-does-not-support-cgroup-swap-limit-capabilities\"}),\"Learn more\"),\".\"),mdx(\"h4\",null,\"Memory\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Understand the risks of running out of memory\")),mdx(\"p\",null,\"It is important not to allow a running container to consume too much of the host machine's memory. On Linux hosts, if the kernel detects that there is not enough memory to perform important system functions, it throws an\\xA0OOME, or\\xA0Out Of Memory Exception, and starts killing processes to free up memory. Any process is subject to killing, including Docker and other important applications. This can effectively bring the entire system down if the wrong process is killed.\"),mdx(\"p\",null,\"Docker attempts to mitigate these risks by adjusting the OOM priority on the Docker daemon so that it is less likely to be killed than other processes on the system. The OOM priority on containers is not adjusted. This makes it more likely for an individual container to be killed than for the Docker daemon or other system processes to be killed. You should not try to circumvent these safeguards by manually setting\\xA0--oom-score-adj\\xA0to an extreme negative number on the daemon or a container, or by setting\\xA0--oom-disable-kill\\xA0on a container.\"),mdx(\"p\",null,\"For more information about the Linux kernel's OOM management, see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://www.kernel.org/doc/gorman/html/understand/understand016.html\"}),\"Out of Memory Management\"),\".\"),mdx(\"p\",null,\"You can mitigate the risk of system instability due to OOME by:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Perform tests to understand the memory requirements of your application before placing it into production.\"),mdx(\"li\",{parentName:\"ul\"},\"Ensure that your application runs only on hosts with adequate resources.\"),mdx(\"li\",{parentName:\"ul\"},\"Limit the amount of memory your container can use, as described below.\"),mdx(\"li\",{parentName:\"ul\"},\"Be mindful when configuring swap on your Docker hosts. Swap is slower and less performant than memory but can provide a buffer against running out of system memory.\"),mdx(\"li\",{parentName:\"ul\"},\"Consider converting your container to a\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/services/\"}),\"service\"),\", and using service-level constraints and node labels to ensure that the application runs only on hosts with enough memory\")),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Limit a container's access to memory\")),mdx(\"p\",null,\"Docker can enforce hard memory limits, which allow the container to use no more than a given amount of user or system memory, or soft limits, which allow the container to use as much memory as it needs unless certain conditions are met, such as when the kernel detects low memory or contention on the host machine. Some of these options have different effects when used alone or when more than one option is set.\"),mdx(\"p\",null,\"Most of these options take a positive integer, followed by a suffix of\\xA0b,\\xA0k,\\xA0m,\\xA0g, to indicate bytes, kilobytes, megabytes, or gigabytes.\"),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Option\"),\"              \",mdx(\"strong\",{parentName:\"p\"},\"Description\")),mdx(\"hr\",null),mdx(\"p\",null,\"  -m\\xA0or\\xA0--memory=        The maximum amount of memory the container can use. If you set this option, the minimum allowed value is\\xA04m\\xA0(4 megabyte).\\n--memory-swap*        The amount of memory this container is allowed to swap to disk. See\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/containers/resource_constraints/#--memory-swap-details\"}),\"--memory-swap\\xA0details\"),\".\\n--memory-swappiness    By default, the host kernel can swap out a percentage of anonymous pages used by a container. You can set\\xA0--memory-swappiness\\xA0to a value between 0 and 100, to tune this percentage. See\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/containers/resource_constraints/#--memory-swappiness-details\"}),\"--memory-swappiness\\xA0details\"),\".\\n--memory-reservation   Allows you to specify a soft limit smaller than\\xA0--memory\\xA0which is activated when Docker detects contention or low memory on the host machine. If you use\\xA0--memory-reservation, it must be set lower than\\xA0--memory\\xA0for it to take precedence. Because it is a soft limit, it does not guarantee that the container doesn't exceed the limit.\\n--kernel-memory        The maximum amount of kernel memory the container can use. The minimum allowed value is\\xA04m. Because kernel memory cannot be swapped out, a container which is starved of kernel memory may block host machine resources, which can have side effects on the host machine and on other containers. See\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/containers/resource_constraints/#--kernel-memory-details\"}),\"--kernel-memorydetails\"),\".\\n--oom-kill-disable     By default, if an out-of-memory (OOM) error occurs, the kernel kills processes in a container. To change this behavior, use the\\xA0--oom-kill-disable\\xA0option. Only disable the OOM killer on containers where you have also set the\\xA0-m/--memory\\xA0option. If the\\xA0-m\\xA0flag is not set, the host can run out of memory and the kernel may need to kill the host system's processes to free memory.\"),mdx(\"p\",null,\"For more information about cgroups and memory in general, see the documentation for\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://www.kernel.org/doc/Documentation/cgroup-v1/memory.txt\"}),\"Memory Resource Controller\"),\".\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"--memory-swap\\xA0details\")),mdx(\"p\",null,\"--memory-swap\\xA0is a modifier flag that only has meaning if\\xA0--memory\\xA0is also set. Using swap allows the container to write excess memory requirements to disk when the container has exhausted all the RAM that is available to it. There is a performance penalty for applications that swap memory to disk often.\"),mdx(\"p\",null,\"Its setting can have complicated effects:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"If\\xA0--memory-swap\\xA0is set to a positive integer, then both\\xA0--memory\\xA0and\\xA0--memory-swapmust be set.\\xA0--memory-swap\\xA0represents the total amount of memory and swap that can be used, and\\xA0--memory\\xA0controls the amount used by non-swap memory. So if\\xA0--memory=\\\"300m\\\"\\xA0and\\xA0--memory-swap=\\\"1g\\\", the container can use 300m of memory and 700m (1g - 300m) swap.\"),mdx(\"li\",{parentName:\"ul\"},\"If\\xA0--memory-swap\\xA0is set to\\xA00, the setting is ignored, and the value is treated as unset.\"),mdx(\"li\",{parentName:\"ul\"},\"If\\xA0--memory-swap\\xA0is set to the same value as\\xA0--memory, and\\xA0--memory\\xA0is set to a positive integer,\\xA0\",mdx(\"strong\",{parentName:\"li\"},\"the container does not have access to swap\"),\". See\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/config/containers/resource_constraints/#prevent-a-container-from-using-swap\"}),\"Prevent a container from using swap\"),\".\"),mdx(\"li\",{parentName:\"ul\"},\"If\\xA0--memory-swap\\xA0is unset, and\\xA0--memory\\xA0is set, the container can use twice as much swap as the\\xA0--memory\\xA0setting, if the host container has swap memory configured. For instance, if\\xA0--memory=\\\"300m\\\"\\xA0and\\xA0--memory-swap\\xA0is not set, the container can use 300m of memory and 600m of swap.\"),mdx(\"li\",{parentName:\"ul\"},\"If\\xA0--memory-swap\\xA0is explicitly set to\\xA0-1, the container is allowed to use unlimited swap, up to the amount available on the host system.\")),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"PREVENT A CONTAINER FROM USING SWAP\")),mdx(\"p\",null,\"If\\xA0--memory\\xA0and\\xA0--memory-swap\\xA0are set to the same value, this prevents containers from using any swap. This is because\\xA0--memory-swap\\xA0is the amount of combined memory and swap that can be used, while\\xA0--memory\\xA0is only the amount of physical memory that can be used.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"--memory-swappiness\\xA0details\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"A value of 0 turns off anonymous page swapping.\"),mdx(\"li\",{parentName:\"ul\"},\"A value of 100 sets all anonymous pages as swappable.\"),mdx(\"li\",{parentName:\"ul\"},\"By default, if you do not set\\xA0--memory-swappiness, the value is inherited from the host machine.\")),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"--kernel-memory\\xA0details\")),mdx(\"p\",null,\"Kernel memory limits are expressed in terms of the overall memory allocated to a container. Consider the following scenarios:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Unlimited memory, unlimited kernel memory\"),\": This is the default behavior.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Unlimited memory, limited kernel memory\"),\": This is appropriate when the amount of memory needed by all cgroups is greater than the amount of memory that actually exists on the host machine. You can configure the kernel memory to never go over what is available on the host machine, and containers which need more memory need to wait for it.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Limited memory, unlimited kernel memory\"),\": The overall memory is limited, but the kernel memory is not.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Limited memory, limited kernel memory\"),\": Limiting both user and kernel memory can be useful for debugging memory-related problems. If a container is using an unexpected amount of either type of memory, it runs out of memory without affecting other containers or the host machine. Within this setting, if the kernel memory limit is lower than the user memory limit, running out of kernel memory causes the container to experience an OOM error. If the kernel memory limit is higher than the user memory limit, the kernel limit does not cause the container to experience an OOM.\")),mdx(\"p\",null,\"When you turn on any kernel memory limits, the host machine tracks \\\"high water mark\\\" statistics on a per-process basis, so you can track which processes (in this case, containers) are using excess memory. This can be seen per process by viewing\\xA0/proc/\",mdx(\"inlineCode\",{parentName:\"p\"},\"<PID>\"),\"/status\\xA0on the host machine.\"),mdx(\"h4\",null,\"CPU\"),mdx(\"p\",null,\"By default, each container's access to the host machine's CPU cycles is unlimited. You can set various constraints to limit a given container's access to the host machine's CPU cycles. Most users use and configure the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/containers/resource_constraints/#configure-the-default-cfs-scheduler\"}),\"default CFS scheduler\"),\". In Docker 1.13 and higher, you can also configure the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/containers/resource_constraints/#configure-the-realtime-scheduler\"}),\"realtime scheduler\"),\".\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Configure the default CFS scheduler\")),mdx(\"p\",null,\"The CFS is the Linux kernel CPU scheduler for normal Linux processes. Several runtime flags allow you to configure the amount of access to CPU resources your container has. When you use these settings, Docker modifies the settings for the container's cgroup on the host machine.\"),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Option\"),\"                \",mdx(\"strong\",{parentName:\"p\"},\"Description\")),mdx(\"hr\",null),mdx(\"p\",null,\"  --cpus=\",mdx(\"inlineCode\",{parentName:\"p\"},\"<value>\"),\"         Specify how much of the available CPU resources a container can use. For instance, if the host machine has two CPUs and you set\\xA0--cpus=\\\"1.5\\\", the container is guaranteed at most one and a half of the CPUs. This is the equivalent of setting\\xA0--cpu-period=\\\"100000\\\"\\xA0and\\xA0--cpu-quota=\\\"150000\\\". Available in Docker 1.13 and higher.\\n--cpu-period=\",mdx(\"inlineCode\",{parentName:\"p\"},\"<value>\"),\"   Specify the CPU CFS scheduler period, which is used alongside--cpu-quota. Defaults to 100 micro-seconds. Most users do not change this from the default. If you use Docker 1.13 or higher, use\\xA0--cpus\\xA0instead.\\n--cpu-quota=\",mdx(\"inlineCode\",{parentName:\"p\"},\"<value>\"),\"    Impose a CPU CFS quota on the container. The number of microseconds per\\xA0--cpu-period\\xA0that the container is guaranteed CPU access. In other words,\\xA0cpu-quota / cpu-period. If you use Docker 1.13 or higher, use\\xA0--cpus\\xA0instead.\\n--cpuset-cpus            Limit the specific CPUs or cores a container can use. A comma-separated list or hyphen-separated range of CPUs a container can use, if you have more than one CPU. The first CPU is numbered 0. A valid value might be\\xA00-3\\xA0(to use the first, second, third, and fourth CPU) or\\xA01,3\\xA0(to use the second and fourth CPU).\\n--cpu-shares             Set this flag to a value greater or less than the default of 1024 to increase or reduce the container's weight, and give it access to a greater or lesser proportion of the host machine's CPU cycles. This is only enforced when CPU cycles are constrained. When plenty of CPU cycles are available, all containers use as much CPU as they need. In that way, this is a soft limit.\\xA0--cpu-shares\\xA0does not prevent containers from being scheduled in swarm mode. It prioritizes container CPU resources for the available CPU cycles. It does not guarantee or reserve any specific CPU access.\"),mdx(\"p\",null,\"If you have 1 CPU, each of the following commands guarantees the container at most 50% of the CPU every second.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Docker 1.13 and higher\"),\":\"),mdx(\"p\",null,\"docker run -it --cpus=\\\".5\\\" ubuntu /bin/bash\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Docker 1.12 and lower\"),\":\"),mdx(\"p\",null,\"$ docker run -it --cpu-period=100000 --cpu-quota=50000 ubuntu /bin/bash\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Configure the realtime scheduler\")),mdx(\"p\",null,\"In Docker 1.13 and higher, you can configure your container to use the realtime scheduler, for tasks which cannot use the CFS scheduler. You need to\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/containers/resource_constraints/#configure-the-host-machines-kernel\"}),\"make sure the host machine's kernel is configured correctly\"),\"\\xA0before you can\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/containers/resource_constraints/#configure-the-docker-daemon\"}),\"configure the Docker daemon\"),\"\\xA0or\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/containers/resource_constraints/#configure-individual-containers\"}),\"configure individual containers\"),\".\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Warning\"),\": CPU scheduling and prioritization are advanced kernel-level features. Most users do not need to change these values from their defaults. Setting these values incorrectly can cause your host system to become unstable or unusable.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"CONFIGURE THE HOST MACHINE'S KERNEL\")),mdx(\"p\",null,\"Verify that\\xA0CONFIG_RT_GROUP_SCHED\\xA0is enabled in the Linux kernel by runningzcat /proc/config.gz | grep CONFIG_RT_GROUP_SCHED\\xA0or by checking for the existence of the file\\xA0/sys/fs/cgroup/cpu.rt_runtime_us. For guidance on configuring the kernel realtime scheduler, consult the documentation for your operating system.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"CONFIGURE THE DOCKER DAEMON\")),mdx(\"p\",null,\"To run containers using the realtime scheduler, run the Docker daemon with the\\xA0--cpu-rt-runtime\\xA0flag set to the maximum number of microseconds reserved for realtime tasks per runtime period. For instance, with the default period of 1000000 microseconds (1 second), setting\\xA0--cpu-rt-runtime=950000\\xA0ensures that containers using the realtime scheduler can run for 950000 microseconds for every 1000000-microsecond period, leaving at least 50000 microseconds available for non-realtime tasks. To make this configuration permanent on systems which use\\xA0systemd, see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/daemon/systemd/\"}),\"Control and configure Docker with systemd\"),\".\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"CONFIGURE INDIVIDUAL CONTAINERS\")),mdx(\"p\",null,\"You can pass several flags to control a container's CPU priority when you start the container using\\xA0docker run. Consult your operating system's documentation or the\\xA0ulimit\\xA0command for information on appropriate values.\"),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Option\"),\"                    \",mdx(\"strong\",{parentName:\"p\"},\"Description\")),mdx(\"hr\",null),mdx(\"p\",null,\"  --cap-add=sys_nice           Grants the container the\\xA0CAP_SYS_NICE\\xA0capability, which allows the container to raise process\\xA0nice\\xA0values, set real-time scheduling policies, set CPU affinity, and other operations.\\n--cpu-rt-runtime=\",mdx(\"inlineCode\",{parentName:\"p\"},\"<value>\"),\"   The maximum number of microseconds the container can run at realtime priority within the Docker daemon's realtime scheduler period. You also need the\\xA0--cap-add=sys_nice\\xA0flag.\\n--ulimit rtprio=\",mdx(\"inlineCode\",{parentName:\"p\"},\"<value>\"),\"    The maximum realtime priority allowed for the container. You also need the\\xA0--cap-add=sys_nice\\xA0flag.\"),mdx(\"p\",null,\"The following example command sets each of these three flags on a\\xA0debian:jessie\\xA0container.\"),mdx(\"p\",null,\"$ docker run --it --cpu-rt-runtime=950000 \\\\\"),mdx(\"p\",null,\"--ulimit rtprio=99 \\\\\"),mdx(\"p\",null,\"--cap-add=sys_nice \\\\\"),mdx(\"p\",null,\"debian:jessie\"),mdx(\"p\",null,\"If the kernel or Docker daemon is not configured correctly, an error occurs.\"),mdx(\"h3\",null,\"Logging\"),mdx(\"h4\",null,\"View logs for a container or service\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA02 minutes\")),mdx(\"p\",null,\"The\\xA0docker logs\\xA0command shows information logged by a running container. Thedocker service logs\\xA0command shows information logged by all containers participating in a service. The information that is logged and the format of the log depends almost entirely on the container's endpoint command.\"),mdx(\"p\",null,\"By default,\\xA0docker logs\\xA0or\\xA0docker service logs\\xA0shows the command's output just as it would appear if you ran the command interactively in a terminal. UNIX and Linux commands typically open three I/O streams when they run, called\\xA0STDIN,\\xA0STDOUT, and\\xA0STDERR.\\xA0STDIN\\xA0is the commmand's input stream, which may include input from the keyboard or input from another command.\\xA0STDOUT\\xA0is usually a command's normal output, and\\xA0STDERR\\xA0is typically used to output error messages. By default,\\xA0docker logs\\xA0shows the command's\\xA0STDOUT\\xA0and\\xA0STDERR. To read more about I/O and Linux, see the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://www.tldp.org/LDP/abs/html/io-redirection.html\"}),\"Linux Documentation Project article on I/O redirection\"),\".\"),mdx(\"p\",null,\"In some cases,\\xA0docker logs\\xA0may not show useful information unless you take additional steps.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"If you use a\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/config/containers/logging/configure/\"}),\"logging driver\"),\"\\xA0which sends logs to a file, an external host, a database, or another logging back-end,\\xA0docker logs\\xA0may not show useful information.\"),mdx(\"li\",{parentName:\"ul\"},\"If your image runs a non-interactive process such as a web server or a database, that application may send its output to log files instead of\\xA0STDOUT\\xA0and\\xA0STDERR.\")),mdx(\"p\",null,\"In the first case, your logs are processed in other ways and you may choose not to use\\xA0docker logs. In the second case, the official\\xA0nginx\\xA0image shows one workaround, and the official Apache\\xA0httpd\\xA0image shows another.\"),mdx(\"p\",null,\"The official\\xA0nginx\\xA0image creates a symbolic link from\\xA0/dev/stdout\\xA0to\\xA0/var/log/nginx/access.log, and creates another symbolic link from\\xA0/dev/stderr\\xA0to\\xA0/var/log/nginx/error.log, overwriting the log files and causing logs to be sent to the relevant special device instead. See the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/nginxinc/docker-nginx/blob/8921999083def7ba43a06fabd5f80e4406651353/mainline/jessie/Dockerfile#L21-L23\"}),\"Dockerfile\"),\".\"),mdx(\"p\",null,\"The official\\xA0httpd\\xA0driver changes the\\xA0httpd\\xA0application's configuration to write its normal output directly to\\xA0/proc/self/fd/1\\xA0(which is\\xA0STDOUT) and its errors to\\xA0/proc/self/fd/2\\xA0(which is\\xA0STDERR). See the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/docker-library/httpd/blob/b13054c7de5c74bbaa6d595dbe38969e6d4f860c/2.2/Dockerfile#L72-L75\"}),\"Dockerfile\"),\".\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Next steps\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Configure\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/config/containers/logging/configure/\"}),\"logging drivers\"),\".\"),mdx(\"li\",{parentName:\"ul\"},\"Write a\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/builder/\"}),\"Dockerfile\"),\".\")),mdx(\"h4\",null,\"Configure logging drivers\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA06 minutes\")),mdx(\"p\",null,\"Docker includes multiple logging mechanisms to help you\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/admin/logging/view_container_logs/\"}),\"get information from running containers and services\"),\". These mechanisms are called logging drivers.\"),mdx(\"p\",null,\"Each Docker daemon has a default logging driver, which each container uses unless you configure it to use a different logging driver.\"),mdx(\"p\",null,\"In addition to using the logging drivers included with Docker, you can also implement and use\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/admin/logging/plugins/\"}),\"logging driver plugins\"),\". Logging driver plugins are available in Docker 17.05 and higher.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Configure the default logging driver\")),mdx(\"p\",null,\"To configure the Docker daemon to default to a specific logging driver, set the value of\\xA0log-driver\\xA0to the name of the logging driver in the\\xA0daemon.json\\xA0file, which is located in\\xA0/etc/docker/\\xA0on Linux hosts or\\xA0C:\\\\ProgramData\\\\docker\\\\config\\\\\\xA0on Windows server hosts. The default logging driver is\\xA0json-file. The following example explicitly sets the default logging driver to\\xA0syslog:\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"log-driver\\\": \\\"syslog\\\"\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"If the logging driver has configurable options, you can set them in the\\xA0daemon.json\\xA0file as a JSON array with the key\\xA0log-opts. The following example sets two configurable options on the\\xA0json-file\\xA0logging driver:\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"log-driver\\\": \\\"json-file\\\",\"),mdx(\"p\",null,\"\\\"log-opts\\\": {\"),mdx(\"p\",null,\"\\\"labels\\\": \\\"production_status\\\",\"),mdx(\"p\",null,\"\\\"env\\\": \\\"os,customer\\\"\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"If you do not specify a logging driver, the default is\\xA0json-file. Thus, the default output for commands such as\\xA0docker inspect \",mdx(\"inlineCode\",{parentName:\"p\"},\"<CONTAINER>\"),\"\\xA0is JSON.\"),mdx(\"p\",null,\"To find the current default logging driver for the Docker daemon, run\\xA0docker info\\xA0and search for\\xA0Logging Driver. You can use the following command on Linux, macOS, or PowerShell on Windows:\"),mdx(\"p\",null,\"$ docker info | grep \\\\'Logging Driver\\\\'\"),mdx(\"p\",null,\"Logging Driver: json-file\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Configure the logging driver for a container\")),mdx(\"p\",null,\"When you start a container, you can configure it to use a different logging driver than the Docker daemon's default, using the\\xA0--log-driver\\xA0flag. If the logging driver has configurable options, you can set them using one or more instances of the\\xA0--log-opt \",mdx(\"inlineCode\",{parentName:\"p\"},\"<NAME>=<VALUE>\"),\"\\xA0flag. Even if the container uses the default logging driver, it can use different configurable options.\"),mdx(\"p\",null,\"The following example starts an Alpine container with the\\xA0none\\xA0logging driver.\"),mdx(\"p\",null,\"$ docker run -it --log-driver none alpine ash\"),mdx(\"p\",null,\"To find the current logging driver for a running container, if the daemon is using the\\xA0json-filelogging driver, run the following\\xA0docker inspect\\xA0command, substituting the container name or ID for\\xA0\",mdx(\"inlineCode\",{parentName:\"p\"},\"<CONTAINER>\"),\":\"),mdx(\"p\",null,\"$ docker inspect -f \\\\'{{.HostConfig.LogConfig.Type}}\\\\' \",mdx(\"inlineCode\",{parentName:\"p\"},\"<CONTAINER>\")),mdx(\"p\",null,\"json-file\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Configure the delivery mode of log messages from container to log driver\")),mdx(\"p\",null,\"Docker provides two modes for delivering messages from the container to the log driver:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"(default) direct, blocking delivery from container to driver\"),mdx(\"li\",{parentName:\"ul\"},\"non-blocking delivery that stores log messages in an intermediate per-container ring buffer for consumption by driver\")),mdx(\"p\",null,\"The\\xA0non-blocking\\xA0message delivery mode prevents applications from blocking due to logging back pressure. Applications are likely to fail in unexpected ways when STDERR or STDOUT streams block.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"WARNING\"),\": When the buffer is full and a new message is enqueued, the oldest message in memory is dropped. Dropping messages is often preferred to blocking the log-writing process of an application.\"),mdx(\"p\",null,\"The\\xA0mode\\xA0log option controls whether to use the\\xA0blocking\\xA0(default) or\\xA0non-blocking\\xA0message delivery.\"),mdx(\"p\",null,\"The\\xA0max-buffer-size\\xA0log option controls the size of the ring buffer used for intermediate message storage when\\xA0mode\\xA0is set to\\xA0non-blocking.\\xA0max-buffer-size\\xA0defaults to 1 megabyte.\"),mdx(\"p\",null,\"The following example starts an Alpine container with log output in non-blocking mode and a 4 megabyte buffer:\"),mdx(\"p\",null,\"$ docker run -it --log-opt mode=non-blocking --log-opt max-buffer-size=4m alpine ping 127.0.0.1\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Use environment variables or labels with logging drivers\")),mdx(\"p\",null,\"Some logging drivers add the value of a container's\\xA0--env|-e\\xA0or\\xA0--label\\xA0flags to the container's logs. This example starts a container using the Docker daemon's default logging driver (let's assume\\xA0json-file) but sets the environment variable\\xA0os=ubuntu.\"),mdx(\"p\",null,\"$ docker run -dit --label production_status=testing -e os=ubuntu alpine sh\"),mdx(\"p\",null,\"If the logging driver supports it, this adds additional fields to the logging output. The following output is generated by the\\xA0json-file\\xA0logging driver:\"),mdx(\"p\",null,\"\\\"attrs\\\":{\\\"production_status\\\":\\\"testing\\\",\\\"os\\\":\\\"ubuntu\\\"}\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Supported logging drivers\")),mdx(\"p\",null,\"The following logging drivers are supported. See the link to each driver's documentation for its configurable options, if applicable. If you are using\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/admin/logging/plugins/\"}),\"logging driver plugins\"),\", you may see more options.\"),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Driver\"),\"                                                                    \",mdx(\"strong\",{parentName:\"p\"},\"Description\")),mdx(\"hr\",null),mdx(\"p\",null,\"  none                                                                          No logs are available for the container and\\xA0docker logs\\xA0does not return any output.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/containers/logging/json-file/\"}),\"json-file\"),\"     The logs are formatted as JSON. The default logging driver for Docker.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/containers/logging/syslog/\"}),\"syslog\"),\"           Writes logging messages to the\\xA0syslog\\xA0facility. The\\xA0syslog\\xA0daemon must be running on the host machine.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/containers/logging/journald/\"}),\"journald\"),\"       Writes log messages to\\xA0journald. The\\xA0journald\\xA0daemon must be running on the host machine.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/containers/logging/gelf/\"}),\"gelf\"),\"               Writes log messages to a Graylog Extended Log Format (GELF) endpoint such as Graylog or Logstash.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/containers/logging/fluentd/\"}),\"fluentd\"),\"         Writes log messages to\\xA0fluentd\\xA0(forward input). The\\xA0fluentd\\xA0daemon must be running on the host machine.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/containers/logging/awslogs/\"}),\"awslogs\"),\"         Writes log messages to Amazon CloudWatch Logs.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/containers/logging/splunk/\"}),\"splunk\"),\"           Writes log messages to\\xA0splunk\\xA0using the HTTP Event Collector.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/containers/logging/etwlogs/\"}),\"etwlogs\"),\"         Writes log messages as Event Tracing for Windows (ETW) events. Only available on Windows platforms.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/containers/logging/gcplogs/\"}),\"gcplogs\"),\"         Writes log messages to Google Cloud Platform (GCP) Logging.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/containers/logging/logentries/\"}),\"logentries\"),\"   Writes log messages to Rapid7 Logentries.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Limitations of logging drivers\")),mdx(\"p\",null,\"The\\xA0docker logs\\xA0command is not available for drivers other than\\xA0json-file\\xA0and\\xA0journald.\"),mdx(\"h4\",null,\"Use a logging driver plugin\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA01 minute\")),mdx(\"p\",null,\"Docker logging plugins allow you to extend and customize Docker's logging capabilities beyond those of the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/containers/logging/configure/\"}),\"built-in logging drivers\"),\". A logging service provider can\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/extend/plugins_logging/\"}),\"implement their own plugins\"),\"and make them available on Docker Hub, Docker Store, or a private registry. This topic shows how a user of that logging service can configure Docker to use the plugin.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Install the logging driver plugin\")),mdx(\"p\",null,\"To install a logging driver plugin, use\\xA0docker plugin install \",mdx(\"inlineCode\",{parentName:\"p\"},\"<org/image>\"),\", using the information provided by the plugin developer.\"),mdx(\"p\",null,\"You can list all installed plugins using\\xA0docker plugin ls, and you can inspect a specific plugin using\\xA0docker inspect.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Configure the plugin as the default logging driver\")),mdx(\"p\",null,\"After the plugin is installed, you can configure the Docker daemon to use it as the default by setting the plugin's name as the value of the\\xA0logging-driver\\xA0key in the\\xA0daemon.json, as detailed in the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/containers/logging/configure/#configure-the-default-logging-driver\"}),\"logging overview\"),\". If the logging driver supports additional options, you can set those as the values of the\\xA0log-opts\\xA0array in the same file.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Configure a container to use the plugin as the logging driver\")),mdx(\"p\",null,\"After the plugin is installed, you can configure a container to use the plugin as its logging driver by specifying the\\xA0--log-driver\\xA0flag to\\xA0docker run, as detailed in the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/containers/logging/configure/#configure-the-logging-driver-for-a-container\"}),\"logging overview\"),\". If the logging driver supports additional options, you can specify them using one or more\\xA0--log-optflags with the option name as the key and the option value as the value.\"),mdx(\"h4\",null,\"Customize log driver output\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA01 minute\")),mdx(\"p\",null,\"The\\xA0tag\\xA0log option specifies how to format a tag that identifies the container's log messages. By default, the system uses the first 12 characters of the container ID. To override this behavior, specify a\\xA0tag\\xA0option:\"),mdx(\"p\",null,\"$ docker run --log-driver=fluentd --log-opt fluentd-address=myhost.local:24224 --log-opt tag=\\\"mailer\\\"\"),mdx(\"p\",null,\"Docker supports some special template markup you can use when specifying a tag's value:\"),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Markup\"),\"         \",mdx(\"strong\",{parentName:\"p\"},\"Description\")),mdx(\"hr\",null),mdx(\"p\",null,\"  {{.ID}}            The first 12 characters of the container ID.\\n{{.FullID}}        The full container ID.\\n{{.Name}}          The container name.\\n{{.ImageID}}       The first 12 characters of the container's image ID.\\n{{.ImageFullID}}   The container's full image ID.\\n{{.ImageName}}     The name of the image used by the container.\\n{{.DaemonName}}    The name of the docker program (docker).\"),mdx(\"p\",null,\"For example, specifying a\\xA0--log-opt tag=\\\"{{.ImageName}}/{{.Name}}/{{.ID}}\\\"\\xA0value yields\\xA0syslog\\xA0log lines like:\"),mdx(\"p\",null,\"Aug 7 18:33:19 HOSTNAME hello-world/foobar/5790672ab6a0\",\"[9103]\",\": Hello from Docker.\"),mdx(\"p\",null,\"At startup time, the system sets the\\xA0container_name\\xA0field and\\xA0{{.Name}}\\xA0in the tags. If you use\\xA0docker rename\\xA0to rename a container, the new name is not reflected in the log messages. Instead, these messages continue to use the original container name.\"),mdx(\"h4\",null,\"Logging Driver Details\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Logentries logging driver\")),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA01 minute\")),mdx(\"p\",null,\"The\\xA0logentries\\xA0logging driver sends container logs to the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://logentries.com/\"}),\"Logentries\"),\"\\xA0server.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Usage\")),mdx(\"p\",null,\"Some options are supported by specifying\\xA0--log-opt\\xA0as many times as needed:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"logentries-token: specify the logentries log set token\"),mdx(\"li\",{parentName:\"ul\"},\"line-only: send raw payload only\")),mdx(\"p\",null,\"Configure the default logging driver by passing the\\xA0--log-driver\\xA0option to the Docker daemon:\"),mdx(\"p\",null,\"$ dockerd --log-driver=logentries\"),mdx(\"p\",null,\"To set the logging driver for a specific container, pass the\\xA0--log-driver\\xA0option to\\xA0docker run:\"),mdx(\"p\",null,\"$ docker run --log-driver=logentries ...\"),mdx(\"p\",null,\"Before using this logging driver, you need to create a new Log Set in the Logentries web interface and pass the token of that log set to Docker:\"),mdx(\"p\",null,\"$ docker run --log-driver=logentries --log-opt logentries-token=abcd1234-12ab-34cd-5678-0123456789ab\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Options\")),mdx(\"p\",null,\"Users can use the\\xA0--log-opt NAME=VALUE\\xA0flag to specify additional Logentries logging driver options.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"logentries-token\")),mdx(\"p\",null,\"You need to provide your log set token for logentries driver to work:\"),mdx(\"p\",null,\"$ docker run --log-driver=logentries --log-opt logentries-token=abcd1234-12ab-34cd-5678-0123456789ab\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"line-only\")),mdx(\"p\",null,\"You could specify whether to send log message wrapped into container data (default) or to send raw log line\"),mdx(\"p\",null,\"$ docker run --log-driver=logentries --log-opt logentries-token=abcd1234-12ab-34cd-5678-012\"),mdx(\"h4\",null,\"JSON File logging driver\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA02 minutes\")),mdx(\"p\",null,\"By default, Docker captures the standard output (and standard error) of all your containers, and writes them in files using the JSON format. The JSON format annotates each line with its origin (stdout\\xA0or\\xA0stderr) and its timestamp. Each log file contains information about only one container.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Usage\")),mdx(\"p\",null,\"To use the\\xA0json-file\\xA0driver as the default logging driver, set the\\xA0log-driver\\xA0and\\xA0log-optkeys to appropriate values in the\\xA0daemon.json\\xA0file, which is located in\\xA0/etc/docker/\\xA0on Linux hosts or\\xA0C:\\\\ProgramData\\\\docker\\\\config\\\\daemon.json\\xA0on Windows Server. For more information about configuring Docker using\\xA0daemon.json, see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-configuration-file\"}),\"daemon.json\"),\".\"),mdx(\"p\",null,\"The following example sets the log driver to\\xA0json-file\\xA0and sets the\\xA0max-size\\xA0option.\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"log-driver\\\": \\\"json-file\\\",\"),mdx(\"p\",null,\"\\\"log-opts\\\": {\"),mdx(\"p\",null,\"\\\"max-size\\\": \\\"10m\\\"\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"Restart Docker for the changes to take effect for newly created containers. Existing containers do not use the new logging configuration.\"),mdx(\"p\",null,\"You can set the logging driver for a specific container by using the\\xA0--log-driver\\xA0flag to\\xA0docker container create\\xA0or\\xA0docker run:\"),mdx(\"p\",null,\"$ docker run \\\\\"),mdx(\"p\",null,\"--log-driver json-file --log-opt max-size=10m \\\\\"),mdx(\"p\",null,\"alpine echo hello world\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Options\")),mdx(\"p\",null,\"The\\xA0json-file\\xA0logging driver supports the following logging options:\"),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Option\"),\"   \",mdx(\"strong\",{parentName:\"p\"},\"Description\"),\"                                                                                                                                                                                                                   \",mdx(\"strong\",{parentName:\"p\"},\"Example value\")),mdx(\"hr\",null),mdx(\"p\",null,\"  max-size     The maximum size of the log before it is rolled. A positive integer plus a modifier representing the unit of measure (k,\\xA0m, or\\xA0g). Defaults to -1 (unlimited).                                                                    --log-opt max-size=10m\\nmax-file     The maximum number of log files that can be present. If rolling the logs creates excess files, the oldest file is removed.\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"Only effective when\\xA0max-size\\xA0is also set.\"),\"\\xA0A positive integer. Defaults to 1.                       --log-opt max-file=3\\nlabels       Applies when starting the Docker daemon. A comma-separated list of logging-related labels this daemon accepts. Used for advanced\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/containers/logging/log_tags/\"}),\"log tag options\"),\".                  --log-opt labels=production_status,geo\\nenv          Applies when starting the Docker daemon. A comma-separated list of logging-related environment variables this daemon accepts. Used for advanced\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/containers/logging/log_tags/\"}),\"log tag options\"),\".   --log-opt env=os,customer\\nenv-regex    Similar to and compatible with\\xA0env. A regular expression to match logging-related environment variables. Used for advanced\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/containers/logging/log_tags/\"}),\"log tag options\"),\".                        --log-opt env-regex=\\\\^(os|customer).\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Examples\")),mdx(\"p\",null,\"This example starts an\\xA0alpine\\xA0container which can have a maximum of 3 log files no larger than 10 megabytes each.\"),mdx(\"p\",null,\"$ docker run -it --log-opt max-size=10m --log-opt max-file=3 alpine ash\"),mdx(\"h4\",null,\"Graylog Extended Format logging driver\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA04 minutes\")),mdx(\"p\",null,\"The\\xA0gelf\\xA0logging driver is a convenient format that is understood by a number of tools such as\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://www.graylog.org/\"}),\"Graylog\"),\",\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://www.elastic.co/products/logstash\"}),\"Logstash\"),\", and\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://www.fluentd.org/\"}),\"Fluentd\"),\". Many tools use this format.\"),mdx(\"p\",null,\"In GELF, every log message is a dict with the following fields:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"version\"),mdx(\"li\",{parentName:\"ul\"},\"host (who sent the message in the first place)\"),mdx(\"li\",{parentName:\"ul\"},\"timestamp\"),mdx(\"li\",{parentName:\"ul\"},\"short and long version of the message\"),mdx(\"li\",{parentName:\"ul\"},\"any custom fields you configure yourself\")),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Usage\")),mdx(\"p\",null,\"To use the\\xA0gelf\\xA0driver as the default logging driver, set the\\xA0log-driver\\xA0and\\xA0log-opt\\xA0keys to appropriate values in the\\xA0daemon.json\\xA0file, which is located in\\xA0/etc/docker/\\xA0on Linux hosts or\\xA0C:\\\\ProgramData\\\\docker\\\\config\\\\daemon.json\\xA0on Windows Server. For more about configuring Docker using\\xA0daemon.json, see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-configuration-file\"}),\"daemon.json\"),\".\"),mdx(\"p\",null,\"The following example sets the log driver to\\xA0gelf\\xA0and sets the\\xA0gelf-address\\xA0option.\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"log-driver\\\": \\\"gelf\\\",\"),mdx(\"p\",null,\"\\\"log-opts\\\": {\"),mdx(\"p\",null,\"\\\"gelf-address\\\": \\\"udp://1.2.3.4:12201\\\"\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"Restart Docker for the changes to take effect.\"),mdx(\"p\",null,\"To use\\xA0gelf\\xA0as the default logging driver for new containers, pass the\\xA0--log-driver\\xA0and\\xA0--log-opt\\xA0options to the Docker daemon:\"),mdx(\"p\",null,\"dockerd\"),mdx(\"p\",null,\"--log-driver gelf ---log-opt gelf-address=udp://1.2.3.4:12201 \\\\\"),mdx(\"p\",null,\"To make the configuration permanent, you can configure it in\\xA0/etc/docker/daemon.json:\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"log-driver\\\": \\\"gelf\\\",\"),mdx(\"p\",null,\"\\\"log-opts\\\": {\"),mdx(\"p\",null,\"\\\"gelf-address\\\": \\\"udp://1.2.3.4:12201\\\"\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"You can set the logging driver for a specific container by setting the\\xA0--log-driver\\xA0flag when using\\xA0docker container create\\xA0or\\xA0docker run:\"),mdx(\"p\",null,\"$ docker run \\\\\"),mdx(\"p\",null,\"--log-driver gelf ---log-opt gelf-address=udp://1.2.3.4:12201 \\\\\"),mdx(\"p\",null,\"alpine echo hello world\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"GELF options\")),mdx(\"p\",null,\"The\\xA0gelf\\xA0logging driver supports the following options:\"),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Option\"),\"                 \",mdx(\"strong\",{parentName:\"p\"},\"Required\"),\"   \",mdx(\"strong\",{parentName:\"p\"},\"Description\"),\"                                                                                                                                                                                                                                                                                            \",mdx(\"strong\",{parentName:\"p\"},\"Example value\")),mdx(\"hr\",null),mdx(\"p\",null,\"  gelf-address               required       The address of the GELF server.\\xA0tcp\\xA0and\\xA0udpare the only supported URI specifier and you must specify the port.                                                                                                                                                                                             --log-opt gelf-address=udp://192.168.0.42:12201\\ngelf-compression-type      optional       UDP Only\\xA0The type of compression the GELF driver uses to compress each log message. Allowed values are\\xA0gzip,\\xA0zlib\\xA0and\\xA0none. The default is\\xA0gzip.                                                                                                                                                           --log-opt gelf-compression-type=gzip\\ngelf-compression-level     optional       UDP Only\\xA0The level of compression when\\xA0gzip\\xA0or\\xA0zlib\\xA0is the\\xA0gelf-compression-type. An integer in the range of\\xA0-1\\xA0to\\xA09(BestCompression). Default value is 1 (BestSpeed). Higher levels provide more compression at lower speed. Either\\xA0-1\\xA0or\\xA00disables compression.                                          --log-opt gelf-compression-level=2\\ngelf-tcp-max-reconnect     optional       TCP Only\\xA0The maximum number of reconnection attempts when the connection drop. An positive integer. Default value is 3.                                                                                                                                                                                    --log-opt gelf-tcp-max-reconnect=3\\ngelf-tcp-reconnect-delay   optional       TCP Only\\xA0The number of seconds to wait between reconnection attempts. A positive integer. Default value is 1.                                                                                                                                                                                              --log-opt gelf-tcp-reconnect-delay=1\\ntag                        optional       A string that is appended to the\\xA0APP-NAME\\xA0in the\\xA0gelf\\xA0message. By default, Docker uses the first 12 characters of the container ID to tag log messages. Refer to the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/containers/logging/log_tags/\"}),\"log tag option documentation\"),\"\\xA0for customizing the log tag format.       --log-opt tag=mailer\\nlabels                     optional       Applies when starting the Docker daemon. A comma-separated list of logging-related labels this daemon accepts. Adds additional key on the\\xA0extra\\xA0fields, prefixed by an underscore (\",mdx(\"em\",{parentName:\"p\"},\"). Used for advanced\\xA0\",mdx(\"a\",_extends({parentName:\"em\"},{\"href\":\"https://docs.docker.com/config/containers/logging/log_tags/\"}),\"log tag options\"),\".                  --log-opt labels=production_status,geo\\nenv                        optional       Applies when starting the Docker daemon. A comma-separated list of logging-related environment variables this daemon accepts. Adds additional key on the\\xA0extra\\xA0fields, prefixed by an underscore (\"),\"). Used for advanced\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/containers/logging/log_tags/\"}),\"log tag options\"),\".   --log-opt env=os,customer\\nenv-regex                  optional       Similar to and compatible with\\xA0env. A regular expression to match logging-related environment variables. Used for advanced\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/containers/logging/log_tags/\"}),\"log tag options\"),\".                                                                                                 --log-opt env-regex=\\\\^(os | customer).\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Examples\")),mdx(\"p\",null,\"This example configures the container to use the GELF server running at\\xA0192.168.0.42\\xA0on port\\xA012201.\"),mdx(\"p\",null,\"$ docker run -dit \\\\\"),mdx(\"p\",null,\"--log-driver=gelf \\\\\"),mdx(\"p\",null,\"--log-opt gelf-address=udp://192.168.0.42:12201 \\\\\"),mdx(\"p\",null,\"alpine sh\"),mdx(\"h4\",null,\"Syslog logging driver\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA04 minutes\")),mdx(\"p\",null,\"The\\xA0syslog\\xA0logging driver routes logs to a\\xA0syslog\\xA0server. The\\xA0syslog\\xA0protocol uses a raw string as the log message and supports a limited set of metadata. The syslog message must be formatted in a specific way to be valid. From a valid message, the receiver can extract the following information:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"priority\"),\": the logging level, such as\\xA0debug,\\xA0warning,\\xA0error,\\xA0info.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"timestamp\"),\": when the event occurred.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"hostname\"),\": where the event happened.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"facility\"),\": which subsystem logged the message, such as\\xA0mail\\xA0or\\xA0kernel.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"process name\"),\"\\xA0and\\xA0\",mdx(\"strong\",{parentName:\"li\"},\"process ID (PID)\"),\": The name and ID of the process that generated the log.\")),mdx(\"p\",null,\"The format is defined in\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://tools.ietf.org/html/rfc5424\"}),\"RFC 5424\"),\"\\xA0and Docker's syslog driver implements the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://tools.ietf.org/html/rfc5424#section-6\"}),\"ABNF reference\"),\"\\xA0in the following way:\"),mdx(\"p\",null,\"TIMESTAMP SP HOSTNAME SP APP-NAME SP PROCID SP MSGID\"),mdx(\"p\",null,\"+\",\" + + | +\"),mdx(\"p\",null,\"| | | | |\"),mdx(\"p\",null,\"| | | | |\"),mdx(\"p\",null,\"+------------+ +----+ | +----+ +---------+\"),mdx(\"p\",null,\"v v v v v\"),mdx(\"p\",null,\"2017-04-01T17:41:05.616647+08:00 a.vm {taskid:aa,version:} 1787791 {taskid:aa,version:}\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Usage\")),mdx(\"p\",null,\"To use the\\xA0syslog\\xA0driver as the default logging driver, set the\\xA0log-driver\\xA0and\\xA0log-opt\\xA0keys to appropriate values in the\\xA0daemon.json\\xA0file, which is located in\\xA0/etc/docker/\\xA0on Linux hosts orC:\\\\ProgramData\\\\docker\\\\config\\\\daemon.json\\xA0on Windows Server. For more about configuring Docker using\\xA0daemon.json, see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-configuration-file\"}),\"daemon.json\"),\".\"),mdx(\"p\",null,\"The following example sets the log driver to\\xA0syslog\\xA0and sets the\\xA0syslog-address\\xA0option.\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"log-driver\\\": \\\"syslog\\\",\"),mdx(\"p\",null,\"\\\"log-opts\\\": {\"),mdx(\"p\",null,\"\\\"syslog-address\\\": \\\"udp://1.2.3.4:1111\\\"\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"Restart Docker for the changes to take effect.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": The syslog-address supports both UDP and TCP.\"),mdx(\"p\",null,\"You can set the logging driver for a specific container by using the\\xA0--log-driver\\xA0flag to\\xA0docker container create\\xA0or\\xA0docker run:\"),mdx(\"p\",null,\"docker run \\\\\"),mdx(\"p\",null,\"---log-driver syslog ---log-opt syslog-address=udp://1.2.3.4:1111 \\\\\"),mdx(\"p\",null,\"alpine echo hello world\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Options\")),mdx(\"p\",null,\"The following logging options are supported as options for the\\xA0syslog\\xA0logging driver. They can be set as defaults in the\\xA0daemon.json, by adding them as key-value pairs to the\\xA0log-opts\\xA0JSON array. They can also be set on a given container by adding a\\xA0--log-opt \",mdx(\"inlineCode\",{parentName:\"p\"},\"<key>=<value>\"),\"\\xA0flag for each option when starting the container.\"),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Option\"),\"               \",mdx(\"strong\",{parentName:\"p\"},\"Description\"),\"                                                                                                                                                                                                                                                                                            \",mdx(\"strong\",{parentName:\"p\"},\"Example value\")),mdx(\"hr\",null),mdx(\"p\",null,\"  syslog-address           The address of an external\\xA0syslogserver. The URI specifier may be\\xA0\",\"[tcp | udp|tcp+tls]\",\"://host:port,\\xA0unix://path, or\\xA0unixgram://path. If the transport is\\xA0tcp,\\xA0udp, or\\xA0tcp+tls, the default port is\\xA0514.                                                                                                 --log-opt syslog-address=tcp+tls://192.168.1.3:514,\\xA0--log-opt syslog-address=unix:///tmp/syslog.sock\\nsyslog-facility          The\\xA0syslog\\xA0facility to use. Can be the number or name for any valid\\xA0syslog\\xA0facility. See the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://tools.ietf.org/html/rfc5424#section-6.2.1\"}),\"syslog documentation\"),\".                                                                                                                                    --log-opt syslog-facility=daemon\\nsyslog-tls-ca-cert       The absolute path to the trust certificates signed by the CA.\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"Ignored if the address protocol is not\\xA0tcp+tls.\"),\"                                                                                                                                                                                          --log-opt syslog-tls-ca-cert=/etc/ca-certificates/custom/ca.pem\\nsyslog-tls-cert          The absolute path to the TLS certificate file.\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"Ignored if the address protocol is not\\xA0tcp+tls\"),\".                                                                                                                                                                                                         --log-opt syslog-tls-cert=/etc/ca-certificates/custom/cert.pem\\nsyslog-tls-key           The absolute path to the TLS key file.\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"Ignored if the address protocol is not\\xA0tcp+tls.\"),\"                                                                                                                                                                                                                 --log-opt syslog-tls-key=/etc/ca-certificates/custom/key.pem\\nsyslog-tls-skip-verify   If set to\\xA0true, TLS verification is skipped when connecting to the\\xA0syslog\\xA0daemon. Defaults to\\xA0false.\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"Ignored if the address protocol is not\\xA0tcp+tls.\"),\"                                                                                                                                                   --log-opt syslog-tls-skip-verify=true\\ntag                      A string that is appended to the\\xA0APP-NAME\\xA0in the\\xA0syslogmessage. By default, Docker uses the first 12 characters of the container ID to tag log messages. Refer to the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/containers/logging/log_tags/\"}),\"log tag option documentation\"),\"\\xA0for customizing the log tag format.      --log-opt tag=mailer\\nsyslog-format            The\\xA0syslog\\xA0message format to use. If not specified the local UNIX syslog format is used, without a specified hostname. Specify\\xA0rfc3164\\xA0for the RFC-3164 compatible format,\\xA0rfc5424\\xA0for RFC-5424 compatible format, or\\xA0rfc5424micro\\xA0for RFC-5424 compatible format with microsecond timestamp resolution.   --log-opt syslog-format=rfc5424micro\\nlabels                   Applies when starting the Docker daemon. A comma-separated list of logging-related labels this daemon accepts. Used for advanced\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/containers/logging/log_tags/\"}),\"log tag options\"),\".                                                                                           --log-opt labels=production_status,geo\\nenv                      Applies when starting the Docker daemon. A comma-separated list of logging-related environment variables this daemon accepts. Used for advanced\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/containers/logging/log_tags/\"}),\"log tag options\"),\".                                                                            --log-opt env=os,customer\\nenv-regex                Applies when starting the Docker daemon. Similar to and compatible with\\xA0env. A regular expression to match logging-related environment variables. Used for advanced\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/containers/logging/log_tags/\"}),\"log tag options\"),\".                                                        --log-opt env-regex=\\\\^(os\",\"|\",\"customer)\"),mdx(\"h4\",null,\"Amazon CloudWatch Logs logging driver\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA08 minutes\")),mdx(\"p\",null,\"The\\xA0awslogs\\xA0logging driver sends container logs to\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://aws.amazon.com/cloudwatch/details/#log-monitoring\"}),\"Amazon CloudWatch Logs\"),\". Log entries can be retrieved through the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://console.aws.amazon.com/cloudwatch/home#logs:\"}),\"AWS Management Console\"),\"\\xA0or the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://docs.aws.amazon.com/cli/latest/reference/logs/index.html\"}),\"AWS SDKs and Command Line Tools\"),\".\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Usage\")),mdx(\"p\",null,\"To use the\\xA0awslogs\\xA0driver as the default logging driver, set the\\xA0log-driver\\xA0and\\xA0log-opt\\xA0keys to appropriate values in the\\xA0daemon.json\\xA0file, which is located in\\xA0/etc/docker/\\xA0on Linux hosts or\\xA0C:\\\\ProgramData\\\\docker\\\\config\\\\daemon.json\\xA0on Windows Server. For more about configuring Docker using\\xA0daemon.json, see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-configuration-file\"}),\"daemon.json\"),\". The following example sets the log driver to\\xA0awslogs\\xA0and sets the\\xA0awslogs-region\\xA0option.\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"log-driver\\\": \\\"awslogs\\\",\"),mdx(\"p\",null,\"\\\"log-opts\\\": {\"),mdx(\"p\",null,\"\\\"awslogs-region\\\": \\\"us-east-1\\\"\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"Restart Docker for the changes to take effect.\"),mdx(\"p\",null,\"You can set the logging driver for a specific container by using the\\xA0--log-driver\\xA0option to\\xA0docker run:\"),mdx(\"p\",null,\"docker run --log-driver=awslogs ...\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Amazon CloudWatch Logs options\")),mdx(\"p\",null,\"You can add logging options to the\\xA0daemon.json\\xA0to set Docker-wide defaults, or use the\\xA0--log-opt NAME=VALUE\\xA0flag to specify Amazon CloudWatch Logs logging driver options when starting a container.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"awslogs-region\")),mdx(\"p\",null,\"The\\xA0awslogs\\xA0logging driver sends your Docker logs to a specific region. Use the\\xA0awslogs-regionlog option or the\\xA0AWS_REGION\\xA0environment variable to set the region. By default, if your Docker daemon is running on an EC2 instance and no region is set, the driver uses the instance's region.\"),mdx(\"p\",null,\"docker run --log-driver=awslogs --log-opt awslogs-region=us-east-1 ...\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"awslogs-group\")),mdx(\"p\",null,\"You must specify a\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://docs.aws.amazon.com/AmazonCloudWatch/latest/DeveloperGuide/WhatIsCloudWatchLogs.html\"}),\"log group\"),\"\\xA0for the\\xA0awslogs\\xA0logging driver. You can specify the log group with the\\xA0awslogs-group\\xA0log option:\"),mdx(\"p\",null,\"docker run --log-driver=awslogs --log-opt awslogs-region=us-east-1 --log-opt awslogs-group=myLogGroup ...\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"awslogs-stream\")),mdx(\"p\",null,\"To configure which\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://docs.aws.amazon.com/AmazonCloudWatch/latest/DeveloperGuide/WhatIsCloudWatchLogs.html\"}),\"log stream\"),\"\\xA0should be used, you can specify the\\xA0awslogs-stream\\xA0log option. If not specified, the container ID is used as the log stream.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": Log streams within a given log group should only be used by one container at a time. Using the same log stream for multiple containers concurrently can cause reduced logging performance.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"awslogs-create-group\")),mdx(\"p\",null,\"Log driver returns an error by default if the log group does not exist. However, you can set theawslogs-create-group\\xA0to\\xA0true\\xA0to automatically create the log group as needed. The\\xA0awslogs-create-group\\xA0option defaults to\\xA0false.\"),mdx(\"p\",null,\"$ docker run --log-driver=awslogs \\\\\"),mdx(\"p\",null,\"--log-opt awslogs-region=us-east-1 \\\\\"),mdx(\"p\",null,\"--log-opt awslogs-group=myLogGroup \\\\\"),mdx(\"p\",null,\"--log-opt awslogs-create-group=true \\\\\"),mdx(\"p\",null,\"...\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": Your AWS IAM policy must include the\\xA0logs:CreateLogGroup\\xA0permission before you attempt to use\\xA0awslogs-create-group.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"awslogs-datetime-format\")),mdx(\"p\",null,\"The\\xA0awslogs-datetime-format\\xA0option defines a multiline start pattern in\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://strftime.org/\"}),\"Python\\xA0strftimeformat\"),\". A log message consists of a line that matches the pattern and any following lines that don't match the pattern. Thus the matched line is the delimiter between log messages.\"),mdx(\"p\",null,\"One example of a use case for using this format is for parsing output such as a stack dump, which might otherwise be logged in multiple entries. The correct pattern allows it to be captured in a single entry.\"),mdx(\"p\",null,\"This option always takes precedence if both\\xA0awslogs-datetime-format\\xA0andawslogs-multiline-pattern\\xA0are configured.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": Multiline logging performs regular expression parsing and matching of all log messages, which may have a negative impact on logging performance.\"),mdx(\"p\",null,\"Consider the following log stream, where new log messages start with a timestamp:\"),mdx(\"p\",null,\"[May 01, 2017 19:00:01]\",\" A message was logged\"),mdx(\"p\",null,\"[May 01, 2017 19:00:04]\",\" Another multiline message was logged\"),mdx(\"p\",null,\"Some random message\"),mdx(\"p\",null,\"with some random words\"),mdx(\"p\",null,\"[May 01, 2017 19:01:32]\",\" Another message was logged\"),mdx(\"p\",null,\"The format can be expressed as a\\xA0strftime\\xA0expression of\\xA0\",\"[%b %d, %Y %H:%M:%S]\",\", and the\\xA0awslogs-datetime-format\\xA0value can be set to that expression:\"),mdx(\"p\",null,\"$ docker run --log-driver=awslogs \\\\\"),mdx(\"p\",null,\"--log-opt awslogs-region=us-east-1 \\\\\"),mdx(\"p\",null,\"--log-opt awslogs-group=myLogGroup \\\\\"),mdx(\"p\",null,\"--log-opt awslogs-datetime-format=\\\\'\",\"[\",\"%b %d, %Y %H:%M:%S\",\"]\",\"\\\\' \\\\\"),mdx(\"p\",null,\"...\"),mdx(\"p\",null,\"This parses the logs into the following CloudWatch log events:\"),mdx(\"h1\",null,\"First event\"),mdx(\"p\",null,\"[May 01, 2017 19:00:01]\",\" A message was logged\"),mdx(\"h1\",null,\"Second event\"),mdx(\"p\",null,\"[May 01, 2017 19:00:04]\",\" Another multiline message was logged\"),mdx(\"p\",null,\"Some random message\"),mdx(\"p\",null,\"with some random words\"),mdx(\"h1\",null,\"Third event\"),mdx(\"p\",null,\"[May 01, 2017 19:01:32]\",\" Another message was logged\"),mdx(\"p\",null,\"The following\\xA0strftime\\xA0codes are supported:\"),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Code\"),\"   \",mdx(\"strong\",{parentName:\"p\"},\"Meaning\"),\"                                                        \",mdx(\"strong\",{parentName:\"p\"},\"Example\")),mdx(\"hr\",null),mdx(\"p\",null,\"  %a         Weekday abbreviated name.                                          Mon\\n%A         Weekday full name.                                                 Monday\\n%w         Weekday as a decimal number where 0 is Sunday and 6 is Saturday.   0\\n%d         Day of the month as a zero-padded decimal number.                  08\\n%b         Month abbreviated name.                                            Feb\\n%B         Month full name.                                                   February\\n%m         Month as a zero-padded decimal number.                             02\\n%Y         Year with century as a decimal number.                             2008\\n%y         Year without century as a zero-padded decimal number.              08\\n%H         Hour (24-hour clock) as a zero-padded decimal number.              19\\n%I         Hour (12-hour clock) as a zero-padded decimal number.              07\\n%p         AM or PM.                                                          AM\\n%M         Minute as a zero-padded decimal number.                            57\\n%S         Second as a zero-padded decimal number.                            04\\n%L         Milliseconds as a zero-padded decimal number.                      123\\n%f         Microseconds as a zero-padded decimal number.                      000345\\n%z         UTC offset in the form +HHMM or -HHMM.                             +1300\\n%Z         Time zone name.                                                    PST\\n%j         Day of the year as a zero-padded decimal number.                   363\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"awslogs-multiline-pattern\")),mdx(\"p\",null,\"The\\xA0awslogs-multiline-pattern\\xA0option defines a multiline start pattern using a regular expression. A log message consists of a line that matches the pattern and any following lines that don't match the pattern. Thus the matched line is the delimiter between log messages.\"),mdx(\"p\",null,\"This option is ignored if\\xA0awslogs-datetime-format\\xA0is also configured.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": Multiline logging performs regular expression parsing and matching of all log messages. This may have a negative impact on logging performance.\"),mdx(\"p\",null,\"For example, to process the following log stream where new log messages start with the pattern\\xA0INFO:\"),mdx(\"p\",null,\"Consider the following log stream, where each log message should start with the patther\\xA0INFO:\"),mdx(\"p\",null,\"INFO A message was logged\"),mdx(\"p\",null,\"INFO Another multiline message was logged\"),mdx(\"p\",null,\"Some random message\"),mdx(\"p\",null,\"INFO Another message was logged\"),mdx(\"p\",null,\"You can use the regular expression of\\xA0\\\\^INFO:\"),mdx(\"p\",null,\"$ docker run --log-driver=awslogs \\\\\"),mdx(\"p\",null,\"--log-opt awslogs-region=us-east-1 \\\\\"),mdx(\"p\",null,\"--log-opt awslogs-group=myLogGroup \\\\\"),mdx(\"p\",null,\"--log-opt awslogs-multiline-pattern=\\\\'\\\\^INFO\\\\' \\\\\"),mdx(\"p\",null,\"...\"),mdx(\"p\",null,\"This parses the logs into the following CloudWatch log events:\"),mdx(\"h1\",null,\"First event\"),mdx(\"p\",null,\"INFO A message was logged\"),mdx(\"h1\",null,\"Second event\"),mdx(\"p\",null,\"INFO Another multiline message was logged\"),mdx(\"p\",null,\"Some random message\"),mdx(\"h1\",null,\"Third event\"),mdx(\"p\",null,\"INFO Another message was logged\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"tag\")),mdx(\"p\",null,\"Specify\\xA0tag\\xA0as an alternative to the\\xA0awslogs-stream\\xA0option.\\xA0tag\\xA0interprets Go template markup, such as\\xA0{{.ID}},\\xA0{{.FullID}}\\xA0or\\xA0{{.Name}}\\xA0docker.{{.ID}}. See the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/containers/logging/log_tags/\"}),\"tag option documentation\"),\"\\xA0for details on all supported template substitutions.\"),mdx(\"p\",null,\"When both\\xA0awslogs-stream\\xA0and\\xA0tag\\xA0are specified, the value supplied for\\xA0awslogs-streamoverrides the template specified with\\xA0tag.\"),mdx(\"p\",null,\"If not specified, the container ID is used as the log stream.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": The CloudWatch log API doesn't support\\xA0:\\xA0in the log name. This can cause some issues when using the\\xA0{{ .ImageName }}\\xA0as a tag, since a docker image has a format of\\xA0IMAGE:TAG, such as\\xA0alpine:latest. Template markup can be used to get the proper format. To get the image name and the first 12 characters of the container ID, you can use:\\xA0--log-opt tag=\\\\'{{ with split .ImageName \\\":\\\" }}{{join . \\\"_\\\"}}{{end}}-{{.ID}}\\\\'\\xA0the output is something like:\\xA0alpine_latest-bf0072049c76\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Credentials\")),mdx(\"p\",null,\"You must provide AWS credentials to the Docker daemon to use the\\xA0awslogs\\xA0logging driver. You can provide these credentials with the\\xA0AWS_ACCESS_KEY_ID,\\xA0AWS_SECRET_ACCESS_KEY, and\\xA0AWS_SESSION_TOKEN\\xA0environment variables, the default AWS shared credentials file (\",\"~\",\"/.aws/credentials\\xA0of the root user), or (if you are running the Docker daemon on an Amazon EC2 instance) the Amazon EC2 instance profile.\"),mdx(\"p\",null,\"Credentials must have a policy applied that allows the\\xA0logs:CreateLogStream\\xA0and\\xA0logs:PutLogEvents\\xA0actions, as shown in the following example.\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"Version\\\": \\\"2012-10-17\\\",\"),mdx(\"p\",null,\"\\\"Statement\\\": [\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"Action\\\": [\"),mdx(\"p\",null,\"\\\"logs:CreateLogStream\\\",\"),mdx(\"p\",null,\"\\\"logs:PutLogEvents\\\"\"),mdx(\"p\",null,\"],\"),mdx(\"p\",null,\"\\\"Effect\\\": \\\"Allow\\\",\"),mdx(\"p\",null,\"\\\"Resource\\\": \\\"*\\\"\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"]\"),mdx(\"p\",null,\"}\"),mdx(\"h4\",null,\"ETW logging driver\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA02 minutes\")),mdx(\"p\",null,\"The ETW logging driver forwards container logs as ETW events. ETW stands for Event Tracing in Windows, and is the common framework for tracing applications in Windows. Each ETW event contains a message with both the log and its context information. A client can then create an ETW listener to listen to these events.\"),mdx(\"p\",null,\"The ETW provider that this logging driver registers with Windows, has the GUID identifier of:\\xA0{a3693192-9ed6-46d2-a981-f8226c8363bd}. A client creates an ETW listener and registers to listen to events from the logging driver's provider. It does not matter the order in which the provider and listener are created. A client can create their ETW listener and start listening for events from the provider, before the provider has been registered with the system.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Usage\")),mdx(\"p\",null,\"Here is an example of how to listen to these events using the logman utility program included in most installations of Windows:\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"logman start -ets DockerContainerLogs -p {a3693192-9ed6-46d2-a981-f8226c8363bd} 0 0 -o trace.etl\"),mdx(\"li\",{parentName:\"ol\"},\"Run your container(s) with the etwlogs driver, by adding\\xA0--log-driver=etwlogs\\xA0to the Docker run command, and generate log messages.\"),mdx(\"li\",{parentName:\"ol\"},\"logman stop -ets DockerContainerLogs\"),mdx(\"li\",{parentName:\"ol\"},\"This generates an etl file that contains the events. One way to convert this file into human-readable form is to run:\\xA0tracerpt -y trace.etl.\")),mdx(\"p\",null,\"Each ETW event contains a structured message string in this format:\"),mdx(\"p\",null,\"container_name: %s, image_name: %s, container_id: %s, image_id: %s, source: \",\"[stdout | stderr]\",\", log: %s\"),mdx(\"p\",null,\"Details on each item in the message can be found below:\"),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Field\"),\"        \",mdx(\"strong\",{parentName:\"p\"},\"Description\")),mdx(\"hr\",null),mdx(\"p\",null,\"  container_name   The container name at the time it was started.\\nimage_name       The name of the container's image.\\ncontainer_id     The full 64-character container ID.\\nimage_id         The full ID of the container's image.\\nsource           stdout\\xA0or\\xA0stderr.\\nlog              The container log message.\"),mdx(\"p\",null,\"Here is an example event message:\"),mdx(\"p\",null,\"container_name: backstabbing_spence,\"),mdx(\"p\",null,\"image_name: windowsservercore,\"),mdx(\"p\",null,\"container_id: f14bb55aa862d7596b03a33251c1be7dbbec8056bbdead1da8ec5ecebbe29731,\"),mdx(\"p\",null,\"image_id: sha256:2f9e19bd998d3565b4f345ac9aaf6e3fc555406239a4fb1b1ba879673713824b,\"),mdx(\"p\",null,\"source: stdout,\"),mdx(\"p\",null,\"log: Hello world!\"),mdx(\"p\",null,\"A client can parse this message string to get both the log message, as well as its context information. The timestamp is also available within the ETW event.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": This ETW provider emits only a message string, and not a specially structured ETW event. Therefore, it is not required to register a manifest file with the system to read and interpret its ETW events.\"),mdx(\"h4\",null,\"Fluentd logging driver\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA04 minutes\")),mdx(\"p\",null,\"The\\xA0fluentd\\xA0logging driver sends container logs to the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://www.fluentd.org/\"}),\"Fluentd\"),\"\\xA0collector as structured log data. Then, users can use any of the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://www.fluentd.org/plugins\"}),\"various output plugins of Fluentd\"),\"\\xA0to write these logs to various destinations.\"),mdx(\"p\",null,\"In addition to the log message itself, the\\xA0fluentd\\xA0log driver sends the following metadata in the structured log message:\"),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Field\"),\"        \",mdx(\"strong\",{parentName:\"p\"},\"Description\")),mdx(\"hr\",null),mdx(\"p\",null,\"  container_id     The full 64-character container ID.\\ncontainer_name   The container name at the time it was started. If you use\\xA0docker renameto rename a container, the new name is not reflected in the journal entries.\\nsource           stdout\\xA0or\\xA0stderr\\nlog              The container log\"),mdx(\"p\",null,\"The\\xA0docker logs\\xA0command is not available for this logging driver.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Usage\")),mdx(\"p\",null,\"Some options are supported by specifying\\xA0--log-opt\\xA0as many times as needed:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"fluentd-address: specify a socket address to connect to the Fluentd daemon, ex\\xA0fluentdhost:24224\\xA0or\\xA0unix:///path/to/fluentd.sock\"),mdx(\"li\",{parentName:\"ul\"},\"tag: specify a tag for fluentd message, which interprets some markup, ex\\xA0{{.ID}},\\xA0{{.FullID}}\\xA0or\\xA0{{.Name}}\\xA0docker.{{.ID}}\")),mdx(\"p\",null,\"To use the\\xA0fluentd\\xA0driver as the default logging driver, set the\\xA0log-driver\\xA0and\\xA0log-opt\\xA0keys to appropriate values in the\\xA0daemon.json\\xA0file, which is located in\\xA0/etc/docker/\\xA0on Linux hosts or\\xA0C:\\\\ProgramData\\\\docker\\\\config\\\\daemon.json\\xA0on Windows Server. For more about +configuring Docker using\\xA0daemon.json, see +\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-configuration-file\"}),\"daemon.json\"),\".\"),mdx(\"p\",null,\"The following example sets the log driver to\\xA0fluentd\\xA0and sets the\\xA0fluentd-address\\xA0option.\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"log-driver\\\": \\\"fluentd\\\",\"),mdx(\"p\",null,\"\\\"log-opts\\\": {\"),mdx(\"p\",null,\"\\\"fluentd-address\\\": \\\"fluentdhost:24224\\\"\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"Restart Docker for the changes to take effect.\"),mdx(\"p\",null,\"To set the logging driver for a specific container, pass the\\xA0--log-driver\\xA0option to\\xA0docker run:\"),mdx(\"p\",null,\"docker run --log-driver=fluentd ...\"),mdx(\"p\",null,\"Before using this logging driver, launch a Fluentd daemon. The logging driver connects to this daemon through\\xA0localhost:24224\\xA0by default. Use the\\xA0fluentd-address\\xA0option to connect to a different address.\"),mdx(\"p\",null,\"docker run --log-driver=fluentd --log-opt fluentd-address=fluentdhost:24224\"),mdx(\"p\",null,\"If container cannot connect to the Fluentd daemon, the container stops immediately unless the\\xA0fluentd-async-connect\\xA0option is used.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Options\")),mdx(\"p\",null,\"Users can use the\\xA0--log-opt NAME=VALUE\\xA0flag to specify additional Fluentd logging driver options.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"fluentd-address\")),mdx(\"p\",null,\"By default, the logging driver connects to\\xA0localhost:24224. Supply the\\xA0fluentd-address\\xA0option to connect to a different address.\\xA0tcp(default) and\\xA0unix\\xA0sockets are supported.\"),mdx(\"p\",null,\"docker run --log-driver=fluentd --log-opt fluentd-address=fluentdhost:24224\"),mdx(\"p\",null,\"docker run --log-driver=fluentd --log-opt fluentd-address=tcp://fluentdhost:24224\"),mdx(\"p\",null,\"docker run --log-driver=fluentd --log-opt fluentd-address=unix:///path/to/fluentd.sock\"),mdx(\"p\",null,\"Two of the above specify the same address, because\\xA0tcp\\xA0is default.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"tag\")),mdx(\"p\",null,\"By default, Docker uses the first 12 characters of the container ID to tag log messages. Refer to the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/containers/logging/log_tags/\"}),\"log tag option documentation\"),\"\\xA0for customizing the log tag format.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"labels, env, and env-regex\")),mdx(\"p\",null,\"The\\xA0labels\\xA0and\\xA0env\\xA0options each take a comma-separated list of keys. If there is collision between\\xA0label\\xA0and\\xA0env\\xA0keys, the value of the\\xA0env\\xA0takes precedence. Both options add additional fields to the extra attributes of a logging message.\"),mdx(\"p\",null,\"The\\xA0env-regex\\xA0option is similar to and compatible with\\xA0env. Its value is a regular expression to match logging-related environment variables. It is used for advanced\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/containers/logging/log_tags/\"}),\"log tag options\"),\".\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"fluentd-async-connect\")),mdx(\"p\",null,\"Docker connects to Fluentd in the background. Messages are buffered until the connection is established.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"fluentd-buffer-limit\")),mdx(\"p\",null,\"The amount of data to buffer before flushing to disk. Defaults to the amount of RAM available to the container.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"fluentd-retry-wait\")),mdx(\"p\",null,\"How long to wait between retries. Defaults to 1 second.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"fluentd-max-retries\")),mdx(\"p\",null,\"The maximum number of retries. Defaults to 10.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"fluentd-sub-second-precision\")),mdx(\"p\",null,\"Generates event logs in nanosecond resolution. Defaults to false.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Fluentd daemon management with Docker\")),mdx(\"p\",null,\"About\\xA0Fluentd\\xA0itself, see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://www.fluentd.org/\"}),\"the project webpage\"),\"\\xA0and\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://docs.fluentd.org/\"}),\"its documents\"),\".\"),mdx(\"p\",null,\"To use this logging driver, start the\\xA0fluentd\\xA0daemon on a host. We recommend that you use\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://hub.docker.com/r/fluent/fluentd/\"}),\"the Fluentd docker image\"),\". This image is especially useful if you want to aggregate multiple container logs on each host then, later, transfer the logs to another Fluentd node to create an aggregate store.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Test container loggers\")),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Write a configuration file (test.conf) to dump input logs:\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<source>\")),mdx(\"li\",{parentName:\"ol\"},\"\\\\@type forward\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"</source>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<match *>\")),mdx(\"li\",{parentName:\"ol\"},\"\\\\@type stdout\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"</match>\")),mdx(\"li\",{parentName:\"ol\"},\"Launch Fluentd container with this configuration file:\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker run -it -p 24224:24224 -v /path/to/conf/test.conf:/fluentd/etc/test.conf -e FLUENTD_CONF=test.conf fluent/fluentd:latest\"),mdx(\"li\",{parentName:\"ol\"},\"Start one or more containers with the\\xA0fluentd\\xA0logging driver:\")),mdx(\"p\",null,\"$ docker run --log-driver=fluentd your/application\"),mdx(\"h4\",null,\"Google Cloud Logging driver\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA03 minutes\")),mdx(\"p\",null,\"The Google Cloud Logging driver sends container logs to\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://cloud.google.com/logging/docs/\"}),\"Google Cloud Logging\"),\"\\xA0Logging.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Usage\")),mdx(\"p\",null,\"To use the\\xA0gcplogs\\xA0driver as the default logging driver, set the\\xA0log-driver\\xA0and\\xA0log-opt\\xA0keys to appropriate values in the\\xA0daemon.json\\xA0file, which is located in\\xA0/etc/docker/\\xA0on Linux hosts or\\xA0C:\\\\ProgramData\\\\docker\\\\config\\\\daemon.json\\xA0on Windows Server. For more about configuring Docker using\\xA0daemon.json, see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-configuration-file\"}),\"daemon.json\"),\".\"),mdx(\"p\",null,\"The following example sets the log driver to\\xA0gcplogs\\xA0and sets the\\xA0gcp-meta-name\\xA0option.\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"log-driver\\\": \\\"gcplogs\\\",\"),mdx(\"p\",null,\"\\\"log-opts\\\": {\"),mdx(\"p\",null,\"\\\"gcp-meta-name\\\": \\\"example-instance-12345\\\"\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"Restart Docker for the changes to take effect.\"),mdx(\"p\",null,\"You can set the logging driver for a specific container by using the\\xA0--log-driver\\xA0option to\\xA0docker run:\"),mdx(\"p\",null,\"docker run --log-driver=gcplogs ...\"),mdx(\"p\",null,\"This log driver does not implement a reader so it is incompatible with\\xA0docker logs.\"),mdx(\"p\",null,\"If Docker detects that it is running in a Google Cloud Project, it discovers configuration from the\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://cloud.google.com/compute/docs/metadata\"}),\"instance metadata service\"),\". Otherwise, the user must specify which project to log to using the\\xA0--gcp-project\\xA0log option and Docker attempts to obtain credentials from the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://developers.google.com/identity/protocols/application-default-credentials\"}),\"Google Application Default Credential\"),\". The\\xA0--gcp-project\\xA0flag takes precedence over information discovered from the metadata server so a Docker daemon running in a Google Cloud Project can be overridden to log to a different Google Cloud Project using\\xA0--gcp-project.\"),mdx(\"p\",null,\"Docker fetches the values for zone, instance name and instance ID from Google Cloud metadata server. Those values can be provided via options if metadata server is not available. They do not override the values from metadata server.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"gcplogs options\")),mdx(\"p\",null,\"You can use the\\xA0--log-opt NAME=VALUE\\xA0flag to specify these additional Google Cloud Logging driver options:\"),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Option\"),\"      \",mdx(\"strong\",{parentName:\"p\"},\"Required\"),\"   \",mdx(\"strong\",{parentName:\"p\"},\"Description\")),mdx(\"hr\",null),mdx(\"p\",null,\"  gcp-project     optional       Which GCP project to log to. Defaults to discovering this value from the GCE metadata service.\\ngcp-log-cmd     optional       Whether to log the command that the container was started with. Defaults to false.\\nlabels          optional       Comma-separated list of keys of labels, which should be included in message, if these labels are specified for the container.\\nenv             optional       Comma-separated list of keys of environment variables, which should be included in message, if these variables are specified for the container.\\nenv-regex       optional       Similar to and compatible with\\xA0env. A regular expression to match logging-related environment variables. Used for advanced\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/containers/logging/log_tags/\"}),\"log tag options\"),\".\\ngcp-meta-zone   optional       Zone name for the instance.\\ngcp-meta-name   optional       Instance name.\\ngcp-meta-id     optional       Instance ID.\"),mdx(\"p\",null,\"If there is collision between\\xA0label\\xA0and\\xA0env\\xA0keys, the value of the\\xA0env\\xA0takes precedence. Both options add additional fields to the attributes of a logging message.\"),mdx(\"p\",null,\"Below is an example of the logging options required to log to the default logging destination which is discovered by querying the GCE metadata server.\"),mdx(\"p\",null,\"docker run --log-driver=gcplogs \\\\\"),mdx(\"p\",null,\"--log-opt labels=location \\\\\"),mdx(\"p\",null,\"--log-opt env=TEST \\\\\"),mdx(\"p\",null,\"--log-opt gcp-log-cmd=true \\\\\"),mdx(\"p\",null,\"--env \\\"TEST=false\\\" \\\\\"),mdx(\"p\",null,\"--label location=west \\\\\"),mdx(\"p\",null,\"your/application\"),mdx(\"p\",null,\"This configuration also directs the driver to include in the payload the label\\xA0location, the environment variable\\xA0ENV, and the command used to start the container.\"),mdx(\"p\",null,\"An example of the logging options for running outside of GCE (the daemon must be configured with GOOGLE_APPLICATION_CREDENTIALS):\"),mdx(\"p\",null,\"docker run --log-driver=gcplogs \\\\\"),mdx(\"p\",null,\"--log-opt gcp-project=test-project\"),mdx(\"p\",null,\"--log-opt gcp-meta-zone=west1 \\\\\"),mdx(\"p\",null,\"--log-opt gcp-meta-name=\",mdx(\"inlineCode\",{parentName:\"p\"},\"hostname\"),\" \\\\\"),mdx(\"p\",null,\"your/application\"),mdx(\"h4\",null,\"Journald logging driver\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA05 minutes\")),mdx(\"p\",null,\"The\\xA0journald\\xA0logging driver sends container logs to the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://www.freedesktop.org/software/systemd/man/systemd-journald.service.html\"}),\"systemd\\xA0journal\"),\". Log entries can be retrieved using the\\xA0journalctl\\xA0command, through use of the\\xA0journal\\xA0API, or using the\\xA0docker logs\\xA0command.\"),mdx(\"p\",null,\"In addition to the text of the log message itself, the\\xA0journald\\xA0log driver stores the following metadata in the journal with each message:\"),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Field\"),\"                          \",mdx(\"strong\",{parentName:\"p\"},\"Description\")),mdx(\"hr\",null),mdx(\"p\",null,\"  CONTAINER_ID                       The container ID truncated to 12 characters.\\nCONTAINER_ID_FULL                  The full 64-character container ID.\\nCONTAINER_NAME                     The container name at the time it was started. If you use\\xA0docker rename\\xA0to rename a container, the new name is not reflected in the journal entries.\\nCONTAINER_TAG,\\xA0SYSLOG_IDENTIFIER   The container tag (\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/containers/logging/log_tags/\"}),\"log tag option documentation\"),\").\\nCONTAINER_PARTIAL_MESSAGE          A field that flags log integrity. Improve logging of long log lines.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Usage\")),mdx(\"p\",null,\"To use the\\xA0journald\\xA0driver as the default logging driver, set the\\xA0log-driver\\xA0and\\xA0log-opt\\xA0keys to appropriate values in the\\xA0daemon.json\\xA0file, which is located in\\xA0/etc/docker/\\xA0on Linux hosts or\\xA0C:\\\\ProgramData\\\\docker\\\\config\\\\daemon.json\\xA0on Windows Server. For more about configuring Docker using\\xA0daemon.json, see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-configuration-file\"}),\"daemon.json\"),\".\"),mdx(\"p\",null,\"The following example sets the log driver to\\xA0journald:\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"log-driver\\\": \\\"journald\\\"\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"Restart Docker for the changes to take effect.\"),mdx(\"p\",null,\"To configure the logging driver for a specific container, use the\\xA0--log-driver\\xA0flag on the\\xA0docker run\\xA0command.\"),mdx(\"p\",null,\"$ docker run --log-driver=journald ...\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Options\")),mdx(\"p\",null,\"Use the\\xA0--log-opt NAME=VALUE\\xA0flag to specify additional\\xA0journald\\xA0logging driver options.\"),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Option\"),\"   \",mdx(\"strong\",{parentName:\"p\"},\"Required\"),\"   \",mdx(\"strong\",{parentName:\"p\"},\"Description\")),mdx(\"hr\",null),mdx(\"p\",null,\"  tag          optional       Specify template to set\\xA0CONTAINER_TAG\\xA0and\\xA0SYSLOG_IDENTIFIERvalue in journald logs. Refer to\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/admin/logging/log_tags/\"}),\"log tag option documentation\"),\"\\xA0to customize the log tag format\\nlabel        optional       Comma-separated list of keys of labels, which should be included in message, if these labels are specified for the container.\\nenv          optional       Comma-separated list of keys of environment variables, which should be included in message, if these variables are specified for the container.\\nenv-regex    optional       Similar to and compatible with env. A regular expression to match logging-related environment variables. Used for advanced\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/admin/logging/log_tags/\"}),\"log tag options\"),\".\"),mdx(\"p\",null,\"If a collision occurs between label and env keys, the value of the env takes precedence. Each option adds additional fields to the attributes of a logging message.\"),mdx(\"p\",null,\"Below is an example of the logging options required to log to journald.\"),mdx(\"p\",null,\"$ docker run --log-driver=journald \\\\\"),mdx(\"p\",null,\"--log-opt labels=location \\\\\"),mdx(\"p\",null,\"--log-opt env=TEST \\\\\"),mdx(\"p\",null,\"--env \\\"TEST=false\\\" \\\\\"),mdx(\"p\",null,\"--label location=west \\\\\"),mdx(\"p\",null,\"your/application\"),mdx(\"p\",null,\"This configuration also directs the driver to include in the payload the label location, and the environment variable TEST. If the\\xA0--env \\\"TEST=false\\\"\\xA0or\\xA0--label location=west\\xA0arguments were omitted, the corresponding key would not be set in the journald log.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Note regarding container names\")),mdx(\"p\",null,\"The value logged in the\\xA0CONTAINER_NAME\\xA0field is the name of the container that was set at startup. If you use\\xA0docker rename\\xA0to rename a container, the new name\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"is not reflected\"),\"\\xA0in the journal entries. Journal entries continue to use the original name.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Retrieve log messages with\\xA0journalctl\")),mdx(\"p\",null,\"Use the\\xA0journalctl\\xA0command to retrieve log messages. You can apply filter expressions to limit the retrieved messages to those associated with a specific container:\"),mdx(\"p\",null,\"$ sudo journalctl CONTAINER_NAME=webserver\"),mdx(\"p\",null,\"You can use additional filters to further limit the messages retrieved. The\\xA0-b\\xA0flag only retrieves messages generated since the last system boot:\"),mdx(\"p\",null,\"$ sudo journalctl -b CONTAINER_NAME=webserver\"),mdx(\"p\",null,\"The\\xA0-o\\xA0flag specifies the format for the retried log messages. Use\\xA0-o json\\xA0to return the log messages in JSON format.\"),mdx(\"p\",null,\"$ sudo journalctl -o json CONTAINER_NAME=webserver\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"View logs for a container with a TTY enabled\")),mdx(\"p\",null,\"If TTY is enabled on a container you may see\\xA0\",\"[10B blob data]\",\"\\xA0in the output when retrieving log messages. The reason for that is that\\xA0\\\\r\\xA0is appended to the end of the line and\\xA0journalctldoesn't strip it automatically unless\\xA0--all\\xA0is set:\"),mdx(\"p\",null,\"$ sudo journalctl -b CONTAINER_NAME=webserver --all\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Retrieve log messages with the\\xA0journal\\xA0API\")),mdx(\"p\",null,\"This example uses the\\xA0systemd\\xA0Python module to retrieve container logs:\"),mdx(\"pre\",null,mdx(\"code\",_extends({parentName:\"pre\"},{\"className\":\"language-python\"}),\"import systemd.journal\\n\\nreader = systemd.journal.Reader()\\n\\nreader.add_match(\\\\'CONTAINER_NAME=web\\\\')\\n\\nfor msg in reader:\\n\\nprint \\\\'{CONTAINER_ID_FULL}: {MESSAGE}\\\\'.format(**msg)\\n\")),mdx(\"h4\",null,\"Splunk logging driver\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA06 minutes\")),mdx(\"p\",null,\"The\\xA0splunk\\xA0logging driver sends container logs to\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://dev.splunk.com/view/event-collector/SP-CAAAE6M\"}),\"HTTP Event Collector\"),\"\\xA0in Splunk Enterprise and Splunk Cloud.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Usage\")),mdx(\"p\",null,\"You can configure Docker logging to use the\\xA0splunk\\xA0driver by default or on a per-container basis.\"),mdx(\"p\",null,\"To use the\\xA0splunk\\xA0driver as the default logging driver, set the keys\\xA0log-driver\\xA0and\\xA0log-optsto appropriate values in the\\xA0daemon.json\\xA0configuration file and restart Docker. For example:\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"log-driver\\\": \\\"splunk\\\",\"),mdx(\"p\",null,\"\\\"log-opts\\\": {\"),mdx(\"p\",null,\"\\\"splunk-token\\\": \\\"\\\",\"),mdx(\"p\",null,\"\\\"splunk-url\\\": \\\"\\\",\"),mdx(\"p\",null,\"...\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"The daemon.json file is located in\\xA0/etc/docker/\\xA0on Linux hosts orC:\\\\ProgramData\\\\docker\\\\config\\\\daemon.json\\xA0on Windows Server. For more about configuring Docker using\\xA0daemon.json, see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-configuration-file\"}),\"daemon.json\"),\".\"),mdx(\"p\",null,\"To use the\\xA0splunk\\xA0driver for a specific container, use the commandline flags\\xA0--log-driver\\xA0and\\xA0log-opt\\xA0with\\xA0docker run:\"),mdx(\"p\",null,\"docker run --log-driver=splunk --log-opt splunk-token=VALUE --log-opt splunk-url=VALUE ...\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Splunk options\")),mdx(\"p\",null,\"The following properties let you configure the splunk logging driver.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},\"To configure the\\xA0splunk\\xA0driver across the Docker environment, edit\\xA0daemon.json\\xA0with the key,\\xA0\\\"log-opts\\\": {\\\"NAME\\\": \\\"VALUE\\\", ...}.\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},\"To configure the\\xA0splunk\\xA0driver for an indiviual container, use\\xA0docker run\\xA0with the flag,\\xA0--log-opt NAME=VALUE ....\"),mdx(\"p\",{parentName:\"li\"},mdx(\"strong\",{parentName:\"p\"},\"Option\"),\"                  \",mdx(\"strong\",{parentName:\"p\"},\"Required\"),\"   \",mdx(\"strong\",{parentName:\"p\"},\"Description\")),mdx(\"hr\",{parentName:\"li\"}),mdx(\"p\",{parentName:\"li\"},\"splunk-token                required       Splunk HTTP Event Collector token.\\nsplunk-url                  required       Path to your Splunk Enterprise, self-service Splunk Cloud instance, or Splunk Cloud managed cluster (including port and scheme used by HTTP Event Collector) in one of the following formats:\\xA0https://your_splunk_instance:8088\\xA0or\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://input-prd-p-XXXXXXX.cloud.splunk.com:8088or\"}),\"https://input-prd-p-XXXXXXX.cloud.splunk.com:8088or\"),\"\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://http-inputs-XXXXXXXX.splunkcloud.com.\"}),\"https://http-inputs-XXXXXXXX.splunkcloud.com.\"),\"\\nsplunk-source               optional       Event source.\\nsplunk-sourcetype           optional       Event source type.\\nsplunk-index                optional       Event index.\\nsplunk-capath               optional       Path to root certificate.\\nsplunk-caname               optional       Name to use for validating server certificate; by default the hostname of the\\xA0splunk-url\\xA0is used.\\nsplunk-insecureskipverify   optional       Ignore server certificate validation.\\nsplunk-format               optional       Message format. Can be\\xA0inline,\\xA0json\\xA0or\\xA0raw. Defaults to\\xA0inline.\\nsplunk-verify-connection    optional       Verify on start, that docker can connect to Splunk server. Defaults to true.\\nsplunk-gzip                 optional       Enable/disable gzip compression to send events to Splunk Enterprise or Splunk Cloud instance. Defaults to false.\\nsplunk-gzip-level           optional       Set compression level for gzip. Valid values are -1 (default), 0 (no compression), 1 (best speed) ... 9 (best compression). Defaults to\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://golang.org/pkg/compress/gzip/#DefaultCompression\"}),\"DefaultCompression\"),\".\\ntag                         optional       Specify tag for message, which interpret some markup. Default value is\\xA0{{.ID}}\\xA0(12 characters of the container ID). Refer to the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/containers/logging/log_tags/\"}),\"log tag option documentation\"),\"\\xA0for customizing the log tag format.\\nlabels                      optional       Comma-separated list of keys of labels, which should be included in message, if these labels are specified for container.\\nenv                         optional       Comma-separated list of keys of environment variables, which should be included in message, if these variables are specified for container.\\nenv-regex                   optional       Similar to and compatible with\\xA0env. A regular expression to match logging-related environment variables. Used for advanced\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/config/containers/logging/log_tags/\"}),\"log tag options\"),\".\"))),mdx(\"p\",null,\"If there is collision between the\\xA0label\\xA0and\\xA0env\\xA0keys, the value of the\\xA0env\\xA0takes precedence. Both options add additional fields to the attributes of a logging message.\"),mdx(\"p\",null,\"Below is an example of the logging options specified for the Splunk Enterprise instance. The instance is installed locally on the same machine on which the Docker daemon is running.\"),mdx(\"p\",null,\"The path to the root certificate and Common Name is specified using an HTTPS scheme. This is used for verification. The\\xA0SplunkServerDefaultCert\\xA0is automatically generated by Splunk certificates.\"),mdx(\"p\",null,\"$ docker run --log-driver=splunk \\\\\"),mdx(\"p\",null,\"--log-opt splunk-token=176FCEBF-4CF5-4EDF-91BC-703796522D20 \\\\\"),mdx(\"p\",null,\"--log-opt splunk-url=https://splunkhost:8088 \\\\\"),mdx(\"p\",null,\"--log-opt splunk-capath=/path/to/cert/cacert.pem \\\\\"),mdx(\"p\",null,\"--log-opt splunk-caname=SplunkServerDefaultCert \\\\\"),mdx(\"p\",null,\"--log-opt tag=\\\"{{.Name}}/{{.FullID}}\\\" \\\\\"),mdx(\"p\",null,\"--log-opt labels=location \\\\\"),mdx(\"p\",null,\"--log-opt env=TEST \\\\\"),mdx(\"p\",null,\"--env \\\"TEST=false\\\" \\\\\"),mdx(\"p\",null,\"--label location=west \\\\\"),mdx(\"p\",null,\"your/application\"),mdx(\"p\",null,\"The\\xA0splunk-url\\xA0for Splunk instances hosted on Splunk Cloud is in a format like\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://http-inputs-XXXXXXXX.splunkcloud.com\"}),\"https://http-inputs-XXXXXXXX.splunkcloud.com\"),\"\\xA0and does not include a port specifier.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Message formats\")),mdx(\"p\",null,\"There are three logging driver messaging formats:\\xA0inline\\xA0(default),\\xA0json, and\\xA0raw.\"),mdx(\"p\",null,\"The default format is\\xA0inline\\xA0where each log message is embedded as a string. For example:\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"attrs\\\": {\"),mdx(\"p\",null,\"\\\"env1\\\": \\\"val1\\\",\"),mdx(\"p\",null,\"\\\"label1\\\": \\\"label1\\\"\"),mdx(\"p\",null,\"},\"),mdx(\"p\",null,\"\\\"tag\\\": \\\"MyImage/MyContainer\\\",\"),mdx(\"p\",null,\"\\\"source\\\": \\\"stdout\\\",\"),mdx(\"p\",null,\"\\\"line\\\": \\\"my message\\\"\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"attrs\\\": {\"),mdx(\"p\",null,\"\\\"env1\\\": \\\"val1\\\",\"),mdx(\"p\",null,\"\\\"label1\\\": \\\"label1\\\"\"),mdx(\"p\",null,\"},\"),mdx(\"p\",null,\"\\\"tag\\\": \\\"MyImage/MyContainer\\\",\"),mdx(\"p\",null,\"\\\"source\\\": \\\"stdout\\\",\"),mdx(\"p\",null,\"\\\"line\\\": \\\"{\\\\\\\"foo\\\\\\\": \\\\\\\"bar\\\\\\\"}\\\"\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": If your messages are JSON objects, you may want to embed them in the message we send to Splunk.\"),mdx(\"p\",null,\"To format messages as\\xA0json\\xA0objects, set\\xA0--log-opt splunk-format=json. The driver trys to parse every line as a JSON object and send it as an embedded object. If it cannot parse the message, it is sent\\xA0inline. For example:\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"attrs\\\": {\"),mdx(\"p\",null,\"\\\"env1\\\": \\\"val1\\\",\"),mdx(\"p\",null,\"\\\"label1\\\": \\\"label1\\\"\"),mdx(\"p\",null,\"},\"),mdx(\"p\",null,\"\\\"tag\\\": \\\"MyImage/MyContainer\\\",\"),mdx(\"p\",null,\"\\\"source\\\": \\\"stdout\\\",\"),mdx(\"p\",null,\"\\\"line\\\": \\\"my message\\\"\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"attrs\\\": {\"),mdx(\"p\",null,\"\\\"env1\\\": \\\"val1\\\",\"),mdx(\"p\",null,\"\\\"label1\\\": \\\"label1\\\"\"),mdx(\"p\",null,\"},\"),mdx(\"p\",null,\"\\\"tag\\\": \\\"MyImage/MyContainer\\\",\"),mdx(\"p\",null,\"\\\"source\\\": \\\"stdout\\\",\"),mdx(\"p\",null,\"\\\"line\\\": {\"),mdx(\"p\",null,\"\\\"foo\\\": \\\"bar\\\"\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"To format messages as\\xA0raw, set\\xA0--log-opt splunk-format=raw. Attributes (environment variables and labels) and tags are prefixed to the message. For example:\"),mdx(\"p\",null,\"MyImage/MyContainer env1=val1 label1=label1 my message\"),mdx(\"p\",null,\"MyImage/MyContainer env1=val1 label1=label1 {\\\"foo\\\": \\\"bar\\\"}\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Advanced options\")),mdx(\"p\",null,\"Splunk Logging Driver allows you to configure few advanced options by specifying next environment variables for the Docker daemon.\"),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Environment variable name\"),\"                    \",mdx(\"strong\",{parentName:\"p\"},\"Default value\"),\"   \",mdx(\"strong\",{parentName:\"p\"},\"Description\")),mdx(\"hr\",null),mdx(\"p\",null,\"  SPLUNK_LOGGING_DRIVER_POST_MESSAGES_FREQUENCY    5s                  If there is nothing to batch how often driver posts messages. You can think about this as the maximum time to wait for more messages to batch.\\nSPLUNK_LOGGING_DRIVER_POST_MESSAGES_BATCH_SIZE   1000                How many messages driver should wait before sending them in one batch.\\nSPLUNK_LOGGING_DRIVER_BUFFER_MAX                 10 \",mdx(\"em\",{parentName:\"p\"},\" 1000          If driver cannot connect to remote server, what is the maximum amount of messages it can hold in buffer for retries.\\nSPLUNK_LOGGING_DRIVER_CHANNEL_SIZE               4 \"),\" 1000           How many pending messages can be in the channel which is used to send messages to background logger worker, which batches them.\"),mdx(\"h3\",null,\"Registry as a pull through cache\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA04 minutes\")),mdx(\"h4\",null,\"Use-case\"),mdx(\"p\",null,\"If you have multiple instances of Docker running in your environment, such as multiple physical or virtual machines all running Docker, each daemon goes out to the internet and fetches an image it doesn't have locally, from the Docker repository. You can run a local registry mirror and point all your daemons there, to avoid this extra internet traffic.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Alternatives\")),mdx(\"p\",null,\"Alternatively, if the set of images you are using is well delimited, you can simply pull them manually and push them to a simple, local, private registry.\"),mdx(\"p\",null,\"Furthermore, if your images are all built in-house, not using the Hub at all and relying entirely on your local registry is the simplest scenario.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Gotcha\")),mdx(\"p\",null,\"It's currently not possible to mirror another private registry. Only the central Hub can be mirrored.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Solution\")),mdx(\"p\",null,\"The Registry can be configured as a pull through cache. In this mode a Registry responds to all normal docker pull requests but stores all content locally.\"),mdx(\"h4\",null,\"How does it work?\"),mdx(\"p\",null,\"The first time you request an image from your local registry mirror, it pulls the image from the public Docker registry and stores it locally before handing it back to you. On subsequent requests, the local registry mirror is able to serve the image from its own storage.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"What if the content changes on the Hub?\")),mdx(\"p\",null,\"When a pull is attempted with a tag, the Registry checks the remote to ensure if it has the latest version of the requested content. Otherwise, it fetches and caches the latest content.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"What about my disk?\")),mdx(\"p\",null,\"In environments with high churn rates, stale data can build up in the cache. When running as a pull through cache the Registry periodically removes old content to save disk space. Subsequent requests for removed content causes a remote fetch and local re-caching.\"),mdx(\"p\",null,\"To ensure best performance and guarantee correctness the Registry cache should be configured to use the\\xA0filesystem\\xA0driver for storage.\"),mdx(\"h4\",null,\"Run a Registry as a pull-through cache\"),mdx(\"p\",null,\"The easiest way to run a registry as a pull through cache is to run the official Registry image. At least, you need to specify\\xA0proxy.remoteurl\\xA0within\\xA0/etc/docker/registry/config.yml\\xA0as described in the following subsection.\"),mdx(\"p\",null,\"Multiple registry caches can be deployed over the same back-end. A single registry cache ensures that concurrent requests do not pull duplicate data, but this property does not hold true for a registry cache cluster.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Configure the cache\")),mdx(\"p\",null,\"To configure a Registry to run as a pull through cache, the addition of a\\xA0proxy\\xA0section is required to the config file.\"),mdx(\"p\",null,\"To access private images on the Docker Hub, a username and password can be supplied.\"),mdx(\"p\",null,\"proxy:\"),mdx(\"p\",null,\"remoteurl: \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://registry-1.docker.io\"}),\"https://registry-1.docker.io\")),mdx(\"p\",null,\"username: \",\"[username]\"),mdx(\"p\",null,\"password: \",\"[password]\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Warning\"),\": If you specify a username and password, it's very important to understand that private resources that this user has access to Docker Hub is made available on your mirror.\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"You must secure your mirror\"),\"\\xA0by implementing authentication if you expect these resources to stay private!\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Warning\"),\": For the scheduler to clean up old entries,\\xA0delete\\xA0must be enabled in the registry configuration. See\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/registry/configuration/\"}),\"Registry Configuration\"),\"\\xA0for more details.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Configure the Docker daemon\")),mdx(\"p\",null,\"Either pass the\\xA0--registry-mirror\\xA0option when starting\\xA0dockerd\\xA0manually, or edit\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-configuration-file\"}),\"/etc/docker/daemon.json\"),\"\\xA0and add the\\xA0registry-mirrors\\xA0key and value, to make the change persistent.\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"registry-mirrors\\\": \",\"[\\\"https://\",mdx(\"inlineCode\",{parentName:\"p\"},\"<my-docker-mirror-host>\"),\"\\\"]\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"Save the file and reload Docker for the change to take effect.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Some log messages that appear to be errors are actually informational messages.\")),mdx(\"p\",null,\"Check the\\xA0level\\xA0field to determine whether the message is warning you about an error or is giving you information. For example, this log message is informational:\"),mdx(\"p\",null,\"time=\\\"2017-06-02T15:47:37Z\\\" level=info msg=\\\"error statting local store, serving from upstream: unknown blob\\\" go.version=go1.7.4\"),mdx(\"p\",null,\"It's telling you that the file doesn't exist yet in the local cache and is being pulled from upstream.\"),mdx(\"h4\",null,\"Use case: the China registry mirror\"),mdx(\"p\",null,\"The URL of the registry mirror for China is\\xA0registry.docker-cn.com. You can pull images from this mirror just like you do for other registries by specifying the full path, including the registry, in your\\xA0docker pull\\xA0command, for example:\"),mdx(\"p\",null,\"$ docker pull registry.docker-cn.com/library/ubuntu\"),mdx(\"p\",null,\"You can add\\xA0\\\"\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://registry.docker-cn.com%22\"}),\"https://registry.docker-cn.com\\\"\"),\"\\xA0to the\\xA0registry-mirrors\\xA0array in\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-configuration-file\"}),\"/etc/docker/daemon.json\"),\"\\xA0to pull from the China registry mirror by default.\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"registry-mirrors\\\": \",\"[\\\"https://registry.docker-cn.com\\\"]\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"Save the file and reload Docker for the change to take effect.\"),mdx(\"p\",null,\"Or, you can configure the Docker daemon with the\\xA0--registry-mirror\\xA0startup parameter:\"),mdx(\"p\",null,\"$ dockerd --registry-mirror=\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://registry.docker-cn.com\"}),\"https://registry.docker-cn.com\")),mdx(\"h3\",null,\"Work with external tools\"),mdx(\"h4\",null,\"Use PowerShell DSC\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA04 minutes\")),mdx(\"p\",null,\"Windows PowerShell Desired State Configuration (DSC) is a configuration management tool that extends the existing functionality of Windows PowerShell. DSC uses a declarative syntax to define the state in which a target should be configured. More information about PowerShell DSC can be found at\\xA0\",mdx(\"inlineCode\",{parentName:\"p\"},\"<http://technet.microsoft.com/en-us/library/dn249912.aspx>\"),\".\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Requirements\")),mdx(\"p\",null,\"To use this guide you need a Windows host with PowerShell v4.0 or newer.\"),mdx(\"p\",null,\"The included DSC configuration script also uses the official PPA so only an Ubuntu target is supported. The Ubuntu target must already have the required OMI Server and PowerShell DSC for Linux providers installed. More information can be found at\\xA0\",mdx(\"inlineCode\",{parentName:\"p\"},\"<https://github.com/MSFTOSSMgmt/WPSDSCLinux>\"),\". The source repository listed below also includes PowerShell DSC for Linux installation and init scripts along with more detailed installation information.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Installation\")),mdx(\"p\",null,\"The DSC configuration example source is available in the following repository:\",mdx(\"inlineCode\",{parentName:\"p\"},\"<https://github.com/anweiss/DockerClientDSC>\"),\". It can be cloned with:\"),mdx(\"p\",null,\"$ git clone \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/anweiss/DockerClientDSC.git\"}),\"https://github.com/anweiss/DockerClientDSC.git\")),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Usage\")),mdx(\"p\",null,\"The DSC configuration utilizes a set of shell scripts to determine whether or not the specified Docker components are configured on the target node(s). The source repository also includes a script (RunDockerClientConfig.ps1) that can be used to establish the required CIM session(s) and execute the\\xA0Set-DscConfiguration\\xA0cmdlet.\"),mdx(\"p\",null,\"More detailed usage information can be found at\\xA0\",mdx(\"inlineCode\",{parentName:\"p\"},\"<https://github.com/anweiss/DockerClientDSC>\"),\".\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Install Docker\")),mdx(\"p\",null,\"The Docker installation configuration is equivalent to running:\"),mdx(\"p\",null,\"apt-key adv --keyserver hkp://p80.pool.sks-keyservers.net:80 --recv-keys\\\\\"),mdx(\"p\",null,\"36A1D7869245C8950F966E92D8576A8BA88D21E9\"),mdx(\"p\",null,\"sh -c \\\"echo deb \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://apt.dockerproject.org/repo\"}),\"https://apt.dockerproject.org/repo\"),\" ubuntu-trusty main\\\\\"),mdx(\"blockquote\",null,mdx(\"p\",{parentName:\"blockquote\"},\"/etc/apt/sources.list.d/docker.list\\\"\")),mdx(\"p\",null,\"apt-get update\"),mdx(\"p\",null,\"apt-get install docker-engine\"),mdx(\"p\",null,\"Ensure that your current working directory is set to the\\xA0DockerClientDSC\\xA0source and load the DockerClient configuration into the current PowerShell session\"),mdx(\"p\",null,\". .\\\\DockerClient.ps1\"),mdx(\"p\",null,\"Generate the required DSC configuration .mof file for the targeted node\"),mdx(\"p\",null,\"DockerClient -Hostname \\\"myhost\\\"\"),mdx(\"p\",null,\"A sample DSC configuration data file has also been included and can be modified and used in conjunction with or in place of the\\xA0Hostname\\xA0parameter:\"),mdx(\"p\",null,\"DockerClient -ConfigurationData .\\\\DockerConfigData.psd1\"),mdx(\"p\",null,\"Start the configuration application process on the targeted node\"),mdx(\"p\",null,\".\\\\RunDockerClientConfig.ps1 -Hostname \\\"myhost\\\"\"),mdx(\"p\",null,\"The\\xA0RunDockerClientConfig.ps1\\xA0script can also parse a DSC configuration data file and execute configurations against multiple nodes as such:\"),mdx(\"p\",null,\".\\\\RunDockerClientConfig.ps1 -ConfigurationData .\\\\DockerConfigData.psd1\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Images\")),mdx(\"p\",null,\"Image configuration is equivalent to running:\\xA0docker pull \",\"[image]\",\"\\xA0ordocker image rm -f \",\"[IMAGE]\",\".\"),mdx(\"p\",null,\"Using the same steps defined above, execute\\xA0DockerClient\\xA0with the\\xA0Image\\xA0parameter and apply the configuration:\"),mdx(\"p\",null,\"DockerClient -Hostname \\\"myhost\\\" -Image \\\"node\\\"\"),mdx(\"p\",null,\".\\\\RunDockerClientConfig.ps1 -Hostname \\\"myhost\\\"\"),mdx(\"p\",null,\"You can also configure the host to pull multiple images:\"),mdx(\"p\",null,\"DockerClient -Hostname \\\"myhost\\\" -Image \\\"node\\\",\\\"mongo\\\"\"),mdx(\"p\",null,\".\\\\RunDockerClientConfig.ps1 -Hostname \\\"myhost\\\"\"),mdx(\"p\",null,\"To remove images, use a hashtable as follows:\"),mdx(\"p\",null,\"DockerClient -Hostname \\\"myhost\\\" -Image @{Name=\\\"node\\\"; Remove=$true}\"),mdx(\"p\",null,\".\\\\RunDockerClientConfig.ps1 -Hostname $hostname\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Containers\")),mdx(\"p\",null,\"Container configuration is equivalent to running:\"),mdx(\"p\",null,\"docker run -d --name=\\\"\",\"[containername]\",\"\\\" -p \\\\'\",\"[port]\",\"\\\\' -e \\\\'\",\"[env]\",\"\\\\' --link \\\\'\",\"[link]\",\"\\\\'\\\\\"),mdx(\"p\",null,\"\\\\'\",\"[image]\",\"\\\\' \\\\'\",\"[command]\",\"\\\\'\"),mdx(\"p\",null,\"or\"),mdx(\"p\",null,\"docker container rm -f \",\"[containername]\"),mdx(\"p\",null,\"To create or remove containers, you can use the\\xA0Container\\xA0parameter with one or more hashtables. The hashtable(s) passed to this parameter can have the following properties:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Name (required)\"),mdx(\"li\",{parentName:\"ul\"},\"Image (required unless Remove property is set to\\xA0$true)\"),mdx(\"li\",{parentName:\"ul\"},\"Port\"),mdx(\"li\",{parentName:\"ul\"},\"Env\"),mdx(\"li\",{parentName:\"ul\"},\"Link\"),mdx(\"li\",{parentName:\"ul\"},\"Command\"),mdx(\"li\",{parentName:\"ul\"},\"Remove\")),mdx(\"p\",null,\"For example, create a hashtable with the settings for your container:\"),mdx(\"p\",null,\"$webContainer = @{Name=\\\"web\\\"; Image=\\\"anweiss/docker-platynem\\\"; Port=\\\"80:80\\\"}\"),mdx(\"p\",null,\"Then, using the same steps defined above, execute\\xA0DockerClient\\xA0with the\\xA0-Image\\xA0and\\xA0-Container\\xA0parameters:\"),mdx(\"p\",null,\"DockerClient -Hostname \\\"myhost\\\" -Image node -Container $webContainer\"),mdx(\"p\",null,\".\\\\RunDockerClientConfig.ps1 -Hostname \\\"myhost\\\"\"),mdx(\"p\",null,\"Existing containers can also be removed as follows:\"),mdx(\"p\",null,\"$containerToRemove = @{Name=\\\"web\\\"; Remove=$true}\"),mdx(\"p\",null,\"DockerClient -Hostname \\\"myhost\\\" -Container $containerToRemove\"),mdx(\"p\",null,\".\\\\RunDockerClientConfig.ps1 -Hostname \\\"myhost\\\"\"),mdx(\"p\",null,\"Here is a hashtable with all of the properties that can be used to create a container:\"),mdx(\"p\",null,\"$containerProps = @{Name=\\\"web\\\"; Image=\\\"node:latest\\\"; Port=\\\"80:80\\\"; `\"),mdx(\"p\",null,\"Env=\\\"PORT=80\\\"; Link=\\\"db:db\\\"; Command=\\\"grunt\\\"}\"),mdx(\"h4\",null,\"Chef\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Docker Cookbook\")),mdx(\"p\",null,\"The Docker Cookbook provides resources for installing docker as well as managing and running docker containers.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Scope\")),mdx(\"p\",null,\"This cookbook is concerned with the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://docker.io/\"}),\"Docker\"),\"\\xA0container engine as distributed by Docker, Inc. It does not address Docker ecosystem tooling or prerequisite technology such as cgroups or aufs.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Requirements\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Chef 12.15 or later\"),mdx(\"li\",{parentName:\"ul\"},\"Network accessible web server hosting the docker binary.\"),mdx(\"li\",{parentName:\"ul\"},\"SELinux permissive/disabled if CentOS\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://github.com/docker/docker/issues/15498\"}),\"Docker Issue #15498\"))),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Platform Support\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Amazon Linux\"),mdx(\"li\",{parentName:\"ul\"},\"Debian 8/9\"),mdx(\"li\",{parentName:\"ul\"},\"Fedora\"),mdx(\"li\",{parentName:\"ul\"},\"Ubuntu 14.04/16.04\"),mdx(\"li\",{parentName:\"ul\"},\"CentOS 7\")),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Cookbook Dependencies\")),mdx(\"p\",null,\"This cookbook automatically sets up the upstream Docker package repositories. If you would like to use your own repositories this functionality can be disabled and you can instead setup the repos yourself with yum_repository/apt_repository resources or the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://supermarket.chef.io/cookbooks/chef-apt-docker\"}),\"chef-apt-docker\"),\"\\xA0/\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://supermarket.chef.io/cookbooks/chef-yum-docker\"}),\"chef-yum-docker\"),\"\\xA0cookbooks.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Docker Group\")),mdx(\"p\",null,\"If you are not using the official docker repositories you may run into issues with the docker group being different. RHEL is a known issue that defaults to using\\xA0dockerroot\\xA0for the service group. Add the\\xA0groupproperty to the\\xA0docker_service.\"),mdx(\"p\",null,\"docker_service \\\\'default\\\\' do\"),mdx(\"p\",null,\"group \\\\'dockerroot\\\\'\"),mdx(\"p\",null,\"action \",\"[:create, :start]\"),mdx(\"p\",null,\"end\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Usage\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Add\\xA0depends \\\\'docker\\\\'\\xA0to your cookbook\\\\'s metadata.rb\"),mdx(\"li\",{parentName:\"ul\"},\"Use the resources shipped in cookbook in a recipe, the same way you\\\\'d use core Chef resources (file, template, directory, package, etc).\")),mdx(\"p\",null,\"docker_service \\\\'default\\\\' do\"),mdx(\"p\",null,\"action \",\"[:create, :start]\"),mdx(\"p\",null,\"end\"),mdx(\"p\",null,\"docker_image \\\\'busybox\\\\' do\"),mdx(\"p\",null,\"action :pull\"),mdx(\"p\",null,\"end\"),mdx(\"p\",null,\"docker_container \\\\'an-echo-server\\\\' do\"),mdx(\"p\",null,\"repo \\\\'busybox\\\\'\"),mdx(\"p\",null,\"port \\\\'1234:1234\\\\'\"),mdx(\"p\",null,\"command \\\"nc -ll -p 1234 -e /bin/cat\\\"\"),mdx(\"p\",null,\"end\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Test Cookbooks as Examples\")),mdx(\"p\",null,\"The cookbooks ran under test-kitchen make excellent usage examples.\"),mdx(\"p\",null,\"The test recipes are found at:\"),mdx(\"p\",null,\"test/cookbooks/docker_test/\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Resources Overview\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://supermarket.chef.io/cookbooks/docker#docker_service\"}),\"docker_service\"),\": composite resource that uses docker_installation and docker_service_manager\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://supermarket.chef.io/cookbooks/docker#docker_installation\"}),\"docker_installation\"),\": automatically select an installation method\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://supermarket.chef.io/cookbooks/docker#docker_service_manager\"}),\"docker_service_manager\"),\": automatically selects a service manager\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://supermarket.chef.io/cookbooks/docker#docker_installation_script\"}),\"docker_installation_script\"),\": curl | bash\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://supermarket.chef.io/cookbooks/docker#docker_installation_package\"}),\"docker_installation_package\"),\": package \\\\'docker-ce\\\\'\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://supermarket.chef.io/cookbooks/docker#docker_service_manager_execute\"}),\"docker_service_manager_execute\"),\": manage docker daemon with Chef\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://supermarket.chef.io/cookbooks/docker#docker_service_manager_sysvinit\"}),\"docker_service_manager_sysvinit\"),\": manage docker daemon with a sysvinit script\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://supermarket.chef.io/cookbooks/docker#docker_service_manager_upstart\"}),\"docker_service_manager_upstart\"),\": manage docker daemon with upstart script\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://supermarket.chef.io/cookbooks/docker#docker_service_manager_systemd\"}),\"docker_service_manager_systemd\"),\": manage docker daemon with systemd unit files\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://supermarket.chef.io/cookbooks/docker#docker_image\"}),\"docker_image\"),\": image/repository operations\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://supermarket.chef.io/cookbooks/docker#docker_container\"}),\"docker_container\"),\": container operations\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://supermarket.chef.io/cookbooks/docker#docker_tag\"}),\"docker_tag\"),\": image tagging operations\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://supermarket.chef.io/cookbooks/docker#docker_registry\"}),\"docker_registry\"),\": registry operations\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://supermarket.chef.io/cookbooks/docker#docker_network\"}),\"docker_network\"),\": network operations\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://supermarket.chef.io/cookbooks/docker#docker_volume\"}),\"docker_volume\"),\": volume operations\")),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Getting Started\")),mdx(\"p\",null,\"Here\\\\'s a quick example of pulling the latest image and running a container with exposed ports.\"),mdx(\"h1\",null,\"Pull latest image\"),mdx(\"p\",null,\"docker_image \\\\'nginx\\\\' do\"),mdx(\"p\",null,\"tag \\\\'latest\\\\'\"),mdx(\"p\",null,\"action :pull\"),mdx(\"p\",null,\"notifies :redeploy, \\\\'docker_container\",\"[my_nginx]\",\"\\\\'\"),mdx(\"p\",null,\"end\"),mdx(\"h1\",null,\"Run container mapping containers port 80 to the host\\\\'s port 80\"),mdx(\"p\",null,\"docker_container \\\\'my_nginx\\\\' do\"),mdx(\"p\",null,\"repo \\\\'nginx\\\\'\"),mdx(\"p\",null,\"tag \\\\'latest\\\\'\"),mdx(\"p\",null,\"port \\\\'80:80\\\\'\"),mdx(\"p\",null,\"host_name \\\\'www\\\\'\"),mdx(\"p\",null,\"domain_name \\\\'computers.biz\\\\'\"),mdx(\"p\",null,\"env \\\\'FOO=bar\\\\'\"),mdx(\"p\",null,\"volumes \",\"[ \\\\'/some/local/files/:/etc/nginx/conf.d\\\\' ]\"),mdx(\"p\",null,\"end\"),mdx(\"p\",null,\"You might run a private registry and multiple Docker hosts.\"),mdx(\"h1\",null,\"Login to private registry\"),mdx(\"p\",null,\"docker_registry \\\\'\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://registry.computers.biz/%5C'\"}),\"https://registry.computers.biz/\\\\'\"),\" do\"),mdx(\"p\",null,\"username \\\\'shipper\\\\'\"),mdx(\"p\",null,\"password \\\\'iloveshipping\\\\'\"),mdx(\"p\",null,\"email \\\\'shipper\\\\@computers.biz\\\\'\"),mdx(\"p\",null,\"end\"),mdx(\"h1\",null,\"Pull tagged image\"),mdx(\"p\",null,\"docker_image \\\\'registry.computers.biz:443/my_project/my_container\\\\' do\"),mdx(\"p\",null,\"tag \\\\'latest\\\\'\"),mdx(\"p\",null,\"action :pull\"),mdx(\"p\",null,\"host \\\\'tcp://host-1.computers.biz:2376\\\\'\"),mdx(\"p\",null,\"end\"),mdx(\"h1\",null,\"Run container\"),mdx(\"p\",null,\"docker_container \\\\'crowsnest\\\\' do\"),mdx(\"p\",null,\"repo \\\\'registry.computers.biz:443/my_project/my_container\\\\'\"),mdx(\"p\",null,\"tag \\\\'latest\\\\'\"),mdx(\"p\",null,\"host \\\\'tcp://host-2.computers.biz:2376\\\\'\"),mdx(\"p\",null,\"tls_verify true\"),mdx(\"p\",null,\"tls_ca_cert \\\"/path/to/ca.pem\\\"\"),mdx(\"p\",null,\"tls_client_cert \\\"/path/to/cert.pem\\\"\"),mdx(\"p\",null,\"tls_client_key \\\"/path/to/key.pem\\\"\"),mdx(\"p\",null,\"action :run\"),mdx(\"p\",null,\"end\"),mdx(\"p\",null,\"You can manipulate Docker volumes and networks\"),mdx(\"p\",null,\"docker_network \\\\'my_network\\\\' do\"),mdx(\"p\",null,\"subnet \\\\'10.9.8.0/24\\\\'\"),mdx(\"p\",null,\"gateway \\\\'10.9.8.1\\\\'\"),mdx(\"p\",null,\"end\"),mdx(\"p\",null,\"docker_volume \\\\'my_volume\\\\' do\"),mdx(\"p\",null,\"action :create\"),mdx(\"p\",null,\"end\"),mdx(\"p\",null,\"docker_container \\\\'my_container\\\\' do\"),mdx(\"p\",null,\"repo \\\\'alpine\\\\'\"),mdx(\"p\",null,\"tag \\\\'3.1\\\\'\"),mdx(\"p\",null,\"command \\\"nc -ll -p 1234 -e /bin/cat\\\"\"),mdx(\"p\",null,\"volumes \\\\'my_volume:/my_data\\\\'\"),mdx(\"p\",null,\"network_mode \\\\'my_network\\\\'\"),mdx(\"p\",null,\"action :run\"),mdx(\"p\",null,\"end\"),mdx(\"p\",null,\"See full documentation for each resource and action below for more information.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Resources\")),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"docker_installation\")),mdx(\"p\",null,\"The\\xA0docker_installation\\xA0resource auto-selects one of the below resources with the provider resolution system.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Example\")),mdx(\"p\",null,\"docker_installation \\\\'default\\\\'\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"docker_installation_tarball\")),mdx(\"p\",null,\"The\\xA0docker_installation_tarball\\xA0resource copies the precompiled Go binary tarball onto the disk. It should not be used in production, especially with devicemapper.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Example\")),mdx(\"p\",null,\"docker_installation_tarball \\\\'default\\\\' do\"),mdx(\"p\",null,\"version \\\\'1.11.0\\\\'\"),mdx(\"p\",null,\"source \\\\'\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://my.computers.biz/dist/docker.tgz%5C'\"}),\"https://my.computers.biz/dist/docker.tgz\\\\'\")),mdx(\"p\",null,\"checksum \\\\'97a3f5924b0b831a310efa8bf0a4c91956cd6387c4a8667d27e2b2dd3da67e4d\\\\'\"),mdx(\"p\",null,\"action :create\"),mdx(\"p\",null,\"end\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Properties\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"version\\xA0- The desired version of docker to fetch.\"),mdx(\"li\",{parentName:\"ul\"},\"channel\\xA0- The docker channel to fetch the tarball from. Default: stable\"),mdx(\"li\",{parentName:\"ul\"},\"source\\xA0- Path to network accessible Docker binary tarball. Ignores version when set.\"),mdx(\"li\",{parentName:\"ul\"},\"checksum\\xA0- SHA-256 checksum of the tarball file.\")),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"docker_installation_script\")),mdx(\"p\",null,\"The\\xA0docker_installation_script\\xA0resource runs the script hosted by Docker, Inc at\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://get.docker.com/\"}),\"http://get.docker.com\"),\". It configures package repositories and installs a dynamically compiled binary.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Example\")),mdx(\"p\",null,\"docker_installation_script \\\\'default\\\\' do\"),mdx(\"p\",null,\"repo \\\\'main\\\\'\"),mdx(\"p\",null,\"script_url \\\\'\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://my.computers.biz/dist/scripts/docker.sh%5C'\"}),\"https://my.computers.biz/dist/scripts/docker.sh\\\\'\")),mdx(\"p\",null,\"action :create\"),mdx(\"p\",null,\"end\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Properties\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"repo\\xA0- One of \\\\'main\\\\', \\\\'test\\\\', or \\\\'experimental\\\\'. Used to calculate script_url in its absence. Defaults to \\\\'main\\\\'\"),mdx(\"li\",{parentName:\"ul\"},\"script_url\\xA0- \\\\'URL of script to pipe into /bin/sh as root.\")),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"docker_installation_package\")),mdx(\"p\",null,\"The\\xA0docker_installation_package\\xA0resource uses the system package manager to install Docker. It relies on the pre-configuration of the system\\\\'s package repositories. The\\xA0chef-yum-docker\\xA0and\\xA0chef-apt-docker\\xA0Supermarket cookbooks can be used to use Docker\\\\'s own repositories.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"This is the recommended production installation method.\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Example\")),mdx(\"p\",null,\"docker_installation_package \\\\'default\\\\' do\"),mdx(\"p\",null,\"version \\\\'1.8.3\\\\'\"),mdx(\"p\",null,\"action :create\"),mdx(\"p\",null,\"package_options %q|--force-yes -o Dpkg::Options::=\\\\'--force-confold\\\\' -o Dpkg::Options::=\\\\'--force-all\\\\'| # if Ubuntu for example\"),mdx(\"p\",null,\"end\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Properties\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"version\\xA0- Used to calculate package_version string\"),mdx(\"li\",{parentName:\"ul\"},\"package_version\\xA0- Manually specify the package version string\"),mdx(\"li\",{parentName:\"ul\"},\"package_name\\xA0- Name of package to install. Defaults to \\\\'docker-ce\\\\'\"),mdx(\"li\",{parentName:\"ul\"},\"package_options\\xA0- Manually specify additional options, like apt-get directives for example\"),mdx(\"li\",{parentName:\"ul\"},\"setup_docker_repo\\xA0- Setup the download.docker.com repo. If you would like to manage the repo yourself so you can use an internal repo then set this to false. default: true on all platforms except Amazon Linux.\"),mdx(\"li\",{parentName:\"ul\"},\"repo_channel\\xA0- The channel of docker to setup from download.docker.com. Only used if\\xA0setup_docker_repo\\xA0is true. default: \\\\'stable\\\\'\")),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"docker_service_manager\")),mdx(\"p\",null,\"The\\xA0docker\",mdx(\"em\",{parentName:\"p\"},\"service_manager\\xA0resource auto-selects a strategy from the\\xA0docker_service_manager\"),\"*group of resources based on platform and version. The\\xA0docker_service\\xA0family share a common set of properties.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Example\")),mdx(\"p\",null,\"docker_service_manager \\\\'default\\\\' do\"),mdx(\"p\",null,\"action :start\"),mdx(\"p\",null,\"end\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"docker_service_manager_execute\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Example\")),mdx(\"p\",null,\"docker_service_manager_execute \\\\'default\\\\' do\"),mdx(\"p\",null,\"action :start\"),mdx(\"p\",null,\"end\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"docker_service_manager_sysvinit\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Example\")),mdx(\"p\",null,\"docker_service_manager_sysvinit \\\\'default\\\\' do\"),mdx(\"p\",null,\"host \\\\'unix:///var/run/docker.sock\\\\'\"),mdx(\"p\",null,\"action :stop\"),mdx(\"p\",null,\"end\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"docker_service_manager_upstart\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Example\")),mdx(\"p\",null,\"docker_service_manager_upstart \\\\'default\\\\' do\"),mdx(\"p\",null,\"host \",\"[\\\\'unix:///var/run/docker.sock\\\\', \\\\'tcp://127.0.0.1:2376\\\\']\"),mdx(\"p\",null,\"action :start\"),mdx(\"p\",null,\"end\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"docker_service_manager_systemd\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Example\")),mdx(\"p\",null,\"docker_service_manager_systemd \\\\'default\\\\' do\"),mdx(\"p\",null,\"host \",\"[\\\\'unix:///var/run/docker.sock\\\\', \\\\'tcp://127.0.0.1:2376\\\\']\"),mdx(\"p\",null,\"tls_verify true\"),mdx(\"p\",null,\"tls_ca_cert \\\"/path/to/ca.pem\\\"\"),mdx(\"p\",null,\"tls_server_cert \\\"/path/to/server.pem\\\"\"),mdx(\"p\",null,\"tls_server_key \\\"/path/to/server-key.pem\\\"\"),mdx(\"p\",null,\"tls_client_cert \\\"/path/to/cert.pem\\\"\"),mdx(\"p\",null,\"tls_client_key \\\"/path/to/key.pem\\\"\"),mdx(\"p\",null,\"systemd_opts \",\"[\\\"TasksMax=infinity\\\",\\\"MountFlags=private\\\"]\"),mdx(\"p\",null,\"action :start\"),mdx(\"p\",null,\"end\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"docker_service\")),mdx(\"p\",null,\"The\\xA0docker_service: resource is a composite resource that uses\\xA0docker_installation\\xA0and\\xA0docker_service_manager\\xA0resources.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"The\\xA0:create\\xA0action uses a\\xA0docker_installation\"),mdx(\"li\",{parentName:\"ul\"},\"The\\xA0:delete\\xA0action uses a\\xA0docker_installation\"),mdx(\"li\",{parentName:\"ul\"},\"The\\xA0:start\\xA0action uses a\\xA0docker_service_manager\"),mdx(\"li\",{parentName:\"ul\"},\"The\\xA0:stop\\xA0action uses a\\xA0docker_service_manager\")),mdx(\"p\",null,\"The service management strategy for the host platform is dynamically chosen based on platform, but can be overridden.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Example\")),mdx(\"p\",null,\"docker_service \\\\'tls_test:2376\\\\' do\"),mdx(\"p\",null,\"host [ \\\"tcp://#{node\",\"[\\\\'ipaddress\\\\']\",\"}:2376\\\", \\\\'unix:///var/run/docker.sock\\\\' ]\"),mdx(\"p\",null,\"tls_verify true\"),mdx(\"p\",null,\"tls_ca_cert \\\\'/path/to/ca.pem\\\\'\"),mdx(\"p\",null,\"tls_server_cert \\\\'/path/to/server.pem\\\\'\"),mdx(\"p\",null,\"tls_server_key \\\\'/path/to/server-key.pem\\\\'\"),mdx(\"p\",null,\"tls_client_cert \\\\'/path/to/client.pem\\\\'\"),mdx(\"p\",null,\"tls_client_key \\\\'/path/to/client-key.pem\\\\'\"),mdx(\"p\",null,\"action \",\"[:create, :start]\"),mdx(\"p\",null,\"end\"),mdx(\"p\",null,\"WARNING - When creating multiple\\xA0docker_service\\xA0resources on the same machine, you will need to specify unique data_root properties to avoid unexpected behavior and possible data corruption.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Properties\")),mdx(\"p\",null,\"The\\xA0docker_service\\xA0resource property list mostly corresponds to the options found in the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/docker/\"}),\"Docker Command Line Reference\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"api_cors_header\\xA0- Set CORS headers in the remote API\"),mdx(\"li\",{parentName:\"ul\"},\"auto_restart\"),mdx(\"li\",{parentName:\"ul\"},\"exec_opts\"),mdx(\"li\",{parentName:\"ul\"},\"bip\\xA0- Specify network bridge IP\"),mdx(\"li\",{parentName:\"ul\"},\"bridge\\xA0- Attach containers to a network bridge\"),mdx(\"li\",{parentName:\"ul\"},\"checksum\\xA0- sha256 checksum of Docker binary\"),mdx(\"li\",{parentName:\"ul\"},\"cluster_advertise\\xA0- IP and port that this daemon should advertise to the cluster\"),mdx(\"li\",{parentName:\"ul\"},\"cluster_store_opts\\xA0- Cluster store options\"),mdx(\"li\",{parentName:\"ul\"},\"cluster_store\\xA0- Cluster store to use\"),mdx(\"li\",{parentName:\"ul\"},\"daemon\\xA0- Enable daemon mode\"),mdx(\"li\",{parentName:\"ul\"},\"data_root\\xA0- Root of the Docker runtime\"),mdx(\"li\",{parentName:\"ul\"},\"debug\\xA0- Enable debug mode\"),mdx(\"li\",{parentName:\"ul\"},\"default_ulimit\\xA0- Set default ulimit settings for containers\"),mdx(\"li\",{parentName:\"ul\"},\"disable_legacy_registry\\xA0- Do not contact legacy registries\"),mdx(\"li\",{parentName:\"ul\"},\"dns_search\\xA0- DNS search domains to use\"),mdx(\"li\",{parentName:\"ul\"},\"dns\\xA0- DNS server(s) to use\"),mdx(\"li\",{parentName:\"ul\"},\"exec_driver\\xA0- Exec driver to use\"),mdx(\"li\",{parentName:\"ul\"},\"fixed_cidr_v6\\xA0- IPv6 subnet for fixed IPs\"),mdx(\"li\",{parentName:\"ul\"},\"fixed_cidr\\xA0- IPv4 subnet for fixed IPs\"),mdx(\"li\",{parentName:\"ul\"},\"group\\xA0- Posix group for the unix socket. Default to\\xA0docker\"),mdx(\"li\",{parentName:\"ul\"},\"host\\xA0- Daemon socket(s) to connect to -\\xA0tcp://host:port,\\xA0unix:///path/to/socket,\\xA0fd://*\\xA0or\\xA0fd://socketfd\"),mdx(\"li\",{parentName:\"ul\"},\"http_proxy\\xA0- ENV variable set before for Docker daemon starts\"),mdx(\"li\",{parentName:\"ul\"},\"https_proxy\\xA0- ENV variable set before for Docker daemon starts\"),mdx(\"li\",{parentName:\"ul\"},\"icc\\xA0- Enable inter-container communication\"),mdx(\"li\",{parentName:\"ul\"},\"insecure_registry\\xA0- Enable insecure registry communication\"),mdx(\"li\",{parentName:\"ul\"},\"install_method\\xA0- Select script, package, tarball, none, or auto. Defaults to\\xA0auto.\"),mdx(\"li\",{parentName:\"ul\"},\"instance- Optional property used to override the name provided in the resource.\"),mdx(\"li\",{parentName:\"ul\"},\"ip_forward\\xA0- Enable ip forwarding\"),mdx(\"li\",{parentName:\"ul\"},\"ip_masq\\xA0- Enable IP masquerading\"),mdx(\"li\",{parentName:\"ul\"},\"ip\\xA0- Default IP when binding container ports\"),mdx(\"li\",{parentName:\"ul\"},\"iptables\\xA0- Enable addition of iptables rules\"),mdx(\"li\",{parentName:\"ul\"},\"ipv4_forward\\xA0- Enable net.ipv4.ip_forward\"),mdx(\"li\",{parentName:\"ul\"},\"ipv6_forward\\xA0- Enable net.ipv6.ip_forward\"),mdx(\"li\",{parentName:\"ul\"},\"ipv6\\xA0- Enable IPv6 networking\"),mdx(\"li\",{parentName:\"ul\"},\"labels\\xA0A string or array to set metadata on the daemon in the form \",\"[\\\\'foo:bar\\\\', \\\\'hello:world\\\\']\",\"`\"),mdx(\"li\",{parentName:\"ul\"},\"log_driver\\xA0- Container\\\\'s logging driver (json-file/syslog/journald/gelf/fluentd/awslogs/splunk/etwlogs/gcplogs/none)\"),mdx(\"li\",{parentName:\"ul\"},\"log_level\\xA0- Set the logging level\"),mdx(\"li\",{parentName:\"ul\"},\"log_opts\\xA0- Container\\\\'s logging driver options (driver-specific)\"),mdx(\"li\",{parentName:\"ul\"},\"logfile\\xA0- Location of Docker daemon log file\"),mdx(\"li\",{parentName:\"ul\"},\"mount_flags\\xA0- Set the systemd mount propagation flag.\"),mdx(\"li\",{parentName:\"ul\"},\"mtu\\xA0- Set the containers network MTU\"),mdx(\"li\",{parentName:\"ul\"},\"no_proxy\\xA0- ENV variable set before for Docker daemon starts\"),mdx(\"li\",{parentName:\"ul\"},\"package_name\\xA0- Set the package name. Defaults to\\xA0docker-ce\"),mdx(\"li\",{parentName:\"ul\"},\"pidfile\\xA0- Path to use for daemon PID file\"),mdx(\"li\",{parentName:\"ul\"},\"registry_mirror\\xA0- Preferred Docker registry mirror\"),mdx(\"li\",{parentName:\"ul\"},\"selinux_enabled\\xA0- Enable selinux support\"),mdx(\"li\",{parentName:\"ul\"},\"source\\xA0- URL to the pre-compiled Docker binary used for installation. Defaults to a calculated URL based on kernel version, Docker version, and platform arch. By default, this will try to get to \\\"\",mdx(\"inlineCode\",{parentName:\"li\"},\"<http://get.docker.io/builds/>\"),\"\\\".\"),mdx(\"li\",{parentName:\"ul\"},\"storage_driver\\xA0- Storage driver to use\"),mdx(\"li\",{parentName:\"ul\"},\"storage_opts\\xA0- Set storage driver options\"),mdx(\"li\",{parentName:\"ul\"},\"tls_ca_cert\\xA0- Trust certs signed only by this CA. Defaults to ENV\",\"[\\\\'DOCKER_CERT_PATH\\\\']\",\" if set\"),mdx(\"li\",{parentName:\"ul\"},\"tls_client_cert\\xA0- Path to TLS certificate file for docker cli. Defaults to ENV\",\"[\\\\'DOCKER_CERT_PATH\\\\']\",\" if set\"),mdx(\"li\",{parentName:\"ul\"},\"tls_client_key\\xA0- Path to TLS key file for docker cli. Defaults to ENV\",\"[\\\\'DOCKER_CERT_PATH\\\\']\",\" if set\"),mdx(\"li\",{parentName:\"ul\"},\"tls_server_cert\\xA0- Path to TLS certificate file for docker service\"),mdx(\"li\",{parentName:\"ul\"},\"tls_server_key\\xA0- Path to TLS key file for docker service\"),mdx(\"li\",{parentName:\"ul\"},\"tls_verify\\xA0- Use TLS and verify the remote. Defaults to ENV\",\"[\\\\'DOCKER_TLS_VERIFY\\\\']\",\" if set\"),mdx(\"li\",{parentName:\"ul\"},\"tls\\xA0- Use TLS; implied by --tlsverify. Defaults to ENV\",\"[\\\\'DOCKER_TLS\\\\']\",\" if set\"),mdx(\"li\",{parentName:\"ul\"},\"tmpdir\\xA0- ENV variable set before for Docker daemon starts\"),mdx(\"li\",{parentName:\"ul\"},\"userland_proxy- Enables or disables docker-proxy\"),mdx(\"li\",{parentName:\"ul\"},\"userns_remap\\xA0- Enable user namespace remapping options -\\xA0default,\\xA0uid,\\xA0uid:gid,\\xA0username,\\xA0username:groupname\\xA0(see:\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"see:%20https://docs.docker.com/v1.10/engine/reference/commandline/daemon/#daemon-user-namespace-options\"}),\"Docker User Namespaces\"),\")\"),mdx(\"li\",{parentName:\"ul\"},\"version\\xA0- Docker version to install\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Miscellaneous Options\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"misc_opts\\xA0- Pass the docker daemon any other options bypassing flag validation, supplied as\\xA0--flag=value\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Systemd-specific Options\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"systemd_opts\\xA0- An array of strings that will be included as individual lines in the systemd service unit for Docker.\\xA0Note: This option is only relevant for systems where systemd is the default service manager or where systemd is specified explicitly as the service manager.\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Actions\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\":create\\xA0- Lays the Docker bits out on disk\"),mdx(\"li\",{parentName:\"ul\"},\":delete\\xA0- Removes the Docker bits from the disk\"),mdx(\"li\",{parentName:\"ul\"},\":start\\xA0- Makes sure the service provider is set up properly and start it\"),mdx(\"li\",{parentName:\"ul\"},\":stop\\xA0- Stops the service\"),mdx(\"li\",{parentName:\"ul\"},\":restart\\xA0- Restarts the service\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"docker_service\\xA0implementations\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"docker_service_execute\\xA0- The simplest docker_service. Just starts a process. Fire and forget.\"),mdx(\"li\",{parentName:\"ul\"},\"docker_service_sysvinit\\xA0- Uses a SystemV init script to manage the service state.\"),mdx(\"li\",{parentName:\"ul\"},\"docker_service_upstart\\xA0- Uses an Upstart script to manage the service state.\"),mdx(\"li\",{parentName:\"ul\"},\"docker_service_systemd\\xA0- Uses an Systemd unit file to manage the service state. NOTE: This does NOT enable systemd socket activation.\")),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"docker_image\")),mdx(\"p\",null,\"The\\xA0docker_image\\xA0is responsible for managing Docker image pulls, builds, and deletions. It speaks directly to the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/v1.35/#tag/Image\"}),\"Docker Engine API\"),\".\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Actions\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\":pull\\xA0- Pulls an image from the registry. Default action.\"),mdx(\"li\",{parentName:\"ul\"},\":pull_if_missing\\xA0- Pulls an image from the registry, only if it missing\"),mdx(\"li\",{parentName:\"ul\"},\":build\\xA0- Builds an image from a Dockerfile, directory, or tarball\"),mdx(\"li\",{parentName:\"ul\"},\":build_if_missing\\xA0- Same build, but only if it is missing\"),mdx(\"li\",{parentName:\"ul\"},\":save\\xA0- Exports an image to a tarball at\\xA0destination\"),mdx(\"li\",{parentName:\"ul\"},\":import\\xA0- Imports an image from a tarball at\\xA0destination\"),mdx(\"li\",{parentName:\"ul\"},\":remove\\xA0- Removes (untags) an image\"),mdx(\"li\",{parentName:\"ul\"},\":push\\xA0- Pushes an image to the registry\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Properties\")),mdx(\"p\",null,\"The\\xA0docker_image\\xA0resource properties mostly corresponds to the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/v1.35/#tag/Image\"}),\"Docker Engine API\"),\"\\xA0as driven by the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/swipely/docker-api\"}),\"docker-api Ruby gem\")),mdx(\"p\",null,\"A\\xA0docker_image\\\\'s full identifier is a string in the form \\\"\\\\\"),mdx(\"p\",null,mdx(\"inlineCode\",{parentName:\"p\"},\"<repo\\\\>:<tag>\\\". There is some nuance around naming using the public registry vs a private one.</tag\\\\></repo\\\\>\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"repo\\xA0- aka\\xA0image_name\\xA0- The first half of a Docker image\\\\'s identity. This is a string in the form:\\xA0registry:port/owner/image_name. If the\\xA0registry:port\\xA0portion is left off, Docker will implicitly use the Docker public registry. \\\"Official Images\\\" omit the owner part. This means a repo id can be as short as\\xA0busybox,\\xA0alpine, or\\xA0centos. These names refer to official images on the public registry. Names can be as long as\\xA0my.computers.biz:5043/what/ever\\xA0to refer to custom images on an private registry. Often you\\\\'ll see something like\\xA0chef/chef\\xA0to refer to private images on the public registry. - Defaults to resource name.\"),mdx(\"li\",{parentName:\"ul\"},\"tag\\xA0- The second half of a Docker image\\\\'s identity. - Defaults to\\xA0latest\"),mdx(\"li\",{parentName:\"ul\"},\"source\\xA0- Path to input for the\\xA0:import,\\xA0:build\\xA0and\\xA0:build_if_missing\\xA0actions. For building, this can be a Dockerfile, a tarball containing a Dockerfile in its root, or a directory containing a Dockerfile. For\\xA0:import, this should be a tarball containing Docker formatted image, as generated with\\xA0:save.\"),mdx(\"li\",{parentName:\"ul\"},\"destination\\xA0- Path for output from the\\xA0:save\\xA0action.\"),mdx(\"li\",{parentName:\"ul\"},\"force\\xA0- A force boolean used in various actions - Defaults to false\"),mdx(\"li\",{parentName:\"ul\"},\"nocache\\xA0- Used in\\xA0:build\\xA0operations. - Defaults to false\"),mdx(\"li\",{parentName:\"ul\"},\"noprune\\xA0- Used in\\xA0:remove\\xA0operations - Defaults to false\"),mdx(\"li\",{parentName:\"ul\"},\"rm\\xA0- Remove intermediate containers after a successful build (default behavior) - Defaults to\\xA0true\"),mdx(\"li\",{parentName:\"ul\"},\"read_timeout\\xA0- May need to increase for long image builds/pulls\"),mdx(\"li\",{parentName:\"ul\"},\"write_timeout\\xA0- May need to increase for long image builds/pulls\"),mdx(\"li\",{parentName:\"ul\"},\"host\\xA0- A string containing the host the API should communicate with. Defaults to\\xA0ENV\",\"[\\\\'DOCKER_HOST\\\\']\",\"\\xA0if set.\"),mdx(\"li\",{parentName:\"ul\"},\"tls\\xA0- Use TLS; implied by --tlsverify. Defaults to ENV\",\"[\\\\'DOCKER_TLS\\\\']\",\" if set.\"),mdx(\"li\",{parentName:\"ul\"},\"tls_verify\\xA0- Use TLS and verify the remote. Defaults to\\xA0ENV\",\"[\\\\'DOCKER_TLS_VERIFY\\\\']\",\"\\xA0if set\"),mdx(\"li\",{parentName:\"ul\"},\"tls_ca_cert\\xA0- Trust certs signed only by this CA. Defaults to\\xA0ENV\",\"[\\\\'DOCKER_CERT_PATH\\\\']\",\"\\xA0if set.\"),mdx(\"li\",{parentName:\"ul\"},\"tls_client_cert\\xA0- Path to TLS certificate file for docker cli. Defaults to\\xA0ENV\",\"[\\\\'DOCKER_CERT_PATH\\\\']\",\"if set\"),mdx(\"li\",{parentName:\"ul\"},\"tls_client_key\\xA0- Path to TLS key file for docker cli. Defaults to\\xA0ENV\",\"[\\\\'DOCKER_CERT_PATH\\\\']\",\"\\xA0if set.\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Examples\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"default action, default properties\")),mdx(\"p\",null,\"docker_image \\\\'hello-world\\\\'\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"non-default name property\")),mdx(\"p\",null,\"docker_image \\\"Tom\\\\'s container\\\" do\"),mdx(\"p\",null,\"repo \\\\'tduffield/testcontainerd\\\\'\"),mdx(\"p\",null,\"action :pull\"),mdx(\"p\",null,\"end\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"pull every time\")),mdx(\"p\",null,\"docker_image \\\\'busybox\\\\' do\"),mdx(\"p\",null,\"action :pull\"),mdx(\"p\",null,\"end\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"specify a tag\")),mdx(\"p\",null,\"docker_image \\\\'alpine\\\\' do\"),mdx(\"p\",null,\"tag \\\\'3.1\\\\'\"),mdx(\"p\",null,\"end\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"specify read/write timeouts\")),mdx(\"p\",null,\"docker_image \\\\'alpine\\\\' do\"),mdx(\"p\",null,\"read_timeout 60\"),mdx(\"p\",null,\"write_timeout 60\"),mdx(\"p\",null,\"end\"),mdx(\"p\",null,\"docker_image \\\\'vbatts/slackware\\\\' do\"),mdx(\"p\",null,\"action :remove\"),mdx(\"p\",null,\"end\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"save\")),mdx(\"p\",null,\"docker_image \\\\'save hello-world\\\\' do\"),mdx(\"p\",null,\"repo \\\\'hello-world\\\\'\"),mdx(\"p\",null,\"destination \\\\'/tmp/hello-world.tar\\\\'\"),mdx(\"p\",null,\"not_if { ::File.exist?(\\\\'/tmp/hello-world.tar\\\\') }\"),mdx(\"p\",null,\"action :save\"),mdx(\"p\",null,\"end\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"build from a Dockerfile on every chef-client run\")),mdx(\"p\",null,\"docker_image \\\\'image_1\\\\' do\"),mdx(\"p\",null,\"tag \\\\'v0.1.0\\\\'\"),mdx(\"p\",null,\"source \\\\'/src/myproject/container1/Dockerfile\\\\'\"),mdx(\"p\",null,\"action :build\"),mdx(\"p\",null,\"end\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"build from a directory, only if image is missing\")),mdx(\"p\",null,\"docker_image \\\\'image_2\\\\' do\"),mdx(\"p\",null,\"tag \\\\'v0.1.0\\\\'\"),mdx(\"p\",null,\"source \\\\'/src/myproject/container2\\\\'\"),mdx(\"p\",null,\"action :build_if_missing\"),mdx(\"p\",null,\"end\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"build from a tarball NOTE: this is not an \\\"export\\\" tarball generated from an an image save. The contents should be a Dockerfile, and anything it references to COPY or ADD\")),mdx(\"p\",null,\"docker_image \\\\'image_3\\\\' do\"),mdx(\"p\",null,\"tag \\\\'v0.1.0\\\\'\"),mdx(\"p\",null,\"source \\\\'/tmp/image_3.tar\\\\'\"),mdx(\"p\",null,\"action :build\"),mdx(\"p\",null,\"end\"),mdx(\"p\",null,\"docker_image \\\\'hello-again\\\\' do\"),mdx(\"p\",null,\"tag \\\\'v0.1.0\\\\'\"),mdx(\"p\",null,\"source \\\\'/tmp/hello-world.tar\\\\'\"),mdx(\"p\",null,\"action :import\"),mdx(\"p\",null,\"end\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"push\")),mdx(\"p\",null,\"docker_image \\\\'my.computers.biz:5043/someara/hello-again\\\\' do\"),mdx(\"p\",null,\"action :push\"),mdx(\"p\",null,\"end\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Connect to an external docker daemon and pull an image\")),mdx(\"p\",null,\"docker_image \\\\'alpine\\\\' do\"),mdx(\"p\",null,\"host \\\\'tcp://127.0.0.1:2376\\\\'\"),mdx(\"p\",null,\"tag \\\\'2.7\\\\'\"),mdx(\"p\",null,\"end\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"docker_tag\")),mdx(\"p\",null,\"Docker tags work very much like hard links in a Unix filesystem. They are just references to an existing image. Therefore, the docker_tag resource has taken inspiration from the Chef\\xA0link\\xA0resource.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Actions\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\":tag\\xA0- Tags the image\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Properties\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"target_repo\\xA0- The repo half of the source image identifier.\"),mdx(\"li\",{parentName:\"ul\"},\"target_tag\\xA0- The tag half of the source image identifier.\"),mdx(\"li\",{parentName:\"ul\"},\"to_repo\\xA0- The repo half of the new image identifier\"),mdx(\"li\",{parentName:\"ul\"},\"to_tag- The tag half of the new image identifier\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Examples\")),mdx(\"p\",null,\"docker_tag \\\\'private repo tag for hello-again:1.0.1\\\\' do\"),mdx(\"p\",null,\"target_repo \\\\'hello-again\\\\'\"),mdx(\"p\",null,\"target_tag \\\\'v0.1.0\\\\'\"),mdx(\"p\",null,\"to_repo \\\\'localhost:5043/someara/hello-again\\\\'\"),mdx(\"p\",null,\"to_tag \\\\'latest\\\\'\"),mdx(\"p\",null,\"action :tag\"),mdx(\"p\",null,\"end\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"docker_container\")),mdx(\"p\",null,\"The\\xA0docker_container\\xA0is responsible for managing Docker container actions. It speaks directly to the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/reference/api/docker_remote_api_v1.20/\"}),\"Docker remote API\"),\".\"),mdx(\"p\",null,\"Containers are process oriented, and move through an event cycle. Thanks to\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://gliderlabs.com/\"}),\"Glider Labs\"),\"\\xA0for this excellent diagram.\\xA0\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Actions\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\":create\\xA0- Creates the container but does not start it. Useful for Volume containers.\"),mdx(\"li\",{parentName:\"ul\"},\":start\\xA0- Starts the container. Useful for containers that run jobs.. command that exit.\"),mdx(\"li\",{parentName:\"ul\"},\":run\\xA0- The default action. Both\\xA0:create\\xA0and\\xA0:start\\xA0the container in one action. Redeploys the container on resource change.\"),mdx(\"li\",{parentName:\"ul\"},\":run_if_missing\\xA0- Runs a container only once.\"),mdx(\"li\",{parentName:\"ul\"},\":stop\\xA0- Stops the container.\"),mdx(\"li\",{parentName:\"ul\"},\":restart\\xA0- Stops and then starts the container.\"),mdx(\"li\",{parentName:\"ul\"},\":kill\\xA0- Send a signal to the container process. Defaults to\\xA0SIGKILL.\"),mdx(\"li\",{parentName:\"ul\"},\":pause\\xA0- Pauses the container.\"),mdx(\"li\",{parentName:\"ul\"},\":unpause\\xA0- Unpauses the container.\"),mdx(\"li\",{parentName:\"ul\"},\":delete\\xA0- Deletes the container.\"),mdx(\"li\",{parentName:\"ul\"},\":redeploy\\xA0- Deletes and runs the container.\"),mdx(\"li\",{parentName:\"ul\"},\":reload\\xA0- Sends SIGHUP to pid 1 in the container\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Properties\")),mdx(\"p\",null,\"Most\\xA0docker_container\\xA0properties are the\\xA0snake_case\\xA0version of the\\xA0CamelCase\\xA0keys found in the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/reference/api/docker_remote_api_v1.20/\"}),\"Docker Remote Api\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"container_name\\xA0- The name of the container. Defaults to the name of the\\xA0docker_containerresource.\"),mdx(\"li\",{parentName:\"ul\"},\"repo\\xA0- aka\\xA0image_name. The first half of a the complete identifier for a Docker Image.\"),mdx(\"li\",{parentName:\"ul\"},\"tag\\xA0- The second half of a Docker image\\\\'s identity. - Defaults to\\xA0latest.\"),mdx(\"li\",{parentName:\"ul\"},\"command\\xA0- The command to run when starting the container.\"),mdx(\"li\",{parentName:\"ul\"},\"autoremove\\xA0- Boolean - Automatically delete a container when it\\\\'s command exits. Defaults to\\xA0false.\"),mdx(\"li\",{parentName:\"ul\"},\"volumes\\xA0- An array of volume bindings for this container. Each volume binding is a string in one of these forms:\\xA0container_path\\xA0to create a new volume for the container.\\xA0host_path:container_path\\xA0to bind-mount a host path into the container.\\xA0host_path:container_path:ro\\xA0to make the bind-mount read-only inside the container.\"),mdx(\"li\",{parentName:\"ul\"},\"cap_add\\xA0- An array Linux Capabilities (man 7 capabilities) to add to grant the container beyond what it normally gets.\"),mdx(\"li\",{parentName:\"ul\"},\"cap_drop\\xA0- An array Linux Capabilities (man 7 capabilities) to revoke that the container normally has.\"),mdx(\"li\",{parentName:\"ul\"},\"cpu_shares\\xA0- An integer value containing the CPU Shares for the container.\"),mdx(\"li\",{parentName:\"ul\"},\"devices\\xA0- A Hash of devices to add to the container.\"),mdx(\"li\",{parentName:\"ul\"},\"dns\\xA0- An array of DNS servers the container will use for name resolution.\"),mdx(\"li\",{parentName:\"ul\"},\"dns_search\\xA0- An array of domains the container will search for name resolution.\"),mdx(\"li\",{parentName:\"ul\"},\"domain_name\\xA0- Set\\\\'s the container\\\\'s dnsdomainname as returned by the\\xA0dnsdomainname\\xA0command.\"),mdx(\"li\",{parentName:\"ul\"},\"entrypoint\\xA0- Set the entry point for the container as a string or an array of strings.\"),mdx(\"li\",{parentName:\"ul\"},\"env\\xA0- Set environment variables in the container in the form\\xA0\",\"[\\\\'FOO=bar\\\\', \\\\'BIZ=baz\\\\']\"),mdx(\"li\",{parentName:\"ul\"},\"env_file\\xA0- Read environment variables from a file and set in the container. Accepts an Array or String to the file location. lazy evaluator must be set if the file passed is created by Chef.\"),mdx(\"li\",{parentName:\"ul\"},\"extra_hosts\\xA0- An array of hosts to add to the container\\\\'s\\xA0/etc/hosts\\xA0in the form\\xA0\",\"[\\\\'host_a:10.9.8.7\\\\', \\\\'host_b:10.9.8.6\\\\']\"),mdx(\"li\",{parentName:\"ul\"},\"force\\xA0- A boolean to use in container operations that support a\\xA0force\\xA0option. Defaults to\\xA0false\"),mdx(\"li\",{parentName:\"ul\"},\"host\\xA0- A string containing the host the API should communicate with. Defaults to ENV\",\"[\\\\'DOCKER_HOST\\\\']\",\" if set\"),mdx(\"li\",{parentName:\"ul\"},\"host_name\\xA0- The hostname for the container.\"),mdx(\"li\",{parentName:\"ul\"},\"labels\\xA0A string, array, or hash to set metadata on the container in the form \",\"[\\\\'foo:bar\\\\', \\\\'hello:world\\\\']\",\"`\"),mdx(\"li\",{parentName:\"ul\"},\"links\\xA0- An array of source container/alias pairs to link the container to in the form\\xA0\",\"[container_a:www\\\\', container_b:db\\\\']\"),mdx(\"li\",{parentName:\"ul\"},\"log_driver\\xA0- Sets a custom logging driver for the container (json-file/syslog/journald/gelf/fluentd/none).\"),mdx(\"li\",{parentName:\"ul\"},\"log_opts\\xA0- Configures the above logging driver options (driver-specific).\"),mdx(\"li\",{parentName:\"ul\"},\"init\\xA0- Run an init inside the container that forwards signals and reaps processes.\"),mdx(\"li\",{parentName:\"ul\"},\"ip_address\\xA0- Container IPv4 address (e.g. 172.30.100.104)\"),mdx(\"li\",{parentName:\"ul\"},\"mac_address\\xA0- The mac address for the container to use.\"),mdx(\"li\",{parentName:\"ul\"},\"memory\\xA0- Memory limit in bytes.\"),mdx(\"li\",{parentName:\"ul\"},\"memory_swap\\xA0- Total memory limit (memory + swap); set\\xA0-1\\xA0to disable swap limit (unlimited). You must use this with memory and make the swap value larger than memory.\"),mdx(\"li\",{parentName:\"ul\"},\"network_disabled\\xA0- Boolean to disable networking. Defaults to\\xA0false.\"),mdx(\"li\",{parentName:\"ul\"},\"network_mode\\xA0- Sets the networking mode for the container. One of\\xA0bridge,\\xA0host,\\xA0container.\"),mdx(\"li\",{parentName:\"ul\"},\"network_aliases\\xA0- Adds network-scoped alias for the container in form\\xA0\",\"[\\\\'alias-1\\\\', \\\\'alias-2\\\\']\",\".\"),mdx(\"li\",{parentName:\"ul\"},\"open_stdin\\xA0- Boolean value, opens stdin. Defaults to\\xA0false.\"),mdx(\"li\",{parentName:\"ul\"},\"outfile\\xA0- The path to write the file when using\\xA0:export\\xA0action.\"),mdx(\"li\",{parentName:\"ul\"},\"port\\xA0- The port configuration to use in the container. Matches the syntax used by the\\xA0docker\\xA0CLI tool.\"),mdx(\"li\",{parentName:\"ul\"},\"privileged\\xA0- Boolean to start the container in privileged more. Defaults to\\xA0false\"),mdx(\"li\",{parentName:\"ul\"},\"publish_all_ports\\xA0- Allocates a random host port for all of a container\\\\'s exposed ports.\"),mdx(\"li\",{parentName:\"ul\"},\"remove_volumes\\xA0- A boolean to clean up \\\"dangling\\\" volumes when removing the last container with a reference to it. Default to\\xA0false\\xA0to match the Docker CLI behavior.\"),mdx(\"li\",{parentName:\"ul\"},\"restart_policy\\xA0- One of\\xA0no,\\xA0on-failure,\\xA0unless-stopped, or\\xA0always. Use\\xA0always\\xA0if you want a service container to survive a Dockerhost reboot. Defaults to\\xA0no.\"),mdx(\"li\",{parentName:\"ul\"},\"restart_maximum_retry_count\\xA0- Maximum number of restarts to try when\\xA0restart_policy\\xA0is\\xA0on-failure. Defaults to an ever increasing delay (double the previous delay, starting at 100mS), to prevent flooding the server.\"),mdx(\"li\",{parentName:\"ul\"},\"running_wait_time\\xA0- Amount of seconds\\xA0docker_container\\xA0wait to determine if a process is running.\"),mdx(\"li\",{parentName:\"ul\"},\"runtime\\xA0- Runtime to use when running container. Defaults to\\xA0runc.\"),mdx(\"li\",{parentName:\"ul\"},\"security_opt\\xA0- A list of string values to customize labels for MLS systems, such as SELinux.\"),mdx(\"li\",{parentName:\"ul\"},\"signal\\xA0- The signal to send when using the\\xA0:kill\\xA0action. Defaults to\\xA0SIGTERM.\"),mdx(\"li\",{parentName:\"ul\"},\"sysctls\\xA0- A hash of sysctls to set on the container. Defaults to\\xA0{}.\"),mdx(\"li\",{parentName:\"ul\"},\"tty\\xA0- Boolean value to allocate a pseudo-TTY. Defaults to\\xA0false.\"),mdx(\"li\",{parentName:\"ul\"},\"user\\xA0- A string value specifying the user inside the container.\"),mdx(\"li\",{parentName:\"ul\"},\"volumes\\xA0- An Array of paths inside the container to expose. Does the same thing as the\\xA0VOLUMEdirective in a Dockerfile, but works on container creation.\"),mdx(\"li\",{parentName:\"ul\"},\"volumes_from\\xA0- A list of volumes to inherit from another container. Specified in the form\\xA0\",mdx(\"inlineCode\",{parentName:\"li\"},\"<container name>[:<ro|rw>\"),\"]\"),mdx(\"li\",{parentName:\"ul\"},\"volume_driver\\xA0- Driver that this container users to mount volumes.\"),mdx(\"li\",{parentName:\"ul\"},\"working_dir\\xA0- A string specifying the working directory for commands to run in.\"),mdx(\"li\",{parentName:\"ul\"},\"read_timeout\\xA0- May need to increase for commits or exports that are slow\"),mdx(\"li\",{parentName:\"ul\"},\"write_timeout\\xA0- May need to increase for commits or exports that are slow\"),mdx(\"li\",{parentName:\"ul\"},\"kill_after\\xA0- Number of seconds to wait before killing the container. Defaults to wait indefinitely; eventually will hit read_timeout limit.\"),mdx(\"li\",{parentName:\"ul\"},\"timeout\\xA0- Seconds to wait for an attached container to return\"),mdx(\"li\",{parentName:\"ul\"},\"tls\\xA0- Use TLS; implied by --tlsverify. Defaults to ENV\",\"[\\\\'DOCKER_TLS\\\\']\",\" if set\"),mdx(\"li\",{parentName:\"ul\"},\"tls_verify\\xA0- Use TLS and verify the remote. Defaults to ENV\",\"[\\\\'DOCKER_TLS_VERIFY\\\\']\",\" if set\"),mdx(\"li\",{parentName:\"ul\"},\"tls_ca_cert\\xA0- Trust certs signed only by this CA. Defaults to ENV\",\"[\\\\'DOCKER_CERT_PATH\\\\']\",\" if set\"),mdx(\"li\",{parentName:\"ul\"},\"tls_client_cert\\xA0- Path to TLS certificate file for docker cli. Defaults to ENV\",\"[\\\\'DOCKER_CERT_PATH\\\\']\",\" if set\"),mdx(\"li\",{parentName:\"ul\"},\"tls_client_key\\xA0- Path to TLS key file for docker cli. Defaults to ENV\",\"[\\\\'DOCKER_CERT_PATH\\\\']\",\" if set\"),mdx(\"li\",{parentName:\"ul\"},\"userns_mode\\xA0- Modify the user namespace mode - Defaults to\\xA0nil, example option:\\xA0host\"),mdx(\"li\",{parentName:\"ul\"},\"pid_mode\\xA0- Set the PID (Process) Namespace mode for the container.\\xA0host: use the host\\\\'s PID namespace inside the container.\"),mdx(\"li\",{parentName:\"ul\"},\"ipc_mode\\xA0- Set the IPC mode for the container - Defaults to\\xA0nil, example option:\\xA0host\"),mdx(\"li\",{parentName:\"ul\"},\"uts_mode\\xA0- Set the UTS namespace mode for the container. The UTS namespace is for setting the hostname and the domain that is visible to running processes in that namespace. By default, all containers, including those with\\xA0--network=host, have their own UTS namespace. The host setting will result in the container using the same UTS namespace as the host. Note that --hostname is invalid in host UTS mode.\"),mdx(\"li\",{parentName:\"ul\"},\"ro_rootfs\\xA0- Mount the container\\\\'s root filesystem as read only using the\\xA0--read-only\\xA0flag. Defaults to\\xA0false\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Examples\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Create a container without starting it.\")),mdx(\"p\",null,\"docker_container \\\\'hello-world\\\\' do\"),mdx(\"p\",null,\"command \\\\'/hello\\\\'\"),mdx(\"p\",null,\"action :create\"),mdx(\"p\",null,\"end\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"This will exit succesfully. It will happen on every chef-client run.\")),mdx(\"p\",null,\"docker_container \\\\'busybox_ls\\\\' do\"),mdx(\"p\",null,\"repo \\\\'busybox\\\\'\"),mdx(\"p\",null,\"command \\\\'ls -la /\\\\'\"),mdx(\"p\",null,\"action :run\"),mdx(\"p\",null,\"end\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"The :run action contains both :create and :start the container in one action. Redeploys the container on resource change. It is the default action.\")),mdx(\"p\",null,\"docker_container \\\\'alpine_ls\\\\' do\"),mdx(\"p\",null,\"repo \\\\'alpine\\\\'\"),mdx(\"p\",null,\"tag \\\\'3.1\\\\'\"),mdx(\"p\",null,\"command \\\\'ls -la /\\\\'\"),mdx(\"p\",null,\"action :run\"),mdx(\"p\",null,\"end\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Set environment variables in a container\")),mdx(\"p\",null,\"docker_container \\\\'env\\\\' do\"),mdx(\"p\",null,\"repo \\\\'debian\\\\'\"),mdx(\"p\",null,\"env \",\"[\\\\'PATH=/usr/bin\\\\', \\\\'FOO=bar\\\\']\"),mdx(\"p\",null,\"command \\\\'env\\\\'\"),mdx(\"p\",null,\"action :run\"),mdx(\"p\",null,\"end\"),mdx(\"p\",null,\"docker_container \\\\'env_files\\\\' do\"),mdx(\"p\",null,\"repo \\\\'debian\\\\'\"),mdx(\"p\",null,\"env_file lazy { \",\"[\\\\'/env_file1\\\\', \\\\'/env_file2\\\\']\",\" }\"),mdx(\"p\",null,\"command \\\\'env\\\\'\"),mdx(\"p\",null,\"action :run\"),mdx(\"p\",null,\"end\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"This process remains running between chef-client runs, :run will do nothing on subsequent converges.\")),mdx(\"p\",null,\"docker_container \\\\'an_echo_server\\\\' do\"),mdx(\"p\",null,\"repo \\\\'alpine\\\\'\"),mdx(\"p\",null,\"tag \\\\'3.1\\\\'\"),mdx(\"p\",null,\"command \\\\'nc -ll -p 7 -e /bin/cat\\\\'\"),mdx(\"p\",null,\"port \\\\'7:7\\\\'\"),mdx(\"p\",null,\"action :run\"),mdx(\"p\",null,\"end\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Let docker pick the host port\")),mdx(\"p\",null,\"docker_container \\\\'another_echo_server\\\\' do\"),mdx(\"p\",null,\"repo \\\\'alpine\\\\'\"),mdx(\"p\",null,\"tag \\\\'3.1\\\\'\"),mdx(\"p\",null,\"command \\\\'nc -ll -p 7 -e /bin/cat\\\\'\"),mdx(\"p\",null,\"port \\\\'7\\\\'\"),mdx(\"p\",null,\"action :run\"),mdx(\"p\",null,\"end\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Specify the udp protocol\")),mdx(\"p\",null,\"docker_container \\\\'an_udp_echo_server\\\\' do\"),mdx(\"p\",null,\"repo \\\\'alpine\\\\'\"),mdx(\"p\",null,\"tag \\\\'3.1\\\\'\"),mdx(\"p\",null,\"command \\\\'nc -ul -p 7 -e /bin/cat\\\\'\"),mdx(\"p\",null,\"port \\\\'5007:7/udp\\\\'\"),mdx(\"p\",null,\"action :run\"),mdx(\"p\",null,\"end\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Kill a container\")),mdx(\"p\",null,\"docker_container \\\\'bill\\\\' do\"),mdx(\"p\",null,\"action :kill\"),mdx(\"p\",null,\"end\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Stop a container\")),mdx(\"p\",null,\"docker_container \\\\'hammer_time\\\\' do\"),mdx(\"p\",null,\"action :stop\"),mdx(\"p\",null,\"end\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Force-stop a container after 30 seconds\")),mdx(\"p\",null,\"docker_container \\\\'hammer_time\\\\' do\"),mdx(\"p\",null,\"kill_after 30\"),mdx(\"p\",null,\"action :stop\"),mdx(\"p\",null,\"end\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Pause a container\")),mdx(\"p\",null,\"docker_container \\\\'red_light\\\\' do\"),mdx(\"p\",null,\"action :pause\"),mdx(\"p\",null,\"end\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Unpause a container\")),mdx(\"p\",null,\"docker_container \\\\'green_light\\\\' do\"),mdx(\"p\",null,\"action :unpause\"),mdx(\"p\",null,\"end\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Restart a container\")),mdx(\"p\",null,\"docker_container \\\\'restarter\\\\' do\"),mdx(\"p\",null,\"action :restart\"),mdx(\"p\",null,\"end\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Delete a container\")),mdx(\"p\",null,\"docker_container \\\\'deleteme\\\\' do\"),mdx(\"p\",null,\"remove_volumes true\"),mdx(\"p\",null,\"action :delete\"),mdx(\"p\",null,\"end\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Redeploy a container\")),mdx(\"p\",null,\"docker_container \\\\'redeployer\\\\' do\"),mdx(\"p\",null,\"repo \\\\'alpine\\\\'\"),mdx(\"p\",null,\"tag \\\\'3.1\\\\'\"),mdx(\"p\",null,\"command \\\\'nc -ll -p 7777 -e /bin/cat\\\\'\"),mdx(\"p\",null,\"port \\\\'7\\\\'\"),mdx(\"p\",null,\"action :run\"),mdx(\"p\",null,\"end\"),mdx(\"p\",null,\"execute \\\\'redeploy redeployer\\\\' do\"),mdx(\"p\",null,\"notifies :redeploy, \\\\'docker_container\",\"[redeployer]\",\"\\\\', :immediately\"),mdx(\"p\",null,\"action :run\"),mdx(\"p\",null,\"end\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Bind mount local directories\")),mdx(\"p\",null,\"docker_container \\\\'bind_mounter\\\\' do\"),mdx(\"p\",null,\"repo \\\\'busybox\\\\'\"),mdx(\"p\",null,\"command \\\\'ls -la /bits /more-bits\\\\'\"),mdx(\"p\",null,\"volumes \",\"[\\\\'/hostbits:/bits\\\\', \\\\'/more-hostbits:/more-bits\\\\']\"),mdx(\"p\",null,\"action :run_if_missing\"),mdx(\"p\",null,\"end\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Mount volumes from another container\")),mdx(\"p\",null,\"docker_container \\\\'chef_container\\\\' do\"),mdx(\"p\",null,\"command \\\\'true\\\\'\"),mdx(\"p\",null,\"volumes \\\\'/opt/chef\\\\'\"),mdx(\"p\",null,\"action :create\"),mdx(\"p\",null,\"end\"),mdx(\"p\",null,\"docker_container \\\\'ohai_debian\\\\' do\"),mdx(\"p\",null,\"command \\\\'/opt/chef/embedded/bin/ohai platform\\\\'\"),mdx(\"p\",null,\"repo \\\\'debian\\\\'\"),mdx(\"p\",null,\"volumes_from \\\\'chef_container\\\\'\"),mdx(\"p\",null,\"end\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Set a container\\\\'s entrypoint\")),mdx(\"p\",null,\"docker_container \\\\'ohai_again_debian\\\\' do\"),mdx(\"p\",null,\"repo \\\\'debian\\\\'\"),mdx(\"p\",null,\"volumes_from \\\\'chef_container\\\\'\"),mdx(\"p\",null,\"entrypoint \\\\'/opt/chef/embedded/bin/ohai\\\\'\"),mdx(\"p\",null,\"command \\\\'platform\\\\'\"),mdx(\"p\",null,\"action :run_if_missing\"),mdx(\"p\",null,\"end\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Automatically remove a container after it exits\")),mdx(\"p\",null,\"docker_container \\\\'sean_was_here\\\\' do\"),mdx(\"p\",null,\"command \\\"touch /opt/chef/sean_was_here-#{Time.new.strftime(\\\\'%Y%m%d%H%M\\\\')}\\\"\"),mdx(\"p\",null,\"repo \\\\'debian\\\\'\"),mdx(\"p\",null,\"volumes_from \\\\'chef_container\\\\'\"),mdx(\"p\",null,\"autoremove true\"),mdx(\"p\",null,\"action :run\"),mdx(\"p\",null,\"end\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Grant NET_ADMIN rights to a container\")),mdx(\"p\",null,\"docker_container \\\\'cap_add_net_admin\\\\' do\"),mdx(\"p\",null,\"repo \\\\'debian\\\\'\"),mdx(\"p\",null,\"command \\\\'bash -c \\\"ip addr add 10.9.8.7/24 brd + dev eth0 label eth0:0 ; ip addr list\\\"\\\\'\"),mdx(\"p\",null,\"cap_add \\\\'NET_ADMIN\\\\'\"),mdx(\"p\",null,\"action :run_if_missing\"),mdx(\"p\",null,\"end\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Revoke MKNOD rights to a container\")),mdx(\"p\",null,\"docker_container \\\\'cap_drop_mknod\\\\' do\"),mdx(\"p\",null,\"repo \\\\'debian\\\\'\"),mdx(\"p\",null,\"command \\\\'bash -c \\\"mknod -m 444 /dev/urandom2 c 1 9 ; ls -la /dev/urandom2\\\"\\\\'\"),mdx(\"p\",null,\"cap_drop \\\\'MKNOD\\\\'\"),mdx(\"p\",null,\"action :run_if_missing\"),mdx(\"p\",null,\"end\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Set a container\\\\'s hostname and domainname\")),mdx(\"p\",null,\"docker_container \\\\'fqdn\\\\' do\"),mdx(\"p\",null,\"repo \\\\'debian\\\\'\"),mdx(\"p\",null,\"command \\\\'hostname -f\\\\'\"),mdx(\"p\",null,\"host_name \\\\'computers\\\\'\"),mdx(\"p\",null,\"domain_name \\\\'biz\\\\'\"),mdx(\"p\",null,\"action :run_if_missing\"),mdx(\"p\",null,\"end\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Set a container\\\\'s DNS resolution\")),mdx(\"p\",null,\"docker_container \\\\'dns\\\\' do\"),mdx(\"p\",null,\"repo \\\\'debian\\\\'\"),mdx(\"p\",null,\"command \\\\'cat /etc/resolv.conf\\\\'\"),mdx(\"p\",null,\"host_name \\\\'computers\\\\'\"),mdx(\"p\",null,\"dns \",\"[\\\\'4.3.2.1\\\\', \\\\'1.2.3.4\\\\']\"),mdx(\"p\",null,\"dns_search \",\"[\\\\'computers.biz\\\\', \\\\'chef.io\\\\']\"),mdx(\"p\",null,\"action :run_if_missing\"),mdx(\"p\",null,\"end\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Add extra hosts to a container\\\\'s\\xA0/etc/hosts\")),mdx(\"p\",null,\"docker_container \\\\'extra_hosts\\\\' do\"),mdx(\"p\",null,\"repo \\\\'debian\\\\'\"),mdx(\"p\",null,\"command \\\\'cat /etc/hosts\\\\'\"),mdx(\"p\",null,\"extra_hosts \",\"[\\\\'east:4.3.2.1\\\\', \\\\'west:1.2.3.4\\\\']\"),mdx(\"p\",null,\"action :run_if_missing\"),mdx(\"p\",null,\"end\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Manage container\\\\'s restart_policy\")),mdx(\"p\",null,\"docker_container \\\\'try_try_again\\\\' do\"),mdx(\"p\",null,\"repo \\\\'alpine\\\\'\"),mdx(\"p\",null,\"tag \\\\'3.1\\\\'\"),mdx(\"p\",null,\"command \\\\'grep asdasdasd /etc/passwd\\\\'\"),mdx(\"p\",null,\"restart_policy \\\\'on-failure\\\\'\"),mdx(\"p\",null,\"restart_maximum_retry_count 2\"),mdx(\"p\",null,\"action :run_if_missing\"),mdx(\"p\",null,\"end\"),mdx(\"p\",null,\"docker_container \\\\'reboot_survivor\\\\' do\"),mdx(\"p\",null,\"repo \\\\'alpine\\\\'\"),mdx(\"p\",null,\"tag \\\\'3.1\\\\'\"),mdx(\"p\",null,\"command \\\\'nc -ll -p 123 -e /bin/cat\\\\'\"),mdx(\"p\",null,\"port \\\\'123\\\\'\"),mdx(\"p\",null,\"restart_policy \\\\'always\\\\'\"),mdx(\"p\",null,\"action :run_if_missing\"),mdx(\"p\",null,\"end\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Manage container links\")),mdx(\"p\",null,\"docker_container \\\\'link_source\\\\' do\"),mdx(\"p\",null,\"repo \\\\'alpine\\\\'\"),mdx(\"p\",null,\"tag \\\\'3.1\\\\'\"),mdx(\"p\",null,\"env \",\"[\\\\'FOO=bar\\\\', \\\\'BIZ=baz\\\\']\"),mdx(\"p\",null,\"command \\\\'nc -ll -p 321 -e /bin/cat\\\\'\"),mdx(\"p\",null,\"port \\\\'321\\\\'\"),mdx(\"p\",null,\"action :run_if_missing\"),mdx(\"p\",null,\"end\"),mdx(\"p\",null,\"docker_container \\\\'link_target_1\\\\' do\"),mdx(\"p\",null,\"repo \\\\'alpine\\\\'\"),mdx(\"p\",null,\"tag \\\\'3.1\\\\'\"),mdx(\"p\",null,\"env \",\"[\\\\'ASD=asd\\\\']\"),mdx(\"p\",null,\"command \\\\'ping -c 1 hello\\\\'\"),mdx(\"p\",null,\"links \",\"[\\\\'link_source:hello\\\\']\"),mdx(\"p\",null,\"action :run_if_missing\"),mdx(\"p\",null,\"end\"),mdx(\"p\",null,\"docker_container \\\\'link_target_2\\\\' do\"),mdx(\"p\",null,\"repo \\\\'alpine\\\\'\"),mdx(\"p\",null,\"tag \\\\'3.1\\\\'\"),mdx(\"p\",null,\"command \\\\'env\\\\'\"),mdx(\"p\",null,\"links \",\"[\\\\'link_source:hello\\\\']\"),mdx(\"p\",null,\"action :run_if_missing\"),mdx(\"p\",null,\"end\"),mdx(\"p\",null,\"execute \\\\'redeploy_link_source\\\\' do\"),mdx(\"p\",null,\"command \\\\'touch /marker_container_redeploy_link_source\\\\'\"),mdx(\"p\",null,\"creates \\\\'/marker_container_redeploy_link_source\\\\'\"),mdx(\"p\",null,\"notifies :redeploy, \\\\'docker_container\",\"[link_source]\",\"\\\\', :immediately\"),mdx(\"p\",null,\"notifies :redeploy, \\\\'docker_container\",\"[link_target_1]\",\"\\\\', :immediately\"),mdx(\"p\",null,\"notifies :redeploy, \\\\'docker_container\",\"[link_target_2]\",\"\\\\', :immediately\"),mdx(\"p\",null,\"action :run\"),mdx(\"p\",null,\"end\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Mutate a container between chef-client runs\")),mdx(\"p\",null,\"docker_tag \\\\'mutator_from_busybox\\\\' do\"),mdx(\"p\",null,\"target_repo \\\\'busybox\\\\'\"),mdx(\"p\",null,\"target_tag \\\\'latest\\\\'\"),mdx(\"p\",null,\"to_repo \\\\'someara/mutator\\\\'\"),mdx(\"p\",null,\"target_tag \\\\'latest\\\\'\"),mdx(\"p\",null,\"end\"),mdx(\"p\",null,\"docker_container \\\\'mutator\\\\' do\"),mdx(\"p\",null,\"repo \\\\'someara/mutator\\\\'\"),mdx(\"p\",null,\"tag \\\\'latest\\\\'\"),mdx(\"p\",null,\"command \\\"sh -c \\\\'touch /mutator-\",mdx(\"inlineCode\",{parentName:\"p\"},\"date +\\\\\\\"%Y-%m-%d_%H-%M-%S\\\\\\\"\"),\"\\\\'\\\"\"),mdx(\"p\",null,\"outfile \\\\'/mutator.tar\\\\'\"),mdx(\"p\",null,\"force true\"),mdx(\"p\",null,\"action :run_if_missing\"),mdx(\"p\",null,\"end\"),mdx(\"p\",null,\"execute \\\\'commit mutator\\\\' do\"),mdx(\"p\",null,\"command \\\\'true\\\\'\"),mdx(\"p\",null,\"notifies :commit, \\\\'docker_container\",\"[mutator]\",\"\\\\', :immediately\"),mdx(\"p\",null,\"notifies :export, \\\\'docker_container\",\"[mutator]\",\"\\\\', :immediately\"),mdx(\"p\",null,\"notifies :redeploy, \\\\'docker_container\",\"[mutator]\",\"\\\\', :immediately\"),mdx(\"p\",null,\"action :run\"),mdx(\"p\",null,\"end\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Specify read/write timeouts\")),mdx(\"p\",null,\"docker_container \\\\'api_timeouts\\\\' do\"),mdx(\"p\",null,\"repo \\\\'alpine\\\\'\"),mdx(\"p\",null,\"read_timeout 60\"),mdx(\"p\",null,\"write_timeout 60\"),mdx(\"p\",null,\"end\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Specify a custom logging driver and its options\")),mdx(\"p\",null,\"docker_container \\\\'syslogger\\\\' do\"),mdx(\"p\",null,\"repo \\\\'alpine\\\\'\"),mdx(\"p\",null,\"tag \\\\'3.1\\\\'\"),mdx(\"p\",null,\"command \\\\'nc -ll -p 780 -e /bin/cat\\\\'\"),mdx(\"p\",null,\"log_driver \\\\'syslog\\\\'\"),mdx(\"p\",null,\"log_opts \\\\'tag=container-syslogger\\\\'\"),mdx(\"p\",null,\"end\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Connect to an external docker daemon and create a container\")),mdx(\"p\",null,\"docker_container \\\\'external_daemon\\\\' do\"),mdx(\"p\",null,\"repo \\\\'alpine\\\\'\"),mdx(\"p\",null,\"host \\\\'tcp://1.2.3.4:2376\\\\'\"),mdx(\"p\",null,\"action :create\"),mdx(\"p\",null,\"end\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"docker_registry\")),mdx(\"p\",null,\"The\\xA0docker_registry\\xA0resource is responsible for managing the connection auth information to a Docker registry.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Actions\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\":login\\xA0- Login to the Docker Registry\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Properties\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"email\"),mdx(\"li\",{parentName:\"ul\"},\"password\"),mdx(\"li\",{parentName:\"ul\"},\"serveraddress\"),mdx(\"li\",{parentName:\"ul\"},\"username\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Examples\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Log into or register with public registry:\")),mdx(\"p\",null,\"docker_registry \\\\'\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://index.docker.io/v1/%5C'\"}),\"https://index.docker.io/v1/\\\\'\"),\" do\"),mdx(\"p\",null,\"username \\\\'publicme\\\\'\"),mdx(\"p\",null,\"password \\\\'hope_this_is_in_encrypted_databag\\\\'\"),mdx(\"p\",null,\"email \\\\'publicme\\\\@computers.biz\\\\'\"),mdx(\"p\",null,\"end\"),mdx(\"p\",null,\"Log into private registry with optional port:\"),mdx(\"p\",null,\"docker_registry \\\\'my local registry\\\\' do\"),mdx(\"p\",null,\"serveraddress \\\\'\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://registry.computers.biz:8443/%5C'\"}),\"https://registry.computers.biz:8443/\\\\'\")),mdx(\"p\",null,\"username \\\\'privateme\\\\'\"),mdx(\"p\",null,\"password \\\\'still_hope_this_is_in_encrypted_databag\\\\'\"),mdx(\"p\",null,\"email \\\\'privateme\\\\@computers.biz\\\\'\"),mdx(\"p\",null,\"end\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"docker_network\")),mdx(\"p\",null,\"The\\xA0docker_network\\xA0resource is responsible for managing Docker named networks. Usage of\\xA0overlaydriver requires the\\xA0docker_service\\xA0to be configured to use a distributed key/value store like\\xA0etcd,\\xA0consul, or\\xA0zookeeper.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Actions\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\":create\\xA0- create a network\"),mdx(\"li\",{parentName:\"ul\"},\":delete\\xA0- delete a network\"),mdx(\"li\",{parentName:\"ul\"},\":connect\\xA0- connect a container to a network\"),mdx(\"li\",{parentName:\"ul\"},\":disconnect\\xA0- disconnect a container from a network\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Properties\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"aux_address\\xA0- Auxiliary addresses for the network. Ex:\\xA0\",\"[\\\\'a=192.168.1.5\\\\', \\\\'b=192.168.1.6\\\\']\"),mdx(\"li\",{parentName:\"ul\"},\"container\\xA0- Container-id/name to be connected/disconnected to/from the network. Used only by\\xA0:connect\\xA0and\\xA0:disconnect\\xA0actions\"),mdx(\"li\",{parentName:\"ul\"},\"driver\\xA0- The network driver to use. Defaults to\\xA0bridge, other options include\\xA0overlay.\"),mdx(\"li\",{parentName:\"ul\"},\"enable_ipv6\\xA0- Enable IPv6 on the network. Ex: true\"),mdx(\"li\",{parentName:\"ul\"},\"gateway\\xA0- Specify the gateway(s) for the network. Ex:\\xA0192.168.0.1\"),mdx(\"li\",{parentName:\"ul\"},\"ip_range\\xA0- Specify a range of IPs to allocate for containers. Ex:\\xA0192.168.1.0/24\"),mdx(\"li\",{parentName:\"ul\"},\"subnet\\xA0- Specify the subnet(s) for the network. Ex:\\xA0192.168.0.0/16\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Examples\")),mdx(\"p\",null,\"Create a network and use it in a container\"),mdx(\"p\",null,\"docker_network \\\\'network_g\\\\' do\"),mdx(\"p\",null,\"driver \\\\'overlay\\\\'\"),mdx(\"p\",null,\"subnet \",\"[\\\\'192.168.0.0/16\\\\', \\\\'192.170.0.0/16\\\\']\"),mdx(\"p\",null,\"gateway \",\"[\\\\'192.168.0.100\\\\', \\\\'192.170.0.100\\\\']\"),mdx(\"p\",null,\"ip_range \\\\'192.168.1.0/24\\\\'\"),mdx(\"p\",null,\"aux_address \",\"[\\\\'a=192.168.1.5\\\\', \\\\'b=192.168.1.6\\\\', \\\\'a=192.170.1.5\\\\', \\\\'b=192.170.1.6\\\\']\"),mdx(\"p\",null,\"end\"),mdx(\"p\",null,\"docker_container \\\\'echo-base\\\\' do\"),mdx(\"p\",null,\"repo \\\\'alpine\\\\'\"),mdx(\"p\",null,\"tag \\\\'3.1\\\\'\"),mdx(\"p\",null,\"command \\\\'nc -ll -p 1337 -e /bin/cat\\\\'\"),mdx(\"p\",null,\"port \\\\'1337\\\\'\"),mdx(\"p\",null,\"network_mode \\\\'network_g\\\\'\"),mdx(\"p\",null,\"action :run\"),mdx(\"p\",null,\"end\"),mdx(\"p\",null,\"Connect to multiple networks\"),mdx(\"p\",null,\"docker_network \\\\'network_h1\\\\' do\"),mdx(\"p\",null,\"action :create\"),mdx(\"p\",null,\"end\"),mdx(\"p\",null,\"docker_network \\\\'network_h2\\\\' do\"),mdx(\"p\",null,\"action :create\"),mdx(\"p\",null,\"end\"),mdx(\"p\",null,\"docker_container \\\\'echo-base-networks_h\\\\' do\"),mdx(\"p\",null,\"repo \\\\'alpine\\\\'\"),mdx(\"p\",null,\"tag \\\\'3.1\\\\'\"),mdx(\"p\",null,\"command \\\\'nc -ll -p 1337 -e /bin/cat\\\\'\"),mdx(\"p\",null,\"port \\\\'1337\\\\'\"),mdx(\"p\",null,\"network_mode \\\\'network_h1\\\\'\"),mdx(\"p\",null,\"action :run\"),mdx(\"p\",null,\"end\"),mdx(\"p\",null,\"docker_network \\\\'network_h2\\\\' do\"),mdx(\"p\",null,\"container \\\\'echo-base-networks_h\\\\'\"),mdx(\"p\",null,\"action :connect\"),mdx(\"p\",null,\"end\"),mdx(\"p\",null,\"IPv6 enabled network\"),mdx(\"p\",null,\"docker_network \\\\'network_i1\\\\' do\"),mdx(\"p\",null,\"enable_ipv6 true\"),mdx(\"p\",null,\"subnet \\\\'fd00:dead:beef::/48\\\\'\"),mdx(\"p\",null,\"action :create\"),mdx(\"p\",null,\"end\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"docker_volume\")),mdx(\"p\",null,\"The\\xA0docker_volume\\xA0resource is responsible for managing Docker named volumes.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Actions\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\":create\\xA0- create a volume\"),mdx(\"li\",{parentName:\"ul\"},\":remove\\xA0- remove a volume\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Properties\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"driver\"),mdx(\"li\",{parentName:\"ul\"},\"host\"),mdx(\"li\",{parentName:\"ul\"},\"opts\"),mdx(\"li\",{parentName:\"ul\"},\"volume\"),mdx(\"li\",{parentName:\"ul\"},\"volume_name\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Examples\")),mdx(\"p\",null,\"Create a volume named \\\\'hello\\\\'\"),mdx(\"p\",null,\"docker_volume \\\\'hello\\\\' do\"),mdx(\"p\",null,\"action :create\"),mdx(\"p\",null,\"end\"),mdx(\"p\",null,\"docker_container \\\\'file_writer\\\\' do\"),mdx(\"p\",null,\"repo \\\\'alpine\\\\'\"),mdx(\"p\",null,\"tag \\\\'3.1\\\\'\"),mdx(\"p\",null,\"volumes \\\\'hello:/hello\\\\'\"),mdx(\"p\",null,\"command \\\\'touch /hello/sean_was_here\\\\'\"),mdx(\"p\",null,\"action :run_if_missing\"),mdx(\"p\",null,\"end\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"docker_execute\")),mdx(\"p\",null,\"The\\xA0docker_execute\\xA0resource allows you to execute commands inside of a running container.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Actions\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\":run\\xA0- Runs the command\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Properties\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"host\\xA0- Daemon socket(s) to connect to -\\xA0tcp://host:port,\\xA0unix:///path/to/socket,\\xA0fd://*\\xA0or\\xA0fd://socketfd.\"),mdx(\"li\",{parentName:\"ul\"},\"command\\xA0- A command structured as an Array similar to\\xA0CMD\\xA0in a Dockerfile.\"),mdx(\"li\",{parentName:\"ul\"},\"container\\xA0- Name of the container to execute the command in.\"),mdx(\"li\",{parentName:\"ul\"},\"timeout- Seconds to wait for an attached container to return. Defaults to 60 seconds.\"),mdx(\"li\",{parentName:\"ul\"},\"container_obj\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Examples\")),mdx(\"p\",null,\"docker_exec \\\\'touch_it\\\\' do\"),mdx(\"p\",null,\"container \\\\'busybox_exec\\\\'\"),mdx(\"p\",null,\"command \",\"[\\\\'touch\\\\', \\\\'/tmp/onefile\\\\']\"),mdx(\"p\",null,\"end\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Maintainers\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Sean OMeara (\",mdx(\"inlineCode\",{parentName:\"li\"},\"<sean@sean.io>\"),\")\"),mdx(\"li\",{parentName:\"ul\"},\"Brian Flad (\",mdx(\"inlineCode\",{parentName:\"li\"},\"<bflad417@gmail.com>\"),\")\"),mdx(\"li\",{parentName:\"ul\"},\"Chase Bolt (\",mdx(\"inlineCode\",{parentName:\"li\"},\"<chase.bolt@gmail.com>\"),\")\")),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"License\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Copyright:\"),\"\\xA02015-2018, Chef Software, Inc.\"),mdx(\"p\",null,\"Licensed under the Apache License, Version 2.0 (the \\\"License\\\");\"),mdx(\"p\",null,\"you may not use this file except in compliance with the License.\"),mdx(\"p\",null,\"You may obtain a copy of the License at\"),mdx(\"p\",null,mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://www.apache.org/licenses/LICENSE-2.0\"}),\"http://www.apache.org/licenses/LICENSE-2.0\")),mdx(\"p\",null,\"Unless required by applicable law or agreed to in writing, software\"),mdx(\"p\",null,\"distributed under the License is distributed on an \\\"AS IS\\\" BASIS,\"),mdx(\"p\",null,\"WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\"),mdx(\"p\",null,\"See the License for the specific language governing permissions and\"),mdx(\"p\",null,\"limitations under the License.\"),mdx(\"h3\",null,\"Security\"),mdx(\"h4\",null,\"Docker security\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA010 minutes\")),mdx(\"p\",null,\"There are four major areas to consider when reviewing Docker security:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"the intrinsic security of the kernel and its support for namespaces and cgroups;\"),mdx(\"li\",{parentName:\"ul\"},\"the attack surface of the Docker daemon itself;\"),mdx(\"li\",{parentName:\"ul\"},\"loopholes in the container configuration profile, either by default, or when customized by users.\"),mdx(\"li\",{parentName:\"ul\"},\"the \\\"hardening\\\" security features of the kernel and how they interact with containers.\")),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Kernel namespaces\")),mdx(\"p\",null,\"Docker containers are very similar to LXC containers, and they have similar security features. When you start a container with\\xA0docker run, behind the scenes Docker creates a set of namespaces and control groups for the container.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Namespaces provide the first and most straightforward form of isolation\"),\": processes running within a container cannot see, and even less affect, processes running in another container, or in the host system.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Each container also gets its own network stack\"),\", meaning that a container doesn't get privileged access to the sockets or interfaces of another container. Of course, if the host system is setup accordingly, containers can interact with each other through their respective network interfaces --- just like they can interact with external hosts. When you specify public ports for your containers or use\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/userguide/networking/default_network/dockerlinks/\"}),\"links\"),\"\\xA0then IP traffic is allowed between containers. They can ping each other, send/receive UDP packets, and establish TCP connections, but that can be restricted if necessary. From a network architecture point of view, all containers on a given Docker host are sitting on bridge interfaces. This means that they are just like physical machines connected through a common Ethernet switch; no more, no less.\"),mdx(\"p\",null,\"How mature is the code providing kernel namespaces and private networking? Kernel namespaces were introduced\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://man7.org/linux/man-pages/man7/namespaces.7.html\"}),\"between kernel version 2.6.15 and 2.6.26\"),\". This means that since July 2008 (date of the 2.6.26 release ), namespace code has been exercised and scrutinized on a large number of production systems. And there is more: the design and inspiration for the namespaces code are even older. Namespaces are actually an effort to reimplement the features of\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://en.wikipedia.org/wiki/OpenVZ\"}),\"OpenVZ\"),\"\\xA0in such a way that they could be merged within the mainstream kernel. And OpenVZ was initially released in 2005, so both the design and the implementation are pretty mature.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Control groups\")),mdx(\"p\",null,\"Control Groups are another key component of Linux Containers. They implement resource accounting and limiting. They provide many useful metrics, but they also help ensure that each container gets its fair share of memory, CPU, disk I/O; and, more importantly, that a single container cannot bring the system down by exhausting one of those resources.\"),mdx(\"p\",null,\"So while they do not play a role in preventing one container from accessing or affecting the data and processes of another container, they are essential to fend off some denial-of-service attacks. They are particularly important on multi-tenant platforms, like public and private PaaS, to guarantee a consistent uptime (and performance) even when some applications start to misbehave.\"),mdx(\"p\",null,\"Control Groups have been around for a while as well: the code was started in 2006, and initially merged in kernel 2.6.24.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Docker daemon attack surface\")),mdx(\"p\",null,\"Running containers (and applications) with Docker implies running the Docker daemon. This daemon currently requires\\xA0root\\xA0privileges, and you should therefore be aware of some important details.\"),mdx(\"p\",null,\"First of all,\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"only trusted users should be allowed to control your Docker daemon\"),\". This is a direct consequence of some powerful Docker features. Specifically, Docker allows you to share a directory between the Docker host and a guest container; and it allows you to do so without limiting the access rights of the container. This means that you can start a container where the\\xA0/host\\xA0directory is the\\xA0/\\xA0directory on your host; and the container can alter your host filesystem without any restriction. This is similar to how virtualization systems allow filesystem resource sharing. Nothing prevents you from sharing your root filesystem (or even your root block device) with a virtual machine.\"),mdx(\"p\",null,\"This has a strong security implication: for example, if you instrument Docker from a web server to provision containers through an API, you should be even more careful than usual with parameter checking, to make sure that a malicious user cannot pass crafted parameters causing Docker to create arbitrary containers.\"),mdx(\"p\",null,\"For this reason, the REST API endpoint (used by the Docker CLI to communicate with the Docker daemon) changed in Docker 0.5.2, and now uses a UNIX socket instead of a TCP socket bound on 127.0.0.1 (the latter being prone to cross-site request forgery attacks if you happen to run Docker directly on your local machine, outside of a VM). You can then use traditional UNIX permission checks to limit access to the control socket.\"),mdx(\"p\",null,\"You can also expose the REST API over HTTP if you explicitly decide to do so. However, if you do that, be aware of the above mentioned security implications. Ensure that it is reachable only from a trusted network or VPN or protected with a mechanism such as\\xA0stunnel\\xA0and client SSL certificates. You can also secure API endpoints with\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/security/https/\"}),\"HTTPS and certificates\"),\".\"),mdx(\"p\",null,\"The daemon is also potentially vulnerable to other inputs, such as image loading from either disk with\\xA0docker load, or from the network with\\xA0docker pull. As of Docker 1.3.2, images are now extracted in a chrooted subprocess on Linux/Unix platforms, being the first-step in a wider effort toward privilege separation. As of Docker 1.10.0, all images are stored and accessed by the cryptographic checksums of their contents, limiting the possibility of an attacker causing a collision with an existing image.\"),mdx(\"p\",null,\"Finally, if you run Docker on a server, it is recommended to run exclusively Docker on the server, and move all other services within containers controlled by Docker. Of course, it is fine to keep your favorite admin tools (probably at least an SSH server), as well as existing monitoring/supervision processes, such as NRPE and collectd.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Linux kernel capabilities\")),mdx(\"p\",null,\"By default, Docker starts containers with a restricted set of capabilities. What does that mean?\"),mdx(\"p\",null,\"Capabilities turn the binary \\\"root/non-root\\\" dichotomy into a fine-grained access control system. Processes (like web servers) that just need to bind on a port below 1024 do not need to run as root: they can just be granted the\\xA0net_bind_service\\xA0capability instead. And there are many other capabilities, for almost all the specific areas where root privileges are usually needed.\"),mdx(\"p\",null,\"This means a lot for container security; let's see why!\"),mdx(\"p\",null,\"Typical servers run several processes as\\xA0root, including the SSH daemon,\\xA0cron\\xA0daemon, logging daemons, kernel modules, network configuration tools, and more. A container is different, because almost all of those tasks are handled by the infrastructure around the container:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"SSH access are typically managed by a single server running on the Docker host;\"),mdx(\"li\",{parentName:\"ul\"},\"cron, when necessary, should run as a user process, dedicated and tailored for the app that needs its scheduling service, rather than as a platform-wide facility;\"),mdx(\"li\",{parentName:\"ul\"},\"log management is also typically handed to Docker, or to third-party services like Loggly or Splunk;\"),mdx(\"li\",{parentName:\"ul\"},\"hardware management is irrelevant, meaning that you never need to run\\xA0udevd\\xA0or equivalent daemons within containers;\"),mdx(\"li\",{parentName:\"ul\"},\"network management happens outside of the containers, enforcing separation of concerns as much as possible, meaning that a container should never need to perform\\xA0ifconfig,route, or ip commands (except when a container is specifically engineered to behave like a router or firewall, of course).\")),mdx(\"p\",null,\"This means that in most cases, containers do not need \\\"real\\\" root privileges\\xA0at all. And therefore, containers can run with a reduced capability set; meaning that \\\"root\\\" within a container has much less privileges than the real \\\"root\\\". For instance, it is possible to:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"deny all \\\"mount\\\" operations;\"),mdx(\"li\",{parentName:\"ul\"},\"deny access to raw sockets (to prevent packet spoofing);\"),mdx(\"li\",{parentName:\"ul\"},\"deny access to some filesystem operations, like creating new device nodes, changing the owner of files, or altering attributes (including the immutable flag);\"),mdx(\"li\",{parentName:\"ul\"},\"deny module loading;\"),mdx(\"li\",{parentName:\"ul\"},\"and many others.\")),mdx(\"p\",null,\"This means that even if an intruder manages to escalate to root within a container, it is much harder to do serious damage, or to escalate to the host.\"),mdx(\"p\",null,\"This doesn't affect regular web apps, but reduces the vectors of attack by malicious users considerably. By default Docker drops all capabilities except\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/moby/moby/blob/master/oci/defaults.go#L14-L30\"}),\"those needed\"),\", a whitelist instead of a blacklist approach. You can see a full list of available capabilities in\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://man7.org/linux/man-pages/man7/capabilities.7.html\"}),\"Linux manpages\"),\".\"),mdx(\"p\",null,\"One primary risk with running Docker containers is that the default set of capabilities and mounts given to a container may provide incomplete isolation, either independently, or when used in combination with kernel vulnerabilities.\"),mdx(\"p\",null,\"Docker supports the addition and removal of capabilities, allowing use of a non-default profile. This may make Docker more secure through capability removal, or less secure through the addition of capabilities. The best practice for users would be to remove all capabilities except those explicitly required for their processes.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Other kernel security features\")),mdx(\"p\",null,\"Capabilities are just one of the many security features provided by modern Linux kernels. It is also possible to leverage existing, well-known systems like TOMOYO, AppArmor, SELinux, GRSEC, etc. with Docker.\"),mdx(\"p\",null,\"While Docker currently only enables capabilities, it doesn't interfere with the other systems. This means that there are many different ways to harden a Docker host. Here are a few examples.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"You can run a kernel with GRSEC and PAX. This adds many safety checks, both at compile-time and run-time; it also defeats many exploits, thanks to techniques like address randomization. It doesn't require Docker-specific configuration, since those security features apply system-wide, independent of containers.\"),mdx(\"li\",{parentName:\"ul\"},\"If your distribution comes with security model templates for Docker containers, you can use them out of the box. For instance, we ship a template that works with AppArmor and Red Hat comes with SELinux policies for Docker. These templates provide an extra safety net (even though it overlaps greatly with capabilities).\"),mdx(\"li\",{parentName:\"ul\"},\"You can define your own policies using your favorite access control mechanism.\")),mdx(\"p\",null,\"Just as you can use third-party tools to augment Docker containers, including special network topologies or shared filesystems, tools exist to harden Docker containers without the need to modify Docker itself.\"),mdx(\"p\",null,\"As of Docker 1.10 User Namespaces are supported directly by the docker daemon. This feature allows for the root user in a container to be mapped to a non uid-0 user outside the container, which can help to mitigate the risks of container breakout. This facility is available but not enabled by default.\"),mdx(\"p\",null,\"Refer to the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-user-namespace-options\"}),\"daemon command\"),\"\\xA0in the command line reference for more information on this feature. Additional information on the implementation of User Namespaces in Docker can be found in\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://integratedcode.us/2015/10/13/user-namespaces-have-arrived-in-docker/\"}),\"this blog post\"),\".\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Conclusions\")),mdx(\"p\",null,\"Docker containers are, by default, quite secure; especially if you run your processes as non-privileged users inside the container.\"),mdx(\"p\",null,\"You can add an extra layer of safety by enabling AppArmor, SELinux, GRSEC, or another appropriate hardening system.\"),mdx(\"p\",null,\"If you think of ways to make docker more secure, we welcome feature requests, pull requests, or comments on the Docker community forums.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Related information\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/security/trust/\"}),\"Use trusted images\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/security/seccomp/\"}),\"Seccomp security profiles for Docker\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/security/apparmor/\"}),\"AppArmor security profiles for Docker\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://medium.com/@ewindisch/on-the-security-of-containers-2c60ffe25a9e\"}),\"On the Security of Containers (2014)\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/userguide/networking/overlay-security-model/\"}),\"Docker swarm mode overlay network security model\"))),mdx(\"h4\",null,\"Docker security non-events\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA03 minutes\")),mdx(\"p\",null,\"This page lists security vulnerabilities which Docker mitigated, such that processes run in Docker containers were never vulnerable to the bug---even before it was fixed. This assumes containers are run without adding extra capabilities or not run as\\xA0--privileged.\"),mdx(\"p\",null,\"The list below is not even remotely complete. Rather, it is a sample of the few bugs we've actually noticed to have attracted security review and publicly disclosed vulnerabilities. In all likelihood, the bugs that haven't been reported far outnumber those that have. Luckily, since Docker's approach to secure by default through apparmor, seccomp, and dropping capabilities, it likely mitigates unknown bugs just as well as it does known ones.\"),mdx(\"p\",null,\"Bugs mitigated:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2013-1956\"}),\"CVE-2013-1956\"),\",\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2013-1957\"}),\"1957\"),\",\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2013-1958\"}),\"1958\"),\",\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2013-1959\"}),\"1959\"),\",\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2013-1979\"}),\"1979\"),\",\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-4014\"}),\"CVE-2014-4014\"),\",\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-5206\"}),\"5206\"),\",\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-5207\"}),\"5207\"),\",\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-7970\"}),\"7970\"),\",\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-7975\"}),\"7975\"),\",\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-2925\"}),\"CVE-2015-2925\"),\",\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-8543\"}),\"8543\"),\",\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-3134\"}),\"CVE-2016-3134\"),\",\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-3135\"}),\"3135\"),\", etc.: The introduction of unprivileged user namespaces lead to a huge increase in the attack surface available to unprivileged users by giving such users legitimate access to previously root-only system calls like\\xA0mount(). All of these CVEs are examples of security vulnerabilities due to introduction of user namespaces. Docker can use user namespaces to set up containers, but then disallows the process inside the container from creating its own nested namespaces through the default seccomp profile, rendering these vulnerabilities unexploitable.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-0181\"}),\"CVE-2014-0181\"),\",\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-3339\"}),\"CVE-2015-3339\"),\": These are bugs that require the presence of a setuid binary. Docker disables setuid binaries inside containers via the\\xA0NO_NEW_PRIVS\\xA0process flag and other mechanisms.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-4699\"}),\"CVE-2014-4699\"),\": A bug in\\xA0ptrace()\\xA0could allow privilege escalation. Docker disables\\xA0ptrace()\\xA0inside the container using apparmor, seccomp and by dropping\\xA0CAP_PTRACE. Three times the layers of protection there!\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-9529\"}),\"CVE-2014-9529\"),\": A series of crafted\\xA0keyctl()\\xA0calls could cause kernel DoS / memory corruption. Docker disables\\xA0keyctl()\\xA0inside containers using seccomp.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-3214\"}),\"CVE-2015-3214\"),\",\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-4036\"}),\"4036\"),\": These are bugs in common virtualization drivers which could allow a guest OS user to execute code on the host OS. Exploiting them requires access to virtualization devices in the guest. Docker hides direct access to these devices when run without\\xA0--privileged. Interestingly, these seem to be cases where containers are \\\"more secure\\\" than a VM, going against common wisdom that VMs are \\\"more secure\\\" than containers.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-0728\"}),\"CVE-2016-0728\"),\": Use-after-free caused by crafted\\xA0keyctl()\\xA0calls could lead to privilege escalation. Docker disables\\xA0keyctl()\\xA0inside containers using the default seccomp profile.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-2383\"}),\"CVE-2016-2383\"),\": A bug in eBPF -- the special in-kernel DSL used to express things like seccomp filters -- allowed arbitrary reads of kernel memory. The\\xA0bpf()\\xA0system call is blocked inside Docker containers using (ironically) seccomp.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-3134\"}),\"CVE-2016-3134\"),\",\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-4997\"}),\"4997\"),\",\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-4998\"}),\"4998\"),\": A bug in setsockopt with\\xA0IPT_SO_SET_REPLACE,\\xA0ARPT_SO_SET_REPLACE, and\\xA0ARPT_SO_SET_REPLACE\\xA0causing memory corruption / local privilege escalation. These arguments are blocked by\\xA0CAP_NET_ADMIN, which Docker does not allow by default.\")),mdx(\"p\",null,\"Bugs\\xA0not\\xA0mitigated:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-3290\"}),\"CVE-2015-3290\"),\",\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-5157\"}),\"5157\"),\": Bugs in the kernel's non-maskable interrupt handling allowed privilege escalation. Can be exploited in Docker containers because the\\xA0modify_ldt()system call is not currently blocked using seccomp.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-5195\"}),\"CVE-2016-5195\"),\": A race condition was found in the way the Linux kernel's memory subsystem handled the copy-on-write (COW) breakage of private read-only memory mappings, which allowed unprivileged local users to gain write access to read-only memory. Also known as \\\"dirty COW.\\\"\\xA0Partial mitigations:\\xA0on some operating systems this vulnerability is mitigated by the combination of seccomp filtering of\\xA0ptrace\\xA0and the fact that\\xA0/proc/self/mem\\xA0is read-only.\")),mdx(\"h4\",null,\"Protect the Docker daemon socket\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA07 minutes\")),mdx(\"p\",null,\"By default, Docker runs via a non-networked Unix socket. It can also optionally communicate using an HTTP socket.\"),mdx(\"p\",null,\"If you need Docker to be reachable via the network in a safe manner, you can enable TLS by specifying the\\xA0tlsverify\\xA0flag and pointing Docker's\\xA0tlscacert\\xA0flag to a trusted CA certificate.\"),mdx(\"p\",null,\"In the daemon mode, it only allows connections from clients authenticated by a certificate signed by that CA. In the client mode, it only connects to servers with a certificate signed by that CA.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Advanced topic\")),mdx(\"p\",null,\"Using TLS and managing a CA is an advanced topic. Please familiarize yourself with OpenSSL, x509 and TLS before using it in production.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Create a CA, server and client keys with OpenSSL\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": replace all instances of\\xA0$HOST\\xA0in the following example with the DNS name of your Docker daemon's host.\"),mdx(\"p\",null,\"First, on the\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"Docker daemon's host machine\"),\", generate CA private and public keys:\"),mdx(\"p\",null,\"$ openssl genrsa -aes256 -out ca-key.pem 4096\"),mdx(\"p\",null,\"Generating RSA private key, 4096 bit long modulus\"),mdx(\"p\",null,\"............................................................................................................................................................................................++\"),mdx(\"p\",null,\"........++\"),mdx(\"p\",null,\"e is 65537 (0x10001)\"),mdx(\"p\",null,\"Enter pass phrase for ca-key.pem:\"),mdx(\"p\",null,\"Verifying - Enter pass phrase for ca-key.pem:\"),mdx(\"p\",null,\"$ openssl req -new -x509 -days 365 -key ca-key.pem -sha256 -out ca.pem\"),mdx(\"p\",null,\"Enter pass phrase for ca-key.pem:\"),mdx(\"p\",null,\"You are about to be asked to enter information that will be incorporated\"),mdx(\"p\",null,\"into your certificate request.\"),mdx(\"p\",null,\"What you are about to enter is what is called a Distinguished Name or a DN.\"),mdx(\"p\",null,\"There are quite a few fields but you can leave some blank\"),mdx(\"p\",null,\"For some fields there will be a default value,\"),mdx(\"p\",null,\"If you enter \\\\'.\\\\', the field will be left blank.\"),mdx(\"hr\",null),mdx(\"p\",null,\"Country Name (2 letter code) \",\"[AU]\",\":\"),mdx(\"p\",null,\"State or Province Name (full name) \",\"[Some-State]\",\":Queensland\"),mdx(\"p\",null,\"Locality Name (eg, city) []:Brisbane\"),mdx(\"p\",null,\"Organization Name (eg, company) \",\"[Internet Widgits Pty Ltd]\",\":Docker Inc\"),mdx(\"p\",null,\"Organizational Unit Name (eg, section) []:Sales\"),mdx(\"p\",null,\"Common Name (e.g. server FQDN or YOUR name) []:$HOST\"),mdx(\"p\",null,\"Email Address []:Sven\\\\@home.org.au\"),mdx(\"p\",null,\"Now that you have a CA, you can create a server key and certificate signing request (CSR). Make sure that \\\"Common Name\\\" matches the hostname you use to connect to Docker:\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": replace all instances of\\xA0$HOST\\xA0in the following example with the DNS name of your Docker daemon's host.\"),mdx(\"p\",null,\"$ openssl genrsa -out server-key.pem 4096\"),mdx(\"p\",null,\"Generating RSA private key, 4096 bit long modulus\"),mdx(\"p\",null,\".....................................................................++\"),mdx(\"p\",null,\".................................................................................................++\"),mdx(\"p\",null,\"e is 65537 (0x10001)\"),mdx(\"p\",null,\"$ openssl req -subj \\\"/CN=$HOST\\\" -sha256 -new -key server-key.pem -out server.csr\"),mdx(\"p\",null,\"Next, we're going to sign the public key with our CA:\"),mdx(\"p\",null,\"Since TLS connections can be made via IP address as well as DNS name, the IP addresses need to be specified when creating the certificate. For example, to allow connections using\\xA010.10.10.20and\\xA0127.0.0.1:\"),mdx(\"p\",null,\"$ echo subjectAltName = DNS:$HOST,IP:10.10.10.20,IP:127.0.0.1 >> extfile.cnf\"),mdx(\"p\",null,\"Set the Docker daemon key's extended usage attributes to be used only for server authentication:\"),mdx(\"p\",null,\"$ echo extendedKeyUsage = serverAuth >> extfile.cnf\"),mdx(\"p\",null,\"Now, generate the signed certificate:\"),mdx(\"p\",null,\"$ openssl x509 -req -days 365 -sha256 -in server.csr -CA ca.pem -CAkey ca-key.pem \\\\\"),mdx(\"p\",null,\"-CAcreateserial -out server-cert.pem -extfile extfile.cnf\"),mdx(\"p\",null,\"Signature ok\"),mdx(\"p\",null,\"subject=/CN=your.host.com\"),mdx(\"p\",null,\"Getting CA Private Key\"),mdx(\"p\",null,\"Enter pass phrase for ca-key.pem:\"),mdx(\"p\",null,mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/extend/plugins_authorization\"}),\"Authorization plugins\"),\"\\xA0offer more fine-grained control to supplement authentication from mutual TLS. In addition to other information described in the above document, authorization plugins running on a Docker daemon receive the certificate information for connecting Docker clients.\"),mdx(\"p\",null,\"For client authentication, create a client key and certificate signing request:\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note:\"),\"\\xA0for simplicity of the next couple of steps, you may perform this step on the Docker daemon's host machine as well.\"),mdx(\"p\",null,\"$ openssl genrsa -out key.pem 4096\"),mdx(\"p\",null,\"Generating RSA private key, 4096 bit long modulus\"),mdx(\"p\",null,\".........................................................++\"),mdx(\"p\",null,\"................++\"),mdx(\"p\",null,\"e is 65537 (0x10001)\"),mdx(\"p\",null,\"$ openssl req -subj \\\\'/CN=client\\\\' -new -key key.pem -out client.csr\"),mdx(\"p\",null,\"To make the key suitable for client authentication, create an extensions config file:\"),mdx(\"p\",null,\"$ echo extendedKeyUsage = clientAuth >> extfile.cnf\"),mdx(\"p\",null,\"Now, generate the signed certificate:\"),mdx(\"p\",null,\"$ openssl x509 -req -days 365 -sha256 -in client.csr -CA ca.pem -CAkey ca-key.pem \\\\\"),mdx(\"p\",null,\"-CAcreateserial -out cert.pem -extfile extfile.cnf\"),mdx(\"p\",null,\"Signature ok\"),mdx(\"p\",null,\"subject=/CN=client\"),mdx(\"p\",null,\"Getting CA Private Key\"),mdx(\"p\",null,\"Enter pass phrase for ca-key.pem:\"),mdx(\"p\",null,\"After generating\\xA0cert.pem\\xA0and\\xA0server-cert.pem\\xA0you can safely remove the two certificate signing requests:\"),mdx(\"p\",null,\"$ rm -v client.csr server.csr\"),mdx(\"p\",null,\"With a default\\xA0umask\\xA0of 022, your secret keys are\\xA0world-readable\\xA0and writable for you and your group.\"),mdx(\"p\",null,\"To protect your keys from accidental damage, remove their write permissions. To make them only readable by you, change file modes as follows:\"),mdx(\"p\",null,\"$ chmod -v 0400 ca-key.pem key.pem server-key.pem\"),mdx(\"p\",null,\"Certificates can be world-readable, but you might want to remove write access to prevent accidental damage:\"),mdx(\"p\",null,\"$ chmod -v 0444 ca.pem server-cert.pem cert.pem\"),mdx(\"p\",null,\"Now you can make the Docker daemon only accept connections from clients providing a certificate trusted by your CA:\"),mdx(\"p\",null,\"$ dockerd --tlsverify --tlscacert=ca.pem --tlscert=server-cert.pem --tlskey=server-key.pem \\\\\"),mdx(\"p\",null,\"-H=0.0.0.0:2376\"),mdx(\"p\",null,\"To connect to Docker and validate its certificate, provide your client keys, certificates and trusted CA:\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Run it on the client machine\")),mdx(\"p\",null,\"This step should be run on your Docker client machine. As such, you need to copy your CA certificate, your server certificate, and your client certificate to that machine.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": replace all instances of\\xA0$HOST\\xA0in the following example with the DNS name of your Docker daemon's host.\"),mdx(\"p\",null,\"$ docker --tlsverify --tlscacert=ca.pem --tlscert=cert.pem --tlskey=key.pem \\\\\"),mdx(\"p\",null,\"-H=$HOST:2376 version\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": Docker over TLS should run on TCP port 2376.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Warning\"),\": As shown in the example above, you don't need to run the\\xA0docker\\xA0client with\\xA0sudo\\xA0or the\\xA0docker\\xA0group when you use certificate authentication. That means anyone with the keys can give any instructions to your Docker daemon, giving them root access to the machine hosting the daemon. Guard these keys as you would a root password!\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Secure by default\")),mdx(\"p\",null,\"If you want to secure your Docker client connections by default, you can move the files to the\\xA0.docker\\xA0directory in your home directory -- and set the\\xA0DOCKER_HOST\\xA0and\\xA0DOCKER_TLS_VERIFYvariables as well (instead of passing\\xA0-H=tcp://$HOST:2376\\xA0and\\xA0--tlsverify\\xA0on every call).\"),mdx(\"p\",null,\"$ mkdir -pv \",\"~\",\"/.docker\"),mdx(\"p\",null,\"$ cp -v {ca,cert,key}.pem \",\"~\",\"/.docker\"),mdx(\"p\",null,\"$ export DOCKER_HOST=tcp://$HOST:2376 DOCKER_TLS_VERIFY=1\"),mdx(\"p\",null,\"Docker now connects securely by default:\"),mdx(\"p\",null,\"$ docker ps\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Other modes\")),mdx(\"p\",null,\"If you don't want to have complete two-way authentication, you can run Docker in various other modes by mixing the flags.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Daemon modes\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"tlsverify,\\xA0tlscacert,\\xA0tlscert,\\xA0tlskey\\xA0set: Authenticate clients\"),mdx(\"li\",{parentName:\"ul\"},\"tls,\\xA0tlscert,\\xA0tlskey: Do not authenticate clients\")),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Client modes\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"tls: Authenticate server based on public/default CA pool\"),mdx(\"li\",{parentName:\"ul\"},\"tlsverify,\\xA0tlscacert: Authenticate server based on given CA\"),mdx(\"li\",{parentName:\"ul\"},\"tls,\\xA0tlscert,\\xA0tlskey: Authenticate with client certificate, do not authenticate server based on given CA\"),mdx(\"li\",{parentName:\"ul\"},\"tlsverify,\\xA0tlscacert,\\xA0tlscert,\\xA0tlskey: Authenticate with client certificate and authenticate server based on given CA\")),mdx(\"p\",null,\"If found, the client sends its client certificate, so you just need to drop your keys into\\xA0\",\"~\",\"/.docker/{ca,cert,key}.pem. Alternatively, if you want to store your keys in another location, you can specify that location using the environment variable\\xA0DOCKER_CERT_PATH.\"),mdx(\"p\",null,\"$ export DOCKER_CERT_PATH=\",\"~\",\"/.docker/zone1/\"),mdx(\"p\",null,\"$ docker --tlsverify ps\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Connecting to the secure Docker port using\\xA0curl\")),mdx(\"p\",null,\"To use\\xA0curl\\xA0to make test API requests, you need to use three extra command line flags:\"),mdx(\"p\",null,\"$ curl https://$HOST:2376/images/json \\\\\"),mdx(\"p\",null,\"--cert \",\"~\",\"/.docker/cert.pem \\\\\"),mdx(\"p\",null,\"--key \",\"~\",\"/.docker/key.pem \\\\\"),mdx(\"p\",null,\"--cacert \",\"~\",\"/.docker/ca.pem\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Related information\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/security/certificates/\"}),\"Using certificates for repository client verification\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/security/trust/\"}),\"Use trusted images\"))),mdx(\"h4\",null,\"Verify repository client with certificates\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA02 minutes\")),mdx(\"p\",null,\"In\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/security/https/\"}),\"Running Docker with HTTPS\"),\", you learned that, by default, Docker runs via a non-networked Unix socket and TLS must be enabled in order to have the Docker client and the daemon communicate securely over HTTPS. TLS ensures authenticity of the registry endpoint and that traffic to/from registry is encrypted.\"),mdx(\"p\",null,\"This article demonstrates how to ensure the traffic between the Docker registry server and the Docker daemon (a client of the registry server) is encrypted and properly authenticated using\\xA0certificate-based client-server authentication.\"),mdx(\"p\",null,\"We show you how to install a Certificate Authority (CA) root certificate for the registry and how to set the client TLS certificate for verification.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Understanding the configuration\")),mdx(\"p\",null,\"A custom certificate is configured by creating a directory under\\xA0/etc/docker/certs.d\\xA0using the same name as the registry's hostname, such as\\xA0localhost. All\\xA0*.crt\\xA0files are added to this directory as CA roots.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": As of Docker 1.13, on Linux any root certificates authorities are merged with the system defaults, including as the host's root CA set. On prior versions of Docker, and on Docker Enterprise Edition for Windows Server, the system default certificates are only used when no custom root certificates are configured.\"),mdx(\"p\",null,\"The presence of one or more\\xA0\",mdx(\"inlineCode\",{parentName:\"p\"},\"<filename>\"),\".key/cert\\xA0pairs indicates to Docker that there are custom certificates required for access to the desired repository.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": If multiple certificates exist, each is tried in alphabetical order. If there is a 4xx-level or 5xx-level authentication error, Docker continues to try with the next certificate.\"),mdx(\"p\",null,\"The following illustrates a configuration with custom certificates:\"),mdx(\"p\",null,\"/etc/docker/certs.d/ <-- Certificate directory\"),mdx(\"p\",null,\"\\u2514\\u2500\\u2500 localhost:5000 <-- Hostname:port\"),mdx(\"p\",null,\"\\u251C\\u2500\\u2500 client.cert <-- Client certificate\"),mdx(\"p\",null,\"\\u251C\\u2500\\u2500 client.key <-- Client key\"),mdx(\"p\",null,\"\\u2514\\u2500\\u2500 ca.crt <-- Certificate authority that signed\"),mdx(\"p\",null,\"the registry certificate\"),mdx(\"p\",null,\"The preceding example is operating-system specific and is for illustrative purposes only. You should consult your operating system documentation for creating an os-provided bundled certificate chain.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Creating the client certificates\")),mdx(\"p\",null,\"Use OpenSSL's\\xA0genrsa\\xA0and\\xA0req\\xA0commands to first generate an RSA key and then use the key to create the certificate.\"),mdx(\"p\",null,\"$ openssl genrsa -out client.key 4096\"),mdx(\"p\",null,\"$ openssl req -new -x509 -text -key client.key -out client.cert\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": These TLS commands only generate a working set of certificates on Linux. The version of OpenSSL in macOS is incompatible with the type of certificate Docker requires.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Troubleshooting tips\")),mdx(\"p\",null,\"The Docker daemon interprets\\xA0.crt\\xA0files as CA certificates and\\xA0.cert\\xA0files as client certificates. If a CA certificate is accidentally given the extension\\xA0.cert\\xA0instead of the correct\\xA0.crtextension, the Docker daemon logs the following error message:\"),mdx(\"p\",null,\"Missing key KEY_NAME for client certificate CERT_NAME. CA certificates should use the extension .crt.\"),mdx(\"p\",null,\"If the Docker registry is accessed without a port number, do not add the port to the directory name. The following shows the configuration for a registry on default port 443 which is accessed with\\xA0docker login my-https.registry.example.com:\"),mdx(\"p\",null,\"/etc/docker/certs.d/\"),mdx(\"p\",null,\"\\u2514\\u2500\\u2500 my-https.registry.example.com <-- Hostname without port\"),mdx(\"p\",null,\"\\u251C\\u2500\\u2500 client.cert\"),mdx(\"p\",null,\"\\u251C\\u2500\\u2500 client.key\"),mdx(\"p\",null,\"\\u2514\\u2500\\u2500 ca.crt\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Related Information\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/security/\"}),\"Use trusted images\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/security/https/\"}),\"Protect the Docker daemon socket\"))),mdx(\"h4\",null,\"Use Trusted Images\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Content trust in Docker\")),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA010 minutes\")),mdx(\"p\",null,\"When transferring data among networked systems,\\xA0trust\\xA0is a central concern. In particular, when communicating over an untrusted medium such as the internet, it is critical to ensure the integrity and the publisher of all the data a system operates on. You use Docker Engine to push and pull images (data) to a public or private registry. Content trust gives you the ability to verify both the integrity and the publisher of all the data received from a registry over any channel.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"About trust in Docker\")),mdx(\"p\",null,\"Content trust allows operations with a remote Docker registry to enforce client-side signing and verification of image tags. Content trust provides the ability to use digital signatures for data sent to and received from remote Docker registries. These signatures allow client-side verification of the integrity and publisher of specific image tags.\"),mdx(\"p\",null,\"Currently, content trust is disabled by default. To enable it, set the\\xA0DOCKER_CONTENT_TRUSTenvironment variable to\\xA01. Refer to the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/cli/#environment-variables\"}),\"environment variables\"),\"\\xA0and\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/cli/#notary\"}),\"Notary\"),\"\\xA0configuration for the docker client for more options.\"),mdx(\"p\",null,\"Once content trust is enabled, image publishers can sign their images. Image consumers can ensure that the images they use are signed. Publishers and consumers can be individuals alone or in organizations. Docker's content trust supports users and automated processes such as builds.\"),mdx(\"p\",null,\"When you enable content trust, signing occurs on the client after push and verification happens on the client after pull if you use Docker CE. If you use Docker EE with UCP, and you have configured UCP to require images to be signed before deploying, signing is verified by UCP.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Image tags and content trust\")),mdx(\"p\",null,\"An individual image record has the following identifier:\"),mdx(\"p\",null,\"[REGISTRY_HOST\",\"[:REGISTRY_PORT]\",\"/]REPOSITORY\",\"[:TAG]\"),mdx(\"p\",null,\"A particular image\\xA0REPOSITORY\\xA0can have multiple tags. For example,\\xA0latest\\xA0and\\xA03.1.2\\xA0are both tags on the\\xA0mongo\\xA0image. An image publisher can build an image and tag combination many times changing the image with each build.\"),mdx(\"p\",null,\"Content trust is associated with the\\xA0TAG\\xA0portion of an image. Each image repository has a set of keys that image publishers use to sign an image tag. Image publishers have discretion on which tags they sign.\"),mdx(\"p\",null,\"An image repository can contain an image with one tag that is signed and another tag that is not. For example, consider\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://hub.docker.com/r/library/mongo/tags/\"}),\"the Mongo image repository\"),\". The\\xA0latest\\xA0tag could be unsigned while the\\xA03.1.6\\xA0tag could be signed. It is the responsibility of the image publisher to decide if an image tag is signed or not. In this representation, some image tags are signed, others are not:\"),mdx(\"p\",null,\"Publishers can choose to sign a specific tag or not. As a result, the content of an unsigned tag and that of a signed tag with the same name may not match. For example, a publisher can push a tagged image\\xA0someimage:latest\\xA0and sign it. Later, the same publisher can push an unsigned\\xA0someimage:latest\\xA0image. This second push replaces the last unsigned tag\\xA0latest\\xA0but does not affect the signed\\xA0latest\\xA0version. The ability to choose which tags they can sign, allows publishers to iterate over the unsigned version of an image before officially signing it.\"),mdx(\"p\",null,\"Image consumers can enable content trust to ensure that images they use were signed. If a consumer enables content trust, they can only pull, run, or build with trusted images. Enabling content trust is like wearing a pair of rose-colored glasses. Consumers \\\"see\\\" only signed image tags and the less desirable, unsigned image tags are \\\"invisible\\\" to them.\"),mdx(\"p\",null,\"To the consumer who has not enabled content trust, nothing about how they work with Docker images changes. Every image is visible regardless of whether it is signed or not.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Content trust operations and keys\")),mdx(\"p\",null,\"When content trust is enabled,\\xA0docker\\xA0CLI commands that operate on tagged images must either have content signatures or explicit content hashes. The commands that operate with content trust are:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"push\"),mdx(\"li\",{parentName:\"ul\"},\"build\"),mdx(\"li\",{parentName:\"ul\"},\"create\"),mdx(\"li\",{parentName:\"ul\"},\"pull\"),mdx(\"li\",{parentName:\"ul\"},\"run\")),mdx(\"p\",null,\"For example, with content trust enabled a\\xA0docker pull someimage:latest\\xA0only succeeds if\\xA0someimage:latest\\xA0is signed. However, an operation with an explicit content hash always succeeds as long as the hash exists:\"),mdx(\"p\",null,\"$ docker pull someimage\\\\@sha256:d149ab53f8718e987c3a3024bb8aa0e2caadf6c0328f1d9d850b2a2a67f2819a\"),mdx(\"p\",null,\"Trust for an image tag is managed through the use of signing keys. A key set is created when an operation using content trust is first invoked. A key set consists of the following classes of keys:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"an offline key that is the root of content trust for an image tag\"),mdx(\"li\",{parentName:\"ul\"},\"repository or tagging keys that sign tags\"),mdx(\"li\",{parentName:\"ul\"},\"server-managed keys such as the timestamp key, which provides freshness security guarantees for your repository\")),mdx(\"p\",null,\"The following image depicts the various signing keys and their relationships:\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"WARNING\"),\": Loss of the root key is\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"very difficult\"),\"\\xA0to recover from. Correcting this loss requires intervention from\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://support.docker.com/\"}),\"Docker Support\"),\"\\xA0to reset the repository state. This loss also requires\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"manual intervention\"),\"\\xA0from every consumer that used a signed tag from this repository prior to the loss.\"),mdx(\"p\",null,\"You should backup the root key somewhere safe. Given that it is only required to create new repositories, it is a good idea to store it offline in hardware. For details on securing, and backing up your keys, make sure you read how to\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/security/trust/trust_key_mng/\"}),\"manage keys for content trust\"),\".\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Survey of typical content trust operations\")),mdx(\"p\",null,\"This section surveys the typical trusted operations users perform with Docker images. Specifically, we go through the following steps to help us exercise these various trusted operations:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Build and push an unsigned image\"),mdx(\"li\",{parentName:\"ul\"},\"Pull an unsigned image\"),mdx(\"li\",{parentName:\"ul\"},\"Build and push a signed image\"),mdx(\"li\",{parentName:\"ul\"},\"Pull the signed image pushed above\"),mdx(\"li\",{parentName:\"ul\"},\"Pull unsigned image pushed above\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Enable and disable content trust per-shell or per-invocation\")),mdx(\"p\",null,\"In a shell, you can enable content trust by setting the\\xA0DOCKER_CONTENT_TRUST\\xA0environment variable. Enabling per-shell is useful because you can have one shell configured for trusted operations and another terminal shell for untrusted operations. You can also add this declaration to your shell profile to have it turned on always by default.\"),mdx(\"p\",null,\"To enable content trust in a\\xA0bash\\xA0shell enter the following command:\"),mdx(\"pre\",null,mdx(\"code\",_extends({parentName:\"pre\"},{\"className\":\"language-bash\"}),\"export DOCKER_CONTENT_TRUST=1\\n\")),mdx(\"p\",null,\"Once set, each of the \\\"tag\\\" operations requires a key for a trusted tag.\"),mdx(\"p\",null,\"In an environment where\\xA0DOCKER_CONTENT_TRUST\\xA0is set, you can use the--disable-content-trust\\xA0flag to run individual operations on tagged images without content trust on an as-needed basis.\"),mdx(\"p\",null,\"Consider the following Dockerfile that uses an untrusted parent image:\"),mdx(\"pre\",null,mdx(\"code\",_extends({parentName:\"pre\"},{\"className\":\"language-bash\"}),\"$ cat Dockerfile\\nFROM docker/trusttest:latest\\nRUN echo\\n\")),mdx(\"p\",null,\"To build a container successfully using this Dockerfile, one can do:\"),mdx(\"pre\",null,mdx(\"code\",_extends({parentName:\"pre\"},{\"className\":\"language-bash\"}),\"$ docker build --disable-content-trust -t `<username>`/nottrusttest:latest .\\nSending build context to Docker daemon 42.84 MB\\n...\\nSuccessfully built f21b872447dc\\n\")),mdx(\"p\",null,\"The same is true for all the other commands, such as\\xA0pull\\xA0and\\xA0push:\"),mdx(\"p\",null,\"$ docker pull --disable-content-trust docker/trusttest:latest\"),mdx(\"p\",null,\"...\"),mdx(\"p\",null,\"$ docker push --disable-content-trust \",mdx(\"inlineCode\",{parentName:\"p\"},\"<username>\"),\"/nottrusttest:latest\"),mdx(\"p\",null,\"...\"),mdx(\"p\",null,\"To invoke a command with content trust enabled regardless of whether or how the\\xA0DOCKER_CONTENT_TRUST\\xA0variable is set:\"),mdx(\"p\",null,\"$ docker build --disable-content-trust=false -t \",mdx(\"inlineCode\",{parentName:\"p\"},\"<username>\"),\"/trusttest:testing .\"),mdx(\"p\",null,\"All of the trusted operations support the\\xA0--disable-content-trust\\xA0flag.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Push trusted content\")),mdx(\"p\",null,\"To create signed content for a specific image tag, simply enable content trust and push a tagged image. If this is the first time you have pushed an image using content trust on your system, the session looks like this:\"),mdx(\"p\",null,\"$ docker push \",mdx(\"inlineCode\",{parentName:\"p\"},\"<username>\"),\"/trusttest:testing\"),mdx(\"p\",null,\"The push refers to a repository \",\"[docker.io/\",mdx(\"inlineCode\",{parentName:\"p\"},\"<username>\"),\"/trusttest]\",\" (len: 1)\"),mdx(\"p\",null,\"9a61b6b1315e: Image already exists\"),mdx(\"p\",null,\"902b87aaaec9: Image already exists\"),mdx(\"p\",null,\"latest: digest: sha256:d02adacee0ac7a5be140adb94fa1dae64f4e71a68696e7f8e7cbf9db8dd49418 size: 3220\"),mdx(\"p\",null,\"Signing and pushing trust metadata\"),mdx(\"p\",null,\"You are about to create a new root signing key passphrase. This passphrase\"),mdx(\"p\",null,\"will be used to protect the most sensitive key in your signing system. Please\"),mdx(\"p\",null,\"choose a long, complex passphrase and be careful to keep the password and the\"),mdx(\"p\",null,\"key file itself secure and backed up. It is highly recommended that you use a\"),mdx(\"p\",null,\"password manager to generate the passphrase and keep it safe. There will be no\"),mdx(\"p\",null,\"way to recover this key. You can find the key in your config directory.\"),mdx(\"p\",null,\"Enter passphrase for new root key with id a1d96fb:\"),mdx(\"p\",null,\"Repeat passphrase for new root key with id a1d96fb:\"),mdx(\"p\",null,\"Enter passphrase for new repository key with id docker.io/\",mdx(\"inlineCode\",{parentName:\"p\"},\"<username>\"),\"/trusttest (3a932f1):\"),mdx(\"p\",null,\"Repeat passphrase for new repository key with id docker.io/\",mdx(\"inlineCode\",{parentName:\"p\"},\"<username>\"),\"/trusttest (3a932f1):\"),mdx(\"p\",null,\"Finished initializing \\\"docker.io/\",mdx(\"inlineCode\",{parentName:\"p\"},\"<username>\"),\"/trusttest\\\"\"),mdx(\"p\",null,\"When you push your first tagged image with content trust enabled, the\\xA0docker\\xA0client recognizes this is your first push and:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"alerts you that it is creating a new root key\"),mdx(\"li\",{parentName:\"ul\"},\"requests a passphrase for the root key\"),mdx(\"li\",{parentName:\"ul\"},\"generates a root key in the\\xA0\",\"~\",\"/.docker/trust\\xA0directory\"),mdx(\"li\",{parentName:\"ul\"},\"requests a passphrase for the repository key\"),mdx(\"li\",{parentName:\"ul\"},\"generates a repository key in the\\xA0\",\"~\",\"/.docker/trust\\xA0directory\")),mdx(\"p\",null,\"The passphrase you chose for both the root key and your repository key-pair should be randomly generated and stored in a\\xA0password manager.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"NOTE\"),\": If you omit the\\xA0testing\\xA0tag, content trust is skipped. This is true even if content trust is enabled and even if this is your first push.\"),mdx(\"p\",null,\"$ docker push \",mdx(\"inlineCode\",{parentName:\"p\"},\"<username>\"),\"/trusttest\"),mdx(\"p\",null,\"The push refers to a repository \",\"[docker.io/\",mdx(\"inlineCode\",{parentName:\"p\"},\"<username>\"),\"/trusttest]\",\" (len: 1)\"),mdx(\"p\",null,\"9a61b6b1315e: Image successfully pushed\"),mdx(\"p\",null,\"902b87aaaec9: Image successfully pushed\"),mdx(\"p\",null,\"latest: digest: sha256:a9a9c4402604b703bed1c847f6d85faac97686e48c579bd9c3b0fa6694a398fc size: 3220\"),mdx(\"p\",null,\"No tag specified, skipping trust metadata push\"),mdx(\"p\",null,\"It is skipped because as the message states, you did not supply an image\\xA0TAG\\xA0value. In Docker content trust, signatures are associated with tags.\"),mdx(\"p\",null,\"Once you have a root key on your system, subsequent images repositories you create can use that same root key:\"),mdx(\"p\",null,\"$ docker push docker.io/\",mdx(\"inlineCode\",{parentName:\"p\"},\"<username>\"),\"/otherimage:latest\"),mdx(\"p\",null,\"The push refers to a repository \",\"[docker.io/\",mdx(\"inlineCode\",{parentName:\"p\"},\"<username>\"),\"/otherimage]\",\" (len: 1)\"),mdx(\"p\",null,\"a9539b34a6ab: Image successfully pushed\"),mdx(\"p\",null,\"b3dbab3810fc: Image successfully pushed\"),mdx(\"p\",null,\"latest: digest: sha256:d2ba1e603661a59940bfad7072eba698b79a8b20ccbb4e3bfb6f9e367ea43939 size: 3346\"),mdx(\"p\",null,\"Signing and pushing trust metadata\"),mdx(\"p\",null,\"Enter key passphrase for root key with id a1d96fb:\"),mdx(\"p\",null,\"Enter passphrase for new repository key with id docker.io/\",mdx(\"inlineCode\",{parentName:\"p\"},\"<username>\"),\"/otherimage (bb045e3):\"),mdx(\"p\",null,\"Repeat passphrase for new repository key with id docker.io/\",mdx(\"inlineCode\",{parentName:\"p\"},\"<username>\"),\"/otherimage (bb045e3):\"),mdx(\"p\",null,\"Finished initializing \\\"docker.io/\",mdx(\"inlineCode\",{parentName:\"p\"},\"<username>\"),\"/otherimage\\\"\"),mdx(\"p\",null,\"The new image has its own repository key and timestamp key. The\\xA0latest\\xA0tag is signed with both of these.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Pull image content\")),mdx(\"p\",null,\"A common way to consume an image is to\\xA0pull\\xA0it. With content trust enabled, the Docker client only allows\\xA0docker pull\\xA0to retrieve signed images. Let's try to pull the image you signed and pushed earlier:\"),mdx(\"p\",null,\"$ docker pull \",mdx(\"inlineCode\",{parentName:\"p\"},\"<username>\"),\"/trusttest:testing\"),mdx(\"p\",null,\"Pull (1 of 1): \",mdx(\"inlineCode\",{parentName:\"p\"},\"<username>\"),\"/trusttest:testing\\\\@sha256:d149ab53f871\"),mdx(\"p\",null,\"...\"),mdx(\"p\",null,\"Tagging \",mdx(\"inlineCode\",{parentName:\"p\"},\"<username>\"),\"/trusttest\\\\@sha256:d149ab53f871 as docker/trusttest:testing\"),mdx(\"p\",null,\"In the following example, the command does not specify a tag, so the system uses the\\xA0latesttag by default again and the\\xA0docker/trusttest:latest\\xA0tag is not signed.\"),mdx(\"p\",null,\"$ docker pull docker/trusttest\"),mdx(\"p\",null,\"Using default tag: latest\"),mdx(\"p\",null,\"no trust data available\"),mdx(\"p\",null,\"Because the tag\\xA0docker/trusttest:latest\\xA0is not trusted, the\\xA0pull\\xA0fails.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Related information\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/security/trust/trust_key_mng/\"}),\"Manage keys for content trust\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/security/trust/trust_automation/\"}),\"Automation with content trust\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/security/trust/trust_delegation/\"}),\"Delegations for content trust\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/security/trust/trust_sandbox/\"}),\"Play in a content trust sandbox\"))),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Automation with content trust\")),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA02 minutes\")),mdx(\"p\",null,\"Your automation systems that pull or build images can also work with trust. Any automation environment must set\\xA0DOCKER_CONTENT_TRUST\\xA0either manually or in a scripted fashion before processing images.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Bypass requests for passphrases\")),mdx(\"p\",null,\"To allow tools to wrap docker and push trusted content, there are two environment variables that allow you to provide the passphrases without an expect script, or typing them in:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"DOCKER_CONTENT_TRUST_ROOT_PASSPHRASE\"),mdx(\"li\",{parentName:\"ul\"},\"DOCKER_CONTENT_TRUST_REPOSITORY_PASSPHRASE\")),mdx(\"p\",null,\"Docker attempts to use the contents of these environment variables as passphrase for the keys. For example, an image publisher can export the repository\\xA0target\\xA0and\\xA0snapshot\\xA0passphrases:\"),mdx(\"p\",null,\"$ export DOCKER_CONTENT_TRUST_ROOT_PASSPHRASE=\\\"u7pEQcGoebUHm6LHe6\\\"\"),mdx(\"p\",null,\"$ export DOCKER_CONTENT_TRUST_REPOSITORY_PASSPHRASE=\\\"l7pEQcTKJjUHm6Lpe4\\\"\"),mdx(\"p\",null,\"Then, when pushing a new tag the Docker client does not request these values but signs automatically:\"),mdx(\"p\",null,\"$ docker push docker/trusttest:latest\"),mdx(\"p\",null,\"The push refers to a repository \",\"[docker.io/docker/trusttest]\",\" (len: 1)\"),mdx(\"p\",null,\"a9539b34a6ab: Image already exists\"),mdx(\"p\",null,\"b3dbab3810fc: Image already exists\"),mdx(\"p\",null,\"latest: digest: sha256:d149ab53f871 size: 3355\"),mdx(\"p\",null,\"Signing and pushing trust metadata\"),mdx(\"p\",null,\"When working directly with the Notary client, it uses its\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/notary/reference/client-config/#environment-variables-optional\"}),\"own set of environment variables\"),\".\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Building with content trust\")),mdx(\"p\",null,\"You can also build with content trust. Before running the\\xA0docker build\\xA0command, you should set the environment variable\\xA0DOCKER_CONTENT_TRUST\\xA0either manually or in a scripted fashion. Consider the simple Dockerfile below.\"),mdx(\"p\",null,\"FROM docker/trusttest:latest\"),mdx(\"p\",null,\"RUN echo\"),mdx(\"p\",null,\"The\\xA0FROM\\xA0tag is pulling a signed image. You cannot build an image that has a\\xA0FROM\\xA0that is not either present locally or signed. Given that content trust data exists for the tag\\xA0latest, the following build should succeed:\"),mdx(\"p\",null,\"$ docker build -t docker/trusttest:testing .\"),mdx(\"p\",null,\"Using default tag: latest\"),mdx(\"p\",null,\"latest: Pulling from docker/trusttest\"),mdx(\"p\",null,\"b3dbab3810fc: Pull complete\"),mdx(\"p\",null,\"a9539b34a6ab: Pull complete\"),mdx(\"p\",null,\"Digest: sha256:d149ab53f871\"),mdx(\"p\",null,\"If content trust is enabled, building from a Dockerfile that relies on tag without trust data, causes the build command to fail:\"),mdx(\"p\",null,\"$ docker build -t docker/trusttest:testing .\"),mdx(\"p\",null,\"unable to process Dockerfile: No trust data for notrust\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Related information\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/security/trust/content_trust/\"}),\"Content trust in Docker\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/security/trust/trust_key_mng/\"}),\"Manage keys for content trust\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/security/trust/trust_delegation/\"}),\"Delegations for content trust\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/security/trust/trust_sandbox/\"}),\"Play in a content trust sandbox\"))),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Delegations for content trust\")),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA06 minutes\")),mdx(\"p\",null,\"Docker Engine supports the usage of the\\xA0targets/releases\\xA0delegation as the canonical source of a trusted image tag.\"),mdx(\"p\",null,\"Using this delegation allows you to collaborate with other publishers without sharing your repository key, which is a combination of your targets and snapshot keys. See\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/security/trust/trust_key_mng/\"}),\"Manage keys for content trust\"),\"\\xA0for more information). Collaborators can keep their own delegation keys private.\"),mdx(\"p\",null,\"The\\xA0targets/releases\\xA0delegation is currently an optional feature - in order to set up delegations, you must use the Notary CLI:\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://github.com/docker/notary/releases\"}),\"Download the client\"),\"\\xA0and ensure that it is available on your path\"),mdx(\"li\",{parentName:\"ol\"},\"Create a configuration file at\\xA0\",\"~\",\"/.notary/config.json\\xA0with the following content:\"),mdx(\"li\",{parentName:\"ol\"},\"{\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"trust_dir\\\" : \\\"\",\"~\",\"/.docker/trust\\\",\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"remote_server\\\": {\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"url\\\": \\\"\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://notary.docker.io%22\"}),\"https://notary.docker.io\\\"\")),mdx(\"li\",{parentName:\"ol\"},\"}\"),mdx(\"li\",{parentName:\"ol\"},\"}\")),mdx(\"p\",null,\"This tells Notary where the Docker Content Trust data is stored, and to use the Notary server used for images in Docker Hub.\"),mdx(\"p\",null,\"For more detailed information about how to use Notary outside of the default Docker Content Trust use cases, refer to the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/notary/getting_started/\"}),\"Notary CLI documentation\"),\".\"),mdx(\"p\",null,\"When publishing and listing delegation changes using the Notary client, your Docker Hub credentials are required.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Generating delegation keys\")),mdx(\"p\",null,\"Your collaborator needs to generate a private key (either RSA or ECDSA) and give you the public key so that you can add it to the\\xA0targets/releases\\xA0delegation.\"),mdx(\"p\",null,\"The easiest way for them to generate these keys is with OpenSSL. Here is an example of how to generate a 2048-bit RSA portion key (all RSA keys must be at least 2048 bits):\"),mdx(\"p\",null,\"$ openssl genrsa -out delegation.key 2048\"),mdx(\"p\",null,\"Generating RSA private key, 2048 bit long modulus\"),mdx(\"p\",null,\"....................................................+++\"),mdx(\"p\",null,\"............+++\"),mdx(\"p\",null,\"e is 65537 (0x10001)\"),mdx(\"p\",null,\"They should keep\\xA0delegation.key\\xA0private because it is used to sign tags.\"),mdx(\"p\",null,\"Then they need to generate an x509 certificate containing the public key, which is what you need from them. Here is the command to generate a CSR (certificate signing request):\"),mdx(\"p\",null,\"$ openssl req -new -sha256 -key delegation.key -out delegation.csr\"),mdx(\"p\",null,\"Then they can send it to whichever CA you trust to sign certificates, or they can self-sign the certificate (in this example, creating a certificate that is valid for 1 year):\"),mdx(\"p\",null,\"$ openssl x509 -req -sha256 -days 365 -in delegation.csr -signkey delegation.key -out delegation.crt\"),mdx(\"p\",null,\"Then they need to give you\\xA0delegation.crt, whether it is self-signed or signed by a CA.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Adding a delegation key to an existing repository\")),mdx(\"p\",null,\"If your repository was created using a version of Docker Engine prior to 1.11, then before adding any delegations, you should rotate the snapshot key to the server so that collaborators don't need your snapshot key to sign and publish tags:\"),mdx(\"p\",null,\"$ notary key rotate docker.io/\",mdx(\"inlineCode\",{parentName:\"p\"},\"<username>/<imagename>\"),\" snapshot -r\"),mdx(\"p\",null,\"This tells Notary to rotate a key for your particular image repository. The\\xA0docker.io/\\xA0prefix is required.\\xA0snapshot -r\\xA0specifies that you want to rotate the snapshot key and that you want the server to manage it (-r\\xA0stands for \\\"remote\\\").\"),mdx(\"p\",null,\"When adding a delegation, your must acquire\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/security/trust/trust_delegation/#generating-delegation-keys\"}),\"the PEM-encoded x509 certificate with the public key\"),\"\\xA0of the collaborator you wish to delegate to.\"),mdx(\"p\",null,\"Assuming you have the certificate\\xA0delegation.crt, you can add a delegation for this user and then publish the delegation change:\"),mdx(\"p\",null,\"$ notary delegation add docker.io/\",mdx(\"inlineCode\",{parentName:\"p\"},\"<username>/<imagename>\"),\" targets/releases delegation.crt --all-paths\"),mdx(\"p\",null,\"$ notary publish docker.io/\",mdx(\"inlineCode\",{parentName:\"p\"},\"<username>/<imagename>\")),mdx(\"p\",null,\"The preceding example illustrates a request to add the delegation\\xA0targets/releases\\xA0to the image repository, if it doesn't exist. Be sure to use\\xA0targets/releases\\xA0- Notary supports multiple delegation roles, so if you mistype the delegation name, the Notary CLI does not error. However, Docker Engine supports reading only from\\xA0targets/releases.\"),mdx(\"p\",null,\"It also adds the collaborator's public key to the delegation, enabling them to sign the\\xA0targets/releases\\xA0delegation so long as they have the private key corresponding to this public key. The\\xA0--all-paths\\xA0flag tells Notary not to restrict the tag names that can be signed into\\xA0targets/releases, which we highly recommend for\\xA0targets/releases.\"),mdx(\"p\",null,\"Publishing the changes tells the server about the changes to the\\xA0targets/releases\\xA0delegation.\"),mdx(\"p\",null,\"After publishing, view the delegation information to ensure that you correctly added the keys to\\xA0targets/releases:\"),mdx(\"p\",null,\"$ notary delegation list docker.io/\",mdx(\"inlineCode\",{parentName:\"p\"},\"<username>/<imagename>\")),mdx(\"p\",null,\"ROLE PATHS KEY IDS THRESHOLD\"),mdx(\"hr\",null),mdx(\"p\",null,\"targets/releases \\\"\\\" \",mdx(\"inlineCode\",{parentName:\"p\"},\"<all paths>\"),\" 729c7094a8210fd1e780e7b17b7bb55c9a28a48b871b07f65d97baf93898523a 1\"),mdx(\"p\",null,\"You can see the\\xA0targets/releases\\xA0with its paths and the key ID you just added.\"),mdx(\"p\",null,\"Notary currently does not map collaborators names to keys, so we recommend that you add and list delegation keys one at a time, and keep a mapping of the key IDs to collaborators yourself should you need to remove a collaborator.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Removing a delegation key from an existing repository\")),mdx(\"p\",null,\"To revoke a collaborator's ability to sign tags for your image repository, you need to remove their keys from the\\xA0targets/releases\\xA0delegation. To do this, you need the IDs of their keys.\"),mdx(\"p\",null,\"$ notary delegation remove docker.io/\",mdx(\"inlineCode\",{parentName:\"p\"},\"<username>/<imagename>\"),\" targets/releases 729c7094a8210fd1e780e7b17b7bb55c9a28a48b871b07f65d97baf93898523a\"),mdx(\"p\",null,\"Removal of delegation role targets/releases with keys \",\"[729c7094a8210fd1e780e7b17b7bb55c9a28a48b871b07f65d97baf93898523a]\",\", to repository \\\"docker.io/\",mdx(\"inlineCode\",{parentName:\"p\"},\"<username>/<imagename>\"),\"\\\" staged for next publish.\"),mdx(\"p\",null,\"The revocation takes effect as soon as you publish:\"),mdx(\"p\",null,\"$ notary publish docker.io/\",mdx(\"inlineCode\",{parentName:\"p\"},\"<username>/<imagename>\")),mdx(\"p\",null,\"By removing all the keys from the\\xA0targets/releases\\xA0delegation, the delegation (and any tags that are signed into it) is removed. That means that these tags are all deleted, and you may end up with older, legacy tags that were signed directly by the targets key.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Removing the\\xA0targets/releases\\xA0delegation entirely from a repository\")),mdx(\"p\",null,\"If you've decided that delegations aren't for you, you can delete the\\xA0targets/releases\\xA0delegation entirely. This also removes all the tags that are currently in\\xA0targets/releases, however, and you may end up with older, legacy tags that were signed directly by the targets key.\"),mdx(\"p\",null,\"To delete the\\xA0targets/releases\\xA0delegation:\"),mdx(\"p\",null,\"$ notary delegation remove docker.io/\",mdx(\"inlineCode\",{parentName:\"p\"},\"<username>/<imagename>\"),\" targets/releases\"),mdx(\"p\",null,\"Are you sure you want to remove all data for this delegation? (yes/no)\"),mdx(\"p\",null,\"yes\"),mdx(\"p\",null,\"Forced removal (including all keys and paths) of delegation role targets/releases to repository \\\"docker.io/\",mdx(\"inlineCode\",{parentName:\"p\"},\"<username>/<imagename>\"),\"\\\" staged for next publish.\"),mdx(\"p\",null,\"$ notary publish docker.io/\",mdx(\"inlineCode\",{parentName:\"p\"},\"<username>/<imagename>\")),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Pushing trusted data as a collaborator\")),mdx(\"p\",null,\"As a collaborator with a private key that has been added to a repository's\\xA0targets/releasesdelegation, you need to import the private key that you generated into Content Trust.\"),mdx(\"p\",null,\"To do so, you can run:\"),mdx(\"p\",null,\"$ notary key import delegation.key --role user\"),mdx(\"p\",null,\"where\\xA0delegation.key\\xA0is the file containing your PEM-encoded private key.\"),mdx(\"p\",null,\"After you have done so, running\\xA0docker push\\xA0on any repository that includes your key in the\\xA0targets/releases\\xA0delegation automatically signs tags using this imported key.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"docker push\\xA0behavior\")),mdx(\"p\",null,\"When running\\xA0docker push\\xA0with Docker Content Trust, Docker Engine attempts to sign and push with the\\xA0targets/releases\\xA0delegation if it exists. If it does not, the targets key is used to sign the tag, if the key is available.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"docker pull\\xA0and\\xA0docker build\\xA0behavior\")),mdx(\"p\",null,\"When running\\xA0docker pull\\xA0or\\xA0docker build\\xA0with Docker Content Trust, Docker Engine pulls tags only signed by the\\xA0targets/releases\\xA0delegation role or the legacy tags that were signed directly with the\\xA0targets\\xA0key.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Related information\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/security/trust/content_trust/\"}),\"Content trust in Docker\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/security/trust/trust_key_mng/\"}),\"Manage keys for content trust\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/security/trust/trust_automation/\"}),\"Automation with content trust\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/security/trust/trust_sandbox/\"}),\"Play in a content trust sandbox\"))),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Deploy Notary Server with Compose\")),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA01 minute\")),mdx(\"p\",null,\"The easiest way to deploy Notary Server is by using Docker Compose. To follow the procedure on this page, you must have already\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/compose/install/\"}),\"installed Docker Compose\"),\".\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Clone the Notary repository.\"),mdx(\"li\",{parentName:\"ol\"},\"git clone git\\\\@github.com:docker/notary.git\"),mdx(\"li\",{parentName:\"ol\"},\"Build and start Notary Server with the sample certificates.\"),mdx(\"li\",{parentName:\"ol\"},\"docker-compose up -d\")),mdx(\"p\",null,\"For more detailed documentation about how to deploy Notary Server, see the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/notary/running_a_service/\"}),\"instructions to run a Notary service\"),\"\\xA0as well as\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/docker/notary\"}),\"the Notary repository\"),\"\\xA0for more information.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Make sure that your Docker or Notary client trusts Notary Server's certificate before you try to interact with the Notary server.\")),mdx(\"p\",null,\"See the instructions for\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/cli/#notary\"}),\"Docker\"),\"\\xA0or for\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/docker/notary#using-notary\"}),\"Notary\"),\"\\xA0depending on which one you are using.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"If you want to use Notary in production\")),mdx(\"p\",null,\"Check back here for instructions after Notary Server has an official stable release. To get a head start on deploying Notary in production, see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/docker/notary\"}),\"the Notary repository\"),\".\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Manage keys for content trust\")),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA04 minutes\")),mdx(\"p\",null,\"Trust for an image tag is managed through the use of keys. Docker's content trust makes use of five different types of keys:\"),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Key\"),\"      \",mdx(\"strong\",{parentName:\"p\"},\"Description\")),mdx(\"hr\",null),mdx(\"p\",null,\"  root key     Root of content trust for an image tag. When content trust is enabled, you create the root key once. Also known as the offline key, because it should be kept offline.\\ntargets      This key allows you to sign image tags, to manage delegations including delegated keys or permitted delegation paths. Also known as the repository key, since this key determines what tags can be signed into an image repository.\\nsnapshot     This key signs the current collection of image tags, preventing mix and match attacks.\\ntimestamp    This key allows Docker image repositories to have freshness security guarantees without requiring periodic content refreshes on the client's side.\\ndelegation   Delegation keys are optional tagging keys and allow you to delegate signing image tags to other publishers without having to share your targets key.\"),mdx(\"p\",null,\"When doing a\\xA0docker push\\xA0with Content Trust enabled for the first time, the root, targets, snapshot, and timestamp keys are generated automatically for the image repository:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"The root and targets key are generated and stored locally client-side.\"),mdx(\"li\",{parentName:\"ul\"},\"The timestamp and snapshot keys are safely generated and stored in a signing server that is deployed alongside the Docker registry. These keys are generated in a backend service that isn't directly exposed to the internet and are encrypted at rest.\")),mdx(\"p\",null,\"Delegation keys are optional, and not generated as part of the normal\\xA0docker\\xA0workflow. They need to be\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/security/trust/trust_delegation/#generating-delegation-keys\"}),\"manually generated and added to the repository\"),\".\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": Prior to Docker Engine 1.11, the snapshot key was also generated and stored locally client-side.\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/notary/advanced_usage/#rotate-keys\"}),\"Use the Notary CLI to manage your snapshot key locally again\"),\"\\xA0for repositories created with newer versions of Docker.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Choosing a passphrase\")),mdx(\"p\",null,\"The passphrases you chose for both the root key and your repository key should be randomly generated and stored in a password manager. Having the repository key allows users to sign image tags on a repository. Passphrases are used to encrypt your keys at rest and ensure that a lost laptop or an unintended backup doesn't put the private key material at risk.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Back up your keys\")),mdx(\"p\",null,\"All the Docker trust keys are stored encrypted using the passphrase you provide on creation. Even so, you should still take care of the location where you back them up. Good practice is to create two encrypted USB keys.\"),mdx(\"p\",null,\"It is very important that you back up your keys to a safe, secure location. Loss of the repository key is recoverable; loss of the root key is not.\"),mdx(\"p\",null,\"The Docker client stores the keys in the\\xA0\",\"~\",\"/.docker/trust/private\\xA0directory. Before backing them up, you should\\xA0tar\\xA0them into an archive:\"),mdx(\"p\",null,\"$ umask 077; tar -zcvf private_keys_backup.tar.gz \",\"~\",\"/.docker/trust/private; umask 022\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Hardware storage and signing\")),mdx(\"p\",null,\"Docker Content Trust can store and sign with root keys from a Yubikey 4. The Yubikey is prioritized over keys stored in the filesystem. When you initialize a new repository with content trust, Docker Engine looks for a root key locally. If a key is not found and the Yubikey 4 exists, Docker Engine creates a root key in the Yubikey 4. Consult the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/notary/advanced_usage/#use-a-yubikey\"}),\"Notary documentation\"),\"\\xA0for more details.\"),mdx(\"p\",null,\"Prior to Docker Engine 1.11, this feature was only in the experimental branch.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Lost keys\")),mdx(\"p\",null,\"If a publisher loses keys it means losing the ability to sign trusted content for your repositories. If you lose a key, contact\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://support.docker.com/\"}),\"Docker Support\"),\"\\xA0(support\\\\@docker.com) to reset the repository state.\"),mdx(\"p\",null,\"This loss also requires\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"manual intervention\"),\"\\xA0from every consumer that pulled the tagged image prior to the loss. Image consumers would get an error for content that they already downloaded:\"),mdx(\"p\",null,\"Warning: potential malicious behavior - trust data has insufficient signatures for remote repository docker.io/my/image: valid signatures did not meet threshold\"),mdx(\"p\",null,\"To correct this, they need to download a new image tag that is signed with the new key.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Related information\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/security/trust/content_trust/\"}),\"Content trust in Docker\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/security/trust/trust_automation/\"}),\"Automation with content trust\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/security/trust/trust_delegation/\"}),\"Delegations for content trust\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/security/trust/trust_sandbox/\"}),\"Play in a content trust sandbox\"))),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Play in a content trust sandbox\")),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA08 minutes\")),mdx(\"p\",null,\"This page explains how to set up and use a sandbox for experimenting with trust. The sandbox allows you to configure and try trust operations locally without impacting your production images.\"),mdx(\"p\",null,\"Before working through this sandbox, you should have read through the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/security/trust/content_trust/\"}),\"trust overview\"),\".\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Prerequisites\")),mdx(\"p\",null,\"These instructions assume you are running in Linux or macOS. You can run this sandbox on a local machine or on a virtual machine. You need to have privileges to run docker commands on your local machine or in the VM.\"),mdx(\"p\",null,\"This sandbox requires you to install two Docker tools: Docker Engine >= 1.10.0 and Docker Compose >= 1.6.0. To install the Docker Engine, choose from the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/installation/\"}),\"list of supported platforms\"),\". To install Docker Compose, see the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/compose/install/\"}),\"detailed instructions here\"),\".\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"What is in the sandbox?\")),mdx(\"p\",null,\"If you are just using trust out-of-the-box you only need your Docker Engine client and access to the Docker Hub. The sandbox mimics a production trust environment, and sets up these additional components.\"),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Container\"),\"     \",mdx(\"strong\",{parentName:\"p\"},\"Description\")),mdx(\"hr\",null),mdx(\"p\",null,\"  trustsandbox      A container with the latest version of Docker Engine and with some preconfigured certificates. This is your sandbox where you can use the\\xA0docker\\xA0client to test trust operations.\\nRegistry server   A local registry service.\\nNotary server     The service that does all the heavy-lifting of managing trust\"),mdx(\"p\",null,\"This means you run your own content trust (Notary) server and registry. If you work exclusively with the Docker Hub, you would not need with these components. They are built into the Docker Hub for you. For the sandbox, however, you build your own entire, mock production environment.\"),mdx(\"p\",null,\"Within the\\xA0trustsandbox\\xA0container, you interact with your local registry rather than the Docker Hub. This means your everyday image repositories are not used. They are protected while you play.\"),mdx(\"p\",null,\"When you play in the sandbox, you also create root and repository keys. The sandbox is configured to store all the keys and files inside the\\xA0trustsandbox\\xA0container. Since the keys you create in the sandbox are for play only, destroying the container destroys them as well.\"),mdx(\"p\",null,\"By using a docker-in-docker image for the\\xA0trustsandbox\\xA0container, you also don't pollute your real Docker daemon cache with any images you push and pull. The images are stored in an anonymous volume attached to this container, and can be destroyed after you destroy the container.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Build the sandbox\")),mdx(\"p\",null,\"In this section, you use Docker Compose to specify how to set up and link together the\\xA0trustsandbox\\xA0container, the Notary server, and the Registry server.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Create a new\\xA0trustsandbox\\xA0directory and change into it.\"),mdx(\"li\",{parentName:\"ol\"},\"$ mkdir trustsandbox\"),mdx(\"li\",{parentName:\"ol\"},\"$ cd trustsandbox\"),mdx(\"li\",{parentName:\"ol\"},\"Create a file called\\xA0docker-compose.yml\\xA0with your favorite editor. For example, using vim:\"),mdx(\"li\",{parentName:\"ol\"},\"$ touch docker-compose.yml\"),mdx(\"li\",{parentName:\"ol\"},\"$ vim docker-compose.yml\"),mdx(\"li\",{parentName:\"ol\"},\"Add the following to the new file.\"),mdx(\"li\",{parentName:\"ol\"},\"version: \\\"2\\\"\"),mdx(\"li\",{parentName:\"ol\"},\"services:\"),mdx(\"li\",{parentName:\"ol\"},\"notaryserver:\"),mdx(\"li\",{parentName:\"ol\"},\"image: dockersecurity/notary_autobuilds:server-v0.4.2\"),mdx(\"li\",{parentName:\"ol\"},\"volumes:\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},\"notarycerts:/go/src/github.com/docker/notary/fixtures\"))),mdx(\"li\",{parentName:\"ol\"},\"networks:\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},\"sandbox\"))),mdx(\"li\",{parentName:\"ol\"},\"environment:\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},\"NOTARY_SERVER_STORAGE_TYPE=memory\"))),mdx(\"li\",{parentName:\"ol\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},\"NOTARY_SERVER_TRUST_SERVICE_TYPE=local\"))),mdx(\"li\",{parentName:\"ol\"},\"sandboxregistry:\"),mdx(\"li\",{parentName:\"ol\"},\"image: registry:2.4.1\"),mdx(\"li\",{parentName:\"ol\"},\"networks:\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},\"sandbox\"))),mdx(\"li\",{parentName:\"ol\"},\"container_name: sandboxregistry\"),mdx(\"li\",{parentName:\"ol\"},\"trustsandbox:\"),mdx(\"li\",{parentName:\"ol\"},\"image: docker:dind\"),mdx(\"li\",{parentName:\"ol\"},\"networks:\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},\"sandbox\"))),mdx(\"li\",{parentName:\"ol\"},\"volumes:\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},\"notarycerts:/notarycerts\"))),mdx(\"li\",{parentName:\"ol\"},\"privileged: true\"),mdx(\"li\",{parentName:\"ol\"},\"container_name: trustsandbox\"),mdx(\"li\",{parentName:\"ol\"},\"entrypoint: \\\"\\\"\"),mdx(\"li\",{parentName:\"ol\"},\"command: |-\"),mdx(\"li\",{parentName:\"ol\"},\"sh -c \\\\'\"),mdx(\"li\",{parentName:\"ol\"},\"cp /notarycerts/root-ca.crt /usr/local/share/ca-certificates/root-ca.crt &&\"),mdx(\"li\",{parentName:\"ol\"},\"update-ca-certificates &&\"),mdx(\"li\",{parentName:\"ol\"},\"dockerd-entrypoint.sh --insecure-registry sandboxregistry:5000\\\\'\"),mdx(\"li\",{parentName:\"ol\"},\"volumes:\"),mdx(\"li\",{parentName:\"ol\"},\"notarycerts:\"),mdx(\"li\",{parentName:\"ol\"},\"external: false\"),mdx(\"li\",{parentName:\"ol\"},\"networks:\"),mdx(\"li\",{parentName:\"ol\"},\"sandbox:\"),mdx(\"li\",{parentName:\"ol\"},\"external: false\"),mdx(\"li\",{parentName:\"ol\"},\"Save and close the file.\"),mdx(\"li\",{parentName:\"ol\"},\"Run the containers on your local system.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker-compose up -d\")),mdx(\"p\",null,\"The first time you run this, the docker-in-docker, Notary server, and registry images are downloaded from Docker Hub.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Playing in the sandbox\")),mdx(\"p\",null,\"Now that everything is setup, you can go into your\\xA0trustsandbox\\xA0container and start testing Docker content trust. From your host machine, obtain a shell in the\\xA0trustsandbox\\xA0container.\"),mdx(\"p\",null,\"$ docker container exec -it trustsandbox sh\"),mdx(\"p\",null,\"/ #\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Test some trust operations\")),mdx(\"p\",null,\"Now, pull some images from within the\\xA0trustsandbox\\xA0container.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Download a\\xA0docker\\xA0image to test with.\"),mdx(\"li\",{parentName:\"ol\"},\"/ # docker pull docker/trusttest\"),mdx(\"li\",{parentName:\"ol\"},\"docker pull docker/trusttest\"),mdx(\"li\",{parentName:\"ol\"},\"Using default tag: latest\"),mdx(\"li\",{parentName:\"ol\"},\"latest: Pulling from docker/trusttest\"),mdx(\"li\",{parentName:\"ol\"},\"b3dbab3810fc: Pull complete\"),mdx(\"li\",{parentName:\"ol\"},\"a9539b34a6ab: Pull complete\"),mdx(\"li\",{parentName:\"ol\"},\"Digest: sha256:d149ab53f8718e987c3a3024bb8aa0e2caadf6c0328f1d9d850b2a2a67f2819a\"),mdx(\"li\",{parentName:\"ol\"},\"Status: Downloaded newer image for docker/trusttest:latest\"),mdx(\"li\",{parentName:\"ol\"},\"Tag it to be pushed to our sandbox registry:\"),mdx(\"li\",{parentName:\"ol\"},\"/ # docker tag docker/trusttest sandboxregistry:5000/test/trusttest:latest\"),mdx(\"li\",{parentName:\"ol\"},\"Enable content trust.\"),mdx(\"li\",{parentName:\"ol\"},\"/ # export DOCKER_CONTENT_TRUST=1\"),mdx(\"li\",{parentName:\"ol\"},\"Identify the trust server.\"),mdx(\"li\",{parentName:\"ol\"},\"/ # export DOCKER_CONTENT_TRUST_SERVER=https://notaryserver:4443\")),mdx(\"p\",null,\"This step is only necessary because the sandbox is using its own server. Normally, if you are using the Docker Public Hub this step isn't necessary.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Pull the test image.\"),mdx(\"li\",{parentName:\"ol\"},\"/ # docker pull sandboxregistry:5000/test/trusttest\"),mdx(\"li\",{parentName:\"ol\"},\"Using default tag: latest\"),mdx(\"li\",{parentName:\"ol\"},\"Error: remote trust data does not exist for sandboxregistry:5000/test/trusttest: notaryserver:4443 does not have trust data for sandboxregistry:5000/test/trusttest\")),mdx(\"p\",null,\"You see an error, because this content doesn't exist on the\\xA0notaryserver\\xA0yet.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Push and sign the trusted image.\"),mdx(\"li\",{parentName:\"ol\"},\"/ # docker push sandboxregistry:5000/test/trusttest:latest\"),mdx(\"li\",{parentName:\"ol\"},\"The push refers to a repository \",\"[sandboxregistry:5000/test/trusttest]\"),mdx(\"li\",{parentName:\"ol\"},\"5f70bf18a086: Pushed\"),mdx(\"li\",{parentName:\"ol\"},\"c22f7bc058a9: Pushed\"),mdx(\"li\",{parentName:\"ol\"},\"latest: digest: sha256:ebf59c538accdf160ef435f1a19938ab8c0d6bd96aef8d4ddd1b379edf15a926 size: 734\"),mdx(\"li\",{parentName:\"ol\"},\"Signing and pushing trust metadata\"),mdx(\"li\",{parentName:\"ol\"},\"You are about to create a new root signing key passphrase. This passphrase\"),mdx(\"li\",{parentName:\"ol\"},\"will be used to protect the most sensitive key in your signing system. Please\"),mdx(\"li\",{parentName:\"ol\"},\"choose a long, complex passphrase and be careful to keep the password and the\"),mdx(\"li\",{parentName:\"ol\"},\"key file itself secure and backed up. It is highly recommended that you use a\"),mdx(\"li\",{parentName:\"ol\"},\"password manager to generate the passphrase and keep it safe. There will be no\"),mdx(\"li\",{parentName:\"ol\"},\"way to recover this key. You can find the key in your config directory.\"),mdx(\"li\",{parentName:\"ol\"},\"Enter passphrase for new root key with ID 27ec255:\"),mdx(\"li\",{parentName:\"ol\"},\"Repeat passphrase for new root key with ID 27ec255:\"),mdx(\"li\",{parentName:\"ol\"},\"Enter passphrase for new repository key with ID 58233f9 (sandboxregistry:5000/test/trusttest):\"),mdx(\"li\",{parentName:\"ol\"},\"Repeat passphrase for new repository key with ID 58233f9 (sandboxregistry:5000/test/trusttest):\"),mdx(\"li\",{parentName:\"ol\"},\"Finished initializing \\\"sandboxregistry:5000/test/trusttest\\\"\"),mdx(\"li\",{parentName:\"ol\"},\"Successfully signed \\\"sandboxregistry:5000/test/trusttest\\\":latest\")),mdx(\"p\",null,\"Because you are pushing this repository for the first time, Docker creates new root and repository keys and asks you for passphrases with which to encrypt them. If you push again after this, it only asks you for repository passphrase so it can decrypt the key and sign again.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Try pulling the image you just pushed:\"),mdx(\"li\",{parentName:\"ol\"},\"/ # docker pull sandboxregistry:5000/test/trusttest\"),mdx(\"li\",{parentName:\"ol\"},\"Using default tag: latest\"),mdx(\"li\",{parentName:\"ol\"},\"Pull (1 of 1): sandboxregistry:5000/test/trusttest:latest\\\\@sha256:ebf59c538accdf160ef435f1a19938ab8c0d6bd96aef8d4ddd1b379edf15a926\"),mdx(\"li\",{parentName:\"ol\"},\"sha256:ebf59c538accdf160ef435f1a19938ab8c0d6bd96aef8d4ddd1b379edf15a926: Pulling from test/trusttest\"),mdx(\"li\",{parentName:\"ol\"},\"Digest: sha256:ebf59c538accdf160ef435f1a19938ab8c0d6bd96aef8d4ddd1b379edf15a926\"),mdx(\"li\",{parentName:\"ol\"},\"Status: Downloaded newer image for sandboxregistry:5000/test/trusttest\\\\@sha256:ebf59c538accdf160ef435f1a19938ab8c0d6bd96aef8d4ddd1b379edf15a926\"),mdx(\"li\",{parentName:\"ol\"},\"Tagging sandboxregistry:5000/test/trusttest\\\\@sha256:ebf59c538accdf160ef435f1a19938ab8c0d6bd96aef8d4ddd1b379edf15a926 as sandboxregistry:5000/test/trusttest:latest\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Test with malicious images\")),mdx(\"p\",null,\"What happens when data is corrupted and you try to pull it when trust is enabled? In this section, you go into the\\xA0sandboxregistry\\xA0and tamper with some data. Then, you try and pull it.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Leave the\\xA0trustsandbox\\xA0shell and container running.\"),mdx(\"li\",{parentName:\"ol\"},\"Open a new interactive terminal from your host, and obtain a shell into thesandboxregistry\\xA0container.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker container exec -it sandboxregistry bash\"),mdx(\"li\",{parentName:\"ol\"},\"root\\\\@65084fc6f047:/#\"),mdx(\"li\",{parentName:\"ol\"},\"List the layers for the\\xA0test/trusttest\\xA0image you pushed:\"),mdx(\"li\",{parentName:\"ol\"},\"root\\\\@65084fc6f047:/# ls -l /var/lib/registry/docker/registry/v2/repositories/test/trusttest/_layers/sha256\"),mdx(\"li\",{parentName:\"ol\"},\"total 12\"),mdx(\"li\",{parentName:\"ol\"},\"drwxr-xr-x 2 root root 4096 Jun 10 17:26 a3ed95caeb02ffe68cdd9fd84406680ae93d633cb16422d00e8a7c22955b46d4\"),mdx(\"li\",{parentName:\"ol\"},\"drwxr-xr-x 2 root root 4096 Jun 10 17:26 aac0c133338db2b18ff054943cee3267fe50c75cdee969aed88b1992539ed042\"),mdx(\"li\",{parentName:\"ol\"},\"drwxr-xr-x 2 root root 4096 Jun 10 17:26 cc7629d1331a7362b5e5126beb5bf15ca0bf67eb41eab994c719a45de53255cd\"),mdx(\"li\",{parentName:\"ol\"},\"Change into the registry storage for one of those layers (this is in a different directory):\"),mdx(\"li\",{parentName:\"ol\"},\"root\\\\@65084fc6f047:/# cd /var/lib/registry/docker/registry/v2/blobs/sha256/aa/aac0c133338db2b18ff054943cee3267fe50c75cdee969aed88b1992539ed042\"),mdx(\"li\",{parentName:\"ol\"},\"Add malicious data to one of the\\xA0trusttest\\xA0layers:\"),mdx(\"li\",{parentName:\"ol\"},\"root\\\\@65084fc6f047:/# echo \\\"Malicious data\\\" > data\"),mdx(\"li\",{parentName:\"ol\"},\"Go back to your\\xA0trustsandbox\\xA0terminal.\"),mdx(\"li\",{parentName:\"ol\"},\"List the\\xA0trusttest\\xA0image.\"),mdx(\"li\",{parentName:\"ol\"},\"/ # docker image ls | grep trusttest\"),mdx(\"li\",{parentName:\"ol\"},\"REPOSITORY TAG IMAGE ID CREATED SIZE\"),mdx(\"li\",{parentName:\"ol\"},\"docker/trusttest latest cc7629d1331a 11 months ago 5.025 MB\"),mdx(\"li\",{parentName:\"ol\"},\"sandboxregistry:5000/test/trusttest latest cc7629d1331a 11 months ago 5.025 MB\"),mdx(\"li\",{parentName:\"ol\"},\"sandboxregistry:5000/test/trusttest \",mdx(\"inlineCode\",{parentName:\"li\"},\"<none>\"),\" cc7629d1331a 11 months ago 5.025 MB\"),mdx(\"li\",{parentName:\"ol\"},\"Remove the\\xA0trusttest:latest\\xA0image from our local cache.\"),mdx(\"li\",{parentName:\"ol\"},\"/ # docker image rm -f cc7629d1331a\"),mdx(\"li\",{parentName:\"ol\"},\"Untagged: docker/trusttest:latest\"),mdx(\"li\",{parentName:\"ol\"},\"Untagged: sandboxregistry:5000/test/trusttest:latest\"),mdx(\"li\",{parentName:\"ol\"},\"Untagged: sandboxregistry:5000/test/trusttest\\\\@sha256:ebf59c538accdf160ef435f1a19938ab8c0d6bd96aef8d4ddd1b379edf15a926\"),mdx(\"li\",{parentName:\"ol\"},\"Deleted: sha256:cc7629d1331a7362b5e5126beb5bf15ca0bf67eb41eab994c719a45de53255cd\"),mdx(\"li\",{parentName:\"ol\"},\"Deleted: sha256:2a1f6535dc6816ffadcdbe20590045e6cbf048d63fd4cc753a684c9bc01abeea\"),mdx(\"li\",{parentName:\"ol\"},\"Deleted: sha256:c22f7bc058a9a8ffeb32989b5d3338787e73855bf224af7aa162823da015d44c\")),mdx(\"p\",null,\"Docker does not re-download images that it already has cached, but we want Docker to attempt to download the tampered image from the registry and reject it because it is invalid.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Pull the image again. This downloads the image from the registry, because we don't have it cached.\"),mdx(\"li\",{parentName:\"ol\"},\"/ # docker pull sandboxregistry:5000/test/trusttest\"),mdx(\"li\",{parentName:\"ol\"},\"Using default tag: latest\"),mdx(\"li\",{parentName:\"ol\"},\"Pull (1 of 1): sandboxregistry:5000/test/trusttest:latest\\\\@sha256:35d5bc26fd358da8320c137784fe590d8fcf9417263ef261653e8e1c7f15672e\"),mdx(\"li\",{parentName:\"ol\"},\"sha256:35d5bc26fd358da8320c137784fe590d8fcf9417263ef261653e8e1c7f15672e: Pulling from test/trusttest\"),mdx(\"li\",{parentName:\"ol\"},\"aac0c133338d: Retrying in 5 seconds\"),mdx(\"li\",{parentName:\"ol\"},\"a3ed95caeb02: Download complete\"),mdx(\"li\",{parentName:\"ol\"},\"error pulling image configuration: unexpected EOF\")),mdx(\"p\",null,\"The pull did not complete because the trust system couldn't verify the image.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"More play in the sandbox\")),mdx(\"p\",null,\"Now, you have a full Docker content trust sandbox on your local system, feel free to play with it and see how it behaves. If you find any security issues with Docker, feel free to send us an email at\\xA0\",mdx(\"inlineCode\",{parentName:\"p\"},\"<security@docker.com>\"),\".\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Cleaning up your sandbox\")),mdx(\"p\",null,\"When you are done, and want to clean up all the services you've started and any anonymous volumes that have been created, just run the following command in the directory where you've created your Docker Compose file:\"),mdx(\"p\",null,\"$ docker-compose down -v\"),mdx(\"h4\",null,\"Antivirus software and Docker\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA01 minute\")),mdx(\"p\",null,\"When antivirus software scans files used by Docker, these files may be locked in a way that causes Docker commands to hang.\"),mdx(\"p\",null,\"One way to reduce these problems is to add the Docker data directory (/var/lib/docker\\xA0on Linux or\\xA0$Env:ProgramData\\xA0on Windows Server) to the antivirus's exclusion list. However, this comes with the trade-off that viruses or malware in Docker images, writable layers of containers, or volumes are not detected. If you do choose to exclude Docker's data directory from background virus scanning, you may want to schedule a recurring task that stops Docker, scans the data directory, and restarts Docker.\"),mdx(\"h4\",null,\"AppArmor security profiles for Docker\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA06 minutes\")),mdx(\"p\",null,\"AppArmor (Application Armor) is a Linux security module that protects an operating system and its applications from security threats. To use it, a system administrator associates an AppArmor security profile with each program. Docker expects to find an AppArmor policy loaded and enforced.\"),mdx(\"p\",null,\"Docker automatically generates and loads a default profile for containers nameddocker-default. On Docker versions\\xA01.13.0\\xA0and later, the Docker binary generates this profile in\\xA0tmpfs\\xA0and then loads it into the kernel. On Docker versions earlier than\\xA01.13.0, this profile is generated in\\xA0/etc/apparmor.d/docker\\xA0instead.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": This profile is used on containers,\\xA0not\\xA0on the Docker Daemon.\"),mdx(\"p\",null,\"A profile for the Docker Engine daemon exists but it is not currently installed with the\\xA0debpackages. If you are interested in the source for the daemon profile, it is located in\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/moby/moby/tree/master/contrib/apparmor\"}),\"contrib/apparmor\"),\"\\xA0in the Docker Engine source repository.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Understand the policies\")),mdx(\"p\",null,\"The\\xA0docker-default\\xA0profile is the default for running containers. It is moderately protective while providing wide application compatibility. The profile is generated from the following\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/moby/moby/blob/master/profiles/apparmor/template.go\"}),\"template\"),\".\"),mdx(\"p\",null,\"When you run a container, it uses the\\xA0docker-default\\xA0policy unless you override it with the\\xA0security-opt\\xA0option. For example, the following explicitly specifies the default policy:\"),mdx(\"p\",null,\"$ docker run --rm -it --security-opt apparmor=docker-default hello-world\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Load and unload profiles\")),mdx(\"p\",null,\"To load a new profile into AppArmor for use with containers:\"),mdx(\"p\",null,\"$ apparmor_parser -r -W /path/to/your_profile\"),mdx(\"p\",null,\"Then, run the custom profile with\\xA0--security-opt\\xA0like so:\"),mdx(\"p\",null,\"$ docker run --rm -it --security-opt apparmor=your_profile hello-world\"),mdx(\"p\",null,\"To unload a profile from AppArmor:\"),mdx(\"h1\",null,\"stop apparmor\"),mdx(\"p\",null,\"$ /etc/init.d/apparmor stop\"),mdx(\"h1\",null,\"unload the profile\"),mdx(\"p\",null,\"$ apparmor_parser -R /path/to/profile\"),mdx(\"h1\",null,\"start apparmor\"),mdx(\"p\",null,\"$ /etc/init.d/apparmor start\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Resources for writing profiles\")),mdx(\"p\",null,\"The syntax for file globbing in AppArmor is a bit different than some other globbing implementations. It is highly suggested you take a look at some of the below resources with regard to AppArmor profile syntax.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://gitlab.com/apparmor/apparmor/wikis/QuickProfileLanguage\"}),\"Quick Profile Language\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://gitlab.com/apparmor/apparmor/wikis/AppArmor_Core_Policy_Reference#AppArmor_globbing_syntax\"}),\"Globbing Syntax\"))),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Nginx example profile\")),mdx(\"p\",null,\"In this example, you create a custom AppArmor profile for Nginx. Below is the custom profile.\"),mdx(\"p\",null,\"#include \",mdx(\"inlineCode\",{parentName:\"p\"},\"<tunables/global>\")),mdx(\"p\",null,\"profile docker-nginx flags=(attach_disconnected,mediate_deleted) {\"),mdx(\"p\",null,\"#include \",mdx(\"inlineCode\",{parentName:\"p\"},\"<abstractions/base>\")),mdx(\"p\",null,\"network inet tcp,\"),mdx(\"p\",null,\"network inet udp,\"),mdx(\"p\",null,\"network inet icmp,\"),mdx(\"p\",null,\"deny network raw,\"),mdx(\"p\",null,\"deny network packet,\"),mdx(\"p\",null,\"file,\"),mdx(\"p\",null,\"umount,\"),mdx(\"p\",null,\"deny /bin/** wl,\"),mdx(\"p\",null,\"deny /boot/** wl,\"),mdx(\"p\",null,\"deny /dev/** wl,\"),mdx(\"p\",null,\"deny /etc/** wl,\"),mdx(\"p\",null,\"deny /home/** wl,\"),mdx(\"p\",null,\"deny /lib/** wl,\"),mdx(\"p\",null,\"deny /lib64/** wl,\"),mdx(\"p\",null,\"deny /media/** wl,\"),mdx(\"p\",null,\"deny /mnt/** wl,\"),mdx(\"p\",null,\"deny /opt/** wl,\"),mdx(\"p\",null,\"deny /proc/** wl,\"),mdx(\"p\",null,\"deny /root/** wl,\"),mdx(\"p\",null,\"deny /sbin/** wl,\"),mdx(\"p\",null,\"deny /srv/** wl,\"),mdx(\"p\",null,\"deny /tmp/** wl,\"),mdx(\"p\",null,\"deny /sys/** wl,\"),mdx(\"p\",null,\"deny /usr/** wl,\"),mdx(\"p\",null,\"audit /** w,\"),mdx(\"p\",null,\"/var/run/nginx.pid w,\"),mdx(\"p\",null,\"/usr/sbin/nginx ix,\"),mdx(\"p\",null,\"deny /bin/dash mrwklx,\"),mdx(\"p\",null,\"deny /bin/sh mrwklx,\"),mdx(\"p\",null,\"deny /usr/bin/top mrwklx,\"),mdx(\"p\",null,\"capability chown,\"),mdx(\"p\",null,\"capability dac_override,\"),mdx(\"p\",null,\"capability setuid,\"),mdx(\"p\",null,\"capability setgid,\"),mdx(\"p\",null,\"capability net_bind_service,\"),mdx(\"p\",null,\"deny @{PROC}/* w, # deny write for all files directly in /proc (not in a subdir)\"),mdx(\"h1\",null,\"deny write to files not in /proc/\",mdx(\"inlineCode\",{parentName:\"h1\"},\"<number>\"),\"/\",mdx(\"strong\",{parentName:\"h1\"},\" or /proc/sys/\")),mdx(\"p\",null,\"deny @{PROC}/{\",\"[\\\\^1-9]\",\",\",\"[\\\\^1-9][\\\\^0-9]\",\",\",\"[\\\\^1-9s][\\\\^0-9y]\",\"[\\\\^0-9s]\",\",\",\"[\\\\^1-9][\\\\^0-9]\",\"[\\\\^0-9][\\\\^0-9]\",\"*}/** w,\"),mdx(\"p\",null,\"deny @{PROC}/sys/\",\"[\\\\^k]\",\"*\",mdx(\"em\",{parentName:\"p\"},\" w, # deny /proc/sys except /proc/sys/k\"),\" (effectively /proc/sys/kernel)\"),mdx(\"p\",null,\"deny @{PROC}/sys/kernel/{?,??,\",\"[\\\\^s][\\\\^h]\",\"[\\\\^m]\",\"*\",mdx(\"em\",{parentName:\"p\"},\"} w, # deny everything except shm\"),\" in /proc/sys/kernel/\"),mdx(\"p\",null,\"deny @{PROC}/sysrq-trigger rwklx,\"),mdx(\"p\",null,\"deny @{PROC}/mem rwklx,\"),mdx(\"p\",null,\"deny @{PROC}/kmem rwklx,\"),mdx(\"p\",null,\"deny @{PROC}/kcore rwklx,\"),mdx(\"p\",null,\"deny mount,\"),mdx(\"p\",null,\"deny /sys/\",\"[\\\\^f]\",\"*/** wklx,\"),mdx(\"p\",null,\"deny /sys/f\",\"[\\\\^s]\",\"*/** wklx,\"),mdx(\"p\",null,\"deny /sys/fs/\",\"[\\\\^c]\",\"*/** wklx,\"),mdx(\"p\",null,\"deny /sys/fs/c\",\"[\\\\^g]\",\"*/** wklx,\"),mdx(\"p\",null,\"deny /sys/fs/cg\",\"[\\\\^r]\",\"*/** wklx,\"),mdx(\"p\",null,\"deny /sys/firmware/** rwklx,\"),mdx(\"p\",null,\"deny /sys/kernel/security/** rwklx,\"),mdx(\"p\",null,\"}\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Save the custom profile to disk in the\\xA0/etc/apparmor.d/containers/docker-nginx\\xA0file.\")),mdx(\"p\",null,\"The file path in this example is not a requirement. In production, you could use another.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Load the profile.\"),mdx(\"li\",{parentName:\"ol\"},\"$ sudo apparmor_parser -r -W /etc/apparmor.d/containers/docker-nginx\"),mdx(\"li\",{parentName:\"ol\"},\"Run a container with the profile.\")),mdx(\"p\",null,\"To run nginx in detached mode:\"),mdx(\"p\",null,\"$ docker run --security-opt \\\"apparmor=docker-nginx\\\" \\\\\"),mdx(\"p\",null,\"-p 80:80 -d --name apparmor-nginx nginx\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Exec into the running container.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker container exec -it apparmor-nginx bash\"),mdx(\"li\",{parentName:\"ol\"},\"Try some operations to test the profile.\"),mdx(\"li\",{parentName:\"ol\"},\"root\\\\@6da5a2a930b9:\",\"~\",\"# ping 8.8.8.8\"),mdx(\"li\",{parentName:\"ol\"},\"ping: Lacking privilege for raw socket.\"),mdx(\"li\",{parentName:\"ol\"},\"root\\\\@6da5a2a930b9:/# top\"),mdx(\"li\",{parentName:\"ol\"},\"bash: /usr/bin/top: Permission denied\"),mdx(\"li\",{parentName:\"ol\"},\"root\\\\@6da5a2a930b9:\",\"~\",\"# touch \",\"~\",\"/thing\"),mdx(\"li\",{parentName:\"ol\"},\"touch: cannot touch \\\\'thing\\\\': Permission denied\"),mdx(\"li\",{parentName:\"ol\"},\"root\\\\@6da5a2a930b9:/# sh\"),mdx(\"li\",{parentName:\"ol\"},\"bash: /bin/sh: Permission denied\"),mdx(\"li\",{parentName:\"ol\"},\"root\\\\@6da5a2a930b9:/# dash\"),mdx(\"li\",{parentName:\"ol\"},\"bash: /bin/dash: Permission denied\")),mdx(\"p\",null,\"Congrats! You just deployed a container secured with a custom apparmor profile!\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Debug AppArmor\")),mdx(\"p\",null,\"You can use\\xA0dmesg\\xA0to debug problems and\\xA0aa-status\\xA0check the loaded profiles.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Use dmesg\")),mdx(\"p\",null,\"Here are some helpful tips for debugging any problems you might be facing with regard to AppArmor.\"),mdx(\"p\",null,\"AppArmor sends quite verbose messaging to\\xA0dmesg. Usually an AppArmor line looks like the following:\"),mdx(\"p\",null,\"[ 5442.864673]\",\" audit: type=1400 audit(1453830992.845:37): apparmor=\\\"ALLOWED\\\" operation=\\\"open\\\" profile=\\\"/usr/bin/docker\\\" name=\\\"/home/jessie/docker/man/man1/docker-attach.1\\\" pid=10923 comm=\\\"docker\\\" requested_mask=\\\"r\\\" denied_mask=\\\"r\\\" fsuid=1000 ouid=0\"),mdx(\"p\",null,\"In the above example, you can see\\xA0profile=/usr/bin/docker. This means the user has the\\xA0docker-engine\\xA0(Docker Engine Daemon) profile loaded.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": On version of Ubuntu > 14.04 this is all fine and well, but Trusty users might run into some issues when trying to\\xA0docker container exec.\"),mdx(\"p\",null,\"Look at another log line:\"),mdx(\"p\",null,\"[ 3256.689120]\",\" type=1400 audit(1405454041.341:73): apparmor=\\\"DENIED\\\" operation=\\\"ptrace\\\" profile=\\\"docker-default\\\" pid=17651 comm=\\\"docker\\\" requested_mask=\\\"receive\\\" denied_mask=\\\"receive\\\"\"),mdx(\"p\",null,\"This time the profile is\\xA0docker-default, which is run on containers by default unless in\\xA0privileged\\xA0mode. This line shows that apparmor has denied\\xA0ptrace\\xA0in the container. This is exactly as expected.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Use aa-status\")),mdx(\"p\",null,\"If you need to check which profiles are loaded, you can use\\xA0aa-status. The output looks like:\"),mdx(\"p\",null,\"$ sudo aa-status\"),mdx(\"p\",null,\"apparmor module is loaded.\"),mdx(\"p\",null,\"14 profiles are loaded.\"),mdx(\"p\",null,\"1 profiles are in enforce mode.\"),mdx(\"p\",null,\"docker-default\"),mdx(\"p\",null,\"13 profiles are in complain mode.\"),mdx(\"p\",null,\"/usr/bin/docker\"),mdx(\"p\",null,\"/usr/bin/docker///bin/cat\"),mdx(\"p\",null,\"/usr/bin/docker///bin/ps\"),mdx(\"p\",null,\"/usr/bin/docker///sbin/apparmor_parser\"),mdx(\"p\",null,\"/usr/bin/docker///sbin/auplink\"),mdx(\"p\",null,\"/usr/bin/docker///sbin/blkid\"),mdx(\"p\",null,\"/usr/bin/docker///sbin/iptables\"),mdx(\"p\",null,\"/usr/bin/docker///sbin/mke2fs\"),mdx(\"p\",null,\"/usr/bin/docker///sbin/modprobe\"),mdx(\"p\",null,\"/usr/bin/docker///sbin/tune2fs\"),mdx(\"p\",null,\"/usr/bin/docker///sbin/xtables-multi\"),mdx(\"p\",null,\"/usr/bin/docker///sbin/zfs\"),mdx(\"p\",null,\"/usr/bin/docker///usr/bin/xz\"),mdx(\"p\",null,\"38 processes have profiles defined.\"),mdx(\"p\",null,\"37 processes are in enforce mode.\"),mdx(\"p\",null,\"docker-default (6044)\"),mdx(\"p\",null,\"...\"),mdx(\"p\",null,\"docker-default (31899)\"),mdx(\"p\",null,\"1 processes are in complain mode.\"),mdx(\"p\",null,\"/usr/bin/docker (29756)\"),mdx(\"p\",null,\"0 processes are unconfined but have a profile defined.\"),mdx(\"p\",null,\"The above output shows that the\\xA0docker-default\\xA0profile running on various container PIDs is in\\xA0enforce\\xA0mode. This means AppArmor is actively blocking and auditing in\\xA0dmesg\\xA0anything outside the bounds of the\\xA0docker-default\\xA0profile.\"),mdx(\"p\",null,\"The output above also shows the\\xA0/usr/bin/docker\\xA0(Docker Engine daemon) profile is running in\\xA0complain\\xA0mode. This means AppArmor\\xA0only\\xA0logs to\\xA0dmesg\\xA0activity outside the bounds of the profile. (Except in the case of Ubuntu Trusty, where some interesting behaviors are enforced.)\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Contribute Docker's AppArmor code\")),mdx(\"p\",null,\"Advanced users and package managers can find a profile for\\xA0/usr/bin/docker\\xA0(Docker Engine Daemon) underneath\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/moby/moby/tree/master/contrib/apparmor\"}),\"contrib/apparmor\"),\"\\xA0in the Docker Engine source repository.\"),mdx(\"p\",null,\"The\\xA0docker-default\\xA0profile for containers lives in\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/moby/moby/tree/master/profiles/apparmor\"}),\"profiles/apparmor\"),\".\"),mdx(\"h4\",null,\"Seccomp security profiles for Docker\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA07 minutes\")),mdx(\"p\",null,\"Secure computing mode (seccomp) is a Linux kernel feature. You can use it to restrict the actions available within the container. The\\xA0seccomp()\\xA0system call operates on the seccomp state of the calling process. You can use this feature to restrict your application's access.\"),mdx(\"p\",null,\"This feature is available only if Docker has been built with\\xA0seccomp\\xA0and the kernel is configured with\\xA0CONFIG_SECCOMP\\xA0enabled. To check if your kernel supports\\xA0seccomp:\"),mdx(\"p\",null,\"$ cat /boot/config-\",mdx(\"inlineCode\",{parentName:\"p\"},\"uname -r\"),\" | grep CONFIG_SECCOMP=\"),mdx(\"p\",null,\"CONFIG_SECCOMP=y\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\":\\xA0seccomp\\xA0profiles require seccomp 2.2.1 which is not available on Ubuntu 14.04, Debian Wheezy, or Debian Jessie. To use\\xA0seccomp\\xA0on these distributions, you must download the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/installation/linux/docker-ce/binaries/\"}),\"latest static Linux binaries\"),\"\\xA0(rather than packages).\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Pass a profile for a container\")),mdx(\"p\",null,\"The default\\xA0seccomp\\xA0profile provides a sane default for running containers with seccomp and disables around 44 system calls out of 300+. It is moderately protective while providing wide application compatibility. The default Docker profile can be found\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/moby/moby/blob/master/profiles/seccomp/default.json\"}),\"here\"),\").\"),mdx(\"p\",null,\"In effect, the profile is a whitelist which denies access to system calls by default, then whitelists specific system calls. The profile works by defining a\\xA0defaultAction\\xA0of\\xA0SCMP_ACT_ERRNO\\xA0and overriding that action only for specific system calls. The effect of\\xA0SCMP_ACT_ERRNO\\xA0is to cause a\\xA0Permission Denied\\xA0error. Next, the profile defines a specific list of system calls which are fully allowed, because their\\xA0action\\xA0is overridden to be\\xA0SCMP_ACT_ALLOW. Finally, some specific rules are for individual system calls such as\\xA0personality,\\xA0socket,\\xA0socketcall, and others, to allow variants of those system calls with specific arguments.\"),mdx(\"p\",null,\"seccomp\\xA0is instrumental for running Docker containers with least privilege. It is not recommended to change the default\\xA0seccomp\\xA0profile.\"),mdx(\"p\",null,\"When you run a container, it uses the default profile unless you override it with the\\xA0--security-opt\\xA0option. For example, the following explicitly specifies a policy:\"),mdx(\"p\",null,\"$ docker run --rm \\\\\"),mdx(\"p\",null,\"-it \\\\\"),mdx(\"p\",null,\"--security-opt seccomp=/path/to/seccomp/profile.json \\\\\"),mdx(\"p\",null,\"hello-world\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Significant syscalls blocked by the default profile\")),mdx(\"p\",null,\"Docker's default seccomp profile is a whitelist which specifies the calls that are allowed. The table below lists the significant (but not all) syscalls that are effectively blocked because they are not on the whitelist. The table includes the reason each syscall is blocked rather than white-listed.\"),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Syscall\"),\"          \",mdx(\"strong\",{parentName:\"p\"},\"Description\")),mdx(\"hr\",null),mdx(\"p\",null,\"  acct                 Accounting syscall which could let containers disable their own resource limits or process accounting. Also gated by\\xA0CAP\",mdx(\"em\",{parentName:\"p\"},\"SYS_PACCT.\\nadd_key              Prevent containers from using the kernel keyring, which is not namespaced.\\nadjtimex             Similar to\\xA0clock_settime\\xA0and\\xA0settimeofday, time/date is not namespaced. Also gated by\\xA0CAP_SYS_TIME.\\nbpf                  Deny loading potentially persistent bpf programs into kernel, already gated by\\xA0CAP_SYS_ADMIN.\\nclock_adjtime        Time/date is not namespaced. Also gated by\\xA0CAP_SYS_TIME.\\nclock_settime        Time/date is not namespaced. Also gated by\\xA0CAP_SYS_TIME.\\nclone                Deny cloning new namespaces. Also gated by\\xA0CAP_SYS_ADMIN\\xA0for CLONE\"),\"* flags, except\\xA0CLONE_USERNS.\\ncreate_module        Deny manipulation and functions on kernel modules. Obsolete. Also gated by\\xA0CAP_SYS_MODULE.\\ndelete_module        Deny manipulation and functions on kernel modules. Also gated by\\xA0CAP_SYS_MODULE.\\nfinit_module         Deny manipulation and functions on kernel modules. Also gated by\\xA0CAP_SYS_MODULE.\\nget_kernel_syms      Deny retrieval of exported kernel and module symbols. Obsolete.\\nget_mempolicy        Syscall that modifies kernel memory and NUMA settings. Already gated by\\xA0CAP_SYS_NICE.\\ninit_module          Deny manipulation and functions on kernel modules. Also gated by\\xA0CAP_SYS_MODULE.\\nioperm               Prevent containers from modifying kernel I/O privilege levels. Already gated by\\xA0CAP_SYS_RAWIO.\\niopl                 Prevent containers from modifying kernel I/O privilege levels. Already gated by\\xA0CAP_SYS_RAWIO.\\nkcmp                 Restrict process inspection capabilities, already blocked by dropping\\xA0CAP_PTRACE.\\nkexec_file_load      Sister syscall of\\xA0kexec_load\\xA0that does the same thing, slightly different arguments. Also gated by\\xA0CAP_SYS_BOOT.\\nkexec_load           Deny loading a new kernel for later execution. Also gated by\\xA0CAP_SYS_BOOT.\\nkeyctl               Prevent containers from using the kernel keyring, which is not namespaced.\\nlookup_dcookie       Tracing/profiling syscall, which could leak a lot of information on the host. Also gated by\\xA0CAP_SYS_ADMIN.\\nmbind                Syscall that modifies kernel memory and NUMA settings. Already gated by\\xA0CAP_SYS_NICE.\\nmount                Deny mounting, already gated by\\xA0CAP_SYS_ADMIN.\\nmove_pages           Syscall that modifies kernel memory and NUMA settings.\\nname_to_handle_at    Sister syscall to\\xA0open_by_handle_at. Already gated by\\xA0CAP_SYS_NICE.\\nnfsservctl           Deny interaction with the kernel nfs daemon. Obsolete since Linux 3.1.\\nopen_by_handle_at    Cause of an old container breakout. Also gated by\\xA0CAP_DAC_READ_SEARCH.\\nperf_event_open      Tracing/profiling syscall, which could leak a lot of information on the host.\\npersonality          Prevent container from enabling BSD emulation. Not inherently dangerous, but poorly tested, potential for a lot of kernel vulns.\\npivot_root           Deny\\xA0pivot_root, should be privileged operation.\\nprocess_vm_readv     Restrict process inspection capabilities, already blocked by dropping\\xA0CAP_PTRACE.\\nprocess_vm_writev    Restrict process inspection capabilities, already blocked by dropping\\xA0CAP_PTRACE.\\nptrace               Tracing/profiling syscall, which could leak a lot of information on the host. Already blocked by dropping\\xA0CAP_PTRACE.\\nquery_module         Deny manipulation and functions on kernel modules. Obsolete.\\nquotactl             Quota syscall which could let containers disable their own resource limits or process accounting. Also gated by\\xA0CAP_SYS_ADMIN.\\nreboot               Don't let containers reboot the host. Also gated by\\xA0CAP_SYS_BOOT.\\nrequest_key          Prevent containers from using the kernel keyring, which is not namespaced.\\nset_mempolicy        Syscall that modifies kernel memory and NUMA settings. Already gated by\\xA0CAP_SYS_NICE.\\nsetns                Deny associating a thread with a namespace. Also gated by\\xA0CAP_SYS_ADMIN.\\nsettimeofday         Time/date is not namespaced. Also gated by\\xA0CAP_SYS_TIME.\\nsocket,\\xA0socketcall   Used to send or receive packets and for other socket operations. All\\xA0socket\\xA0and\\xA0socketcall\\xA0calls are blocked except communication domains\\xA0AF_UNIX,\\xA0AF_INET,\\xA0AF_INET6,\\xA0AF_NETLINK, and\\xA0AF_PACKET.\\nstime                Time/date is not namespaced. Also gated by\\xA0CAP_SYS_TIME.\\nswapon               Deny start/stop swapping to file/device. Also gated by\\xA0CAP_SYS_ADMIN.\\nswapoff              Deny start/stop swapping to file/device. Also gated by\\xA0CAP_SYS_ADMIN.\\nsysfs                Obsolete syscall.\\n_sysctl             Obsolete, replaced by /proc/sys.\\numount               Should be a privileged operation. Also gated by\\xA0CAP_SYS_ADMIN.\\numount2              Should be a privileged operation. Also gated by\\xA0CAP_SYS_ADMIN.\\nunshare              Deny cloning new namespaces for processes. Also gated by\\xA0CAP_SYS_ADMIN, with the exception of\\xA0unshare --user.\\nuselib               Older syscall related to shared libraries, unused for a long time.\\nuserfaultfd          Userspace page fault handling, largely needed for process migration.\\nustat                Obsolete syscall.\\nvm86                 In kernel x86 real mode virtual machine. Also gated by\\xA0CAP_SYS_ADMIN.\\nvm86old              In kernel x86 real mode virtual machine. Also gated by\\xA0CAP_SYS_ADMIN.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Run without the default seccomp profile\")),mdx(\"p\",null,\"You can pass\\xA0unconfined\\xA0to run a container without the default seccomp profile.\"),mdx(\"p\",null,\"$ docker run --rm -it --security-opt seccomp=unconfined debian:jessie \\\\\"),mdx(\"p\",null,\"unshare --map-root-user --user sh -c whoami\"),mdx(\"h4\",null,\"Isolate containers with a user namespace\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA010 minutes\")),mdx(\"p\",null,\"Linux namespaces provide isolation for running processes, limiting their access to system resources without the running process being aware of the limitations. For more information on Linux namespaces, see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://www.linux.com/news/understanding-and-securing-linux-namespaces\"}),\"Linux namespaces\"),\".\"),mdx(\"p\",null,\"The best way to prevent privilege-escalation attacks from within a container is to configure your container's applications to run as unprivileged users. For containers whose processes must run as the\\xA0root\\xA0user within the container, you can re-map this user to a less-privileged user on the Docker host. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"About remapping and subordinate user and group IDs\")),mdx(\"p\",null,\"The remapping itself is handled by two files:\\xA0/etc/subuid\\xA0and\\xA0/etc/subgid. Each file works the same, but one is concerned with the user ID range, and the other with the group ID range. Consider the following entry in\\xA0/etc/subuid:\"),mdx(\"p\",null,\"testuser:231072:65536\"),mdx(\"p\",null,\"This means that\\xA0testuser\\xA0is assigned a subordinate user ID range of\\xA0231072\\xA0and the next 65536 integers in sequence. UID\\xA0231072\\xA0is mapped within the namespace (within the container, in this case) as UID\\xA00\\xA0(root). UID\\xA0231073\\xA0is mapped as UID\\xA01, and so forth. If a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, which does not even map to a real user. This means the process has no privileges on the host system at all.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Multiple ranges\")),mdx(\"p\",null,\"It is possible to assign multiple subordinate ranges for a given user or group by adding multiple non-overlapping mappings for the same user or group in the\\xA0/etc/subuid\\xA0or\\xA0/etc/subgid\\xA0file. In this case, Docker uses only the first five mappings, in accordance with the kernel's limitation of only five entries in\\xA0/proc/self/uid_map\\xA0and\\xA0/proc/self/gid_map.\"),mdx(\"p\",null,\"When you configure Docker to use the\\xA0userns-remap\\xA0feature, you can optionally specify an existing user and/or group, or you can specify\\xA0default. If you specify\\xA0default, a user and group\\xA0dockremap\\xA0is created and used for this purpose.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Warning\"),\": Some distributions, such as RHEL and CentOS 7.3, do not automatically add the new group to the\\xA0/etc/subuid\\xA0and\\xA0/etc/subgid\\xA0files. You are responsible for editing these files and assigning non-overlapping ranges, in this case. This step is covered in\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/security/userns-remap/#prerequisites\"}),\"Prerequisites\"),\".\"),mdx(\"p\",null,\"It is very important that the ranges not overlap, so that a process cannot gain access in a different namespace. On most Linux distributions, system utilities manage the ranges for you when you add or remove users.\"),mdx(\"p\",null,\"This re-mapping is transparent to the container, but introduces some configuration complexity in situations where the container needs access to resources on the Docker host, such as bind mounts into areas of the filesystem that the system user cannot write to. From a security standpoint, it is best to avoid these situations.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Prerequisites\")),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"The subordinate UID and GID ranges must be associated with an existing user, even though the association is an implementation detail. The user owns the namespaced storage directories under\\xA0/var/lib/docker/. If you don't want to use an existing user, Docker can create one for you and use that. If you want to use an existing username or user ID, it must already exist. Typically, this means that the relevant entries need to be in\\xA0/etc/passwd\\xA0and\\xA0/etc/group, but if you are using a different authentication back-end, this requirement may translate differently.\")),mdx(\"p\",null,\"To verify this, use the\\xA0id\\xA0command:\"),mdx(\"p\",null,\"$ id testuser\"),mdx(\"p\",null,\"uid=1001(testuser) gid=1001(testuser) groups=1001(testuser)\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"The way the namespace remapping is handled on the host is using two files,\\xA0/etc/subuidand\\xA0/etc/subgid. These files are typically managed automatically when you add or remove users or groups, but on a few distributions such as RHEL and CentOS 7.3, you may need to manage these files manually.\")),mdx(\"p\",null,\"Each file contains three fields: the username or ID of the user, followed by a beginning UID or GID (which is treated as UID or GID 0 within the namespace) and a maximum number of UIDs or GIDs available to the user. For instance, given the following entry:\"),mdx(\"p\",null,\"testuser:231072:65536\"),mdx(\"p\",null,\"This means that user-namespaced processes started by\\xA0testuser\\xA0are owned by host UID\\xA0231072\\xA0(which looks like UID\\xA00\\xA0inside the namespace) through 296608 (231072 + 65536). These ranges should not overlap, to ensure that namespaced processes cannot access each other's namespaces.\"),mdx(\"p\",null,\"After adding your user, check\\xA0/etc/subuid\\xA0and\\xA0/etc/subgid\\xA0to see if your user has an entry in each. If not, you need to add it, being careful to avoid overlap.\"),mdx(\"p\",null,\"If you want to use the\\xA0dockremap\\xA0user automatically created by Docker, check for the\\xA0dockremap\\xA0entry in these files\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"after\"),\"\\xA0configuring and restarting Docker.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"If there are any locations on the Docker host where the unprivileged user needs to write, adjust the permissions of those locations accordingly. This is also true if you want to use the\\xA0dockremap\\xA0user automatically created by Docker, but you can't modify the permissions until after configuring and restarting Docker.\"),mdx(\"li\",{parentName:\"ol\"},\"Enabling\\xA0userns-remap\\xA0effectively masks existing image and container layers, as well as other Docker objects within\\xA0/var/lib/docker/. This is because Docker needs to adjust the ownership of these resources and actually stores them in a subdirectory within\\xA0/var/lib/docker/. It is best to enable this feature on a new Docker installation rather than an existing one.\")),mdx(\"p\",null,\"Along the same lines, if you disable\\xA0userns-remap\\xA0you can't access any of the resources created while it was enabled.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Check the\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/security/userns-remap/#user-namespace-known-restrictions\"}),\"limitations\"),\"\\xA0on user namespaces to be sure your use case is possible.\")),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Enable userns-remap on the daemon\")),mdx(\"p\",null,\"You can start\\xA0dockerd\\xA0with the\\xA0--userns-remap\\xA0flag or follow this procedure to configure the daemon using the\\xA0daemon.json\\xA0configuration file. The\\xA0daemon.json\\xA0method is recommended. If you use the flag, use the following command as a model:\"),mdx(\"p\",null,\"$ dockerd --userns-remap=\\\"testuser:testuser\\\"\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Edit\\xA0/etc/docker/daemon.json. Assuming the file was previously empty, the following entry enables\\xA0userns-remap\\xA0using user and group called\\xA0testuser. You can address the user and group by ID or name. You only need to specify the group name or ID if it is different from the user name or ID. If you provide both the user and group name or ID, separate them by a colon (:) character. The following formats all work for the value, assuming the UID and GID of\\xA0testuser\\xA0are\\xA01001:\",mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},\"testuser\"),mdx(\"li\",{parentName:\"ul\"},\"testuser:testuser\"),mdx(\"li\",{parentName:\"ul\"},\"1001\"),mdx(\"li\",{parentName:\"ul\"},\"1001:1001\"),mdx(\"li\",{parentName:\"ul\"},\"testuser:1001\"),mdx(\"li\",{parentName:\"ul\"},\"1001:testuser\"))),mdx(\"li\",{parentName:\"ol\"},\"{\"),mdx(\"li\",{parentName:\"ol\"},\"\\\"userns-remap\\\": \\\"testuser\\\"\"),mdx(\"li\",{parentName:\"ol\"},\"}\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": To use the\\xA0dockremap\\xA0user and have Docker create it for you, set the value to\\xA0default\\xA0rather than\\xA0testuser.\"),mdx(\"p\",null,\"Save the file and restart Docker.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"If you are using the\\xA0dockremap\\xA0user, verify that Docker created it using the\\xA0id\\xA0command.\"),mdx(\"li\",{parentName:\"ol\"},\"$ id dockremap\"),mdx(\"li\",{parentName:\"ol\"},\"uid=112(dockremap) gid=116(dockremap) groups=116(dockremap)\")),mdx(\"p\",null,\"Verify that the entry has been added to\\xA0/etc/subuid\\xA0and\\xA0/etc/subgid:\"),mdx(\"p\",null,\"$ grep dockremap /etc/subuid\"),mdx(\"p\",null,\"dockremap:231072:65536\"),mdx(\"p\",null,\"$ grep dockremap /etc/subgid\"),mdx(\"p\",null,\"dockremap:231072:65536\"),mdx(\"p\",null,\"If these entries are not present, edit the files as the\\xA0root\\xA0user and assign a starting UID and GID that is the highest-assigned one plus the offset (in this case,\\xA065536). Be careful not to allow any overlap in the ranges.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Verify that previous images are not available using the\\xA0docker image ls\\xA0command. The output should be empty.\"),mdx(\"li\",{parentName:\"ol\"},\"Start a container from the\\xA0hello-world\\xA0image.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker run hello-world\"),mdx(\"li\",{parentName:\"ol\"},\"Verify that a namespaced directory exists within\\xA0/var/lib/docker/\\xA0named with the UID and GID of the namespaced user, owned by that UID and GID, and not group-or-world-readable. Some of the subdirectories are still owned by\\xA0root\\xA0and have different permissions.\"),mdx(\"li\",{parentName:\"ol\"},\"$ sudo ls -ld /var/lib/docker/231072.231072/\"),mdx(\"li\",{parentName:\"ol\"},\"drwx------ 11 231072 231072 11 Jun 21 21:19 /var/lib/docker/231072.231072/\"),mdx(\"li\",{parentName:\"ol\"},\"$ sudo ls -l /var/lib/docker/231072.231072/\"),mdx(\"li\",{parentName:\"ol\"},\"total 14\"),mdx(\"li\",{parentName:\"ol\"},\"drwx------ 5 231072 231072 5 Jun 21 21:19 aufs\"),mdx(\"li\",{parentName:\"ol\"},\"drwx------ 3 231072 231072 3 Jun 21 21:21 containers\"),mdx(\"li\",{parentName:\"ol\"},\"drwx------ 3 root root 3 Jun 21 21:19 image\"),mdx(\"li\",{parentName:\"ol\"},\"drwxr-x--- 3 root root 3 Jun 21 21:19 network\"),mdx(\"li\",{parentName:\"ol\"},\"drwx------ 4 root root 4 Jun 21 21:19 plugins\"),mdx(\"li\",{parentName:\"ol\"},\"drwx------ 2 root root 2 Jun 21 21:19 swarm\"),mdx(\"li\",{parentName:\"ol\"},\"drwx------ 2 231072 231072 2 Jun 21 21:21 tmp\"),mdx(\"li\",{parentName:\"ol\"},\"drwx------ 2 root root 2 Jun 21 21:19 trust\"),mdx(\"li\",{parentName:\"ol\"},\"drwx------ 2 231072 231072 3 Jun 21 21:19 volumes\")),mdx(\"p\",null,\"Your directory listing may have some differences, especially if you user a different container storage driver than\\xA0aufs.\"),mdx(\"p\",null,\"The directories which are owned by the remapped user are used instead of the same directories directly beneath\\xA0/var/lib/docker/\\xA0and the unused versions (such as\\xA0/var/lib/docker/tmp/\\xA0in the example here) can be removed. Docker does not use them while\\xA0userns-remap\\xA0is enabled.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Disable namespace remapping for a container\")),mdx(\"p\",null,\"If you enable user namespaces on the daemon, all containers are started with user namespaces enabled by default. In some situations, such as privileged containers, you may need to disable user namespaces for a specific container. See\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/security/userns-remap/#user-namespace-known-restrictions\"}),\"user namespace known limitations\"),\"\\xA0for some of these limitations.\"),mdx(\"p\",null,\"To disable user namespaces for a specific container, add the\\xA0--userns=host\\xA0flag to the\\xA0docker container create,\\xA0docker container run, or\\xA0docker container exec\\xA0command.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"User namespace known limitations\")),mdx(\"p\",null,\"The following standard Docker features are incompatible with running a Docker daemon with user namespaces enabled:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"sharing PID or NET namespaces with the host (--pid=host\\xA0or\\xA0--network=host).\"),mdx(\"li\",{parentName:\"ul\"},\"external (volume or storage) drivers which are unaware or incapable of using daemon user mappings.\"),mdx(\"li\",{parentName:\"ul\"},\"Using the\\xA0--privileged\\xA0mode flag on\\xA0docker run\\xA0without also specifying--userns=host.\")),mdx(\"p\",null,\"User namespaces are an advanced feature and require coordination with other capabilities. For example, if volumes are mounted from the host, file ownership must be pre-arranged need read or write access to the volume contents.\"),mdx(\"p\",null,\"While the root user inside a user-namespaced container process has many of the expected privileges of the superuser within the container, the Linux kernel imposes restrictions based on internal knowledge that this is a user-namespaced process. One notable restriction is the inability to use the\\xA0mknod\\xA0command. Permission is denied for device creation within the container when run by the\\xA0root\\xA0user.\"),mdx(\"h3\",null,\"Scale Your App\"),mdx(\"h4\",null,\"Swarm mode overview\"),mdx(\"p\",null,\"To use Docker in swarm mode, install Docker. See\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/install/\"}),\"installation instructions\"),\"\\xA0for all operating systems and platforms.\"),mdx(\"p\",null,\"Current versions of Docker include\\xA0swarm mode\\xA0for natively managing a cluster of Docker Engines called a\\xA0swarm. Use the Docker CLI to create a swarm, deploy application services to a swarm, and manage swarm behavior.\"),mdx(\"p\",null,\"If you are using a Docker version prior to\\xA01.12.0, you can use\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/swarm/\"}),\"standalone swarm\"),\", but we recommend updating.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Feature highlights\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Cluster management integrated with Docker Engine:\"),\"\\xA0Use the Docker Engine CLI to create a swarm of Docker Engines where you can deploy application services. You don't need additional orchestration software to create or manage a swarm.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Decentralized design:\"),\"\\xA0Instead of handling differentiation between node roles at deployment time, the Docker Engine handles any specialization at runtime. You can deploy both kinds of nodes, managers and workers, using the Docker Engine. This means you can build an entire swarm from a single disk image.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Declarative service model:\"),\"\\xA0Docker Engine uses a declarative approach to let you define the desired state of the various services in your application stack. For example, you might describe an application comprised of a web front end service with message queueing services and a database backend.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Scaling:\"),\"\\xA0For each service, you can declare the number of tasks you want to run. When you scale up or down, the swarm manager automatically adapts by adding or removing tasks to maintain the desired state.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Desired state reconciliation:\"),\"\\xA0The swarm manager node constantly monitors the cluster state and reconciles any differences between the actual state and your expressed desired state. For example, if you set up a service to run 10 replicas of a container, and a worker machine hosting two of those replicas crashes, the manager creates two new replicas to replace the replicas that crashed. The swarm manager assigns the new replicas to workers that are running and available.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Multi-host networking:\"),\"\\xA0You can specify an overlay network for your services. The swarm manager automatically assigns addresses to the containers on the overlay network when it initializes or updates the application.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Service discovery:\"),\"\\xA0Swarm manager nodes assign each service in the swarm a unique DNS name and load balances running containers. You can query every container running in the swarm through a DNS server embedded in the swarm.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Load balancing:\"),\"\\xA0You can expose the ports for services to an external load balancer. Internally, the swarm lets you specify how to distribute service containers between nodes.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Secure by default:\"),\"\\xA0Each node in the swarm enforces TLS mutual authentication and encryption to secure communications between itself and all other nodes. You have the option to use self-signed root certificates or certificates from a custom root CA.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Rolling updates:\"),\"\\xA0At rollout time you can apply service updates to nodes incrementally. The swarm manager lets you control the delay between service deployment to different sets of nodes. If anything goes wrong, you can roll-back a task to a previous version of the service.\")),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"What's next?\")),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Swarm mode key concepts and tutorial\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Learn swarm mode\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/key-concepts/\"}),\"key concepts\"),\".\"),mdx(\"li\",{parentName:\"ul\"},\"Get started with the\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/swarm-tutorial/\"}),\"Swarm mode tutorial\"),\".\")),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Swarm mode CLI commands\")),mdx(\"p\",null,\"Explore swarm mode CLI commands\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/swarm_init/\"}),\"swarm init\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/swarm_join/\"}),\"swarm join\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/service_create/\"}),\"service create\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/service_inspect/\"}),\"service inspect\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/service_ls/\"}),\"service ls\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/service_rm/\"}),\"service rm\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/service_scale/\"}),\"service scale\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/service_ps/\"}),\"service ps\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/service_update/\"}),\"service update\"))),mdx(\"h4\",null,\"Swarm mode key concepts\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA04 minutes\")),mdx(\"p\",null,\"This topic introduces some of the concepts unique to the cluster management and orchestration features of Docker Engine 1.12.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"What is a swarm?\")),mdx(\"p\",null,\"The cluster management and orchestration features embedded in the Docker Engine are built using\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/docker/swarmkit/\"}),\"swarmkit\"),\". Swarmkit is a separate project which implements Docker's orchestration layer and is used directly within Docker.\"),mdx(\"p\",null,\"A swarm consists of multiple Docker hosts which run in\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"swarm mode\"),\"\\xA0and act as managers (to manage membership and delegation) and workers (which run\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/key-concepts/#services-and-tasks\"}),\"swarm services\"),\"). A given Docker host can be a manager, a worker, or perform both roles. When you create a service, you define its optimal state (number of replicas, network and storage resources available to it, ports the service exposes to the outside world, and more). Docker works to maintain that desired state. For instance, if a worker node becomes unavailable, Docker schedules that node's tasks on other nodes. A\\xA0task\\xA0is a running container which is part of a swarm service and managed by a swarm manager, as opposed to a standalone container.\"),mdx(\"p\",null,\"One of the key advantages of swarm services over standalone containers is that you can modify a service's configuration, including the networks and volumes it is connected to, without the need to manually restart the service. Docker will update the configuration, stop the service tasks with the out of date configuration, and create new ones matching the desired configuration.\"),mdx(\"p\",null,\"When Docker is running in swarm mode, you can still run standalone containers on any of the Docker hosts participating in the swarm, as well as swarm services. A key difference between standalone containers and swarm services is that only swarm managers can manage a swarm, while standalone containers can be started on any daemon. Docker daemons can participate in a swarm as managers, workers, or both.\"),mdx(\"p\",null,\"In the same way that you can use\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/compose/\"}),\"Docker Compose\"),\"\\xA0to define and run containers, you can define and run swarm service\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/get-started/part5/\"}),\"stacks\"),\".\"),mdx(\"p\",null,\"Keep reading for details about concepts relating to Docker swarm services, including nodes, services, tasks, and load balancing.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Nodes\")),mdx(\"p\",null,\"A\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"node\"),\"\\xA0is an instance of the Docker engine participating in the swarm. You can also think of this as a Docker node. You can run one or more nodes on a single physical computer or cloud server, but production swarm deployments typically include Docker nodes distributed across multiple physical and cloud machines.\"),mdx(\"p\",null,\"To deploy your application to a swarm, you submit a service definition to a\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"manager node\"),\". The manager node dispatches units of work called\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/key-concepts/#services-and-tasks\"}),\"tasks\"),\"\\xA0to worker nodes.\"),mdx(\"p\",null,\"Manager nodes also perform the orchestration and cluster management functions required to maintain the desired state of the swarm. Manager nodes elect a single leader to conduct orchestration tasks.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Worker nodes\"),\"\\xA0receive and execute tasks dispatched from manager nodes. By default manager nodes also run services as worker nodes, but you can configure them to run manager tasks exclusively and be manager-only nodes. An agent runs on each worker node and reports on the tasks assigned to it. The worker node notifies the manager node of the current state of its assigned tasks so that the manager can maintain the desired state of each worker.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Services and tasks\")),mdx(\"p\",null,\"A\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"service\"),\"\\xA0is the definition of the tasks to execute on the manager or worker nodes. It is the central structure of the swarm system and the primary root of user interaction with the swarm.\"),mdx(\"p\",null,\"When you create a service, you specify which container image to use and which commands to execute inside running containers.\"),mdx(\"p\",null,\"In the\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"replicated services\"),\"\\xA0model, the swarm manager distributes a specific number of replica tasks among the nodes based upon the scale you set in the desired state.\"),mdx(\"p\",null,\"For\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"global services\"),\", the swarm runs one task for the service on every available node in the cluster.\"),mdx(\"p\",null,\"A\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"task\"),\"\\xA0carries a Docker container and the commands to run inside the container. It is the atomic scheduling unit of swarm. Manager nodes assign tasks to worker nodes according to the number of replicas set in the service scale. Once a task is assigned to a node, it cannot move to another node. It can only run on the assigned node or fail.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Load balancing\")),mdx(\"p\",null,\"The swarm manager uses\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"ingress load balancing\"),\"\\xA0to expose the services you want to make available externally to the swarm. The swarm manager can automatically assign the service a\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"PublishedPort\"),\"\\xA0or you can configure a PublishedPort for the service. You can specify any unused port. If you do not specify a port, the swarm manager assigns the service a port in the 30000-32767 range.\"),mdx(\"p\",null,\"External components, such as cloud load balancers, can access the service on the PublishedPort of any node in the cluster whether or not the node is currently running the task for the service. All nodes in the swarm route ingress connections to a running task instance.\"),mdx(\"p\",null,\"Swarm mode has an internal DNS component that automatically assigns each service in the swarm a DNS entry. The swarm manager uses\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"internal load balancing\"),\"\\xA0to distribute requests among services within the cluster based upon the DNS name of the service.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"What's next?\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Read the\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/\"}),\"swarm mode overview\"),\".\"),mdx(\"li\",{parentName:\"ul\"},\"Get started with the\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/swarm-tutorial/\"}),\"swarm mode tutorial\"),\".\")),mdx(\"h4\",null,\"Getting started with swarm mode\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA04 minutes\")),mdx(\"p\",null,\"This tutorial introduces you to the features of Docker Engine Swarm mode. You may want to familiarize yourself with the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/key-concepts/\"}),\"key concepts\"),\"\\xA0before you begin.\"),mdx(\"p\",null,\"The tutorial guides you through the following activities:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"initializing a cluster of Docker Engines in swarm mode\"),mdx(\"li\",{parentName:\"ul\"},\"adding nodes to the swarm\"),mdx(\"li\",{parentName:\"ul\"},\"deploying application services to the swarm\"),mdx(\"li\",{parentName:\"ul\"},\"managing the swarm once you have everything running\")),mdx(\"p\",null,\"This tutorial uses Docker Engine CLI commands entered on the command line of a terminal window.\"),mdx(\"p\",null,\"If you are brand new to Docker, see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/\"}),\"About Docker Engine\"),\".\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Set up\")),mdx(\"p\",null,\"To run this tutorial, you need the following:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/swarm-tutorial/#three-networked-host-machines\"}),\"three Linux hosts which can communicate over a network, with Docker installed\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/swarm-tutorial/#docker-engine-1-12-or-newer\"}),\"Docker Engine 1.12 or later installed\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/swarm-tutorial/#the-ip-address-of-the-manager-machine\"}),\"the IP address of the manager machine\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/swarm-tutorial/#open-protocols-and-ports-between-the-hosts\"}),\"open ports between the hosts\"))),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Three networked host machines\")),mdx(\"p\",null,\"This tutorial requires three Linux hosts which have Docker installed and can communicate over a network. These can be physical machines, virtual machines, Amazon EC2 instances, or hosted in some other way. You can even use Docker Machine from a Linux, Mac, or Windows host. Check out\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/get-started/part4/#prerequisites\"}),\"Getting started - Swarms\"),\"\\xA0for one possible set-up for the hosts.\"),mdx(\"p\",null,\"One of these machines is a manager (called\\xA0manager1) and two of them are workers (worker1and\\xA0worker2).\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": You can follow many of the tutorial steps to test single-node swarm as well, in which case you need only one host. Multi-node commands do not work, but you can initialize a swarm, create services, and scale them.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Docker Engine 1.12 or newer\")),mdx(\"p\",null,\"This tutorial requires Docker Engine 1.12 or newer on each of the host machines. Install Docker Engine and verify that the Docker Engine daemon is running on each of the machines. You can get the latest version of Docker Engine as follows:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/swarm-tutorial/#install-docker-engine-on-linux-machines\"}),\"install Docker Engine on Linux machines\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/swarm-tutorial/#use-docker-for-mac-or-docker-for-windows\"}),\"use Docker for Mac or Docker for Windows\"))),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"INSTALL DOCKER ENGINE ON LINUX MACHINES\")),mdx(\"p\",null,\"If you are using Linux based physical computers or cloud-provided computers as hosts, simply follow the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/installation/\"}),\"Linux install instructions\"),\"\\xA0for your platform. Spin up the three machines, and you are ready. You can test both single-node and multi-node swarm scenarios on Linux machines.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"USE DOCKER FOR MAC OR DOCKER FOR WINDOWS\")),mdx(\"p\",null,\"Alternatively, install the latest\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/docker-for-mac/\"}),\"Docker for Mac\"),\"\\xA0or\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/docker-for-windows/\"}),\"Docker for Windows\"),\"\\xA0application on one computer. You can test both single-node and multi-node swarm from this computer, but you need to use Docker Machine to test the multi-node scenarios.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"You can use Docker for Mac or Windows to test\\xA0single-node\\xA0features of swarm mode, including initializing a swarm with a single node, creating services, and scaling services. Docker \\\"Moby\\\" on Hyperkit (Mac) or Hyper-V (Windows) serve as the single swarm node.\"),mdx(\"li\",{parentName:\"ul\"},\"Currently, you cannot use Docker for Mac or Docker for Windows alone to test a\\xA0multi-nodeswarm. However, you can use the included version of\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/machine/overview/\"}),\"Docker Machine\"),\"\\xA0to create the swarm nodes (see\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/machine/get-started/\"}),\"Get started with Docker Machine and a local VM\"),\"), then follow the tutorial for all multi-node features. For this scenario, you run commands from a Docker for Mac or Docker for Windows host, but that Docker host itself is\\xA0not\\xA0participating in the swarm. After you create the nodes, you can run all swarm commands as shown from the Mac terminal or Windows PowerShell with Docker for Mac or Docker for Windows running.\")),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"The IP address of the manager machine\")),mdx(\"p\",null,\"The IP address must be assigned to a network interface available to the host operating system. All nodes in the swarm need to connect to the manager at the IP address.\"),mdx(\"p\",null,\"Because other nodes contact the manager node on its IP address, you should use a fixed IP address.\"),mdx(\"p\",null,\"You can run\\xA0ifconfig\\xA0on Linux or macOS to see a list of the available network interfaces.\"),mdx(\"p\",null,\"If you are using Docker Machine, you can get the manager IP with either\\xA0docker-machine ls\\xA0or\\xA0docker-machine ip \",mdx(\"inlineCode\",{parentName:\"p\"},\"<MACHINE-NAME>\"),\"\\xA0--- for example,\\xA0docker-machine ip manager1.\"),mdx(\"p\",null,\"The tutorial uses\\xA0manager1\\xA0:\\xA0192.168.99.100.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Open protocols and ports between the hosts\")),mdx(\"p\",null,\"The following ports must be available. On some systems, these ports are open by default.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"TCP port 2377\"),\"\\xA0for cluster management communications\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"TCP\"),\"\\xA0and\\xA0\",mdx(\"strong\",{parentName:\"li\"},\"UDP port 7946\"),\"\\xA0for communication among nodes\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"UDP port 4789\"),\"\\xA0for overlay network traffic\")),mdx(\"p\",null,\"If you plan on creating an overlay network with encryption (--opt encrypted), you also need to ensure\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"ip protocol 50\"),\"\\xA0(\",mdx(\"strong\",{parentName:\"p\"},\"ESP\"),\") traffic is allowed.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"What's next?\")),mdx(\"p\",null,\"After you have set up your environment, you are ready to\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/swarm-tutorial/create-swarm/\"}),\"create a swarm\"),\".\"),mdx(\"h4\",null,\"Create a swarm\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA02 minutes\")),mdx(\"p\",null,\"After you complete the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/swarm-tutorial/\"}),\"tutorial setup\"),\"\\xA0steps, you're ready to create a swarm. Make sure the Docker Engine daemon is started on the host machines.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Open a terminal and ssh into the machine where you want to run your manager node. This tutorial uses a machine named\\xA0manager1. If you use Docker Machine, you can connect to it via SSH using the following command:\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker-machine ssh manager1\"),mdx(\"li\",{parentName:\"ol\"},\"Run the following command to create a new swarm:\"),mdx(\"li\",{parentName:\"ol\"},\"docker swarm init --advertise-addr \",mdx(\"inlineCode\",{parentName:\"li\"},\"<MANAGER-IP>\"))),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": If you are using Docker for Mac or Docker for Windows to test single-node swarm, simply run\\xA0docker swarm init\\xA0with no arguments. There is no need to specify\\xA0--advertise-addr\\xA0in this case. To learn more, see the topic on how to\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/swarm-tutorial/#use-docker-for-mac-or-docker-for-windows\"}),\"Use Docker for Mac or Docker for Windows\"),\"\\xA0with Swarm.\"),mdx(\"p\",null,\"In the tutorial, the following command creates a swarm on the\\xA0manager1\\xA0machine:\"),mdx(\"p\",null,\"$ docker swarm init --advertise-addr 192.168.99.100\"),mdx(\"p\",null,\"Swarm initialized: current node (dxn1zf6l61qsb1josjja83ngz) is now a manager.\"),mdx(\"p\",null,\"To add a worker to this swarm, run the following command:\"),mdx(\"p\",null,\"docker swarm join \\\\\"),mdx(\"p\",null,\"--token SWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c \\\\\"),mdx(\"p\",null,\"192.168.99.100:2377\"),mdx(\"p\",null,\"To add a manager to this swarm, run \\\\'docker swarm join-token manager\\\\' and follow the instructions.\"),mdx(\"p\",null,\"The\\xA0--advertise-addr\\xA0flag configures the manager node to publish its address as\\xA0192.168.99.100. The other nodes in the swarm must be able to access the manager at the IP address.\"),mdx(\"p\",null,\"The output includes the commands to join new nodes to the swarm. Nodes will join as managers or workers depending on the value for the\\xA0--token\\xA0flag.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Run\\xA0docker info\\xA0to view the current state of the swarm:\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker info\"),mdx(\"li\",{parentName:\"ol\"},\"Containers: 2\"),mdx(\"li\",{parentName:\"ol\"},\"Running: 0\"),mdx(\"li\",{parentName:\"ol\"},\"Paused: 0\"),mdx(\"li\",{parentName:\"ol\"},\"Stopped: 2\"),mdx(\"li\",{parentName:\"ol\"},\"...snip...\"),mdx(\"li\",{parentName:\"ol\"},\"Swarm: active\"),mdx(\"li\",{parentName:\"ol\"},\"NodeID: dxn1zf6l61qsb1josjja83ngz\"),mdx(\"li\",{parentName:\"ol\"},\"Is Manager: true\"),mdx(\"li\",{parentName:\"ol\"},\"Managers: 1\"),mdx(\"li\",{parentName:\"ol\"},\"Nodes: 1\"),mdx(\"li\",{parentName:\"ol\"},\"...snip...\"),mdx(\"li\",{parentName:\"ol\"},\"Run the\\xA0docker node ls\\xA0command to view information about nodes:\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker node ls\"),mdx(\"li\",{parentName:\"ol\"},\"ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS\"),mdx(\"li\",{parentName:\"ol\"},\"dxn1zf6l61qsb1josjja83ngz * manager1 Ready Active Leader\")),mdx(\"p\",null,\"The\\xA0*\\xA0next to the node ID indicates that you're currently connected on this node.\"),mdx(\"p\",null,\"Docker Engine swarm mode automatically names the node for the machine host name. The tutorial covers other columns in later steps.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"What's next?\")),mdx(\"p\",null,\"In the next section of the tutorial, we\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/swarm-tutorial/add-nodes/\"}),\"add two more nodes\"),\"\\xA0to the cluster.\"),mdx(\"h4\",null,\"Add nodes to the swarm\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA02 minutes\")),mdx(\"p\",null,\"Once you've\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/swarm-tutorial/create-swarm/\"}),\"created a swarm\"),\"\\xA0with a manager node, you're ready to add worker nodes.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Open a terminal and ssh into the machine where you want to run a worker node. This tutorial uses the name\\xA0worker1.\"),mdx(\"li\",{parentName:\"ol\"},\"Run the command produced by the\\xA0docker swarm init\\xA0output from the\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/swarm-tutorial/create-swarm/\"}),\"Create a swarm\"),\"tutorial step to create a worker node joined to the existing swarm:\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker swarm join \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--token SWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"192.168.99.100:2377\"),mdx(\"li\",{parentName:\"ol\"},\"This node joined a swarm as a worker.\")),mdx(\"p\",null,\"If you don't have the command available, you can run the following command on a manager node to retrieve the join command for a worker:\"),mdx(\"p\",null,\"$ docker swarm join-token worker\"),mdx(\"p\",null,\"To add a worker to this swarm, run the following command:\"),mdx(\"p\",null,\"docker swarm join \\\\\"),mdx(\"p\",null,\"--token SWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c \\\\\"),mdx(\"p\",null,\"192.168.99.100:2377\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Open a terminal and ssh into the machine where you want to run a second worker node. This tutorial uses the name\\xA0worker2.\"),mdx(\"li\",{parentName:\"ol\"},\"Run the command produced by the\\xA0docker swarm init\\xA0output from the\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/swarm-tutorial/create-swarm/\"}),\"Create a swarm\"),\"tutorial step to create a second worker node joined to the existing swarm:\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker swarm join \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--token SWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"192.168.99.100:2377\"),mdx(\"li\",{parentName:\"ol\"},\"This node joined a swarm as a worker.\"),mdx(\"li\",{parentName:\"ol\"},\"Open a terminal and ssh into the machine where the manager node runs and run the\\xA0docker node ls\\xA0command to see the worker nodes:\"),mdx(\"li\",{parentName:\"ol\"},\"ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS\"),mdx(\"li\",{parentName:\"ol\"},\"03g1y59jwfg7cf99w4lt0f662 worker2 Ready Active\"),mdx(\"li\",{parentName:\"ol\"},\"9j68exjopxe7wfl6yuxml7a7j worker1 Ready Active\"),mdx(\"li\",{parentName:\"ol\"},\"dxn1zf6l61qsb1josjja83ngz * manager1 Ready Active Leader\")),mdx(\"p\",null,\"The\\xA0MANAGER\\xA0column identifies the manager nodes in the swarm. The empty status in this column for\\xA0worker1\\xA0and\\xA0worker2\\xA0identifies them as worker nodes.\"),mdx(\"p\",null,\"Swarm management commands like\\xA0docker node ls\\xA0only work on manager nodes.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"What's next?\")),mdx(\"p\",null,\"Now your swarm consists of a manager and two worker nodes. In the next step of the tutorial, you\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/swarm-tutorial/deploy-service/\"}),\"deploy a service\"),\"\\xA0to the swarm.\"),mdx(\"h4\",null,\"Deploy a service to the swarm\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA01 minute\")),mdx(\"p\",null,\"After you\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/swarm-tutorial/create-swarm/\"}),\"create a swarm\"),\", you can deploy a service to the swarm. For this tutorial, you also\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/swarm-tutorial/add-nodes/\"}),\"added worker nodes\"),\", but that is not a requirement to deploy a service.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Open a terminal and ssh into the machine where you run your manager node. For example, the tutorial uses a machine named\\xA0manager1.\"),mdx(\"li\",{parentName:\"ol\"},\"Run the following command:\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker service create --replicas 1 --name helloworld alpine ping docker.com\"),mdx(\"li\",{parentName:\"ol\"},\"9uk4639qpg7npwf3fn2aasksr\",mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},\"The\\xA0docker service create\\xA0command creates the service.\"),mdx(\"li\",{parentName:\"ul\"},\"The\\xA0--name\\xA0flag names the service\\xA0helloworld.\"),mdx(\"li\",{parentName:\"ul\"},\"The\\xA0--replicas\\xA0flag specifies the desired state of 1 running instance.\"),mdx(\"li\",{parentName:\"ul\"},\"The arguments\\xA0alpine ping docker.com\\xA0define the service as an Alpine Linux container that executes the command\\xA0ping docker.com.\"))),mdx(\"li\",{parentName:\"ol\"},\"Run\\xA0docker service ls\\xA0to see the list of running services:\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker service ls\"),mdx(\"li\",{parentName:\"ol\"},\"ID NAME SCALE IMAGE COMMAND\"),mdx(\"li\",{parentName:\"ol\"},\"9uk4639qpg7n helloworld 1/1 alpine ping docker.com\")),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"What's next?\")),mdx(\"p\",null,\"Now you've deployed a service to the swarm, you're ready to\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/swarm-tutorial/inspect-service/\"}),\"inspect the service\"),\".\"),mdx(\"h4\",null,\"Inspect a service on the swarm\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA02 minutes\")),mdx(\"p\",null,\"When you have\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/swarm-tutorial/deploy-service/\"}),\"deployed a service\"),\"\\xA0to your swarm, you can use the Docker CLI to see details about the service running in the swarm.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"If you haven't already, open a terminal and ssh into the machine where you run your manager node. For example, the tutorial uses a machine named\\xA0manager1.\"),mdx(\"li\",{parentName:\"ol\"},\"Run\\xA0docker service inspect --pretty \",mdx(\"inlineCode\",{parentName:\"li\"},\"<SERVICE-ID>\"),\"\\xA0to display the details about a service in an easily readable format.\")),mdx(\"p\",null,\"To see the details on the\\xA0helloworld\\xA0service:\"),mdx(\"p\",null,\"[manager1]\",\"$ docker service inspect --pretty helloworld\"),mdx(\"p\",null,\"ID: 9uk4639qpg7npwf3fn2aasksr\"),mdx(\"p\",null,\"Name: helloworld\"),mdx(\"p\",null,\"Service Mode: REPLICATED\"),mdx(\"p\",null,\"Replicas: 1\"),mdx(\"p\",null,\"Placement:\"),mdx(\"p\",null,\"UpdateConfig:\"),mdx(\"p\",null,\"Parallelism: 1\"),mdx(\"p\",null,\"ContainerSpec:\"),mdx(\"p\",null,\"Image: alpine\"),mdx(\"p\",null,\"Args: ping docker.com\"),mdx(\"p\",null,\"Resources:\"),mdx(\"p\",null,\"Endpoint Mode: vip\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Tip\"),\": To return the service details in json format, run the same command without the\\xA0--pretty\\xA0flag.\"),mdx(\"p\",null,\"[manager1]\",\"$ docker service inspect helloworld\"),mdx(\"p\",null,\"[\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"ID\\\": \\\"9uk4639qpg7npwf3fn2aasksr\\\",\"),mdx(\"p\",null,\"\\\"Version\\\": {\"),mdx(\"p\",null,\"\\\"Index\\\": 418\"),mdx(\"p\",null,\"},\"),mdx(\"p\",null,\"\\\"CreatedAt\\\": \\\"2016-06-16T21:57:11.622222327Z\\\",\"),mdx(\"p\",null,\"\\\"UpdatedAt\\\": \\\"2016-06-16T21:57:11.622222327Z\\\",\"),mdx(\"p\",null,\"\\\"Spec\\\": {\"),mdx(\"p\",null,\"\\\"Name\\\": \\\"helloworld\\\",\"),mdx(\"p\",null,\"\\\"TaskTemplate\\\": {\"),mdx(\"p\",null,\"\\\"ContainerSpec\\\": {\"),mdx(\"p\",null,\"\\\"Image\\\": \\\"alpine\\\",\"),mdx(\"p\",null,\"\\\"Args\\\": [\"),mdx(\"p\",null,\"\\\"ping\\\",\"),mdx(\"p\",null,\"\\\"docker.com\\\"\"),mdx(\"p\",null,\"]\"),mdx(\"p\",null,\"},\"),mdx(\"p\",null,\"\\\"Resources\\\": {\"),mdx(\"p\",null,\"\\\"Limits\\\": {},\"),mdx(\"p\",null,\"\\\"Reservations\\\": {}\"),mdx(\"p\",null,\"},\"),mdx(\"p\",null,\"\\\"RestartPolicy\\\": {\"),mdx(\"p\",null,\"\\\"Condition\\\": \\\"any\\\",\"),mdx(\"p\",null,\"\\\"MaxAttempts\\\": 0\"),mdx(\"p\",null,\"},\"),mdx(\"p\",null,\"\\\"Placement\\\": {}\"),mdx(\"p\",null,\"},\"),mdx(\"p\",null,\"\\\"Mode\\\": {\"),mdx(\"p\",null,\"\\\"Replicated\\\": {\"),mdx(\"p\",null,\"\\\"Replicas\\\": 1\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"},\"),mdx(\"p\",null,\"\\\"UpdateConfig\\\": {\"),mdx(\"p\",null,\"\\\"Parallelism\\\": 1\"),mdx(\"p\",null,\"},\"),mdx(\"p\",null,\"\\\"EndpointSpec\\\": {\"),mdx(\"p\",null,\"\\\"Mode\\\": \\\"vip\\\"\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"},\"),mdx(\"p\",null,\"\\\"Endpoint\\\": {\"),mdx(\"p\",null,\"\\\"Spec\\\": {}\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"]\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Run\\xA0docker service ps \",mdx(\"inlineCode\",{parentName:\"li\"},\"<SERVICE-ID>\"),\"\\xA0to see which nodes are running the service:\"),mdx(\"li\",{parentName:\"ol\"},\"[manager1]\",\"$ docker service ps helloworld\"),mdx(\"li\",{parentName:\"ol\"},\"NAME IMAGE NODE DESIRED STATE LAST STATE\"),mdx(\"li\",{parentName:\"ol\"},\"helloworld.1.8p1vev3fq5zm0mi8g0as41w35 alpine worker2 Running Running 3 minutes\")),mdx(\"p\",null,\"In this case, the one instance of the\\xA0helloworld\\xA0service is running on the\\xA0worker2\\xA0node. You may see the service running on your manager node. By default, manager nodes in a swarm can execute tasks just like worker nodes.\"),mdx(\"p\",null,\"Swarm also shows you the\\xA0DESIRED STATE\\xA0and\\xA0LAST STATE\\xA0of the service task so you can see if tasks are running according to the service definition.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Run\\xA0docker ps\\xA0on the node where the task is running to see details about the container for the task.\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Tip\"),\": If\\xA0helloworld\\xA0is running on a node other than your manager node, you must ssh to that node.\"),mdx(\"p\",null,\"[worker2]\",\"$docker ps\"),mdx(\"p\",null,\"CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES\"),mdx(\"p\",null,\"e609dde94e47 alpine:latest \\\"ping docker.com\\\" 3 minutes ago Up 3 minutes helloworld.1.8p1vev3fq5zm0mi8g0as41w35\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"What's next?\")),mdx(\"p\",null,\"Next, you can\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/swarm-tutorial/scale-service/\"}),\"change the scale\"),\"\\xA0for the service running in the swarm.\"),mdx(\"h4\",null,\"Scale the service in the swarm\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA01 minute\")),mdx(\"p\",null,\"Once you have\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/swarm-tutorial/deploy-service/\"}),\"deployed a service\"),\"\\xA0to a swarm, you are ready to use the Docker CLI to scale the number of containers in the service. Containers running in a service are called \\\"tasks.\\\"\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"If you haven't already, open a terminal and ssh into the machine where you run your manager node. For example, the tutorial uses a machine named\\xA0manager1.\"),mdx(\"li\",{parentName:\"ol\"},\"Run the following command to change the desired state of the service running in the swarm:\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker service scale \",mdx(\"inlineCode\",{parentName:\"li\"},\"<SERVICE-ID>=<NUMBER-OF-TASKS>\"))),mdx(\"p\",null,\"For example:\"),mdx(\"p\",null,\"$ docker service scale helloworld=5\"),mdx(\"p\",null,\"helloworld scaled to 5\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Run\\xA0docker service ps \",mdx(\"inlineCode\",{parentName:\"li\"},\"<SERVICE-ID>\"),\"\\xA0to see the updated task list:\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker service ps helloworld\"),mdx(\"li\",{parentName:\"ol\"},\"NAME IMAGE NODE DESIRED STATE CURRENT STATE\"),mdx(\"li\",{parentName:\"ol\"},\"helloworld.1.8p1vev3fq5zm0mi8g0as41w35 alpine worker2 Running Running 7 minutes\"),mdx(\"li\",{parentName:\"ol\"},\"helloworld.2.c7a7tcdq5s0uk3qr88mf8xco6 alpine worker1 Running Running 24 seconds\"),mdx(\"li\",{parentName:\"ol\"},\"helloworld.3.6crl09vdcalvtfehfh69ogfb1 alpine worker1 Running Running 24 seconds\"),mdx(\"li\",{parentName:\"ol\"},\"helloworld.4.auky6trawmdlcne8ad8phb0f1 alpine manager1 Running Running 24 seconds\"),mdx(\"li\",{parentName:\"ol\"},\"helloworld.5.ba19kca06l18zujfwxyc5lkyn alpine worker2 Running Running 24 seconds\")),mdx(\"p\",null,\"You can see that swarm has created 4 new tasks to scale to a total of 5 running instances of Alpine Linux. The tasks are distributed between the three nodes of the swarm. One is running on\\xA0manager1.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Run\\xA0docker ps\\xA0to see the containers running on the node where you're connected. The following example shows the tasks running on\\xA0manager1:\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker ps\"),mdx(\"li\",{parentName:\"ol\"},\"CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES\"),mdx(\"li\",{parentName:\"ol\"},\"528d68040f95 alpine:latest \\\"ping docker.com\\\" About a minute ago Up About a minute helloworld.4.auky6trawmdlcne8ad8phb0f1\")),mdx(\"p\",null,\"If you want to see the containers running on other nodes, ssh into those nodes and run the\\xA0docker ps\\xA0command.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"What's next?\")),mdx(\"p\",null,\"At this point in the tutorial, you're finished with the\\xA0helloworld\\xA0service. The next step shows how to\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/swarm-tutorial/delete-service/\"}),\"delete the service\"),\".\"),mdx(\"h4\",null,\"Delete the service running on the swarm\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA01 minute\")),mdx(\"p\",null,\"The remaining steps in the tutorial don't use the\\xA0helloworld\\xA0service, so now you can delete the service from the swarm.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"If you haven't already, open a terminal and ssh into the machine where you run your manager node. For example, the tutorial uses a machine named\\xA0manager1.\"),mdx(\"li\",{parentName:\"ol\"},\"Run\\xA0docker service rm helloworld\\xA0to remove the\\xA0helloworld\\xA0service.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker service rm helloworld\"),mdx(\"li\",{parentName:\"ol\"},\"helloworld\"),mdx(\"li\",{parentName:\"ol\"},\"Run\\xA0docker service inspect \",mdx(\"inlineCode\",{parentName:\"li\"},\"<SERVICE-ID>\"),\"\\xA0to verify that the swarm manager removed the service. The CLI returns a message that the service is not found:\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker service inspect helloworld\"),mdx(\"li\",{parentName:\"ol\"},\"[]\"),mdx(\"li\",{parentName:\"ol\"},\"Error: no such service: helloworld\"),mdx(\"li\",{parentName:\"ol\"},\"Even though the service no longer exists, the task containers take a few seconds to clean up. You can use\\xA0docker ps\\xA0on the nodes to verify when the tasks have been removed.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker ps\"),mdx(\"li\",{parentName:\"ol\"},\"CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES\"),mdx(\"li\",{parentName:\"ol\"},\"db1651f50347 alpine:latest \\\"ping docker.com\\\" 44 minutes ago Up 46 seconds helloworld.5.9lkmos2beppihw95vdwxy1j3w\"),mdx(\"li\",{parentName:\"ol\"},\"43bf6e532a92 alpine:latest \\\"ping docker.com\\\" 44 minutes ago Up 46 seconds helloworld.3.a71i8rp6fua79ad43ycocl4t2\"),mdx(\"li\",{parentName:\"ol\"},\"5a0fb65d8fa7 alpine:latest \\\"ping docker.com\\\" 44 minutes ago Up 45 seconds helloworld.2.2jpgensh7d935qdc857pxulfr\"),mdx(\"li\",{parentName:\"ol\"},\"afb0ba67076f alpine:latest \\\"ping docker.com\\\" 44 minutes ago Up 46 seconds helloworld.4.1c47o7tluz7drve4vkm2m5olx\"),mdx(\"li\",{parentName:\"ol\"},\"688172d3bfaa alpine:latest \\\"ping docker.com\\\" 45 minutes ago Up About a minute helloworld.1.74nbhb3fhud8jfrhigd7s29we\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker ps\"),mdx(\"li\",{parentName:\"ol\"},\"CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS\")),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"What's next?\")),mdx(\"p\",null,\"In the next step of the tutorial, you set up a new service and apply a\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/swarm-tutorial/rolling-update/\"}),\"rolling update\"),\".\"),mdx(\"h4\",null,\"Apply rolling updates to a service\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA04 minutes\")),mdx(\"p\",null,\"In a previous step of the tutorial, you\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/swarm-tutorial/scale-service/\"}),\"scaled\"),\"\\xA0the number of instances of a service. In this part of the tutorial, you deploy a service based on the Redis 3.0.6 container image. Then you upgrade the service to use the Redis 3.0.7 container image using rolling updates.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"If you haven't already, open a terminal and ssh into the machine where you run your manager node. For example, the tutorial uses a machine named\\xA0manager1.\"),mdx(\"li\",{parentName:\"ol\"},\"Deploy Redis 3.0.6 to the swarm and configure the swarm with a 10 second update delay:\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker service create \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--replicas 3 \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--name redis \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--update-delay 10s \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"redis:3.0.6\"),mdx(\"li\",{parentName:\"ol\"},\"0u6a4s31ybk7yw2wyvtikmu50\")),mdx(\"p\",null,\"You configure the rolling update policy at service deployment time.\"),mdx(\"p\",null,\"The\\xA0--update-delay\\xA0flag configures the time delay between updates to a service task or sets of tasks. You can describe the time\\xA0T\\xA0as a combination of the number of seconds\\xA0Ts, minutes\\xA0Tm, or hours\\xA0Th. So\\xA010m30s\\xA0indicates a 10 minute 30 second delay.\"),mdx(\"p\",null,\"By default the scheduler updates 1 task at a time. You can pass the\\xA0--update-parallelismflag to configure the maximum number of service tasks that the scheduler updates simultaneously.\"),mdx(\"p\",null,\"By default, when an update to an individual task returns a state of\\xA0RUNNING, the scheduler schedules another task to update until all tasks are updated. If, at any time during an update a task returns\\xA0FAILED, the scheduler pauses the update. You can control the behavior using the\\xA0--update-failure-action\\xA0flag for\\xA0docker service create\\xA0ordocker service update.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Inspect the\\xA0redis\\xA0service:\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker service inspect --pretty redis\"),mdx(\"li\",{parentName:\"ol\"},\"ID: 0u6a4s31ybk7yw2wyvtikmu50\"),mdx(\"li\",{parentName:\"ol\"},\"Name: redis\"),mdx(\"li\",{parentName:\"ol\"},\"Service Mode: Replicated\"),mdx(\"li\",{parentName:\"ol\"},\"Replicas: 3\"),mdx(\"li\",{parentName:\"ol\"},\"Placement:\"),mdx(\"li\",{parentName:\"ol\"},\"Strategy: Spread\"),mdx(\"li\",{parentName:\"ol\"},\"UpdateConfig:\"),mdx(\"li\",{parentName:\"ol\"},\"Parallelism: 1\"),mdx(\"li\",{parentName:\"ol\"},\"Delay: 10s\"),mdx(\"li\",{parentName:\"ol\"},\"ContainerSpec:\"),mdx(\"li\",{parentName:\"ol\"},\"Image: redis:3.0.6\"),mdx(\"li\",{parentName:\"ol\"},\"Resources:\"),mdx(\"li\",{parentName:\"ol\"},\"Endpoint Mode: vip\"),mdx(\"li\",{parentName:\"ol\"},\"Now you can update the container image for\\xA0redis. The swarm manager applies the update to nodes according to the\\xA0UpdateConfig\\xA0policy:\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker service update --image redis:3.0.7 redis\"),mdx(\"li\",{parentName:\"ol\"},\"redis\")),mdx(\"p\",null,\"The scheduler applies rolling updates as follows by default:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},\"Stop the first task.\"),mdx(\"li\",{parentName:\"ul\"},\"Schedule update for the stopped task.\"),mdx(\"li\",{parentName:\"ul\"},\"Start the container for the updated task.\"),mdx(\"li\",{parentName:\"ul\"},\"If the update to a task returns\\xA0RUNNING, wait for the specified delay period then start the next task.\"),mdx(\"li\",{parentName:\"ul\"},\"If, at any time during the update, a task returns\\xA0FAILED, pause the update.\")))),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Run\\xA0docker service inspect --pretty redis\\xA0to see the new image in the desired state:\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker service inspect --pretty redis\"),mdx(\"li\",{parentName:\"ol\"},\"ID: 0u6a4s31ybk7yw2wyvtikmu50\"),mdx(\"li\",{parentName:\"ol\"},\"Name: redis\"),mdx(\"li\",{parentName:\"ol\"},\"Service Mode: Replicated\"),mdx(\"li\",{parentName:\"ol\"},\"Replicas: 3\"),mdx(\"li\",{parentName:\"ol\"},\"Placement:\"),mdx(\"li\",{parentName:\"ol\"},\"Strategy: Spread\"),mdx(\"li\",{parentName:\"ol\"},\"UpdateConfig:\"),mdx(\"li\",{parentName:\"ol\"},\"Parallelism: 1\"),mdx(\"li\",{parentName:\"ol\"},\"Delay: 10s\"),mdx(\"li\",{parentName:\"ol\"},\"ContainerSpec:\"),mdx(\"li\",{parentName:\"ol\"},\"Image: redis:3.0.7\"),mdx(\"li\",{parentName:\"ol\"},\"Resources:\"),mdx(\"li\",{parentName:\"ol\"},\"Endpoint Mode: vip\")),mdx(\"p\",null,\"The output of\\xA0service inspect\\xA0shows if your update paused due to failure:\"),mdx(\"p\",null,\"$ docker service inspect --pretty redis\"),mdx(\"p\",null,\"ID: 0u6a4s31ybk7yw2wyvtikmu50\"),mdx(\"p\",null,\"Name: redis\"),mdx(\"p\",null,\"...snip...\"),mdx(\"p\",null,\"Update status:\"),mdx(\"p\",null,\"State: paused\"),mdx(\"p\",null,\"Started: 11 seconds ago\"),mdx(\"p\",null,\"Message: update paused due to failure or early termination of task 9p7ith557h8ndf0ui9s0q951b\"),mdx(\"p\",null,\"...snip...\"),mdx(\"p\",null,\"To restart a paused update run\\xA0docker service update \",mdx(\"inlineCode\",{parentName:\"p\"},\"<SERVICE-ID>\"),\". For example:\"),mdx(\"p\",null,\"docker service update redis\"),mdx(\"p\",null,\"To avoid repeating certain update failures, you may need to reconfigure the service by passing flags to\\xA0docker service update.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Run\\xA0docker service ps \",mdx(\"inlineCode\",{parentName:\"li\"},\"<SERVICE-ID>\"),\"\\xA0to watch the rolling update:\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker service ps redis\"),mdx(\"li\",{parentName:\"ol\"},\"NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR\"),mdx(\"li\",{parentName:\"ol\"},\"redis.1.dos1zffgeofhagnve8w864fco redis:3.0.7 worker1 Running Running 37 seconds\"),mdx(\"li\",{parentName:\"ol\"},\"_\",\" redis.1.88rdo6pa52ki8oqx6dogf04fh redis:3.0.6 worker2 Shutdown Shutdown 56 seconds ago\"),mdx(\"li\",{parentName:\"ol\"},\"redis.2.9l3i4j85517skba5o7tn5m8g0 redis:3.0.7 worker2 Running Running About a minute\"),mdx(\"li\",{parentName:\"ol\"},\"_\",\" redis.2.66k185wilg8ele7ntu8f6nj6i redis:3.0.6 worker1 Shutdown Shutdown 2 minutes ago\"),mdx(\"li\",{parentName:\"ol\"},\"redis.3.egiuiqpzrdbxks3wxgn8qib1g redis:3.0.7 worker1 Running Running 48 seconds\"),mdx(\"li\",{parentName:\"ol\"},\"_\",\" redis.3.ctzktfddb2tepkr45qcmqln04 redis:3.0.6 mmanager1 Shutdown Shutdown 2 minutes ago\")),mdx(\"p\",null,\"Before Swarm updates all of the tasks, you can see that some are running\\xA0redis:3.0.6while others are running\\xA0redis:3.0.7. The output above shows the state once the rolling updates are done.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"What's next?\")),mdx(\"p\",null,\"Next, learn about how to\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/swarm-tutorial/drain-node/\"}),\"drain a node\"),\"\\xA0in the swarm.\"),mdx(\"h4\",null,\"Drain a node on the swarm\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA03 minutes\")),mdx(\"p\",null,\"In earlier steps of the tutorial, all the nodes have been running with\\xA0ACTIVE\\xA0availability. The swarm manager can assign tasks to any\\xA0ACTIVE\\xA0node, so up to now all nodes have been available to receive tasks.\"),mdx(\"p\",null,\"Sometimes, such as planned maintenance times, you need to set a node to\\xA0DRAIN\\xA0availability.\\xA0DRAIN\\xA0availability prevents a node from receiving new tasks from the swarm manager. It also means the manager stops tasks running on the node and launches replica tasks on a node with\\xA0ACTIVE\\xA0availability.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Important\"),\": Setting a node to\\xA0DRAIN\\xA0does not remove standalone containers from that node, such as those created with\\xA0docker run,\\xA0docker-compose up, or the Docker Engine API. A node's status, including\\xA0DRAIN, only affects the node's ability to schedule swarm service workloads.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"If you haven't already, open a terminal and ssh into the machine where you run your manager node. For example, the tutorial uses a machine named\\xA0manager1.\"),mdx(\"li\",{parentName:\"ol\"},\"Verify that all your nodes are actively available.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker node ls\"),mdx(\"li\",{parentName:\"ol\"},\"ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS\"),mdx(\"li\",{parentName:\"ol\"},\"1bcef6utixb0l0ca7gxuivsj0 worker2 Ready Active\"),mdx(\"li\",{parentName:\"ol\"},\"38ciaotwjuritcdtn9npbnkuz worker1 Ready Active\"),mdx(\"li\",{parentName:\"ol\"},\"e216jshn25ckzbvmwlnh5jr3g * manager1 Ready Active Leader\"),mdx(\"li\",{parentName:\"ol\"},\"If you aren't still running the\\xA0redis\\xA0service from the\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/swarm-tutorial/rolling-update/\"}),\"rolling update\"),\"\\xA0tutorial, start it now:\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker service create --replicas 3 --name redis --update-delay 10s redis:3.0.6\"),mdx(\"li\",{parentName:\"ol\"},\"c5uo6kdmzpon37mgj9mwglcfw\"),mdx(\"li\",{parentName:\"ol\"},\"Run\\xA0docker service ps redis\\xA0to see how the swarm manager assigned the tasks to different nodes:\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker service ps redis\"),mdx(\"li\",{parentName:\"ol\"},\"NAME IMAGE NODE DESIRED STATE CURRENT STATE\"),mdx(\"li\",{parentName:\"ol\"},\"redis.1.7q92v0nr1hcgts2amcjyqg3pq redis:3.0.6 manager1 Running Running 26 seconds\"),mdx(\"li\",{parentName:\"ol\"},\"redis.2.7h2l8h3q3wqy5f66hlv9ddmi6 redis:3.0.6 worker1 Running Running 26 seconds\"),mdx(\"li\",{parentName:\"ol\"},\"redis.3.9bg7cezvedmkgg6c8yzvbhwsd redis:3.0.6 worker2 Running Running 26 seconds\")),mdx(\"p\",null,\"In this case the swarm manager distributed one task to each node. You may see the tasks distributed differently among the nodes in your environment.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Run\\xA0docker node update --availability drain \",mdx(\"inlineCode\",{parentName:\"li\"},\"<NODE-ID>\"),\"\\xA0to drain a node that had a task assigned to it:\"),mdx(\"li\",{parentName:\"ol\"},\"docker node update --availability drain worker1\"),mdx(\"li\",{parentName:\"ol\"},\"worker1\"),mdx(\"li\",{parentName:\"ol\"},\"Inspect the node to check its availability:\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker node inspect --pretty worker1\"),mdx(\"li\",{parentName:\"ol\"},\"ID: 38ciaotwjuritcdtn9npbnkuz\"),mdx(\"li\",{parentName:\"ol\"},\"Hostname: worker1\"),mdx(\"li\",{parentName:\"ol\"},\"Status:\"),mdx(\"li\",{parentName:\"ol\"},\"State: Ready\"),mdx(\"li\",{parentName:\"ol\"},\"Availability: Drain\"),mdx(\"li\",{parentName:\"ol\"},\"...snip...\")),mdx(\"p\",null,\"The drained node shows\\xA0Drain\\xA0for\\xA0AVAILABILITY.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Run\\xA0docker service ps redis\\xA0to see how the swarm manager updated the task assignments for the\\xA0redis\\xA0service:\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker service ps redis\"),mdx(\"li\",{parentName:\"ol\"},\"NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR\"),mdx(\"li\",{parentName:\"ol\"},\"redis.1.7q92v0nr1hcgts2amcjyqg3pq redis:3.0.6 manager1 Running Running 4 minutes\"),mdx(\"li\",{parentName:\"ol\"},\"redis.2.b4hovzed7id8irg1to42egue8 redis:3.0.6 worker2 Running Running About a minute\"),mdx(\"li\",{parentName:\"ol\"},\"_\",\" redis.2.7h2l8h3q3wqy5f66hlv9ddmi6 redis:3.0.6 worker1 Shutdown Shutdown 2 minutes ago\"),mdx(\"li\",{parentName:\"ol\"},\"redis.3.9bg7cezvedmkgg6c8yzvbhwsd redis:3.0.6 worker2 Running Running 4 minutes\")),mdx(\"p\",null,\"The swarm manager maintains the desired state by ending the task on a node with\\xA0Drainavailability and creating a new task on a node with\\xA0Active\\xA0availability.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Run\\xA0docker node update --availability active \",mdx(\"inlineCode\",{parentName:\"li\"},\"<NODE-ID>\"),\"\\xA0to return the drained node to an active state:\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker node update --availability active worker1\"),mdx(\"li\",{parentName:\"ol\"},\"worker1\"),mdx(\"li\",{parentName:\"ol\"},\"Inspect the node to see the updated state:\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker node inspect --pretty worker1\"),mdx(\"li\",{parentName:\"ol\"},\"ID: 38ciaotwjuritcdtn9npbnkuz\"),mdx(\"li\",{parentName:\"ol\"},\"Hostname: worker1\"),mdx(\"li\",{parentName:\"ol\"},\"Status:\"),mdx(\"li\",{parentName:\"ol\"},\"State: Ready\"),mdx(\"li\",{parentName:\"ol\"},\"Availability: Active\"),mdx(\"li\",{parentName:\"ol\"},\"...snip...\")),mdx(\"p\",null,\"When you set the node back to\\xA0Active\\xA0availability, it can receive new tasks:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},\"during a service update to scale up\"),mdx(\"li\",{parentName:\"ul\"},\"during a rolling update\"),mdx(\"li\",{parentName:\"ul\"},\"when you set another node to\\xA0Drain\\xA0availability\"),mdx(\"li\",{parentName:\"ul\"},\"when a task fails on another active node\")))),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"What's next?\")),mdx(\"p\",null,\"Learn how to\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/ingress/\"}),\"use a swarm mode routing mesh\"),\".\"),mdx(\"h4\",null,\"Use swarm mode routing mesh\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA08 minutes\")),mdx(\"p\",null,\"Docker Engine swarm mode makes it easy to publish ports for services to make them available to resources outside the swarm. All nodes participate in an ingress\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"routing mesh\"),\". The routing mesh enables each node in the swarm to accept connections on published ports for any service running in the swarm, even if there's no task running on the node. The routing mesh routes all incoming requests to published ports on available nodes to an active container.\"),mdx(\"p\",null,\"To use the ingress network in the swarm, you need to have the following ports open between the swarm nodes before you enable swarm mode:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Port\\xA07946\\xA0TCP/UDP for container network discovery.\"),mdx(\"li\",{parentName:\"ul\"},\"Port\\xA04789\\xA0UDP for the container ingress network.\")),mdx(\"p\",null,\"You must also open the published port between the swarm nodes and any external resources, such as an external load balancer, that require access to the port.\"),mdx(\"p\",null,\"You can also\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/ingress/#bypass-the-routing-mesh\"}),\"bypass the routing mesh\"),\"\\xA0for a given service.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Publish a port for a service\")),mdx(\"p\",null,\"Use the\\xA0--publish\\xA0flag to publish a port when you create a service.\\xA0target\\xA0is used to specify the port inside the container, and\\xA0published\\xA0is used to specify the port to bind on the routing mesh. If you leave off the\\xA0published\\xA0port, a random high-numbered port is bound for each service task. You need to inspect the task to determine the port.\"),mdx(\"p\",null,\"$ docker service create \\\\\"),mdx(\"p\",null,\"--name \",mdx(\"inlineCode\",{parentName:\"p\"},\"<SERVICE-NAME>\"),\" \\\\\"),mdx(\"p\",null,\"--publish published=\",mdx(\"inlineCode\",{parentName:\"p\"},\"<PUBLISHED-PORT>,target=<CONTAINER-PORT>\"),\" \\\\\"),mdx(\"p\",null,mdx(\"inlineCode\",{parentName:\"p\"},\"<IMAGE>\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": The older form of this syntax is a colon-separated string, where the published port is first and the target port is second, such as\\xA0-p 8080:80. The new syntax is preferred because it is easier to read and allows more flexibility.\"),mdx(\"p\",null,\"The\\xA0\",mdx(\"inlineCode\",{parentName:\"p\"},\"<PUBLISHED-PORT>\\xA0is the port where the swarm makes the service available. If you omit it, a random high-numbered port is bound. The\\xA0<CONTAINER-PORT>\"),\"\\xA0is the port where the container listens. This parameter is required.\"),mdx(\"p\",null,\"For example, the following command publishes port 80 in the nginx container to port 8080 for any node in the swarm:\"),mdx(\"p\",null,\"$ docker service create \\\\\"),mdx(\"p\",null,\"--name my-web \\\\\"),mdx(\"p\",null,\"--publish published=8080,target=80 \\\\\"),mdx(\"p\",null,\"--replicas 2 \\\\\"),mdx(\"p\",null,\"nginx\"),mdx(\"p\",null,\"When you access port 8080 on any node, Docker routes your request to an active container. On the swarm nodes themselves, port 8080 may not actually be bound, but the routing mesh knows how to route the traffic and prevents any port conflicts from happening.\"),mdx(\"p\",null,\"The routing mesh listens on the published port for any IP address assigned to the node. For externally routable IP addresses, the port is available from outside the host. For all other IP addresses the access is only available from within the host.\"),mdx(\"p\",null,\"You can publish a port for an existing service using the following command:\"),mdx(\"p\",null,\"$ docker service update \\\\\"),mdx(\"p\",null,\"--publish-add published=\",mdx(\"inlineCode\",{parentName:\"p\"},\"<PUBLISHED-PORT>,target=<CONTAINER-PORT>\"),\" \\\\\"),mdx(\"p\",null,mdx(\"inlineCode\",{parentName:\"p\"},\"<SERVICE>\")),mdx(\"p\",null,\"You can use\\xA0docker service inspect\\xA0to view the service's published port. For instance:\"),mdx(\"p\",null,\"$ docker service inspect --format=\\\"{{json .Endpoint.Spec.Ports}}\\\" my-web\"),mdx(\"p\",null,\"[{\\\"Protocol\\\":\\\"tcp\\\",\\\"TargetPort\\\":80,\\\"PublishedPort\\\":8080}]\"),mdx(\"p\",null,\"The output shows the\\xA0\",mdx(\"inlineCode\",{parentName:\"p\"},\"<CONTAINER-PORT>\\xA0(labeled\\xA0TargetPort) from the containers and the<PUBLISHED-PORT>\"),\"\\xA0(labeled\\xA0PublishedPort) where nodes listen for requests for the service.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Publish a port for TCP only or UDP only\")),mdx(\"p\",null,\"By default, when you publish a port, it is a TCP port. You can specifically publish a UDP port instead of or in addition to a TCP port. When you publish both TCP and UDP ports, If you omit the protocol specifier, the port is published as a TCP port. If you use the longer syntax (recommended for Docker 1.13 and higher), set the\\xA0protocol\\xA0key to either\\xA0tcp\\xA0or\\xA0udp.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"TCP ONLY\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Long syntax:\")),mdx(\"p\",null,\"$ docker service create --name dns-cache \\\\\"),mdx(\"p\",null,\"--publish published=53,target=53 \\\\\"),mdx(\"p\",null,\"dns-cache\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Short syntax:\")),mdx(\"p\",null,\"$ docker service create --name dns-cache \\\\\"),mdx(\"p\",null,\"-p 53:53 \\\\\"),mdx(\"p\",null,\"dns-cache\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"TCP AND UDP\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Long syntax:\")),mdx(\"p\",null,\"$ docker service create --name dns-cache \\\\\"),mdx(\"p\",null,\"--publish published=53,target=53 \\\\\"),mdx(\"p\",null,\"--publish published=53,target=53,protocol=udp \\\\\"),mdx(\"p\",null,\"dns-cache\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Short syntax:\")),mdx(\"p\",null,\"$ docker service create --name dns-cache \\\\\"),mdx(\"p\",null,\"-p 53:53 \\\\\"),mdx(\"p\",null,\"-p 53:53/udp \\\\\"),mdx(\"p\",null,\"dns-cache\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"UDP ONLY\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Long syntax:\")),mdx(\"p\",null,\"$ docker service create --name dns-cache \\\\\"),mdx(\"p\",null,\"--publish published=53,target=53,protocol=udp \\\\\"),mdx(\"p\",null,\"dns-cache\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Short syntax:\")),mdx(\"p\",null,\"$ docker service create --name dns-cache \\\\\"),mdx(\"p\",null,\"-p 53:53/udp \\\\\"),mdx(\"p\",null,\"dns-cache\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Bypass the routing mesh\")),mdx(\"p\",null,\"You can bypass the routing mesh, so that when you access the bound port on a given node, you are always accessing the instance of the service running on that node. This is referred to as\\xA0hostmode. There are a few things to keep in mind.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"If you access a node which is not running a service task, the service does not listen on that port. It is possible that nothing is listening, or that a completely different application is listening.\"),mdx(\"li\",{parentName:\"ul\"},\"If you expect to run multiple service tasks on each node (such as when you have 5 nodes but run 10 replicas), you cannot specify a static target port. Either allow Docker to assign a random high-numbered port (by leaving off the\\xA0target), or ensure that only a single instance of the service runs on a given node, by using a global service rather than a replicated one, or by using placement constraints.\")),mdx(\"p\",null,\"To bypass the routing mesh, you must use the long\\xA0--publish\\xA0service and set\\xA0mode\\xA0to\\xA0host. If you omit the\\xA0mode\\xA0key or set it to\\xA0ingress, the routing mesh is used. The following command creates a global service using\\xA0host\\xA0mode and bypassing the routing mesh.\"),mdx(\"p\",null,\"$ docker service create --name dns-cache \\\\\"),mdx(\"p\",null,\"--publish published=53,target=53,protocol=udp,mode=host \\\\\"),mdx(\"p\",null,\"--mode global \\\\\"),mdx(\"p\",null,\"dns-cache\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Configure an external load balancer\")),mdx(\"p\",null,\"You can configure an external load balancer for swarm services, either in combination with the routing mesh or without using the routing mesh at all.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Using the routing mesh\")),mdx(\"p\",null,\"You can configure an external load balancer to route requests to a swarm service. For example, you could configure\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://www.haproxy.org/\"}),\"HAProxy\"),\"\\xA0to balance requests to an nginx service published to port 8080.\"),mdx(\"p\",null,\"In this case, port 8080 must be open between the load balancer and the nodes in the swarm. The swarm nodes can reside on a private network that is accessible to the proxy server, but that is not publicly accessible.\"),mdx(\"p\",null,\"You can configure the load balancer to balance requests between every node in the swarm even if there are no tasks scheduled on the node. For example, you could have the following HAProxy configuration in\\xA0/etc/haproxy/haproxy.cfg:\"),mdx(\"p\",null,\"global\"),mdx(\"p\",null,\"log /dev/log local0\"),mdx(\"p\",null,\"log /dev/log local1 notice\"),mdx(\"p\",null,\"...snip...\"),mdx(\"h1\",null,\"Configure HAProxy to listen on port 80\"),mdx(\"p\",null,\"frontend http_front\"),mdx(\"p\",null,\"bind *:80\"),mdx(\"p\",null,\"stats uri /haproxy?stats\"),mdx(\"p\",null,\"default_backend http_back\"),mdx(\"h1\",null,\"Configure HAProxy to route requests to swarm nodes on port 8080\"),mdx(\"p\",null,\"backend http_back\"),mdx(\"p\",null,\"balance roundrobin\"),mdx(\"p\",null,\"server node1 192.168.99.100:8080 check\"),mdx(\"p\",null,\"server node2 192.168.99.101:8080 check\"),mdx(\"p\",null,\"server node3 192.168.99.102:8080 check\"),mdx(\"p\",null,\"When you access the HAProxy load balancer on port 80, it forwards requests to nodes in the swarm. The swarm routing mesh routes the request to an active task. If, for any reason the swarm scheduler dispatches tasks to different nodes, you don't need to reconfigure the load balancer.\"),mdx(\"p\",null,\"You can configure any type of load balancer to route requests to swarm nodes. To learn more about HAProxy, see the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://cbonte.github.io/haproxy-dconv/\"}),\"HAProxy documentation\"),\".\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Without the routing mesh\")),mdx(\"p\",null,\"To use an external load balancer without the routing mesh, set\\xA0--endpoint-mode\\xA0to\\xA0dnsrrinstead of the default value of\\xA0vip. In this case, there is not a single virtual IP. Instead, Docker sets up DNS entries for the service such that a DNS query for the service name returns a list of IP addresses, and the client connects directly to one of these. You are responsible for providing the list of IP addresses and ports to your load balancer. See\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/networking/#configure-service-discovery\"}),\"Configure service discovery\"),\".\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Learn more\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/services/\"}),\"Deploy services to a swarm\"))),mdx(\"h4\",null,\"How Swarm Mode Works\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"How nodes work\")),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA02 minutes\")),mdx(\"p\",null,\"Docker Engine 1.12 introduces swarm mode that enables you to create a cluster of one or more Docker Engines called a swarm. A swarm consists of one or more nodes: physical or virtual machines running Docker Engine 1.12 or later in swarm mode.\"),mdx(\"p\",null,\"There are two types of nodes:\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/how-swarm-mode-works/nodes/#manager-nodes\"}),mdx(\"strong\",{parentName:\"a\"},\"managers\")),\"\\xA0and\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/how-swarm-mode-works/nodes/#worker-nodes\"}),mdx(\"strong\",{parentName:\"a\"},\"workers\")),\".\"),mdx(\"p\",null,\"If you haven't already, read through the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/\"}),\"swarm mode overview\"),\"\\xA0and\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/key-concepts/\"}),\"key concepts\"),\".\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Manager nodes\")),mdx(\"p\",null,\"Manager nodes handle cluster management tasks:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"maintaining cluster state\"),mdx(\"li\",{parentName:\"ul\"},\"scheduling services\"),mdx(\"li\",{parentName:\"ul\"},\"serving swarm mode\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/api/\"}),\"HTTP API endpoints\"))),mdx(\"p\",null,\"Using a\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://raft.github.io/raft.pdf\"}),\"Raft\"),\"\\xA0implementation, the managers maintain a consistent internal state of the entire swarm and all the services running on it. For testing purposes it is OK to run a swarm with a single manager. If the manager in a single-manager swarm fails, your services continue to run, but you need to create a new cluster to recover.\"),mdx(\"p\",null,\"To take advantage of swarm mode's fault-tolerance features, Docker recommends you implement an odd number of nodes according to your organization's high-availability requirements. When you have multiple managers you can recover from the failure of a manager node without downtime.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"A three-manager swarm tolerates a maximum loss of one manager.\"),mdx(\"li\",{parentName:\"ul\"},\"A five-manager swarm tolerates a maximum simultaneous loss of two manager nodes.\"),mdx(\"li\",{parentName:\"ul\"},\"An\\xA0N\\xA0manager cluster tolerates the loss of at most\\xA0(N-1)/2\\xA0managers.\"),mdx(\"li\",{parentName:\"ul\"},\"Docker recommends a maximum of seven manager nodes for a swarm.\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Important Note\"),\": Adding more managers does NOT mean increased scalability or higher performance. In general, the opposite is true.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Worker nodes\")),mdx(\"p\",null,\"Worker nodes are also instances of Docker Engine whose sole purpose is to execute containers. Worker nodes don't participate in the Raft distributed state, make scheduling decisions, or serve the swarm mode HTTP API.\"),mdx(\"p\",null,\"You can create a swarm of one manager node, but you cannot have a worker node without at least one manager node. By default, all managers are also workers. In a single manager node cluster, you can run commands like\\xA0docker service create\\xA0and the scheduler places all tasks on the local Engine.\"),mdx(\"p\",null,\"To prevent the scheduler from placing tasks on a manager node in a multi-node swarm, set the availability for the manager node to\\xA0Drain. The scheduler gracefully stops tasks on nodes in\\xA0Drain\\xA0mode and schedules the tasks on an\\xA0Active\\xA0node. The scheduler does not assign new tasks to nodes with\\xA0Drain\\xA0availability.\"),mdx(\"p\",null,\"Refer to the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/node_update/\"}),\"docker node update\"),\"\\xA0command line reference to see how to change node availability.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Change roles\")),mdx(\"p\",null,\"You can promote a worker node to be a manager by running\\xA0docker node promote. For example, you may want to promote a worker node when you take a manager node offline for maintenance. See\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/node_promote/\"}),\"node promote\"),\".\"),mdx(\"p\",null,\"You can also demote a manager node to a worker node. See\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/node_demote/\"}),\"node demote\"),\".\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Learn more\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Read about how swarm mode\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/how-swarm-mode-works/services/\"}),\"services\"),\"\\xA0work.\"),mdx(\"li\",{parentName:\"ul\"},\"Learn how\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/how-swarm-mode-works/pki/\"}),\"PKI\"),\"\\xA0works in swarm mode.\")),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"How services work\")),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA05 minutes\")),mdx(\"p\",null,\"To deploy an application image when Docker Engine is in swarm mode, you create a service. Frequently a service is the image for a microservice within the context of some larger application. Examples of services might include an HTTP server, a database, or any other type of executable program that you wish to run in a distributed environment.\"),mdx(\"p\",null,\"When you create a service, you specify which container image to use and which commands to execute inside running containers. You also define options for the service including:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"the port where the swarm makes the service available outside the swarm\"),mdx(\"li\",{parentName:\"ul\"},\"an overlay network for the service to connect to other services in the swarm\"),mdx(\"li\",{parentName:\"ul\"},\"CPU and memory limits and reservations\"),mdx(\"li\",{parentName:\"ul\"},\"a rolling update policy\"),mdx(\"li\",{parentName:\"ul\"},\"the number of replicas of the image to run in the swarm\")),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Services, tasks, and containers\")),mdx(\"p\",null,\"When you deploy the service to the swarm, the swarm manager accepts your service definition as the desired state for the service. Then it schedules the service on nodes in the swarm as one or more replica tasks. The tasks run independently of each other on nodes in the swarm.\"),mdx(\"p\",null,\"For example, imagine you want to load balance between three instances of an HTTP listener. The diagram below shows an HTTP listener service with three replicas. Each of the three instances of the listener is a task in the swarm.\"),mdx(\"p\",null,\"A container is an isolated process. In the swarm mode model, each task invokes exactly one container. A task is analogous to a \\\"slot\\\" where the scheduler places a container. Once the container is live, the scheduler recognizes that the task is in a running state. If the container fails health checks or terminates, the task terminates.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Tasks and scheduling\")),mdx(\"p\",null,\"A task is the atomic unit of scheduling within a swarm. When you declare a desired service state by creating or updating a service, the orchestrator realizes the desired state by scheduling tasks. For instance, you define a service that instructs the orchestrator to keep three instances of an HTTP listener running at all times. The orchestrator responds by creating three tasks. Each task is a slot that the scheduler fills by spawning a container. The container is the instantiation of the task. If an HTTP listener task subsequently fails its health check or crashes, the orchestrator creates a new replica task that spawns a new container.\"),mdx(\"p\",null,\"A task is a one-directional mechanism. It progresses monotonically through a series of states: assigned, prepared, running, etc. If the task fails the orchestrator removes the task and its container and then creates a new task to replace it according to the desired state specified by the service.\"),mdx(\"p\",null,\"The underlying logic of Docker swarm mode is a general purpose scheduler and orchestrator. The service and task abstractions themselves are unaware of the containers they implement. Hypothetically, you could implement other types of tasks such as virtual machine tasks or non-containerized process tasks. The scheduler and orchestrator are agnostic about the type of task. However, the current version of Docker only supports container tasks.\"),mdx(\"p\",null,\"The diagram below shows how swarm mode accepts service create requests and schedules tasks to worker nodes.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Pending services\")),mdx(\"p\",null,\"A service may be configured in such a way that no node currently in the swarm can run its tasks. In this case, the service remains in state\\xA0pending. Here are a few examples of when a service might remain in state\\xA0pending.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": If your only intention is to prevent a service from being deployed, scale the service to 0 instead of trying to configure it in such a way that it remains in\\xA0pending.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"If all nodes are paused or drained, and you create a service, it is pending until a node becomes available. In reality, the first node to become available gets all of the tasks, so this is not a good thing to do in a production environment.\"),mdx(\"li\",{parentName:\"ul\"},\"You can reserve a specific amount of memory for a service. If no node in the swarm has the required amount of memory, the service remains in a pending state until a node is available which can run its tasks. If you specify a very large value, such as 500 GB, the task stays pending forever, unless you really have a node which can satisfy it.\"),mdx(\"li\",{parentName:\"ul\"},\"You can impose placement constraints on the service, and the constraints may not be able to be honored at a given time.\")),mdx(\"p\",null,\"This behavior illustrates that the requirements and configuration of your tasks are not tightly tied to the current state of the swarm. As the administrator of a swarm, you declare the desired state of your swarm, and the manager works with the nodes in the swarm to create that state. You do not need to micro-manage the tasks on the swarm.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Replicated and global services\")),mdx(\"p\",null,\"There are two types of service deployments, replicated and global.\"),mdx(\"p\",null,\"For a replicated service, you specify the number of identical tasks you want to run. For example, you decide to deploy an HTTP service with three replicas, each serving the same content.\"),mdx(\"p\",null,\"A global service is a service that runs one task on every node. There is no pre-specified number of tasks. Each time you add a node to the swarm, the orchestrator creates a task and the scheduler assigns the task to the new node. Good candidates for global services are monitoring agents, an anti-virus scanners or other types of containers that you want to run on every node in the swarm.\"),mdx(\"p\",null,\"The diagram below shows a three-service replica in yellow and a global service in gray.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Learn more\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Read about how swarm mode\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/how-swarm-mode-works/nodes/\"}),\"nodes\"),\"\\xA0work.\"),mdx(\"li\",{parentName:\"ul\"},\"Learn how\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/how-swarm-mode-works/pki/\"}),\"PKI\"),\"\\xA0works in swarm mode.\")),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Manage swarm security with public key infrastructure (PKI)\")),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA04 minutes\")),mdx(\"p\",null,\"The swarm mode public key infrastructure (PKI) system built into Docker makes it simple to securely deploy a container orchestration system. The nodes in a swarm use mutual Transport Layer Security (TLS) to authenticate, authorize, and encrypt the communications with other nodes in the swarm.\"),mdx(\"p\",null,\"When you create a swarm by running\\xA0docker swarm init, Docker designates itself as a manager node. By default, the manager node generates a new root Certificate Authority (CA) along with a key pair, which are used to secure communications with other nodes that join the swarm. If you prefer, you can specify your own externally-generated root CA, using the\\xA0--external-ca\\xA0flag of the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/swarm_init/\"}),\"docker swarm init\"),\"\\xA0command.\"),mdx(\"p\",null,\"The manager node also generates two tokens to use when you join additional nodes to the swarm: one\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"worker token\"),\"\\xA0and one\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"manager token\"),\". Each token includes the digest of the root CA's certificate and a randomly generated secret. When a node joins the swarm, the joining node uses the digest to validate the root CA certificate from the remote manager. The remote manager uses the secret to ensure the joining node is an approved node.\"),mdx(\"p\",null,\"Each time a new node joins the swarm, the manager issues a certificate to the node. The certificate contains a randomly generated node ID to identify the node under the certificate common name (CN) and the role under the organizational unit (OU). The node ID serves as the cryptographically secure node identity for the lifetime of the node in the current swarm.\"),mdx(\"p\",null,\"The diagram below illustrates how manager nodes and worker nodes encrypt communications using a minimum of TLS 1.2.\"),mdx(\"p\",null,\"The example below shows the information from a certificate from a worker node:\"),mdx(\"p\",null,\"Certificate:\"),mdx(\"p\",null,\"Data:\"),mdx(\"p\",null,\"Version: 3 (0x2)\"),mdx(\"p\",null,\"Serial Number:\"),mdx(\"p\",null,\"3b:1c:06:91:73:fb:16:ff:69:c3:f7:a2:fe:96:c1:73:e2:80:97:3b\"),mdx(\"p\",null,\"Signature Algorithm: ecdsa-with-SHA256\"),mdx(\"p\",null,\"Issuer: CN=swarm-ca\"),mdx(\"p\",null,\"Validity\"),mdx(\"p\",null,\"Not Before: Aug 30 02:39:00 2016 GMT\"),mdx(\"p\",null,\"Not After : Nov 28 03:39:00 2016 GMT\"),mdx(\"p\",null,\"Subject: O=ec2adilxf4ngv7ev8fwsi61i7, OU=swarm-worker, CN=dw02poa4vqvzxi5c10gm4pq2g\"),mdx(\"p\",null,\"...snip...\"),mdx(\"p\",null,\"By default, each node in the swarm renews its certificate every three months. You can configure this interval by running the\\xA0docker swarm update --cert-expiry \",mdx(\"inlineCode\",{parentName:\"p\"},\"<TIME PERIOD>\"),\"\\xA0command. The minimum rotation value is 1 hour. Refer to the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/swarm_update/\"}),\"docker swarm update\"),\"\\xA0CLI reference for details.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Rotating the CA certificate\")),mdx(\"p\",null,\"In the event that a cluster CA key or a manager node is compromised, you can rotate the swarm root CA so that none of the nodes trust certificates signed by the old root CA anymore.\"),mdx(\"p\",null,\"Run\\xA0docker swarm ca --rotate\\xA0to generate a new CA certificate and key. If you prefer, you can pass the\\xA0--ca-cert\\xA0and\\xA0--external-ca\\xA0flags to specify the root certificate and and to use a root CA external to the swarm. Alternately, you can pass the\\xA0--ca-cert\\xA0and\\xA0--ca-key\\xA0flags to specify the exact certificate and key you would like the swarm to use.\"),mdx(\"p\",null,\"When you issue the\\xA0docker swarm ca --rotate\\xA0command, the following things happen in sequence:\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Docker generates a cross-signed certificate. This means that a version of the new root CA certificate is signed with the old root CA certificate. This cross-signed certificate is used as an intermediate certificate for all new node certificates. This ensures that nodes that still trust the old root CA can still validate a certificate signed by the new CA.\"),mdx(\"li\",{parentName:\"ol\"},\"In Docker 17.06 and higher, Docker also tells all nodes to immediately renew their TLS certificates. This process may take several minutes, depending on the number of nodes in the swarm.\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note: If your swarm has nodes with different Docker versions, the following two things are true:\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},\"Only a manager that is running as the leader\\xA0\",mdx(\"strong\",{parentName:\"li\"},\"and\"),\"\\xA0running Docker 17.06 or higher tells nodes to renew their TLS certificates.\"),mdx(\"li\",{parentName:\"ul\"},\"Only nodes running Docker 17.06 or higher obey this directive.\")))),mdx(\"p\",null,\"For the most predictable behavior, ensure that all swarm nodes are running Docker 17.06 or higher.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"After every node in the swarm has a new TLS certificate signed by the new CA, Docker forgets about the old CA certificate and key material, and tells all the nodes to trust the new CA certificate only.\")),mdx(\"p\",null,\"This also causes a change in the swarm's join tokens. The previous join tokens are no longer valid.\"),mdx(\"p\",null,\"From this point on, all new node certificates issued are signed with the new root CA, and do not contain any intermediates.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Learn More\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Read about how\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/how-swarm-mode-works/nodes/\"}),\"nodes\"),\"\\xA0work.\"),mdx(\"li\",{parentName:\"ul\"},\"Learn how swarm mode\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/how-swarm-mode-works/services/\"}),\"services\"),\"\\xA0work.\")),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Swarm task states\")),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA02 minutes\")),mdx(\"p\",null,\"Docker lets you create services, which can start tasks. A service is a description of a desired state, and a task does the work. Work is scheduled on swarm nodes in this sequence:\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Create a service by using\\xA0docker service create\\xA0or the UCP web UI or CLI.\"),mdx(\"li\",{parentName:\"ol\"},\"The request goes to a Docker manager node.\"),mdx(\"li\",{parentName:\"ol\"},\"The Docker manager node schedules the service to run on particular nodes.\"),mdx(\"li\",{parentName:\"ol\"},\"Each service can start multiple tasks.\"),mdx(\"li\",{parentName:\"ol\"},\"Each task has a life cycle, with states like\\xA0NEW,\\xA0PENDING, and\\xA0COMPLETE.\")),mdx(\"p\",null,\"Tasks are execution units that run once to completion. When a task stops, it isn't executed again, but a new task may take its place.\"),mdx(\"p\",null,\"Tasks advance through a number of states until they complete or fail. Tasks are initialized in the\\xA0NEW\\xA0state. The task progresses forward through a number of states, and its state doesn't go backward. For example, a task never goes from\\xA0COMPLETE\\xA0to\\xA0RUNNING.\"),mdx(\"p\",null,\"Tasks go through the states in the following order:\"),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Task state\"),\"   \",mdx(\"strong\",{parentName:\"p\"},\"Description\")),mdx(\"hr\",null),mdx(\"p\",null,\"  NEW              The task was initialized.\\nPENDING          Resources for the task were allocated.\\nASSIGNED         Docker assigned the task to nodes.\\nACCEPTED         The task was accepted by a worker node. If a worker node rejects the task, the state changes to\\xA0REJECTED.\\nPREPARING        Docker is preparing the task.\\nSTARTING         Docker is starting the task.\\nRUNNING          The task is executing.\\nCOMPLETE         The task exited without an error code.\\nFAILED           The task exited with an error code.\\nSHUTDOWN         Docker requested the task to shut down.\\nREJECTED         The worker node rejected the task.\\nORPHANED         The node was down for too long.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"View task state\")),mdx(\"p\",null,\"Run\\xA0docker service ps \",mdx(\"inlineCode\",{parentName:\"p\"},\"<service-name>\"),\"\\xA0to get the state of a task. The\\xA0CURRENT STATE\\xA0field shows the task's state and how long it's been there.\"),mdx(\"p\",null,\"$ docker service ps webserver\"),mdx(\"p\",null,\"ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS\"),mdx(\"p\",null,\"owsz0yp6z375 webserver.1 nginx UbuntuVM Running Running 44 seconds ago\"),mdx(\"p\",null,\"j91iahr8s74p \",\"_\",\" webserver.1 nginx UbuntuVM Shutdown Failed 50 seconds ago \\\"No such container: webserver....\\\"\"),mdx(\"p\",null,\"7dyaszg13mw2 \",\"_\",\" webserver.1 nginx UbuntuVM Shutdown Failed 5 hours ago \\\"No such container: webserver....\\\"\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Where to go next\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://github.com/docker/swarmkit/blob/master/design/task_model.md\"}),\"Learn about swarm tasks\"))),mdx(\"h4\",null,\"Run Docker Engine in swarm mode\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA05 minutes\")),mdx(\"p\",null,\"When you first install and start working with Docker Engine, swarm mode is disabled by default. When you enable swarm mode, you work with the concept of services managed through the\\xA0docker service\\xA0command.\"),mdx(\"p\",null,\"There are two ways to run the Engine in swarm mode:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Create a new swarm, covered in this article.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/join-nodes/\"}),\"Join an existing swarm\"),\".\")),mdx(\"p\",null,\"When you run the Engine in swarm mode on your local machine, you can create and test services based upon images you've created or other available images. In your production environment, swarm mode provides a fault-tolerant platform with cluster management features to keep your services running and available.\"),mdx(\"p\",null,\"These instructions assume you have installed the Docker Engine 1.12 or later on a machine to serve as a manager node in your swarm.\"),mdx(\"p\",null,\"If you haven't already, read through the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/key-concepts/\"}),\"swarm mode key concepts\"),\"\\xA0and try the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/swarm-tutorial/\"}),\"swarm mode tutorial\"),\".\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Create a swarm\")),mdx(\"p\",null,\"When you run the command to create a swarm, the Docker Engine starts running in swarm mode.\"),mdx(\"p\",null,\"Run\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/swarm_init/\"}),\"docker swarm init\"),\"\\xA0to create a single-node swarm on the current node. The Engine sets up the swarm as follows:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"switches the current node into swarm mode.\"),mdx(\"li\",{parentName:\"ul\"},\"creates a swarm named\\xA0default.\"),mdx(\"li\",{parentName:\"ul\"},\"designates the current node as a leader manager node for the swarm.\"),mdx(\"li\",{parentName:\"ul\"},\"names the node with the machine hostname.\"),mdx(\"li\",{parentName:\"ul\"},\"configures the manager to listen on an active network interface on port 2377.\"),mdx(\"li\",{parentName:\"ul\"},\"sets the current node to\\xA0Active\\xA0availability, meaning it can receive tasks from the scheduler.\"),mdx(\"li\",{parentName:\"ul\"},\"starts an internal distributed data store for Engines participating in the swarm to maintain a consistent view of the swarm and all services running on it.\"),mdx(\"li\",{parentName:\"ul\"},\"by default, generates a self-signed root CA for the swarm.\"),mdx(\"li\",{parentName:\"ul\"},\"by default, generates tokens for worker and manager nodes to join the swarm.\"),mdx(\"li\",{parentName:\"ul\"},\"creates an overlay network named\\xA0ingress\\xA0for publishing service ports external to the swarm.\")),mdx(\"p\",null,\"The output for\\xA0docker swarm init\\xA0provides the connection command to use when you join new worker nodes to the swarm:\"),mdx(\"p\",null,\"$ docker swarm init\"),mdx(\"p\",null,\"Swarm initialized: current node (dxn1zf6l61qsb1josjja83ngz) is now a manager.\"),mdx(\"p\",null,\"To add a worker to this swarm, run the following command:\"),mdx(\"p\",null,\"docker swarm join \\\\\"),mdx(\"p\",null,\"--token SWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c \\\\\"),mdx(\"p\",null,\"192.168.99.100:2377\"),mdx(\"p\",null,\"To add a manager to this swarm, run \\\\'docker swarm join-token manager\\\\' and follow the instructions.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Configure the advertise address\")),mdx(\"p\",null,\"Manager nodes use an advertise address to allow other nodes in the swarm access to the Swarmkit API and overlay networking. The other nodes on the swarm must be able to access the manager node on its advertise address.\"),mdx(\"p\",null,\"If you don't specify an advertise address, Docker checks if the system has a single IP address. If so, Docker uses the IP address with the listening port\\xA02377\\xA0by default. If the system has multiple IP addresses, you must specify the correct\\xA0--advertise-addr\\xA0to enable inter-manager communication and overlay networking:\"),mdx(\"p\",null,\"$ docker swarm init --advertise-addr \",mdx(\"inlineCode\",{parentName:\"p\"},\"<MANAGER-IP>\")),mdx(\"p\",null,\"You must also specify the\\xA0--advertise-addr\\xA0if the address where other nodes reach the first manager node is not the same address the manager sees as its own. For instance, in a cloud setup that spans different regions, hosts have both internal addresses for access within the region and external addresses that you use for access from outside that region. In this case, specify the external address with\\xA0--advertise-addr\\xA0so that the node can propagate that information to other nodes that subsequently connect to it.\"),mdx(\"p\",null,\"Refer to the\\xA0docker swarm init\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/swarm_init/\"}),\"CLI reference\"),\"\\xA0for more detail on the advertise address.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"View the join command or update a swarm join token\")),mdx(\"p\",null,\"Nodes require a secret token to join the swarm. The token for worker nodes is different from the token for manager nodes. Nodes only use the join-token at the moment they join the swarm. Rotating the join token after a node has already joined a swarm does not affect the node's swarm membership. Token rotation ensures an old token cannot be used by any new nodes attempting to join the swarm.\"),mdx(\"p\",null,\"To retrieve the join command including the join token for worker nodes, run:\"),mdx(\"p\",null,\"$ docker swarm join-token worker\"),mdx(\"p\",null,\"To add a worker to this swarm, run the following command:\"),mdx(\"p\",null,\"docker swarm join \\\\\"),mdx(\"p\",null,\"--token SWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c \\\\\"),mdx(\"p\",null,\"192.168.99.100:2377\"),mdx(\"p\",null,\"This node joined a swarm as a worker.\"),mdx(\"p\",null,\"To view the join command and token for manager nodes, run:\"),mdx(\"p\",null,\"$ docker swarm join-token manager\"),mdx(\"p\",null,\"To add a worker to this swarm, run the following command:\"),mdx(\"p\",null,\"docker swarm join \\\\\"),mdx(\"p\",null,\"--token SWMTKN-1-59egwe8qangbzbqb3ryawxzk3jn97ifahlsrw01yar60pmkr90-bdjfnkcflhooyafetgjod97sz \\\\\"),mdx(\"p\",null,\"192.168.99.100:2377\"),mdx(\"p\",null,\"Pass the\\xA0--quiet\\xA0flag to print only the token:\"),mdx(\"p\",null,\"$ docker swarm join-token --quiet worker\"),mdx(\"p\",null,\"SWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c\"),mdx(\"p\",null,\"Be careful with the join tokens because they are the secrets necessary to join the swarm. In particular, checking a secret into version control is a bad practice because it would allow anyone with access to the application source code to add new nodes to the swarm. Manager tokens are especially sensitive because they allow a new manager node to join and gain control over the whole swarm.\"),mdx(\"p\",null,\"We recommend that you rotate the join tokens in the following circumstances:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"If a token was checked-in by accident into a version control system, group chat or accidentally printed to your logs.\"),mdx(\"li\",{parentName:\"ul\"},\"If you suspect a node has been compromised.\"),mdx(\"li\",{parentName:\"ul\"},\"If you wish to guarantee that no new nodes can join the swarm.\")),mdx(\"p\",null,\"Additionally, it is a best practice to implement a regular rotation schedule for any secret including swarm join tokens. We recommend that you rotate your tokens at least every 6 months.\"),mdx(\"p\",null,\"Run\\xA0swarm join-token --rotate\\xA0to invalidate the old token and generate a new token. Specify whether you want to rotate the token for\\xA0worker\\xA0or\\xA0manager\\xA0nodes:\"),mdx(\"p\",null,\"$ docker swarm join-token --rotate worker\"),mdx(\"p\",null,\"To add a worker to this swarm, run the following command:\"),mdx(\"p\",null,\"docker swarm join \\\\\"),mdx(\"p\",null,\"--token SWMTKN-1-2kscvs0zuymrsc9t0ocyy1rdns9dhaodvpl639j2bqx55uptag-ebmn5u927reawo27s3azntd44 \\\\\"),mdx(\"p\",null,\"192.168.99.100:2377\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Learn more\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/join-nodes/\"}),\"Join nodes to a swarm\")),mdx(\"li\",{parentName:\"ul\"},\"swarm init\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/swarm_init/\"}),\"command line reference\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/swarm-tutorial/\"}),\"Swarm mode tutorial\"))),mdx(\"h4\",null,\"Join nodes to a swarm\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA03 minutes\")),mdx(\"p\",null,\"When you first create a swarm, you place a single Docker Engine (Engine) into swarm mode. To take full advantage of swarm mode you can add nodes to the swarm:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Adding worker nodes increases capacity. When you deploy a service to a swarm, the Engine schedules tasks on available nodes whether they are worker nodes or manager nodes. When you add workers to your swarm, you increase the scale of the swarm to handle tasks without affecting the manager raft consensus.\"),mdx(\"li\",{parentName:\"ul\"},\"Manager nodes increase fault-tolerance. Manager nodes perform the orchestration and cluster management functions for the swarm. Among manager nodes, a single leader node conducts orchestration tasks. If a leader node goes down, the remaining manager nodes elect a new leader and resume orchestration and maintenance of the swarm state. By default, manager nodes also run tasks.\")),mdx(\"p\",null,\"Before you add nodes to a swarm you must install Docker Engine 1.12 or later on the host machine.\"),mdx(\"p\",null,\"The Docker Engine joins the swarm depending on the\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"join-token\"),\"\\xA0you provide to the\\xA0docker swarm join\\xA0command. The node only uses the token at join time. If you subsequently rotate the token, it doesn't affect existing swarm nodes. Refer to\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/swarm-mode/#view-the-join-command-or-update-a-swarm-join-token\"}),\"Run Docker Engine in swarm mode\"),\".\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Join as a worker node\")),mdx(\"p\",null,\"To retrieve the join command including the join token for worker nodes, run the following command on a manager node:\"),mdx(\"p\",null,\"$ docker swarm join-token worker\"),mdx(\"p\",null,\"To add a worker to this swarm, run the following command:\"),mdx(\"p\",null,\"docker swarm join \\\\\"),mdx(\"p\",null,\"--token SWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c \\\\\"),mdx(\"p\",null,\"192.168.99.100:2377\"),mdx(\"p\",null,\"Run the command from the output on the worker to join the swarm:\"),mdx(\"p\",null,\"$ docker swarm join \\\\\"),mdx(\"p\",null,\"--token SWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c \\\\\"),mdx(\"p\",null,\"192.168.99.100:2377\"),mdx(\"p\",null,\"This node joined a swarm as a worker.\"),mdx(\"p\",null,\"The\\xA0docker swarm join\\xA0command does the following:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"switches the Docker Engine on the current node into swarm mode.\"),mdx(\"li\",{parentName:\"ul\"},\"requests a TLS certificate from the manager.\"),mdx(\"li\",{parentName:\"ul\"},\"names the node with the machine hostname\"),mdx(\"li\",{parentName:\"ul\"},\"joins the current node to the swarm at the manager listen address based upon the swarm token.\"),mdx(\"li\",{parentName:\"ul\"},\"sets the current node to\\xA0Active\\xA0availability, meaning it can receive tasks from the scheduler.\"),mdx(\"li\",{parentName:\"ul\"},\"extends the\\xA0ingress\\xA0overlay network to the current node.\")),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Join as a manager node\")),mdx(\"p\",null,\"When you run\\xA0docker swarm join\\xA0and pass the manager token, the Docker Engine switches into swarm mode the same as for workers. Manager nodes also participate in the raft consensus. The new nodes should be\\xA0Reachable, but the existing manager remains the swarm\\xA0Leader.\"),mdx(\"p\",null,\"Docker recommends three or five manager nodes per cluster to implement high availability. Because swarm mode manager nodes share data using Raft, there must be an odd number of managers. The swarm can continue to function after as long as a quorum of more than half of the manager nodes are available.\"),mdx(\"p\",null,\"For more detail about swarm managers and administering a swarm, see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/admin_guide/\"}),\"Administer and maintain a swarm of Docker Engines\"),\".\"),mdx(\"p\",null,\"To retrieve the join command including the join token for manager nodes, run the following command on a manager node:\"),mdx(\"p\",null,\"$ docker swarm join-token manager\"),mdx(\"p\",null,\"To add a manager to this swarm, run the following command:\"),mdx(\"p\",null,\"docker swarm join \\\\\"),mdx(\"p\",null,\"--token SWMTKN-1-61ztec5kyafptydic6jfc1i33t37flcl4nuipzcusor96k7kby-5vy9t8u35tuqm7vh67lrz9xp6 \\\\\"),mdx(\"p\",null,\"192.168.99.100:2377\"),mdx(\"p\",null,\"Run the command from the output on the manager to join the swarm:\"),mdx(\"p\",null,\"$ docker swarm join \\\\\"),mdx(\"p\",null,\"--token SWMTKN-1-61ztec5kyafptydic6jfc1i33t37flcl4nuipzcusor96k7kby-5vy9t8u35tuqm7vh67lrz9xp6 \\\\\"),mdx(\"p\",null,\"192.168.99.100:2377\"),mdx(\"p\",null,\"This node joined a swarm as a manager.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Learn More\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"swarm join\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/swarm_join/\"}),\"command line reference\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/swarm-tutorial/\"}),\"Swarm mode tutorial\"))),mdx(\"h4\",null,\"Manage nodes in a swarm\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA07 minutes\")),mdx(\"p\",null,\"As part of the swarm management lifecycle, you may need to view or update a node as follows:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/manage-nodes/#list-nodes\"}),\"list nodes in the swarm\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/manage-nodes/#inspect-an-individual-node\"}),\"inspect an individual node\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/manage-nodes/#update-a-node\"}),\"update a node\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/manage-nodes/#leave-the-swarm\"}),\"leave the swarm\"))),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"List nodes\")),mdx(\"p\",null,\"To view a list of nodes in the swarm run\\xA0docker node ls\\xA0from a manager node:\"),mdx(\"p\",null,\"$ docker node ls\"),mdx(\"p\",null,\"ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS\"),mdx(\"p\",null,\"46aqrk4e473hjbt745z53cr3t node-5 Ready Active Reachable\"),mdx(\"p\",null,\"61pi3d91s0w3b90ijw3deeb2q node-4 Ready Active Reachable\"),mdx(\"p\",null,\"a5b2m3oghd48m8eu391pefq5u node-3 Ready Active\"),mdx(\"p\",null,\"e7p8btxeu3ioshyuj6lxiv6g0 node-2 Ready Active\"),mdx(\"p\",null,\"ehkv3bcimagdese79dn78otj5 * node-1 Ready Active Leader\"),mdx(\"p\",null,\"The\\xA0AVAILABILITY\\xA0column shows whether or not the scheduler can assign tasks to the node:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Active\\xA0means that the scheduler can assign tasks to the node.\"),mdx(\"li\",{parentName:\"ul\"},\"Pause\\xA0means the scheduler doesn't assign new tasks to the node, but existing tasks remain running.\"),mdx(\"li\",{parentName:\"ul\"},\"Drain\\xA0means the scheduler doesn't assign new tasks to the node. The scheduler shuts down any existing tasks and schedules them on an available node.\")),mdx(\"p\",null,\"The\\xA0MANAGER STATUS\\xA0column shows node participation in the Raft consensus:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"No value indicates a worker node that does not participate in swarm management.\"),mdx(\"li\",{parentName:\"ul\"},\"Leader\\xA0means the node is the primary manager node that makes all swarm management and orchestration decisions for the swarm.\"),mdx(\"li\",{parentName:\"ul\"},\"Reachable\\xA0means the node is a manager node participating in the Raft consensus quorum. If the leader node becomes unavailable, the node is eligible for election as the new leader.\"),mdx(\"li\",{parentName:\"ul\"},\"Unavailable\\xA0means the node is a manager that can't communicate with other managers. If a manager node becomes unavailable, you should either join a new manager node to the swarm or promote a worker node to be a manager.\")),mdx(\"p\",null,\"For more information on swarm administration refer to the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/admin_guide/\"}),\"Swarm administration guide\"),\".\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Inspect an individual node\")),mdx(\"p\",null,\"You can run\\xA0docker node inspect \",mdx(\"inlineCode\",{parentName:\"p\"},\"<NODE-ID>\"),\"\\xA0on a manager node to view the details for an individual node. The output defaults to JSON format, but you can pass the\\xA0--pretty\\xA0flag to print the results in human-readable format. For example:\"),mdx(\"p\",null,\"$ docker node inspect self --pretty\"),mdx(\"p\",null,\"ID: ehkv3bcimagdese79dn78otj5\"),mdx(\"p\",null,\"Hostname: node-1\"),mdx(\"p\",null,\"Joined at: 2016-06-16 22:52:44.9910662 +0000 utc\"),mdx(\"p\",null,\"Status:\"),mdx(\"p\",null,\"State: Ready\"),mdx(\"p\",null,\"Availability: Active\"),mdx(\"p\",null,\"Manager Status:\"),mdx(\"p\",null,\"Address: 172.17.0.2:2377\"),mdx(\"p\",null,\"Raft Status: Reachable\"),mdx(\"p\",null,\"Leader: Yes\"),mdx(\"p\",null,\"Platform:\"),mdx(\"p\",null,\"Operating System: linux\"),mdx(\"p\",null,\"Architecture: x86_64\"),mdx(\"p\",null,\"Resources:\"),mdx(\"p\",null,\"CPUs: 2\"),mdx(\"p\",null,\"Memory: 1.954 GiB\"),mdx(\"p\",null,\"Plugins:\"),mdx(\"p\",null,\"Network: overlay, host, bridge, overlay, null\"),mdx(\"p\",null,\"Volume: local\"),mdx(\"p\",null,\"Engine Version: 1.12.0-dev\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Update a node\")),mdx(\"p\",null,\"You can modify node attributes as follows:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/manage-nodes/#change-node-availability\"}),\"change node availability\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/manage-nodes/#add-or-remove-label-metadata\"}),\"add or remove label metadata\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/manage-nodes/#promote-or-demote-a-node\"}),\"change a node role\"))),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Change node availability\")),mdx(\"p\",null,\"Changing node availability lets you:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"drain a manager node so that only performs swarm management tasks and is unavailable for task assignment.\"),mdx(\"li\",{parentName:\"ul\"},\"drain a node so you can take it down for maintenance.\"),mdx(\"li\",{parentName:\"ul\"},\"pause a node so it can't receive new tasks.\"),mdx(\"li\",{parentName:\"ul\"},\"restore unavailable or paused nodes available status.\")),mdx(\"p\",null,\"For example, to change a manager node to\\xA0Drain\\xA0availability:\"),mdx(\"p\",null,\"$ docker node update --availability drain node-1\"),mdx(\"p\",null,\"node-1\"),mdx(\"p\",null,\"See\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/manage-nodes/#list-nodes\"}),\"list nodes\"),\"\\xA0for descriptions of the different availability options.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Add or remove label metadata\")),mdx(\"p\",null,\"Node labels provide a flexible method of node organization. You can also use node labels in service constraints. Apply constraints when you create a service to limit the nodes where the scheduler assigns tasks for the service.\"),mdx(\"p\",null,\"Run\\xA0docker node update --label-add\\xA0on a manager node to add label metadata to a node. The\\xA0--label-add\\xA0flag supports either a\\xA0\",mdx(\"inlineCode\",{parentName:\"p\"},\"<key>\\xA0or a\\xA0<key>=<value>\"),\"\\xA0pair.\"),mdx(\"p\",null,\"Pass the\\xA0--label-add\\xA0flag once for each node label you want to add:\"),mdx(\"p\",null,\"$ docker node update --label-add foo --label-add bar=baz node-1\"),mdx(\"p\",null,\"node-1\"),mdx(\"p\",null,\"The labels you set for nodes using docker node update apply only to the node entity within the swarm. Do not confuse them with the docker daemon labels for\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/userguide/labels-custom-metadata/#daemon-labels\"}),\"dockerd\"),\".\"),mdx(\"p\",null,\"Therefore, node labels can be used to limit critical tasks to nodes that meet certain requirements. For example, schedule only on machines where special workloads should be run, such as machines that meet\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://www.pcisecuritystandards.org/\"}),\"PCI-SS compliance\"),\".\"),mdx(\"p\",null,\"A compromised worker could not compromise these special workloads because it cannot change node labels.\"),mdx(\"p\",null,\"Engine labels, however, are still useful because some features that do not affect secure orchestration of containers might be better off set in a decentralized manner. For instance, an engine could have a label to indicate that it has a certain type of disk device, which may not be relevant to security directly. These labels are more easily \\\"trusted\\\" by the swarm orchestrator.\"),mdx(\"p\",null,\"Refer to the\\xA0docker service create\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/service_create/\"}),\"CLI reference\"),\"\\xA0for more information about service constraints.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Promote or demote a node\")),mdx(\"p\",null,\"You can promote a worker node to the manager role. This is useful when a manager node becomes unavailable or if you want to take a manager offline for maintenance. Similarly, you can demote a manager node to the worker role.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": Regardless of your reason to promote or demote a node, you must always maintain a quorum of manager nodes in the swarm. For more information refer to the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/admin_guide/\"}),\"Swarm administration guide\"),\".\"),mdx(\"p\",null,\"To promote a node or set of nodes, run\\xA0docker node promote\\xA0from a manager node:\"),mdx(\"p\",null,\"$ docker node promote node-3 node-2\"),mdx(\"p\",null,\"Node node-3 promoted to a manager in the swarm.\"),mdx(\"p\",null,\"Node node-2 promoted to a manager in the swarm.\"),mdx(\"p\",null,\"To demote a node or set of nodes, run\\xA0docker node demote\\xA0from a manager node:\"),mdx(\"p\",null,\"$ docker node demote node-3 node-2\"),mdx(\"p\",null,\"Manager node-3 demoted in the swarm.\"),mdx(\"p\",null,\"Manager node-2 demoted in the swarm.\"),mdx(\"p\",null,\"docker node promote\\xA0and\\xA0docker node demote\\xA0are convenience commands fordocker node update --role manager\\xA0and\\xA0docker node update --role worker\\xA0respectively.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Install plugins on swarm nodes\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Edge only\"),\": This option is only available in Docker CE Edge versions. See\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/edge/\"}),\"Docker CE Edge\"),\".\"),mdx(\"p\",null,\"If your swarm service relies on one or more\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/extend/plugin_api/\"}),\"plugins\"),\", these plugins need to be available on every node where the service could potentially be deployed. You can manually install the plugin on each node or script the installation. In Docker 17.07 and higher, you can also deploy the plugin in a similar way as a global service using the Docker API, by specifying a\\xA0PluginSpec\\xA0instead of a\\xA0ContainerSpec.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": There is currently no way to deploy a plugin to a swarm using the Docker CLI or Docker Compose. In addition, it is not possible to install plugins from a private repository.\"),mdx(\"p\",null,\"The\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/extend/plugin_api/#json-specification\"}),\"PluginSpec\"),\"\\xA0is defined by the plugin developer. To add the plugin to all Docker nodes, use the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/v1.31/#operation/ServiceCreate\"}),\"service/create\"),\"\\xA0API, passing the\\xA0PluginSpec\\xA0JSON defined in the\\xA0TaskTemplate.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Leave the swarm\")),mdx(\"p\",null,\"Run the\\xA0docker swarm leave\\xA0command on a node to remove it from the swarm.\"),mdx(\"p\",null,\"For example to leave the swarm on a worker node:\"),mdx(\"p\",null,\"$ docker swarm leave\"),mdx(\"p\",null,\"Node left the swarm.\"),mdx(\"p\",null,\"When a node leaves the swarm, the Docker Engine stops running in swarm mode. The orchestrator no longer schedules tasks to the node.\"),mdx(\"p\",null,\"If the node is a manager node, you receive a warning about maintaining the quorum. To override the warning, pass the\\xA0--force\\xA0flag. If the last manager node leaves the swarm, the swarm becomes unavailable requiring you to take disaster recovery measures.\"),mdx(\"p\",null,\"For information about maintaining a quorum and disaster recovery, refer to the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/admin_guide/\"}),\"Swarm administration guide\"),\".\"),mdx(\"p\",null,\"After a node leaves the swarm, you can run the\\xA0docker node rm\\xA0command on a manager node to remove the node from the node list.\"),mdx(\"p\",null,\"For instance:\"),mdx(\"p\",null,\"$ docker node rm node-2\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Learn more\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/admin_guide/\"}),\"Swarm administration guide\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/docker/\"}),\"Docker Engine command line reference\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/swarm-tutorial/\"}),\"Swarm mode tutorial\"))),mdx(\"h4\",null,\"Deploy services to a swarm\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA037 minutes\")),mdx(\"p\",null,\"Swarm services use a\\xA0declarative\\xA0model, which means that you define the desired state of the service, and rely upon Docker to maintain this state. The state includes information such as (but not limited to):\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"the image name and tag the service containers should run\"),mdx(\"li\",{parentName:\"ul\"},\"how many containers participate in the service\"),mdx(\"li\",{parentName:\"ul\"},\"whether any ports are exposed to clients outside the swarm\"),mdx(\"li\",{parentName:\"ul\"},\"whether the service should start automatically when Docker starts\"),mdx(\"li\",{parentName:\"ul\"},\"the specific behavior that happens when the service is restarted (such as whether a rolling restart is used)\"),mdx(\"li\",{parentName:\"ul\"},\"characteristics of the nodes where the service can run (such as resource constraints and placement preferences)\")),mdx(\"p\",null,\"For an overview of swarm mode, see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/key-concepts/\"}),\"Swarm mode key concepts\"),\". For an overview of how services work, see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/how-swarm-mode-works/services/\"}),\"How services work\"),\".\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Create a service\")),mdx(\"p\",null,\"To create a single-replica service with no extra configuration, you only need to supply the image name. This command starts an Nginx service with a randomly-generated name and no published ports. This is a naive example, since you can't interact with the Nginx service.\"),mdx(\"p\",null,\"$ docker service create nginx\"),mdx(\"p\",null,\"The service is scheduled on an available node. To confirm that the service was created and started successfully, use the\\xA0docker service ls\\xA0command:\"),mdx(\"p\",null,\"$ docker service ls\"),mdx(\"p\",null,\"ID NAME MODE REPLICAS IMAGE PORTS\"),mdx(\"p\",null,\"a3iixnklxuem quizzical_lamarr replicated 1/1 docker.io/library/nginx\\\\@sha256:41ad9967ea448d7c2b203c699b429abe1ed5af331cd92533900c6d77490e0268\"),mdx(\"p\",null,\"Created services do not always run right away. A service can be in a pending state if its image is unavailable, if no node meets the requirements you configure for the service, or other reasons. See\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/how-swarm-mode-works/services/#pending-services\"}),\"Pending services\"),\"\\xA0for more information.\"),mdx(\"p\",null,\"To provide a name for your service, use the\\xA0--name\\xA0flag:\"),mdx(\"p\",null,\"$ docker service create --name my_web nginx\"),mdx(\"p\",null,\"Just like with standalone containers, you can specify a command that the service's containers should run, by adding it after the image name. This example starts a service called\\xA0helloworldwhich uses an\\xA0alpine\\xA0image and runs the command\\xA0ping docker.com:\"),mdx(\"p\",null,\"$ docker service create --name helloworld alpine ping docker.com\"),mdx(\"p\",null,\"You can also specify an image tag for the service to use. This example modifies the previous one to use the\\xA0alpine:3.6\\xA0tag:\"),mdx(\"p\",null,\"$ docker service create --name helloworld alpine:3.6 ping docker.com\"),mdx(\"p\",null,\"For more details about image tag resolution, see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/services/#specify-the-image-version-the-service-should-use\"}),\"Specify the image version the service should use\"),\".\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Create a service using an image on a private registry\")),mdx(\"p\",null,\"If your image is available on a private registry which requires login, use the--with-registry-auth\\xA0flag with\\xA0docker service create, after logging in. If your image is stored on\\xA0registry.example.com, which is a private registry, use a command like the following:\"),mdx(\"p\",null,\"$ docker login registry.example.com\"),mdx(\"p\",null,\"$ docker service create \\\\\"),mdx(\"p\",null,\"--with-registry-auth \\\\\"),mdx(\"p\",null,\"--name my_service \\\\\"),mdx(\"p\",null,\"registry.example.com/acme/my_image:latest\"),mdx(\"p\",null,\"This passes the login token from your local client to the swarm nodes where the service is deployed, using the encrypted WAL logs. With this information, the nodes are able to log into the registry and pull the image.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Update a service\")),mdx(\"p\",null,\"You can change almost everything about an existing service using the\\xA0docker service updatecommand. When you update a service, Docker stops its containers and restarts them with the new configuration.\"),mdx(\"p\",null,\"Since Nginx is a web service, it works much better if you publish port 80 to clients outside the swarm. You can specify this when you create the service, using the\\xA0-p\\xA0or\\xA0--publish\\xA0flag. When updating an existing service, the flag is\\xA0--publish-add. There is also a\\xA0--publish-rm\\xA0flag to remove a port that was previously published.\"),mdx(\"p\",null,\"Assuming that the\\xA0my_web\\xA0service from the previous section still exists, use the following command to update it to publish port 80.\"),mdx(\"p\",null,\"$ docker service update --publish-add 80 my_web\"),mdx(\"p\",null,\"To verify that it worked, use\\xA0docker service ls:\"),mdx(\"p\",null,\"$ docker service ls\"),mdx(\"p\",null,\"ID NAME MODE REPLICAS IMAGE PORTS\"),mdx(\"p\",null,\"4nhxl7oxw5vz my_web replicated 1/1 docker.io/library/nginx\\\\@sha256:41ad9967ea448d7c2b203c699b429abe1ed5af331cd92533900c6d77490e0268 *:0->80/tcp\"),mdx(\"p\",null,\"For more information on how publishing ports works, see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/services/#publish-ports\"}),\"publish ports\"),\".\"),mdx(\"p\",null,\"You can update almost every configuration detail about an existing service, including the image name and tag it runs. See\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/services/#update-a-services-image-after-creation\"}),\"Update a service's image after creation\"),\".\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Remove a service\")),mdx(\"p\",null,\"To remove a service, use the\\xA0docker service remove\\xA0command. You can remove a service by its ID or name, as shown in the output of the\\xA0docker service ls\\xA0command. The following command removes the\\xA0my_web\\xA0service.\"),mdx(\"p\",null,\"$ docker service remove my_web\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Service configuration details\")),mdx(\"p\",null,\"The following sections provide details about service configuration. This topic does not cover every flag or scenario. In almost every instance where you can define a configuration at service creation, you can also update an existing service's configuration in a similar way.\"),mdx(\"p\",null,\"See the command-line references for\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/service_create/\"}),\"docker service create\"),\"\\xA0and\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/service_update/\"}),\"docker service update\"),\", or run one of those commands with the\\xA0--help\\xA0flag.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Configure the runtime environment\")),mdx(\"p\",null,\"You can configure the following options for the runtime environment in the container:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"environment variables using the\\xA0--env\\xA0flag\"),mdx(\"li\",{parentName:\"ul\"},\"the working directory inside the container using the\\xA0--workdir\\xA0flag\"),mdx(\"li\",{parentName:\"ul\"},\"the username or UID using the\\xA0--user\\xA0flag\")),mdx(\"p\",null,\"The following service's containers have an environment variable\\xA0$MYVAR\\xA0set to\\xA0myvalue, run from the\\xA0/tmp/\\xA0directory, and run as the\\xA0my_user\\xA0user.\"),mdx(\"p\",null,\"$ docker service create --name helloworld \\\\\"),mdx(\"p\",null,\"--env MYVAR=myvalue \\\\\"),mdx(\"p\",null,\"--workdir /tmp \\\\\"),mdx(\"p\",null,\"--user my_user \\\\\"),mdx(\"p\",null,\"alpine ping docker.com\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Update the command an existing service runs\")),mdx(\"p\",null,\"To update the command an existing service runs, you can use the\\xA0--args\\xA0flag. The following example updates an existing service called\\xA0helloworld\\xA0so that it runs the command\\xA0ping docker.com\\xA0instead of whatever command it was running before:\"),mdx(\"p\",null,\"$ docker service update --args \\\"ping docker.com\\\" helloworld\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Specify the image version a service should use\")),mdx(\"p\",null,\"When you create a service without specifying any details about the version of the image to use, the service uses the version tagged with the\\xA0latest\\xA0tag. You can force the service to use a specific version of the image in a few different ways, depending on your desired outcome.\"),mdx(\"p\",null,\"An image version can be expressed in several different ways:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"If you specify a tag, the manager (or the Docker client, if you use\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/services/#image_resolution_with_trust\"}),\"content trust\"),\") resolves that tag to a digest. When the request to create a container task is received on a worker node, the worker node only sees the digest, not the tag.\"),mdx(\"li\",{parentName:\"ul\"},\"$ docker service create --name=\\\"myservice\\\" ubuntu:16.04\")),mdx(\"p\",null,\"Some tags represent discrete releases, such as\\xA0ubuntu:16.04. Tags like this almost always resolve to a stable digest over time. It is recommended that you use this kind of tag when possible.\"),mdx(\"p\",null,\"Other types of tags, such as\\xA0latest\\xA0or\\xA0nightly, may resolve to a new digest often, depending on how often an image's author updates the tag. It is not recommended to run services using a tag which is updated frequently, to prevent different service replica tasks from using different image versions.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"If you don't specify a version at all, by convention the image's\\xA0latest\\xA0tag is resolved to a digest. Workers use the image at this digest when creating the service task.\")),mdx(\"p\",null,\"Thus, the following two commands are equivalent:\"),mdx(\"p\",null,\"$ docker service create --name=\\\"myservice\\\" ubuntu\"),mdx(\"p\",null,\"$ docker service create --name=\\\"myservice\\\" ubuntu:latest\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"If you specify a digest directly, that exact version of the image is always used when creating service tasks.\"),mdx(\"li\",{parentName:\"ul\"},\"$ docker service create \\\\\"),mdx(\"li\",{parentName:\"ul\"},\"--name=\\\"myservice\\\" \\\\\"),mdx(\"li\",{parentName:\"ul\"},\"ubuntu:16.04\\\\@sha256:35bc48a1ca97c3971611dc4662d08d131869daa692acb281c7e9e052924e38b1\")),mdx(\"p\",null,\"When you create a service, the image's tag is resolved to the specific digest the tag points to\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"at the time of service creation\"),\". Worker nodes for that service use that specific digest forever unless the service is explicitly updated. This feature is particularly important if you do use often-changing tags such as\\xA0latest, because it ensures that all service tasks use the same version of the image.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": If\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/security/trust/content_trust/\"}),\"content trust\"),\"\\xA0is enabled, the client actually resolves the image's tag to a digest before contacting the swarm manager, to verify that the image is signed. Thus, if you use content trust, the swarm manager receives the request pre-resolved. In this case, if the client cannot resolve the image to a digest, the request fails.\"),mdx(\"p\",null,\"If the manager can't resolve the tag to a digest, each worker node is responsible for resolving the tag to a digest, and different nodes may use different versions of the image. If this happens, a warning like the following is logged, substituting the placeholders for real information.\"),mdx(\"p\",null,\"unable to pin image \",mdx(\"inlineCode\",{parentName:\"p\"},\"<IMAGE-NAME> to digest: <REASON>\")),mdx(\"p\",null,\"To see an image's current digest, issue the command\\xA0docker inspect \",mdx(\"inlineCode\",{parentName:\"p\"},\"<IMAGE>:<TAG>\"),\"\\xA0and look for the\\xA0RepoDigests\\xA0line. The following is the current digest for\\xA0ubuntu:latest\\xA0at the time this content was written. The output is truncated for clarity.\"),mdx(\"p\",null,\"$ docker inspect ubuntu:latest\"),mdx(\"p\",null,\"\\\"RepoDigests\\\": [\"),mdx(\"p\",null,\"\\\"ubuntu\\\\@sha256:35bc48a1ca97c3971611dc4662d08d131869daa692acb281c7e9e052924e38b1\\\"\"),mdx(\"p\",null,\"],\"),mdx(\"p\",null,\"After you create a service, its image is never updated unless you explicitly rundocker service update\\xA0with the\\xA0--image\\xA0flag as described below. Other update operations such as scaling the service, adding or removing networks or volumes, renaming the service, or any other type of update operation do not update the service's image.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Update a service's image after creation\")),mdx(\"p\",null,\"Each tag represents a digest, similar to a Git hash. Some tags, such as\\xA0latest, are updated often to point to a new digest. Others, such as\\xA0ubuntu:16.04, represent a released software version and are not expected to update to point to a new digest often if at all. In Docker 1.13 and higher, when you create a service, it is constrained to create tasks using a specific digest of an image until you update the service using\\xA0service update\\xA0with the\\xA0--image\\xA0flag. If you use an older version of Docker Engine, you must remove and re-create the service to update its image.\"),mdx(\"p\",null,\"When you run\\xA0service update\\xA0with the\\xA0--image\\xA0flag, the swarm manager queries Docker Hub or your private Docker registry for the digest the tag currently points to and updates the service tasks to use that digest.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": If you use\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/services/#image_resolution_with_trust\"}),\"content trust\"),\", the Docker client resolves image and the swarm manager receives the image and digest, rather than a tag.\"),mdx(\"p\",null,\"Usually, the manager can resolve the tag to a new digest and the service updates, redeploying each task to use the new image. If the manager can't resolve the tag or some other problem occurs, the next two sections outline what to expect.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"IF THE MANAGER RESOLVES THE TAG\")),mdx(\"p\",null,\"If the swarm manager can resolve the image tag to a digest, it instructs the worker nodes to redeploy the tasks and use the image at that digest.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"If a worker has cached the image at that digest, it uses it.\"),mdx(\"li\",{parentName:\"ul\"},\"If not, it attempts to pull the image from Docker Hub or the private registry.\",mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},\"If it succeeds, the task is deployed using the new image.\"),mdx(\"li\",{parentName:\"ul\"},\"If the worker fails to pull the image, the service fails to deploy on that worker node. Docker tries again to deploy the task, possibly on a different worker node.\")))),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"IF THE MANAGER CANNOT RESOLVE THE TAG\")),mdx(\"p\",null,\"If the swarm manager cannot resolve the image to a digest, all is not lost:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"The manager instructs the worker nodes to redeploy the tasks using the image at that tag.\"),mdx(\"li\",{parentName:\"ul\"},\"If the worker has a locally cached image that resolves to that tag, it uses that image.\"),mdx(\"li\",{parentName:\"ul\"},\"If the worker does not have a locally cached image that resolves to the tag, the worker tries to connect to Docker Hub or the private registry to pull the image at that tag.\",mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},\"If this succeeds, the worker uses that image.\"),mdx(\"li\",{parentName:\"ul\"},\"If this fails, the task fails to deploy and the manager tries again to deploy the task, possibly on a different worker node.\")))),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Publish ports\")),mdx(\"p\",null,\"When you create a swarm service, you can publish that service's ports to hosts outside the swarm in two ways:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/services/#publish-a%20services-ports-using-the-routing-mesh\"}),\"You can rely on the routing mesh\"),\". When you publish a service port, the swarm makes the service accessible at the target port on every node, regardless of whether there is a task for the service running on that node or not. This is less complex and is the right choice for many types of services.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/services/#publish-a-services-ports-directly-on-the-swarm-node\"}),\"You can publish a service task's port directly on the swarm node\"),\"\\xA0where that service is running. This feature is available in Docker 1.13 and higher. This bypasses the routing mesh and provides the maximum flexibility, including the ability for you to develop your own routing framework. However, you are responsible for keeping track of where each task is running and routing requests to the tasks, and load-balancing across the nodes.\")),mdx(\"p\",null,\"Keep reading for more information and use cases for each of these methods.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"PUBLISH A SERVICE'S PORTS USING THE ROUTING MESH\")),mdx(\"p\",null,\"To publish a service's ports externally to the swarm, use the--publish \",mdx(\"inlineCode\",{parentName:\"p\"},\"<PUBLISHED-PORT>:<SERVICE-PORT>\"),\"\\xA0flag. The swarm makes the service accessible at the published port\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"on every swarm node\"),\". If an external host connects to that port on any swarm node, the routing mesh routes it to a task. The external host does not need to know the IP addresses or internally-used ports of the service tasks to interact with the service. When a user or process connects to a service, any worker node running a service task may respond. For more details about swarm service networking, see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/networking/\"}),\"Manage swarm service networks\"),\".\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Example: Run a three-task Nginx service on 10-node swarm\")),mdx(\"p\",null,\"Imagine that you have a 10-node swarm, and you deploy an Nginx service running three tasks on a 10-node swarm:\"),mdx(\"p\",null,\"$ docker service create --name my_web \\\\\"),mdx(\"p\",null,\"--replicas 3 \\\\\"),mdx(\"p\",null,\"--publish published=8080,target=80 \\\\\"),mdx(\"p\",null,\"nginx\"),mdx(\"p\",null,\"Three tasks run on up to three nodes. You don't need to know which nodes are running the tasks; connecting to port 8080 on\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"any\"),\"\\xA0of the 10 nodes connects you to one of the three\\xA0nginx\\xA0tasks. You can test this using\\xA0curl. The following example assumes that\\xA0localhost\\xA0is one of the swarm nodes. If this is not the case, or\\xA0localhost\\xA0does not resolve to an IP address on your host, substitute the host's IP address or resolvable host name.\"),mdx(\"p\",null,\"The HTML output is truncated:\"),mdx(\"p\",null,\"$ curl localhost:8080\"),mdx(\"p\",null,mdx(\"inlineCode\",{parentName:\"p\"},\"<!DOCTYPE html>\")),mdx(\"p\",null,mdx(\"inlineCode\",{parentName:\"p\"},\"<html>\")),mdx(\"p\",null,mdx(\"inlineCode\",{parentName:\"p\"},\"<head>\")),mdx(\"p\",null,mdx(\"inlineCode\",{parentName:\"p\"},\"<title>Welcome to nginx!</title>\")),mdx(\"p\",null,\"...truncated...\"),mdx(\"p\",null,mdx(\"inlineCode\",{parentName:\"p\"},\"</html>\")),mdx(\"p\",null,\"Subsequent connections may be routed to the same swarm node or a different one.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"PUBLISH A SERVICE'S PORTS DIRECTLY ON THE SWARM NODE\")),mdx(\"p\",null,\"Using the routing mesh may not be the right choice for your application if you need to make routing decisions based on application state or you need total control of the process for routing requests to your service's tasks. To publish a service's port directly on the node where it is running, use the\\xA0mode=host\\xA0option to the\\xA0--publish\\xA0flag.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note: If you publish a service's ports directly on the swarm node using\\xA0mode=host\\xA0and also set\\xA0published=\",mdx(\"inlineCode\",{parentName:\"strong\"},\"<PORT>\"),\"\\xA0this creates an implicit limitation that you can only run one task for that service on a given swarm node. You can work around this by specifying\\xA0published\\xA0without a port definition, which causes Docker to assign a random port for each task.\")),mdx(\"p\",null,\"In addition, if you use\\xA0mode=host\\xA0and you do not use the\\xA0--mode=global\\xA0flag on\\xA0docker service create, it is difficult to know which nodes are running the service to route work to them.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Example: Run a\\xA0nginx\\xA0web server service on every swarm node\")),mdx(\"p\",null,mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://hub.docker.com/_/nginx/\"}),\"nginx\"),\"\\xA0is an open source reverse proxy, load balancer, HTTP cache, and a web server. If you run nginx as a service using the routing mesh, connecting to the nginx port on any swarm node shows you the web page for (effectively)\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"a random swarm node\"),\"\\xA0running the service.\"),mdx(\"p\",null,\"The following example runs nginx as a service on each node in your swarm and exposes nginx port locally on each swarm node.\"),mdx(\"p\",null,\"$ docker service create \\\\\"),mdx(\"p\",null,\"--mode global \\\\\"),mdx(\"p\",null,\"--publish mode=host,target=80,published=8080 \\\\\"),mdx(\"p\",null,\"--name=nginx \\\\\"),mdx(\"p\",null,\"nginx:latest\"),mdx(\"p\",null,\"You can reach the nginx server on port 8080 of every swarm node. If you add a node to the swarm, a nginx task is started on it. You cannot start another service or container on any swarm node which binds to port 8080.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": This is a naive example. Creating an application-layer routing framework for a multi-tiered service is complex and out of scope for this topic.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Connect the service to an overlay network\")),mdx(\"p\",null,\"You can use overlay networks to connect one or more services within the swarm.\"),mdx(\"p\",null,\"First, create overlay network on a manager node using the\\xA0docker network create\\xA0command with the\\xA0--driver overlay\\xA0flag.\"),mdx(\"p\",null,\"$ docker network create --driver overlay my-network\"),mdx(\"p\",null,\"After you create an overlay network in swarm mode, all manager nodes have access to the network.\"),mdx(\"p\",null,\"You can create a new service and pass the\\xA0--network\\xA0flag to attach the service to the overlay network:\"),mdx(\"p\",null,\"$ docker service create \\\\\"),mdx(\"p\",null,\"--replicas 3 \\\\\"),mdx(\"p\",null,\"--network my-network \\\\\"),mdx(\"p\",null,\"--name my-web \\\\\"),mdx(\"p\",null,\"nginx\"),mdx(\"p\",null,\"The swarm extends\\xA0my-network\\xA0to each node running the service.\"),mdx(\"p\",null,\"You can also connect an existing service to an overlay network using the\\xA0--network-add\\xA0flag.\"),mdx(\"p\",null,\"$ docker service update --network-add my-network my-web\"),mdx(\"p\",null,\"To disconnect a running service from a network, use the\\xA0--network-rm\\xA0flag.\"),mdx(\"p\",null,\"$ docker service update --network-rm my-network my-web\"),mdx(\"p\",null,\"For more information on overlay networking and service discovery, refer to\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/networking/\"}),\"Attach services to an overlay network\"),\"\\xA0and\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/userguide/networking/overlay-security-model/\"}),\"Docker swarm mode overlay network security model\"),\".\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Grant a service access to secrets\")),mdx(\"p\",null,\"To create a service with access to Docker-managed secrets, use the\\xA0--secret\\xA0flag. For more information, see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/secrets/\"}),\"Manage sensitive strings (secrets) for Docker services\")),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Customize a service's isolation mode\")),mdx(\"p\",null,\"Docker 17.12 CE and higher allow you to specify a swarm service's isolation mode.\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"This setting applies to Windows hosts only and is ignored for Linux hosts.\"),\"\\xA0The isolation mode can be one of the following:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"default: Use the default isolation mode configured for the Docker host, as configured by the\\xA0-exec-opt\\xA0flag or\\xA0exec-opts\\xA0array in\\xA0daemon.json. If the daemon does not specify an isolation technology,\\xA0process\\xA0is the default for Windows Server, and\\xA0hyperv\\xA0is the default (and only) choice for Windows 10.\"),mdx(\"li\",{parentName:\"ul\"},\"process: Run the service tasks as a separate process on the host.\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\":\\xA0process\\xA0isolation mode is only supported on Windows Server. Windows 10 only supports\\xA0hyperv\\xA0isolation mode.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"hyperv: Run the service tasks as isolated\\xA0hyperv\\xA0tasks. This increases overhead but provides more isolation.\")),mdx(\"p\",null,\"You can specify the isolation mode when creating or updating a new service using the\\xA0--isolation\\xA0flag.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Control service placement\")),mdx(\"p\",null,\"Swarm services provide a few different ways for you to control scale and placement of services on different nodes.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"You can specify whether the service needs to run a specific number of replicas or should run globally on every worker node. See\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/services/#replicated-or-global-services\"}),\"Replicated or global services\"),\".\"),mdx(\"li\",{parentName:\"ul\"},\"You can configure the service's\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/services/#reserve-memory-or-cpus-for-a-service\"}),\"CPU or memory requirements\"),\", and the service only runs on nodes which can meet those requirements.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/services/#placement-constraints\"}),\"Placement constraints\"),\"\\xA0let you configure the service to run only on nodes with specific (arbitrary) metadata set, and cause the deployment to fail if appropriate nodes do not exist. For instance, you can specify that your service should only run on nodes where an arbitrary label\\xA0pci_compliant\\xA0is set to\\xA0true.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/services/#placement-preferences\"}),\"Placement preferences\"),\"\\xA0let you apply an arbitrary label with a range of values to each node, and spread your service's tasks across those nodes using an algorithm. Currently, the only supported algorithm is\\xA0spread, which tries to place them evenly. For instance, if you label each node with a label\\xA0rack\\xA0which has a value from 1-10, then specify a placement preference keyed on\\xA0rack, then service tasks are placed as evenly as possible across all nodes with the label\\xA0rack, after taking other placement constraints, placement preferences, and other node-specific limitations into account.\")),mdx(\"p\",null,\"Unlike constraints, placement preferences are best-effort, and a service does not fail to deploy if no nodes can satisfy the preference. If you specify a placement preference for a service, nodes that match that preference are ranked higher when the swarm managers decide which nodes should run the service tasks. Other factors, such as high availability of the service, also factor into which nodes are scheduled to run service tasks. For example, if you have N nodes with the rack label (and then some others), and your service is configured to run N+1 replicas, the +1 is scheduled on a node that doesn't already have the service on it if there is one, regardless of whether that node has the\\xA0rack\\xA0label or not.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"REPLICATED OR GLOBAL SERVICES\")),mdx(\"p\",null,\"Swarm mode has two types of services: replicated and global. For replicated services, you specify the number of replica tasks for the swarm manager to schedule onto available nodes. For global services, the scheduler places one task on each available node that meets the service's\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/services/#placement-constraints\"}),\"placement constraints\"),\"\\xA0and\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/services/#reserve-cpu-or-memory-for-a-service\"}),\"resource requirements\"),\".\"),mdx(\"p\",null,\"You control the type of service using the\\xA0--mode\\xA0flag. If you don't specify a mode, the service defaults to\\xA0replicated. For replicated services, you specify the number of replica tasks you want to start using the\\xA0--replicas\\xA0flag. For example, to start a replicated nginx service with 3 replica tasks:\"),mdx(\"p\",null,\"$ docker service create \\\\\"),mdx(\"p\",null,\"--name my_web \\\\\"),mdx(\"p\",null,\"--replicas 3 \\\\\"),mdx(\"p\",null,\"nginx\"),mdx(\"p\",null,\"To start a global service on each available node, pass\\xA0--mode global\\xA0to\\xA0docker service create. Every time a new node becomes available, the scheduler places a task for the global service on the new node. For example to start a service that runs alpine on every node in the swarm:\"),mdx(\"p\",null,\"$ docker service create \\\\\"),mdx(\"p\",null,\"--name myservice \\\\\"),mdx(\"p\",null,\"--mode global \\\\\"),mdx(\"p\",null,\"alpine top\"),mdx(\"p\",null,\"Service constraints let you set criteria for a node to meet before the scheduler deploys a service to the node. You can apply constraints to the service based upon node attributes and metadata or engine metadata. For more information on constraints, refer to the\\xA0docker service create\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/service_create/\"}),\"CLI reference\"),\".\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"RESERVE MEMORY OR CPUS FOR A SERVICE\")),mdx(\"p\",null,\"To reserve a given amount of memory or number of CPUs for a service, use the--reserve-memory\\xA0or\\xA0--reserve-cpu\\xA0flags. If no available nodes can satisfy the requirement (for instance, if you request 4 CPUs and no node in the swarm has 4 CPUs), the service remains in a pending state until an appropriate node is available to run its tasks.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Out Of Memory Exceptions (OOME)\")),mdx(\"p\",null,\"If your service attempts to use more memory than the swarm node has available, you may experience an Out Of Memory Exception (OOME) and a container, or the Docker daemon, might be killed by the kernel OOM killer. To prevent this from happening, ensure that your application runs on hosts with adequate memory and see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/admin/resource_constraints/#understand-the-risks-of-running-out-of-memory\"}),\"Understand the risks of running out of memory\"),\".\"),mdx(\"p\",null,\"Swarm services allow you to use resource constraints, placement preferences, and labels to ensure that your service is deployed to the appropriate swarm nodes.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"PLACEMENT CONSTRAINTS\")),mdx(\"p\",null,\"Use placement constraints to control the nodes a service can be assigned to. In the following example, the service only runs on nodes with the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/engine/swarm/manage-nodes/#add-or-remove-label-metadata\"}),\"label\"),\"\\xA0region\\xA0set to\\xA0east. If no appropriately-labelled nodes are available, deployment fails. The\\xA0--constraint\\xA0flag uses an equality operator (==\\xA0or\\xA0!=). For replicated services, it is possible that all services run on the same node, or each node only runs one replica, or that some nodes don't run any replicas. For global services, the service runs on every node that meets the placement constraint and any\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/services/#reserve-cpu-or-memory-for-a-service\"}),\"resource requirements\"),\".\"),mdx(\"p\",null,\"$ docker service create \\\\\"),mdx(\"p\",null,\"--name my-nginx \\\\\"),mdx(\"p\",null,\"--replicas 5 \\\\\"),mdx(\"p\",null,\"--constraint region==east \\\\\"),mdx(\"p\",null,\"nginx\"),mdx(\"p\",null,\"You can also use the\\xA0constraint\\xA0service-level key in a\\xA0docker-compose.yml\\xA0file.\"),mdx(\"p\",null,\"If you specify multiple placement constraints, the service only deploys onto nodes where they are all met. The following example limits the service to run on all nodes where\\xA0region\\xA0is set to\\xA0east\\xA0and\\xA0type\\xA0is not set to\\xA0devel:\"),mdx(\"p\",null,\"$ docker service create \\\\\"),mdx(\"p\",null,\"--name my-nginx \\\\\"),mdx(\"p\",null,\"--global \\\\\"),mdx(\"p\",null,\"--constraint region==east \\\\\"),mdx(\"p\",null,\"--constraint type!=devel \\\\\"),mdx(\"p\",null,\"nginx\"),mdx(\"p\",null,\"You can also use placement constraints in conjunction with placement preferences and CPU/memory constraints. Be careful not to use settings that are not possible to fulfill.\"),mdx(\"p\",null,\"For more information on constraints, refer to the\\xA0docker service create\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/service_create/\"}),\"CLI reference\"),\".\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"PLACEMENT PREFERENCES\")),mdx(\"p\",null,\"While\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/services/#placement-constraints\"}),\"placement constraints\"),\"\\xA0limit the nodes a service can run on,\\xA0placement preferences\\xA0try to place services on appropriate nodes in an algorithmic way (currently, only spread evenly). For instance, if you assign each node a\\xA0rack\\xA0label, you can set a placement preference to spread the service evenly across nodes with the\\xA0rack\\xA0label, by value. This way, if you lose a rack, the service is still running on nodes on other racks.\"),mdx(\"p\",null,\"Placement preferences are not strictly enforced. If no node has the label you specify in your preference, the service is deployed as though the preference were not set.\"),mdx(\"p\",null,\"Placement preferences are ignored for global services.\"),mdx(\"p\",null,\"The following example sets a preference to spread the deployment across nodes based on the value of the\\xA0datacenter\\xA0label. If some nodes have\\xA0datacenter=us-east\\xA0and others have\\xA0datacenter=us-west, the service is deployed as evenly as possible across the two sets of nodes.\"),mdx(\"p\",null,\"$ docker service create \\\\\"),mdx(\"p\",null,\"--replicas 9 \\\\\"),mdx(\"p\",null,\"--name redis_2 \\\\\"),mdx(\"p\",null,\"--placement-pref \\\\'spread=node.labels.datacenter\\\\' \\\\\"),mdx(\"p\",null,\"redis:3.0.6\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Missing or null labels\")),mdx(\"p\",null,\"Nodes which are missing the label used to spread still receive task assignments. As a group, these nodes receive tasks in equal proportion to any of the other groups identified by a specific label value. In a sense, a missing label is the same as having the label with a null value attached to it. If the service should\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"only\"),\"\\xA0run on nodes with the label being used for the the spread preference, the preference should be combined with a constraint.\"),mdx(\"p\",null,\"You can specify multiple placement preferences, and they are processed in the order they are encountered. The following example sets up a service with multiple placement preferences. Tasks are spread first over the various datacenters, and then over racks (as indicated by the respective labels):\"),mdx(\"p\",null,\"$ docker service create \\\\\"),mdx(\"p\",null,\"--replicas 9 \\\\\"),mdx(\"p\",null,\"--name redis_2 \\\\\"),mdx(\"p\",null,\"--placement-pref \\\\'spread=node.labels.datacenter\\\\' \\\\\"),mdx(\"p\",null,\"--placement-pref \\\\'spread=node.labels.rack\\\\' \\\\\"),mdx(\"p\",null,\"redis:3.0.6\"),mdx(\"p\",null,\"You can also use placement preferences in conjunction with placement constraints or CPU/memory constraints. Be careful not to use settings that are not possible to fulfill.\"),mdx(\"p\",null,\"This diagram illustrates how placement preferences work:\"),mdx(\"p\",null,\"When updating a service with\\xA0docker service update,\\xA0--placement-pref-add\\xA0appends a new placement preference after all existing placement preferences.\\xA0--placement-pref-rm\\xA0removes an existing placement preference that matches the argument.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Configure a service's update behavior\")),mdx(\"p\",null,\"When you create a service, you can specify a rolling update behavior for how the swarm should apply changes to the service when you run\\xA0docker service update. You can also specify these flags as part of the update, as arguments to\\xA0docker service update.\"),mdx(\"p\",null,\"The\\xA0--update-delay\\xA0flag configures the time delay between updates to a service task or sets of tasks. You can describe the time\\xA0T\\xA0as a combination of the number of seconds\\xA0Ts, minutes\\xA0Tm, or hours\\xA0Th. So\\xA010m30s\\xA0indicates a 10 minute 30 second delay.\"),mdx(\"p\",null,\"By default the scheduler updates 1 task at a time. You can pass the\\xA0--update-parallelism\\xA0flag to configure the maximum number of service tasks that the scheduler updates simultaneously.\"),mdx(\"p\",null,\"When an update to an individual task returns a state of\\xA0RUNNING, the scheduler continues the update by continuing to another task until all tasks are updated. If, at any time during an update a task returns\\xA0FAILED, the scheduler pauses the update. You can control the behavior using the\\xA0--update-failure-action\\xA0flag for\\xA0docker service create\\xA0or\\xA0docker service update.\"),mdx(\"p\",null,\"In the example service below, the scheduler applies updates to a maximum of 2 replicas at a time. When an updated task returns either\\xA0RUNNING\\xA0or\\xA0FAILED, the scheduler waits 10 seconds before stopping the next task to update:\"),mdx(\"p\",null,\"$ docker service create \\\\\"),mdx(\"p\",null,\"--replicas 10 \\\\\"),mdx(\"p\",null,\"--name my_web \\\\\"),mdx(\"p\",null,\"--update-delay 10s \\\\\"),mdx(\"p\",null,\"--update-parallelism 2 \\\\\"),mdx(\"p\",null,\"--update-failure-action continue \\\\\"),mdx(\"p\",null,\"alpine\"),mdx(\"p\",null,\"The\\xA0--update-max-failure-ratio\\xA0flag controls what fraction of tasks can fail during an update before the update as a whole is considered to have failed. For example, with\\xA0--update-max-failure-ratio 0.1 --update-failure-action pause, after 10% of the tasks being updated fail, the update is paused.\"),mdx(\"p\",null,\"An individual task update is considered to have failed if the task doesn't start up, or if it stops running within the monitoring period specified with the\\xA0--update-monitor\\xA0flag. The default value for\\xA0--update-monitor\\xA0is 30 seconds, which means that a task failing in the first 30 seconds after its started counts towards the service update failure threshold, and a failure after that is not counted.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Roll back to the previous version of a service\")),mdx(\"p\",null,\"In case the updated version of a service doesn't function as expected, it's possible to manually roll back to the previous version of the service using\\xA0docker service update's\\xA0--rollback\\xA0flag. This reverts the service to the configuration that was in place before the most recentdocker service update\\xA0command.\"),mdx(\"p\",null,\"Other options can be combined with\\xA0--rollback; for example,\\xA0--update-delay 0s\\xA0to execute the rollback without a delay between tasks:\"),mdx(\"p\",null,\"$ docker service update \\\\\"),mdx(\"p\",null,\"--rollback \\\\\"),mdx(\"p\",null,\"--update-delay 0s\"),mdx(\"p\",null,\"my_web\"),mdx(\"p\",null,\"In Docker 17.04 and higher, you can configure a service to roll back automatically if a service update fails to deploy. See\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/services/#automatically-roll-back-if-an-update-fails\"}),\"Automatically roll back if an update fails\"),\".\"),mdx(\"p\",null,\"Related to the new automatic rollback feature, in Docker 17.04 and higher, manual rollback is handled at the server side, rather than the client, if the daemon is running Docker 17.04 or higher. This allows manually-initiated rollbacks to respect the new rollback parameters. The client is version-aware, so it still uses the old method against an older daemon.\"),mdx(\"p\",null,\"Finally, in Docker 17.04 and higher,\\xA0--rollback\\xA0cannot be used in conjunction with other flags to\\xA0docker service update.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Automatically roll back if an update fails\")),mdx(\"p\",null,\"You can configure a service in such a way that if an update to the service causes redeployment to fail, the service can automatically roll back to the previous configuration. This helps protect service availability. You can set one or more of the following flags at service creation or update. If you do not set a value, the default is used.\"),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Flag\"),\"                        \",mdx(\"strong\",{parentName:\"p\"},\"Default\"),\"   \",mdx(\"strong\",{parentName:\"p\"},\"Description\")),mdx(\"hr\",null),mdx(\"p\",null,\"  --rollback-delay               0s            Amount of time to wait after rolling back a task before rolling back the next one. A value of\\xA00means to roll back the second task immediately after the first rolled-back task deploys.\\n--rollback-failure-action      pause         When a task fails to roll back, whether to\\xA0pauseor\\xA0continue\\xA0trying to roll back other tasks.\\n--rollback-max-failure-ratio   0             The failure rate to tolerate during a rollback, specified as a floating-point number between 0 and 1. For instance, given 5 tasks, a failure ratio of\\xA0.2\\xA0would tolerate one task failing to roll back. A value of\\xA00\\xA0means no failure are tolerated, while a value of\\xA01\\xA0means any number of failure are tolerated.\\n--rollback-monitor             5s            Duration after each task rollback to monitor for failure. If a task stops before this time period has elapsed, the rollback is considered to have failed.\\n--rollback-parallelism         1             The maximum number of tasks to roll back in parallel. By default, one task is rolled back at a time. A value of\\xA00\\xA0causes all tasks to be rolled back in parallel.\"),mdx(\"p\",null,\"The following example configures a\\xA0redis\\xA0service to roll back automatically if a\\xA0docker service update\\xA0fails to deploy. Two tasks can be rolled back in parallel. Tasks are monitored for 20 seconds after rollback to be sure they do not exit, and a maximum failure ratio of 20% is tolerated. Default values are used for\\xA0--rollback-delay\\xA0and\\xA0--rollback-failure-action.\"),mdx(\"p\",null,\"$ docker service create --name=my_redis \\\\\"),mdx(\"p\",null,\"--replicas=5 \\\\\"),mdx(\"p\",null,\"--rollback-parallelism=2 \\\\\"),mdx(\"p\",null,\"--rollback-monitor=20s \\\\\"),mdx(\"p\",null,\"--rollback-max-failure-ratio=.2 \\\\\"),mdx(\"p\",null,\"redis:latest\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Give a service access to volumes or bind mounts\")),mdx(\"p\",null,\"For best performance and portability, you should avoid writing important data directly into a container's writable layer, instead using data volumes or bind mounts. This principle also applies to services.\"),mdx(\"p\",null,\"You can create two types of mounts for services in a swarm,\\xA0volume\\xA0mounts or\\xA0bind\\xA0mounts. Regardless of which type of mount you use, configure it using the\\xA0--mount\\xA0flag when you create a service, or the\\xA0--mount-add\\xA0or\\xA0--mount-rm\\xA0flag when updating an existing service.. The default is a data volume if you don't specify a type.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"DATA VOLUMES\")),mdx(\"p\",null,\"Data volumes are storage that remain alive after a container for a task has been removed. The preferred method to mount volumes is to leverage an existing volume:\"),mdx(\"p\",null,\"$ docker service create \\\\\"),mdx(\"p\",null,\"--mount src=\",mdx(\"inlineCode\",{parentName:\"p\"},\"<VOLUME-NAME>,dst=<CONTAINER-PATH>\"),\" \\\\\"),mdx(\"p\",null,\"--name myservice \\\\\"),mdx(\"p\",null,mdx(\"inlineCode\",{parentName:\"p\"},\"<IMAGE>\")),mdx(\"p\",null,\"For more information on how to create a volume, see the\\xA0volume create\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/volume_create/\"}),\"CLI reference\"),\".\"),mdx(\"p\",null,\"The following method creates the volume at deployment time when the scheduler dispatches a task, just before starting the container:\"),mdx(\"p\",null,\"$ docker service create \\\\\"),mdx(\"p\",null,\"--mount type=volume,src=\",mdx(\"inlineCode\",{parentName:\"p\"},\"<VOLUME-NAME>,dst=<CONTAINER-PATH>,volume-driver=<DRIVER>,volume-opt=<KEY0>=<VALUE0>,volume-opt=<KEY1>=<VALUE1>\")),mdx(\"p\",null,\"--name myservice \\\\\"),mdx(\"p\",null,mdx(\"inlineCode\",{parentName:\"p\"},\"<IMAGE>\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Important:\\xA0If your volume driver accepts a comma-separated list as an option, you must escape the value from the outer CSV parser. To escape a\\xA0volume-opt, surround it with double quotes (\\\") and surround the entire mount parameter with single quotes (\\\\').\")),mdx(\"p\",null,\"For example, the\\xA0local\\xA0driver accepts mount options as a comma-separated list in the\\xA0o\\xA0parameter. This example shows the correct way to escape the list.\"),mdx(\"p\",null,\"$ docker service create \\\\\"),mdx(\"p\",null,\"--mount \\\\'type=volume,src=\",mdx(\"inlineCode\",{parentName:\"p\"},\"<VOLUME-NAME>,dst=<CONTAINER-PATH>,volume-driver=local,volume-opt=type=nfs,volume-opt=device=<nfs-server>:<nfs-path>,\\\"volume-opt=o=addr=<nfs-address>\"),\",vers=4,soft,timeo=180,bg,tcp,rw\\\"\\\\'\"),mdx(\"p\",null,\"--name myservice \\\\\"),mdx(\"p\",null,mdx(\"inlineCode\",{parentName:\"p\"},\"<IMAGE>\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"BIND MOUNTS\")),mdx(\"p\",null,\"Bind mounts are file system paths from the host where the scheduler deploys the container for the task. Docker mounts the path into the container. The file system path must exist before the swarm initializes the container for the task.\"),mdx(\"p\",null,\"The following examples show bind mount syntax:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"To mount a read-write bind:\"),mdx(\"li\",{parentName:\"ul\"},\"$ docker service create \\\\\"),mdx(\"li\",{parentName:\"ul\"},\"--mount type=bind,src=\",mdx(\"inlineCode\",{parentName:\"li\"},\"<HOST-PATH>,dst=<CONTAINER-PATH>\"),\" \\\\\"),mdx(\"li\",{parentName:\"ul\"},\"--name myservice \\\\\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<IMAGE>\")),mdx(\"li\",{parentName:\"ul\"},\"To mount a read-only bind:\"),mdx(\"li\",{parentName:\"ul\"},\"$ docker service create \\\\\"),mdx(\"li\",{parentName:\"ul\"},\"--mount type=bind,src=\",mdx(\"inlineCode\",{parentName:\"li\"},\"<HOST-PATH>,dst=<CONTAINER-PATH>\"),\",readonly \\\\\"),mdx(\"li\",{parentName:\"ul\"},\"--name myservice \\\\\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<IMAGE>\"))),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Important: Bind mounts can be useful but they can also cause problems. In most cases, it is recommended that you architect your application such that mounting paths from the host is unnecessary. The main risks include the following:\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"If you bind mount a host path into your service's containers, the path must exist on every swarm node. The Docker swarm mode scheduler can schedule containers on any machine that meets resource availability requirements and satisfies all constraints and placement preferences you specify.\"),mdx(\"li\",{parentName:\"ul\"},\"The Docker swarm mode scheduler may reschedule your running service containers at any time if they become unhealthy or unreachable.\"),mdx(\"li\",{parentName:\"ul\"},\"Host bind mounts are completely non-portable. When you use bind mounts, there is no guarantee that your application runs the same way in development as it does in production.\")),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Create services using templates\")),mdx(\"p\",null,\"You can use templates for some flags of\\xA0service create, using the syntax provided by the Go's\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://golang.org/pkg/text/template/\"}),\"text/template\"),\"\\xA0package.\"),mdx(\"p\",null,\"The following flags are supported:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"--hostname\"),mdx(\"li\",{parentName:\"ul\"},\"--mount\"),mdx(\"li\",{parentName:\"ul\"},\"--env\")),mdx(\"p\",null,\"Valid placeholders for the Go template are:\"),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Placeholder\"),\"   \",mdx(\"strong\",{parentName:\"p\"},\"Description\")),mdx(\"hr\",null),mdx(\"p\",null,\"  .Service.ID       Service ID\\n.Service.Name     Service name\\n.Service.Labels   Service labels\\n.Node.ID          Node ID\\n.Task.Name        Task name\\n.Task.Slot        Task slot\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"TEMPLATE EXAMPLE\")),mdx(\"p\",null,\"This example sets the template of the created containers based on the service's name and the ID of the node where the container is running:\"),mdx(\"p\",null,\"$ docker service create --name hosttempl \\\\\"),mdx(\"p\",null,\"--hostname=\\\"{{.Node.ID}}-{{.Service.Name}}\\\"\\\\\"),mdx(\"p\",null,\"busybox top\"),mdx(\"p\",null,\"To see the result of using the template, use the\\xA0docker service ps\\xA0and\\xA0docker inspectcommands.\"),mdx(\"p\",null,\"$ docker service ps va8ew30grofhjoychbr6iot8c\"),mdx(\"p\",null,\"ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS\"),mdx(\"p\",null,\"wo41w8hg8qan hosttempl.1 busybox:latest\\\\@sha256:29f5d56d12684887bdfa50dcd29fc31eea4aaf4ad3bec43daf19026a7ce69912 2e7a8a9c4da2 Running Running about a minute ago\"),mdx(\"p\",null,\"$ docker inspect --format=\\\"{{.Config.Hostname}}\\\" hosttempl.1.wo41w8hg8qanxwjwsg4kxpprj\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Learn More\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/admin_guide/\"}),\"Swarm administration guide\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/docker/\"}),\"Docker Engine command line reference\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/swarm-tutorial/\"}),\"Swarm mode tutorial\"))),mdx(\"h4\",null,\"Store configuration data using Docker Configs\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA018 minutes\")),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"About configs\")),mdx(\"p\",null,\"Docker 17.06 introduces swarm service configs, which allow you to store non-sensitive information, such as configuration files, outside a service's image or running containers. This allows you to keep your images as generic as possible, without the need to bind-mount configuration files into the containers or use environment variables.\"),mdx(\"p\",null,\"Configs operate in a similar way to\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/secrets/\"}),\"secrets\"),\", except that they are not encrypted at rest and are mounted directly into the container's filesystem without the use of RAM disks. Configs can be added or removed from a service at any time, and services can share a config. You can even use configs in conjunction with environment variables or labels, for maximum flexibility. Config values can be generic strings or binary content (up to 500 kb in size).\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": Docker configs are only available to swarm services, not to standalone containers. To use this feature, consider adapting your container to run as a service with a scale of 1.\"),mdx(\"p\",null,\"Configs are supported on both Linux and Windows services.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Windows support\")),mdx(\"p\",null,\"Docker 17.06 and higher include support for configs on Windows containers. Where there are differences in the implementations, they are called out in the examples below. Keep the following notable differences in mind:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Config files with custom targets are not directly bind-mounted into Windows containers, since Windows does not support non-directory file bind-mounts. Instead, configs for a container are all mounted in\\xA0C:\\\\ProgramData\\\\Docker\\\\internal\\\\configs\\xA0(an implementation detail which should not be relied upon by applications) within the container. Symbolic links are used to point from there to the desired target of the config within the container. The default target is\\xA0C:\\\\ProgramData\\\\Docker\\\\configs.\"),mdx(\"li\",{parentName:\"ul\"},\"When creating a service which uses Windows containers, the options to specify UID, GID, and mode are not supported for configs. Configs are currently only accessible by administrators and users with\\xA0system\\xA0access within the container.\")),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"How Docker manages configs\")),mdx(\"p\",null,\"When you add a config to the swarm, Docker sends the config to the swarm manager over a mutual TLS connection. The config is stored in the Raft log, which is encrypted. The entire Raft log is replicated across the other managers, ensuring the same high availability guarantees for configs as for the rest of the swarm management data.\"),mdx(\"p\",null,\"When you grant a newly-created or running service access to a config, the config is mounted as a file in the container. The location of the mount point within the container defaults to\\xA0/\",mdx(\"inlineCode\",{parentName:\"p\"},\"<config-name>\\xA0in Linux containers. In Windows containers, configs are all mounted into\\xA0C:\\\\ProgramData\\\\Docker\\\\configs\\xA0and symbolic links are created to the desired location, which defaults to\\xA0C:\\\\<config-name>\"),\".\"),mdx(\"p\",null,\"You can set the ownership (uid\\xA0and\\xA0gid) or the config, using either the numerical ID or the name of the user or group. You can also specify the file permissions (mode). These settings are ignored for Windows containers.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"If not set, the config is owned by the user and that running the container command (often\\xA0root) and that user's default group (also often\\xA0root).\"),mdx(\"li\",{parentName:\"ul\"},\"If not set, the config has world-readable permissions (mode\\xA00444), unless a\\xA0umask\\xA0is set within the container, in which case the mode is impacted by that\\xA0umask\\xA0value.\")),mdx(\"p\",null,\"You can update a service to grant it access to additional configs or revoke its access to a given config at any time.\"),mdx(\"p\",null,\"A node only has access to configs if the node is a swarm manager or if it is running service tasks which have been granted access to the config. When a container task stops running, the configs shared to it are unmounted from the in-memory filesystem for that container and flushed from the node's memory.\"),mdx(\"p\",null,\"If a node loses connectivity to the swarm while it is running a task container with access to a config, the task container still has access to its configs, but cannot receive updates until the node reconnects to the swarm.\"),mdx(\"p\",null,\"You can add or inspect an individual config at any time, or list all configs. You cannot remove a config that a running service is using. See\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/configs/#example-rotate-a-config\"}),\"Rotate a config\"),\"\\xA0for a way to remove a config without disrupting running services.\"),mdx(\"p\",null,\"To update or roll back configs more easily, consider adding a version number or date to the config name. This is made easier by the ability to control the mount point of the config within a given container.\"),mdx(\"p\",null,\"To update a stack, make changes to your Compose file, then re-run\\xA0docker stack deploy -c \",mdx(\"inlineCode\",{parentName:\"p\"},\"<new-compose-file> <stack-name>\"),\". If you use a new config in that file, your services start using them. Keep in mind that configurations are immutable, so you can't change the file for an existing service. Instead, you create a new config to use a different file\"),mdx(\"p\",null,\"You can run\\xA0docker stack rm\\xA0to stop the app and take down the stack. This removes any config that was created by\\xA0docker stack deploy\\xA0with the same stack name. This removes\\xA0all\\xA0configs, including those not referenced by services and those remaining after a\\xA0docker service update --config-rm.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Read more about\\xA0docker config\\xA0commands\")),mdx(\"p\",null,\"Use these links to read about specific commands, or continue to the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/configs/#example-use-configs-with-a-service\"}),\"example about using configs with a service\"),\".\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/config_create/\"}),\"docker config create\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/config_inspect/\"}),\"docker config inspect\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/config_ls/\"}),\"docker config ls\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/config_rm/\"}),\"docker config rm\"))),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Examples\")),mdx(\"p\",null,\"This section includes graduated examples which illustrate how to use Docker configs.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": These examples use a single-Engine swarm and unscaled services for simplicity. The examples use Linux containers, but Windows containers also support configs.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Defining and using configs in compose files\")),mdx(\"p\",null,\"Both the\\xA0docker compose\\xA0and\\xA0docker stack\\xA0commands support defining configs in a compose file. See\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/compose/compose-file/#configs\"}),\"the Compose file reference\"),\"\\xA0for details.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Simple example: Get started with configs\")),mdx(\"p\",null,\"This simple example shows how configs work in just a few commands. For a real-world example, continue to\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/configs/#advanced-example-use-configs-with-a-nginx-service\"}),\"Intermediate example: Use configs with a Nginx service\"),\".\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Add a config to Docker. The\\xA0docker config create\\xA0command reads standard input because the last argument, which represents the file to read the config from, is set to\\xA0-.\"),mdx(\"li\",{parentName:\"ol\"},\"$ echo \\\"This is a config\\\" | docker config create my-config -\"),mdx(\"li\",{parentName:\"ol\"},\"Create a\\xA0redis\\xA0service and grant it access to the config. By default, the container can access the config at\\xA0/my-config, but you can customize the file name on the container using the\\xA0target\\xA0option.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker service create --name redis --config my-config redis:alpine\"),mdx(\"li\",{parentName:\"ol\"},\"Verify that the task is running without issues using\\xA0docker service ps. If everything is working, the output looks similar to this:\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker service ps redis\"),mdx(\"li\",{parentName:\"ol\"},\"ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS\"),mdx(\"li\",{parentName:\"ol\"},\"bkna6bpn8r1a redis.1 redis:alpine ip-172-31-46-109 Running Running 8 seconds ago\"),mdx(\"li\",{parentName:\"ol\"},\"Get the ID of the\\xA0redis\\xA0service task container using\\xA0docker ps, so that you can use\\xA0docker container exec\\xA0to connect to the container and read the contents of the config data file, which defaults to being readable by all and has the same name as the name of the config. The first command below illustrates how to find the container ID, and the second and third commands use shell completion to do this automatically.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker ps --filter name=redis -q\"),mdx(\"li\",{parentName:\"ol\"},\"5cb1c2348a59\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker container exec $(docker ps --filter name=redis -q) ls -l /my-config\"),mdx(\"li\",{parentName:\"ol\"},\"-r--r--r-- 1 root root 12 Jun 5 20:49 my-config\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker container exec $(docker ps --filter name=redis -q) cat /my-config\"),mdx(\"li\",{parentName:\"ol\"},\"This is a config\"),mdx(\"li\",{parentName:\"ol\"},\"Try removing the config. The removal fails because the\\xA0redis\\xA0service is running and has access to the config.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker config ls\"),mdx(\"li\",{parentName:\"ol\"},\"ID NAME CREATED UPDATED\"),mdx(\"li\",{parentName:\"ol\"},\"fzwcfuqjkvo5foqu7ts7ls578 hello 31 minutes ago 31 minutes ago\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker config rm my-config\"),mdx(\"li\",{parentName:\"ol\"},\"Error response from daemon: rpc error: code = 3 desc = config \\\\'my-config\\\\' is\"),mdx(\"li\",{parentName:\"ol\"},\"in use by the following service: redis\"),mdx(\"li\",{parentName:\"ol\"},\"Remove access to the config from the running\\xA0redis\\xA0service by updating the service.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker service update --config-rm my-config redis\"),mdx(\"li\",{parentName:\"ol\"},\"Repeat steps 3 and 4 again, verifying that the service no longer has access to the config. The container ID is different, because the\\xA0service update\\xA0command redeploys the service.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker container exec -it $(docker ps --filter name=redis -q) cat /my-config\"),mdx(\"li\",{parentName:\"ol\"},\"cat: can\\\\'t open \\\\'/my-config\\\\': No such file or directory\"),mdx(\"li\",{parentName:\"ol\"},\"Stop and remove the service, and remove the config from Docker.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker service rm redis\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker config rm my-config\")),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Simple example: Use configs in a Windows service\")),mdx(\"p\",null,\"This is a very simple example which shows how to use configs with a Microsoft IIS service running on Docker 17.06 EE on Microsoft Windows Server 2016 or Docker for Windows 17.06 CE on Microsoft Windows 10. It stores the webpage in a config.\"),mdx(\"p\",null,\"This example assumes that you have PowerShell installed.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Save the following into a new file\\xA0index.html.\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<html>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<head><title>Hello Docker</title></head>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<body>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<p>Hello Docker! You have deployed a HTML page.</p>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"</body>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"</html>\")),mdx(\"li\",{parentName:\"ol\"},\"If you have not already done so, initialize or join the swarm.\"),mdx(\"li\",{parentName:\"ol\"},\"docker swarm init\"),mdx(\"li\",{parentName:\"ol\"},\"Save the\\xA0index.html\\xA0file as a swarm config named\\xA0homepage.\"),mdx(\"li\",{parentName:\"ol\"},\"docker config create homepage index.html\"),mdx(\"li\",{parentName:\"ol\"},\"Create an IIS service and grant it access to the\\xA0homepage\\xA0config.\"),mdx(\"li\",{parentName:\"ol\"},\"docker service create\"),mdx(\"li\",{parentName:\"ol\"},\"--name my-iis\"),mdx(\"li\",{parentName:\"ol\"},\"--publish published=8000,target=8000\"),mdx(\"li\",{parentName:\"ol\"},\"--config src=homepage,target=\\\"\\\\inetpub\\\\wwwroot\\\\index.html\\\"\"),mdx(\"li\",{parentName:\"ol\"},\"microsoft/iis:nanoserver\"),mdx(\"li\",{parentName:\"ol\"},\"Access the IIS service at\\xA0http://localhost:8000/. It should serve the HTML content from the first step.\"),mdx(\"li\",{parentName:\"ol\"},\"Remove the service and the config.\"),mdx(\"li\",{parentName:\"ol\"},\"docker service rm my-iis\"),mdx(\"li\",{parentName:\"ol\"},\"docker config rm homepage\")),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Advanced example: Use configs with a Nginx service\")),mdx(\"p\",null,\"This example is divided into two parts.\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/configs/#generate-the-site-certificate\"}),\"The first part\"),\"\\xA0is all about generating the site certificate and does not directly involve Docker configs at all, but it sets up\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/configs/#configure-the-nginx-container\"}),\"the second part\"),\", where you store and use the site certificate as a series of secrets and the Nginx configuration as a config. The example shows how to set options on the config, such as the target location within the container and the file permissions (mode).\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"GENERATE THE SITE CERTIFICATE\")),mdx(\"p\",null,\"Generate a root CA and TLS certificate and key for your site. For production sites, you may want to use a service such as\\xA0Let's Encrypt\\xA0to generate the TLS certificate and key, but this example uses command-line tools. This step is a little complicated, but is only a set-up step so that you have something to store as a Docker secret. If you want to skip these sub-steps, you can\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://letsencrypt.org/getting-started/\"}),\"use Let's Encrypt\"),\"\\xA0to generate the site key and certificate, name the files\\xA0site.key\\xA0and\\xA0site.crt, and skip to\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/configs/#configure-the-nginx-container\"}),\"Configure the Nginx container\"),\".\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Generate a root key.\"),mdx(\"li\",{parentName:\"ol\"},\"$ openssl genrsa -out \\\"root-ca.key\\\" 4096\"),mdx(\"li\",{parentName:\"ol\"},\"Generate a CSR using the root key.\"),mdx(\"li\",{parentName:\"ol\"},\"$ openssl req \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"-new -key \\\"root-ca.key\\\" \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"-out \\\"root-ca.csr\\\" -sha256 \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"-subj \\\\'/C=US/ST=CA/L=San Francisco/O=Docker/CN=Swarm Secret Example CA\\\\'\"),mdx(\"li\",{parentName:\"ol\"},\"Configure the root CA. Edit a new file called\\xA0root-ca.cnf\\xA0and paste the following contents into it. This constrains the root CA to only sign leaf certificates and not intermediate CAs.\"),mdx(\"li\",{parentName:\"ol\"},\"[root_ca]\"),mdx(\"li\",{parentName:\"ol\"},\"basicConstraints = critical,CA:TRUE,pathlen:1\"),mdx(\"li\",{parentName:\"ol\"},\"keyUsage = critical, nonRepudiation, cRLSign, keyCertSign\"),mdx(\"li\",{parentName:\"ol\"},\"subjectKeyIdentifier=hash\"),mdx(\"li\",{parentName:\"ol\"},\"Sign the certificate.\"),mdx(\"li\",{parentName:\"ol\"},\"$ openssl x509 -req -days 3650 -in \\\"root-ca.csr\\\" \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"-signkey \\\"root-ca.key\\\" -sha256 -out \\\"root-ca.crt\\\" \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"-extfile \\\"root-ca.cnf\\\" -extensions \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"root_ca\"),mdx(\"li\",{parentName:\"ol\"},\"Generate the site key.\"),mdx(\"li\",{parentName:\"ol\"},\"$ openssl genrsa -out \\\"site.key\\\" 4096\"),mdx(\"li\",{parentName:\"ol\"},\"Generate the site certificate and sign it with the site key.\"),mdx(\"li\",{parentName:\"ol\"},\"$ openssl req -new -key \\\"site.key\\\" -out \\\"site.csr\\\" -sha256 \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"-subj \\\\'/C=US/ST=CA/L=San Francisco/O=Docker/CN=localhost\\\\'\"),mdx(\"li\",{parentName:\"ol\"},\"Configure the site certificate. Edit a new file called\\xA0site.cnf\\xA0and paste the following contents into it. This constrains the site certificate so that it can only be used to authenticate a server and can't be used to sign certificates.\"),mdx(\"li\",{parentName:\"ol\"},\"[server]\"),mdx(\"li\",{parentName:\"ol\"},\"authorityKeyIdentifier=keyid,issuer\"),mdx(\"li\",{parentName:\"ol\"},\"basicConstraints = critical,CA:FALSE\"),mdx(\"li\",{parentName:\"ol\"},\"extendedKeyUsage=serverAuth\"),mdx(\"li\",{parentName:\"ol\"},\"keyUsage = critical, digitalSignature, keyEncipherment\"),mdx(\"li\",{parentName:\"ol\"},\"subjectAltName = DNS:localhost, IP:127.0.0.1\"),mdx(\"li\",{parentName:\"ol\"},\"subjectKeyIdentifier=hash\"),mdx(\"li\",{parentName:\"ol\"},\"Sign the site certificate.\"),mdx(\"li\",{parentName:\"ol\"},\"$ openssl x509 -req -days 750 -in \\\"site.csr\\\" -sha256 \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"-CA \\\"root-ca.crt\\\" -CAkey \\\"root-ca.key\\\" -CAcreateserial \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"-out \\\"site.crt\\\" -extfile \\\"site.cnf\\\" -extensions server\"),mdx(\"li\",{parentName:\"ol\"},\"The\\xA0site.csr\\xA0and\\xA0site.cnf\\xA0files are not needed by the Nginx service, but you need them if you want to generate a new site certificate. Protect the\\xA0root-ca.key\\xA0file.\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"CONFIGURE THE NGINX CONTAINER\")),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Produce a very basic Nginx configuration that serves static files over HTTPS. The TLS certificate and key are stored as Docker secrets so that they can be rotated easily.\")),mdx(\"p\",null,\"In the current directory, create a new file called\\xA0site.conf\\xA0with the following contents:\"),mdx(\"p\",null,\"server {\"),mdx(\"p\",null,\"listen 443 ssl;\"),mdx(\"p\",null,\"server_name localhost;\"),mdx(\"p\",null,\"ssl_certificate /run/secrets/site.crt;\"),mdx(\"p\",null,\"ssl_certificate_key /run/secrets/site.key;\"),mdx(\"p\",null,\"location / {\"),mdx(\"p\",null,\"root /usr/share/nginx/html;\"),mdx(\"p\",null,\"index index.html index.htm;\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"}\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Create two secrets, representing the key and the certificate. You can store any file as a secret as long as it is smaller than 500 KB. This allows you to decouple the key and certificate from the services that use them. In these examples, the secret name and the file name are the same.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker secret create site.key site.key\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker secret create site.crt site.crt\"),mdx(\"li\",{parentName:\"ol\"},\"Save the\\xA0site.conf\\xA0file in a Docker config. The first parameter is the name of the config, and the second parameter is the file to read it from.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker config create site.conf site.conf\")),mdx(\"p\",null,\"List the configs:\"),mdx(\"p\",null,\"$ docker config ls\"),mdx(\"p\",null,\"ID NAME CREATED UPDATED\"),mdx(\"p\",null,\"4ory233120ccg7biwvy11gl5z site.conf 4 seconds ago 4 seconds ago\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Create a service that runs Nginx and has access to the two secrets and the config. Set the mode to\\xA00440\\xA0so that the file is only readable by its owner and that owner's group, not the world.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker service create \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--name nginx \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--secret site.key \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--secret site.crt \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--config source=site.conf,target=/etc/nginx/conf.d/site.conf,mode=0440 \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--publish published=3000,target=443 \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"nginx:latest \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"sh -c \\\"exec nginx -g \\\\'daemon off;\\\\'\\\"\")),mdx(\"p\",null,\"Within the running containers, the following three files now exist:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},\"/run/secrets/site.key\"),mdx(\"li\",{parentName:\"ul\"},\"/run/secrets/site.crt\"),mdx(\"li\",{parentName:\"ul\"},\"/etc/nginx/conf.d/site.conf\")))),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Verify that the Nginx service is running.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker service ls\"),mdx(\"li\",{parentName:\"ol\"},\"ID NAME MODE REPLICAS IMAGE\"),mdx(\"li\",{parentName:\"ol\"},\"zeskcec62q24 nginx replicated 1/1 nginx:latest\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker service ps nginx\"),mdx(\"li\",{parentName:\"ol\"},\"NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS\"),mdx(\"li\",{parentName:\"ol\"},\"nginx.1.9ls3yo9ugcls nginx:latest moby Running Running 3 minutes ago\"),mdx(\"li\",{parentName:\"ol\"},\"Verify that the service is operational: you can reach the Nginx server, and that the correct TLS certificate is being used.\"),mdx(\"li\",{parentName:\"ol\"},\"$ curl --cacert root-ca.crt \",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://0.0.0.0:3000\"}),\"https://0.0.0.0:3000\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<!DOCTYPE html>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<html>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<head>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<title>Welcome to nginx!</title>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<style>\")),mdx(\"li\",{parentName:\"ol\"},\"body {\"),mdx(\"li\",{parentName:\"ol\"},\"width: 35em;\"),mdx(\"li\",{parentName:\"ol\"},\"margin: 0 auto;\"),mdx(\"li\",{parentName:\"ol\"},\"font-family: Tahoma, Verdana, Arial, sans-serif;\"),mdx(\"li\",{parentName:\"ol\"},\"}\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"</style>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"</head>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<body>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<h1>Welcome to nginx!</h1>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<p>\"),\"If you see this page, the nginx web server is successfully installed and\"),mdx(\"li\",{parentName:\"ol\"},\"working. Further configuration is required.\",mdx(\"inlineCode\",{parentName:\"li\"},\"</p>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<p>\"),\"For online documentation and support, refer to\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<a href=\\\"http://nginx.org/\\\">nginx.org</a>.<br/>\")),mdx(\"li\",{parentName:\"ol\"},\"Commercial support is available at\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<a href=\\\"http://nginx.com/\\\">nginx.com</a>.</p>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<p><em>Thank you for using nginx.</em></p>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"</body>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"</html>\")),mdx(\"li\",{parentName:\"ol\"},\"$ openssl s_client -connect 0.0.0.0:3000 -CAfile root-ca.crt\"),mdx(\"li\",{parentName:\"ol\"},\"CONNECTED(00000003)\"),mdx(\"li\",{parentName:\"ol\"},\"depth=1 /C=US/ST=CA/L=San Francisco/O=Docker/CN=Swarm Secret Example CA\"),mdx(\"li\",{parentName:\"ol\"},\"verify return:1\"),mdx(\"li\",{parentName:\"ol\"},\"depth=0 /C=US/ST=CA/L=San Francisco/O=Docker/CN=localhost\"),mdx(\"li\",{parentName:\"ol\"},\"verify return:1\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"hr\",{parentName:\"li\"})),mdx(\"li\",{parentName:\"ol\"},\"Certificate chain\"),mdx(\"li\",{parentName:\"ol\"},\"0 s:/C=US/ST=CA/L=San Francisco/O=Docker/CN=localhost\"),mdx(\"li\",{parentName:\"ol\"},\"i:/C=US/ST=CA/L=San Francisco/O=Docker/CN=Swarm Secret Example CA\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"hr\",{parentName:\"li\"})),mdx(\"li\",{parentName:\"ol\"},\"Server certificate\"),mdx(\"li\",{parentName:\"ol\"},\"-----BEGIN CERTIFICATE-----\"),mdx(\"li\",{parentName:\"ol\"},\"...\"),mdx(\"li\",{parentName:\"ol\"},\"-----END CERTIFICATE-----\"),mdx(\"li\",{parentName:\"ol\"},\"subject=/C=US/ST=CA/L=San Francisco/O=Docker/CN=localhost\"),mdx(\"li\",{parentName:\"ol\"},\"issuer=/C=US/ST=CA/L=San Francisco/O=Docker/CN=Swarm Secret Example CA\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"hr\",{parentName:\"li\"})),mdx(\"li\",{parentName:\"ol\"},\"No client certificate CA names sent\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"hr\",{parentName:\"li\"})),mdx(\"li\",{parentName:\"ol\"},\"SSL handshake has read 1663 bytes and written 712 bytes\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"hr\",{parentName:\"li\"})),mdx(\"li\",{parentName:\"ol\"},\"New, TLSv1/SSLv3, Cipher is AES256-SHA\"),mdx(\"li\",{parentName:\"ol\"},\"Server public key is 4096 bit\"),mdx(\"li\",{parentName:\"ol\"},\"Secure Renegotiation IS supported\"),mdx(\"li\",{parentName:\"ol\"},\"Compression: NONE\"),mdx(\"li\",{parentName:\"ol\"},\"Expansion: NONE\"),mdx(\"li\",{parentName:\"ol\"},\"SSL-Session:\"),mdx(\"li\",{parentName:\"ol\"},\"Protocol : TLSv1\"),mdx(\"li\",{parentName:\"ol\"},\"Cipher : AES256-SHA\"),mdx(\"li\",{parentName:\"ol\"},\"Session-ID: A1A8BF35549C5715648A12FD7B7E3D861539316B03440187D9DA6C2E48822853\"),mdx(\"li\",{parentName:\"ol\"},\"Session-ID-ctx:\"),mdx(\"li\",{parentName:\"ol\"},\"Master-Key: F39D1B12274BA16D3A906F390A61438221E381952E9E1E05D3DD784F0135FB81353DA38C6D5C021CB926E844DFC49FC4\"),mdx(\"li\",{parentName:\"ol\"},\"Key-Arg : None\"),mdx(\"li\",{parentName:\"ol\"},\"Start Time: 1481685096\"),mdx(\"li\",{parentName:\"ol\"},\"Timeout : 300 (sec)\"),mdx(\"li\",{parentName:\"ol\"},\"Verify return code: 0 (ok)\"),mdx(\"li\",{parentName:\"ol\"},\"Unless you are going to continue to the next example, clean up after running this example by removing the\\xA0nginx\\xA0service and the stored secrets and config.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker service rm nginx\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker secret rm site.crt site.key\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker config rm site.conf\")),mdx(\"p\",null,\"You have now configured a Nginx service with its configuration decoupled from its image. You could run multiple sites with exactly the same image but separate configurations, without the need to build a custom image at all.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Example: Rotate a config\")),mdx(\"p\",null,\"To rotate a config, you first save a new config with a different name than the one that is currently in use. You then redeploy the service, removing the old config and adding the new config at the same mount point within the container. This example builds upon the previous one by rotating the\\xA0site.conf\\xA0configuration file.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Edit the\\xA0site.conf\\xA0file locally. Add\\xA0index.php\\xA0to the\\xA0index\\xA0line, and save the file.\"),mdx(\"li\",{parentName:\"ol\"},\"server {\"),mdx(\"li\",{parentName:\"ol\"},\"listen 443 ssl;\"),mdx(\"li\",{parentName:\"ol\"},\"server_name localhost;\"),mdx(\"li\",{parentName:\"ol\"},\"ssl_certificate /run/secrets/site.crt;\"),mdx(\"li\",{parentName:\"ol\"},\"ssl_certificate_key /run/secrets/site.key;\"),mdx(\"li\",{parentName:\"ol\"},\"location / {\"),mdx(\"li\",{parentName:\"ol\"},\"root /usr/share/nginx/html;\"),mdx(\"li\",{parentName:\"ol\"},\"index index.html index.htm index.php;\"),mdx(\"li\",{parentName:\"ol\"},\"}\"),mdx(\"li\",{parentName:\"ol\"},\"}\"),mdx(\"li\",{parentName:\"ol\"},\"Create a new Docker config using the new\\xA0site.conf, called\\xA0site-v2.conf.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker config create site-v2.conf site.conf\"),mdx(\"li\",{parentName:\"ol\"},\"Update the\\xA0nginx\\xA0service to use the new config instead of the old one.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker service update \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--config-rm site.conf \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--config-add source=site-v2.conf,target=/etc/nginx/conf.d/site.conf,mode=0440 \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"nginx\"),mdx(\"li\",{parentName:\"ol\"},\"Verify that the\\xA0nginx\\xA0service is fully re-deployed, using\\xA0docker service ls nginx. When it is, you can remove the old\\xA0site.conf\\xA0config.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker config rm site.conf\"),mdx(\"li\",{parentName:\"ol\"},\"To clean up, you can remove the\\xA0nginx\\xA0service, as well as the secrets and configs.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker service rm nginx\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker secret rm site.crt site.key\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker config rm site-v2.conf\")),mdx(\"p\",null,\"You have now updated your\\xA0nginx\\xA0service's configuration without the need to rebuild its image.\"),mdx(\"h4\",null,\"Manage sensitive data with Docker secrets\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA035 minutes\")),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"About secrets\")),mdx(\"p\",null,\"In terms of Docker Swarm services, a\\xA0secret\\xA0is a blob of data, such as a password, SSH private key, SSL certificate, or another piece of data that should not be transmitted over a network or stored unencrypted in a Dockerfile or in your application's source code. In Docker 1.13 and higher, you can use Docker\\xA0secrets\\xA0to centrally manage this data and securely transmit it to only those containers that need access to it. Secrets are encrypted during transit and at rest in a Docker swarm. A given secret is only accessible to those services which have been granted explicit access to it, and only while those service tasks are running.\"),mdx(\"p\",null,\"You can use secrets to manage any sensitive data which a container needs at runtime but you don't want to store in the image or in source control, such as:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Usernames and passwords\"),mdx(\"li\",{parentName:\"ul\"},\"TLS certificates and keys\"),mdx(\"li\",{parentName:\"ul\"},\"SSH keys\"),mdx(\"li\",{parentName:\"ul\"},\"Other important data such as the name of a database or internal server\"),mdx(\"li\",{parentName:\"ul\"},\"Generic strings or binary content (up to 500 kb in size)\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": Docker secrets are only available to swarm services, not to standalone containers. To use this feature, consider adapting your container to run as a service. Stateful containers can typically run with a scale of 1 without changing the container code.\"),mdx(\"p\",null,\"Another use case for using secrets is to provide a layer of abstraction between the container and a set of credentials. Consider a scenario where you have separate development, test, and production environments for your application. Each of these environments can have different credentials, stored in the development, test, and production swarms with the same secret name. Your containers only need to know the name of the secret to function in all three environments.\"),mdx(\"p\",null,\"You can also use secrets to manage non-sensitive data, such as configuration files. However, Docker 17.06 and higher support the use of\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/configs/\"}),\"configs\"),\"\\xA0for storing non-sensitive data. Configs are mounted into the container's filesystem directly, without the use of a RAM disk.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Windows support\")),mdx(\"p\",null,\"Docker 17.06 and higher include support for secrets on Windows containers. Where there are differences in the implementations, they are called out in the examples below. Keep the following notable differences in mind:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Microsoft Windows has no built-in driver for managing RAM disks, so within running Windows containers, secrets\\xA0\",mdx(\"strong\",{parentName:\"li\"},\"are\"),\"\\xA0persisted in clear text to the container's root disk. However, the secrets are explicitly removed when a container stops. In addition, Windows does not support persisting a running container as an image using\\xA0docker commit\\xA0or similar commands.\"),mdx(\"li\",{parentName:\"ul\"},\"On Windows, we recommend enabling\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://technet.microsoft.com/en-us/library/cc732774(v=ws.11).aspx\"}),\"BitLocker\"),\"\\xA0on the volume containing the Docker root directory on the host machine to ensure that secrets for running containers are encrypted at rest.\"),mdx(\"li\",{parentName:\"ul\"},\"Secret files with custom targets are not directly bind-mounted into Windows containers, since Windows does not support non-directory file bind-mounts. Instead, secrets for a container are all mounted in\\xA0C:\\\\ProgramData\\\\Docker\\\\internal\\\\secrets\\xA0(an implementation detail which should not be relied upon by applications) within the container. Symbolic links are used to point from there to the desired target of the secret within the container. The default target is\\xA0C:\\\\ProgramData\\\\Docker\\\\secrets.\"),mdx(\"li\",{parentName:\"ul\"},\"When creating a service which uses Windows containers, the options to specify UID, GID, and mode are not supported for secrets. Secrets are currently only accessible by administrators and users with\\xA0system\\xA0access within the container.\")),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"How Docker manages secrets\")),mdx(\"p\",null,\"When you add a secret to the swarm, Docker sends the secret to the swarm manager over a mutual TLS connection. The secret is stored in the Raft log, which is encrypted. The entire Raft log is replicated across the other managers, ensuring the same high availability guarantees for secrets as for the rest of the swarm management data.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Warning\"),\": Raft data is encrypted in Docker 1.13 and higher. If any of your Swarm managers run an earlier version, and one of those managers becomes the manager of the swarm, the secrets are stored unencrypted in that node's Raft logs. Before adding any secrets, update all of your manager nodes to Docker 1.13 or higher to prevent secrets from being written to plain-text Raft logs.\"),mdx(\"p\",null,\"When you grant a newly-created or running service access to a secret, the decrypted secret is mounted into the container in an in-memory filesystem. The location of the mount point within the container defaults to\\xA0/run/secrets/\",mdx(\"inlineCode\",{parentName:\"p\"},\"<secret_name>\"),\"\\xA0in Linux containers, orC:\\\\ProgramData\\\\Docker\\\\secrets\\xA0in Windows containers. You can specify a custom location in Docker 17.06 and higher.\"),mdx(\"p\",null,\"You can update a service to grant it access to additional secrets or revoke its access to a given secret at any time.\"),mdx(\"p\",null,\"A node only has access to (encrypted) secrets if the node is a swarm manager or if it is running service tasks which have been granted access to the secret. When a container task stops running, the decrypted secrets shared to it are unmounted from the in-memory filesystem for that container and flushed from the node's memory.\"),mdx(\"p\",null,\"If a node loses connectivity to the swarm while it is running a task container with access to a secret, the task container still has access to its secrets, but cannot receive updates until the node reconnects to the swarm.\"),mdx(\"p\",null,\"You can add or inspect an individual secret at any time, or list all secrets. You cannot remove a secret that a running service is using. See\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/secrets/#example-rotate-a-secret\"}),\"Rotate a secret\"),\"\\xA0for a way to remove a secret without disrupting running services.\"),mdx(\"p\",null,\"To update or roll back secrets more easily, consider adding a version number or date to the secret name. This is made easier by the ability to control the mount point of the secret within a given container.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Read more about\\xA0docker secret\\xA0commands\")),mdx(\"p\",null,\"Use these links to read about specific commands, or continue to the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/secrets/#example-use-secrets-with-a-service\"}),\"example about using secrets with a service\"),\".\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/secret_create/\"}),\"docker secret create\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/secret_inspect/\"}),\"docker secret inspect\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/secret_ls/\"}),\"docker secret ls\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/secret_rm/\"}),\"docker secret rm\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/service_create/#create-a-service-with-secrets\"}),\"--secret\"),\"\\xA0flag for\\xA0docker service create\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/service_update/#adding-and-removing-secrets\"}),\"--secret-add\\xA0and\\xA0--secret-rm\"),\"\\xA0flags for\\xA0docker service update\")),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Examples\")),mdx(\"p\",null,\"This section includes three graduated examples which illustrate how to use Docker secrets. The images used in these examples have been updated to make it easier to use Docker secrets. To find out how to modify your own images in a similar way, see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/secrets/#build-support-for-docker-secrets-into-your-images\"}),\"Build support for Docker Secrets into your images\"),\".\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": These examples use a single-Engine swarm and unscaled services for simplicity. The examples use Linux containers, but Windows containers also support secrets in Docker 17.06 and higher. See\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/secrets/#windows-support\"}),\"Windows support\"),\".\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Defining and using secrets in compose files\")),mdx(\"p\",null,\"Both the\\xA0docker-compose\\xA0and\\xA0docker stack\\xA0commands support defining secrets in a compose file. See\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/compose/compose-file/#secrets\"}),\"the Compose file reference\"),\"\\xA0for details.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Simple example: Get started with secrets\")),mdx(\"p\",null,\"This simple example shows how secrets work in just a few commands. For a real-world example, continue to\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/secrets/#intermediate-example-use-secrets-with-a-nginx-service\"}),\"Intermediate example: Use secrets with a Nginx service\"),\".\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Add a secret to Docker. The\\xA0docker secret create\\xA0command reads standard input because the last argument, which represents the file to read the secret from, is set to\\xA0-.\"),mdx(\"li\",{parentName:\"ol\"},\"$ echo \\\"This is a secret\\\" | docker secret create my_secret_data -\"),mdx(\"li\",{parentName:\"ol\"},\"Create a\\xA0redis\\xA0service and grant it access to the secret. By default, the container can access the secret at\\xA0/run/secrets/\",mdx(\"inlineCode\",{parentName:\"li\"},\"<secret_name>\"),\", but you can customize the file name on the container using the\\xA0target\\xA0option.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker service create --name redis --secret my_secret_data redis:alpine\"),mdx(\"li\",{parentName:\"ol\"},\"Verify that the task is running without issues using\\xA0docker service ps. If everything is working, the output looks similar to this:\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker service ps redis\"),mdx(\"li\",{parentName:\"ol\"},\"ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS\"),mdx(\"li\",{parentName:\"ol\"},\"bkna6bpn8r1a redis.1 redis:alpine ip-172-31-46-109 Running Running 8 seconds ago\")),mdx(\"p\",null,\"If there were an error, and the task were failing and repeatedly restarting, you would see something like this:\"),mdx(\"p\",null,\"$ docker service ps redis\"),mdx(\"p\",null,\"NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS\"),mdx(\"p\",null,\"redis.1.siftice35gla redis:alpine moby Running Running 4 seconds ago\"),mdx(\"p\",null,\"_\",\" redis.1.whum5b7gu13e redis:alpine moby Shutdown Failed 20 seconds ago \\\"task: non-zero exit (1)\\\"\"),mdx(\"p\",null,\"_\",\" redis.1.2s6yorvd9zow redis:alpine moby Shutdown Failed 56 seconds ago \\\"task: non-zero exit (1)\\\"\"),mdx(\"p\",null,\"_\",\" redis.1.ulfzrcyaf6pg redis:alpine moby Shutdown Failed about a minute ago \\\"task: non-zero exit (1)\\\"\"),mdx(\"p\",null,\"_\",\" redis.1.wrny5v4xyps6 redis:alpine moby Shutdown Failed 2 minutes ago \\\"task: non-zero exit (1)\\\"\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Get the ID of the\\xA0redis\\xA0service task container using\\xA0docker ps\\xA0, so that you can use\\xA0docker container exec\\xA0to connect to the container and read the contents of the secret data file, which defaults to being readable by all and has the same name as the name of the secret. The first command below illustrates how to find the container ID, and the second and third commands use shell completion to do this automatically.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker ps --filter name=redis -q\"),mdx(\"li\",{parentName:\"ol\"},\"5cb1c2348a59\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker container exec $(docker ps --filter name=redis -q) ls -l /run/secrets\"),mdx(\"li\",{parentName:\"ol\"},\"total 4\"),mdx(\"li\",{parentName:\"ol\"},\"-r--r--r-- 1 root root 17 Dec 13 22:48 my_secret_data\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker container exec $(docker ps --filter name=redis -q) cat /run/secrets/my_secret_data\"),mdx(\"li\",{parentName:\"ol\"},\"This is a secret\"),mdx(\"li\",{parentName:\"ol\"},\"Verify that the secret is\\xA0\",mdx(\"strong\",{parentName:\"li\"},\"not\"),\"\\xA0available if you commit the container.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker commit $(docker ps --filter name=redis -q) committed_redis\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker run --rm -it committed_redis cat /run/secrets/my_secret_data\"),mdx(\"li\",{parentName:\"ol\"},\"cat: can\\\\'t open \\\\'/run/secrets/my_secret_data\\\\': No such file or directory\"),mdx(\"li\",{parentName:\"ol\"},\"Try removing the secret. The removal fails because the\\xA0redis\\xA0service is running and has access to the secret.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker secret ls\"),mdx(\"li\",{parentName:\"ol\"},\"ID NAME CREATED UPDATED\"),mdx(\"li\",{parentName:\"ol\"},\"wwwrxza8sxy025bas86593fqs my_secret_data 4 hours ago 4 hours ago\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker secret rm my_secret_data\"),mdx(\"li\",{parentName:\"ol\"},\"Error response from daemon: rpc error: code = 3 desc = secret\"),mdx(\"li\",{parentName:\"ol\"},\"\\\\'my_secret_data\\\\' is in use by the following service: redis\"),mdx(\"li\",{parentName:\"ol\"},\"Remove access to the secret from the running\\xA0redis\\xA0service by updating the service.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker service update --secret-rm my_secret_data redis\"),mdx(\"li\",{parentName:\"ol\"},\"Repeat steps 3 and 4 again, verifying that the service no longer has access to the secret. The container ID is different, because the\\xA0service update\\xA0command redeploys the service.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker container exec -it $(docker ps --filter name=redis -q) cat /run/secrets/my_secret_data\"),mdx(\"li\",{parentName:\"ol\"},\"cat: can\\\\'t open \\\\'/run/secrets/my_secret_data\\\\': No such file or directory\"),mdx(\"li\",{parentName:\"ol\"},\"Stop and remove the service, and remove the secret from Docker.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker service rm redis\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker secret rm my_secret_data\")),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Simple example: Use secrets in a Windows service\")),mdx(\"p\",null,\"This is a very simple example which shows how to use secrets with a Microsoft IIS service running on Docker 17.06 EE on Microsoft Windows Server 2016 or Docker for Mac 17.06 on Microsoft Windows 10. It is a naive example that stores the webpage in a secret.\"),mdx(\"p\",null,\"This example assumes that you have PowerShell installed.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Save the following into a new file\\xA0index.html.\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<html>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<head><title>Hello Docker</title></head>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<body>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<p>Hello Docker! You have deployed a HTML page.</p>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"</body>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"</html>\")),mdx(\"li\",{parentName:\"ol\"},\"If you have not already done so, initialize or join the swarm.\"),mdx(\"li\",{parentName:\"ol\"},\"docker swarm init\"),mdx(\"li\",{parentName:\"ol\"},\"Save the\\xA0index.html\\xA0file as a swarm secret named\\xA0homepage.\"),mdx(\"li\",{parentName:\"ol\"},\"docker secret create homepage index.html\"),mdx(\"li\",{parentName:\"ol\"},\"Create an IIS service and grant it access to the\\xA0homepage\\xA0secret.\"),mdx(\"li\",{parentName:\"ol\"},\"docker service create\"),mdx(\"li\",{parentName:\"ol\"},\"--name my-iis\"),mdx(\"li\",{parentName:\"ol\"},\"--publish published=8000,target=8000\"),mdx(\"li\",{parentName:\"ol\"},\"--secret src=homepage,target=\\\"\\\\inetpub\\\\wwwroot\\\\index.html\\\"\"),mdx(\"li\",{parentName:\"ol\"},\"microsoft/iis:nanoserver\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": There is technically no reason to use secrets for this example. With Docker 17.06 and higher,\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/configs/\"}),\"configs\"),\"\\xA0are a better fit. This example is for illustration only.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Access the IIS service at\\xA0http://localhost:8000/. It should serve the HTML content from the first step.\"),mdx(\"li\",{parentName:\"ol\"},\"Remove the service and the secret.\"),mdx(\"li\",{parentName:\"ol\"},\"docker service rm my-iis\"),mdx(\"li\",{parentName:\"ol\"},\"docker secret rm homepage\"),mdx(\"li\",{parentName:\"ol\"},\"docker image remove secret-test\")),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Intermediate example: Use secrets with a Nginx service\")),mdx(\"p\",null,\"This example is divided into two parts.\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/secrets/#generate-the-site-certificate\"}),\"The first part\"),\"\\xA0is all about generating the site certificate and does not directly involve Docker secrets at all, but it sets up\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/secrets/#configure-the-nginx-container\"}),\"the second part\"),\", where you store and use the site certificate and Nginx configuration as secrets.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"GENERATE THE SITE CERTIFICATE\")),mdx(\"p\",null,\"Generate a root CA and TLS certificate and key for your site. For production sites, you may want to use a service such as\\xA0Let's Encrypt\\xA0to generate the TLS certificate and key, but this example uses command-line tools. This step is a little complicated, but is only a set-up step so that you have something to store as a Docker secret. If you want to skip these sub-steps, you can\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://letsencrypt.org/getting-started/\"}),\"use Let's Encrypt\"),\"\\xA0to generate the site key and certificate, name the files\\xA0site.key\\xA0and\\xA0site.crt, and skip to\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/secrets/#configure-the-nginx-container\"}),\"Configure the Nginx container\"),\".\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Generate a root key.\"),mdx(\"li\",{parentName:\"ol\"},\"$ openssl genrsa -out \\\"root-ca.key\\\" 4096\"),mdx(\"li\",{parentName:\"ol\"},\"Generate a CSR using the root key.\"),mdx(\"li\",{parentName:\"ol\"},\"$ openssl req \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"-new -key \\\"root-ca.key\\\" \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"-out \\\"root-ca.csr\\\" -sha256 \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"-subj \\\\'/C=US/ST=CA/L=San Francisco/O=Docker/CN=Swarm Secret Example CA\\\\'\"),mdx(\"li\",{parentName:\"ol\"},\"Configure the root CA. Edit a new file called\\xA0root-ca.cnf\\xA0and paste the following contents into it. This constrains the root CA to signing leaf certificates and not intermediate CAs.\"),mdx(\"li\",{parentName:\"ol\"},\"[root_ca]\"),mdx(\"li\",{parentName:\"ol\"},\"basicConstraints = critical,CA:TRUE,pathlen:1\"),mdx(\"li\",{parentName:\"ol\"},\"keyUsage = critical, nonRepudiation, cRLSign, keyCertSign\"),mdx(\"li\",{parentName:\"ol\"},\"subjectKeyIdentifier=hash\"),mdx(\"li\",{parentName:\"ol\"},\"Sign the certificate.\"),mdx(\"li\",{parentName:\"ol\"},\"$ openssl x509 -req -days 3650 -in \\\"root-ca.csr\\\" \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"-signkey \\\"root-ca.key\\\" -sha256 -out \\\"root-ca.crt\\\" \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"-extfile \\\"root-ca.cnf\\\" -extensions \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"root_ca\"),mdx(\"li\",{parentName:\"ol\"},\"Generate the site key.\"),mdx(\"li\",{parentName:\"ol\"},\"$ openssl genrsa -out \\\"site.key\\\" 4096\"),mdx(\"li\",{parentName:\"ol\"},\"Generate the site certificate and sign it with the site key.\"),mdx(\"li\",{parentName:\"ol\"},\"$ openssl req -new -key \\\"site.key\\\" -out \\\"site.csr\\\" -sha256 \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"-subj \\\\'/C=US/ST=CA/L=San Francisco/O=Docker/CN=localhost\\\\'\"),mdx(\"li\",{parentName:\"ol\"},\"Configure the site certificate. Edit a new file called\\xA0site.cnf\\xA0and paste the following contents into it. This constrains the site certificate so that it can only be used to authenticate a server and can't be used to sign certificates.\"),mdx(\"li\",{parentName:\"ol\"},\"[server]\"),mdx(\"li\",{parentName:\"ol\"},\"authorityKeyIdentifier=keyid,issuer\"),mdx(\"li\",{parentName:\"ol\"},\"basicConstraints = critical,CA:FALSE\"),mdx(\"li\",{parentName:\"ol\"},\"extendedKeyUsage=serverAuth\"),mdx(\"li\",{parentName:\"ol\"},\"keyUsage = critical, digitalSignature, keyEncipherment\"),mdx(\"li\",{parentName:\"ol\"},\"subjectAltName = DNS:localhost, IP:127.0.0.1\"),mdx(\"li\",{parentName:\"ol\"},\"subjectKeyIdentifier=hash\"),mdx(\"li\",{parentName:\"ol\"},\"Sign the site certificate.\"),mdx(\"li\",{parentName:\"ol\"},\"$ openssl x509 -req -days 750 -in \\\"site.csr\\\" -sha256 \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"-CA \\\"root-ca.crt\\\" -CAkey \\\"root-ca.key\\\" -CAcreateserial \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"-out \\\"site.crt\\\" -extfile \\\"site.cnf\\\" -extensions server\"),mdx(\"li\",{parentName:\"ol\"},\"The\\xA0site.csr\\xA0and\\xA0site.cnf\\xA0files are not needed by the Nginx service, but you need them if you want to generate a new site certificate. Protect the\\xA0root-ca.key\\xA0file.\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"CONFIGURE THE NGINX CONTAINER\")),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Produce a very basic Nginx configuration that serves static files over HTTPS. The TLS certificate and key are stored as Docker secrets so that they can be rotated easily.\")),mdx(\"p\",null,\"In the current directory, create a new file called\\xA0site.conf\\xA0with the following contents:\"),mdx(\"p\",null,\"server {\"),mdx(\"p\",null,\"listen 443 ssl;\"),mdx(\"p\",null,\"server_name localhost;\"),mdx(\"p\",null,\"ssl_certificate /run/secrets/site.crt;\"),mdx(\"p\",null,\"ssl_certificate_key /run/secrets/site.key;\"),mdx(\"p\",null,\"location / {\"),mdx(\"p\",null,\"root /usr/share/nginx/html;\"),mdx(\"p\",null,\"index index.html index.htm;\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"}\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Create three secrets, representing the key, the certificate, and the\\xA0site.conf. You can store any file as a secret as long as it is smaller than 500 KB. This allows you to decouple the key, certificate, and configuration from the services that use them. In each of these commands, the last argument represents the path to the file to read the secret from on the host machine's filesystem. In these examples, the secret name and the file name are the same.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker secret create site.key site.key\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker secret create site.crt site.crt\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker secret create site.conf site.conf\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker secret ls\"),mdx(\"li\",{parentName:\"ol\"},\"ID NAME CREATED UPDATED\"),mdx(\"li\",{parentName:\"ol\"},\"2hvoi9mnnaof7olr3z5g3g7fp site.key 58 seconds ago 58 seconds ago\"),mdx(\"li\",{parentName:\"ol\"},\"aya1dh363719pkiuoldpter4b site.crt 24 seconds ago 24 seconds ago\"),mdx(\"li\",{parentName:\"ol\"},\"zoa5df26f7vpcoz42qf2csth8 site.conf 11 seconds ago 11 seconds ago\"),mdx(\"li\",{parentName:\"ol\"},\"Create a service that runs Nginx and has access to the three secrets. The last part of the\\xA0docker service create\\xA0command creates a symbolic link from the location of the\\xA0site.conf\\xA0secret to\\xA0/etc/nginx.conf.d/, where Nginx looks for extra configuration files. This step happens before Nginx actually starts, so you don't need to rebuild your image if you change the Nginx configuration.\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": Normally you would create a Dockerfile which copies the\\xA0site.conf\\xA0into place, build the image, and run a container using your custom image. This example does not require a custom image. It puts the\\xA0site.conf\\xA0into place and runs the container all in one step.\"),mdx(\"p\",null,\"In Docker 17.05 and earlier, secrets are always located within the\\xA0/run/secrets/\\xA0directory. Docker 17.06 and higher allow you to specify a custom location for a secret within the container. The two examples below illustrate the difference. The older version of this command requires you to create a symbolic link to the true location of the\\xA0site.conf\\xA0file so that Nginx can read it, but the newer version does not require this. The older example is preserved so that you can see the difference.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Docker 17.06 and higher\"),\":\"),mdx(\"li\",{parentName:\"ul\"},\"$ docker service create \\\\\"),mdx(\"li\",{parentName:\"ul\"},\"--name nginx \\\\\"),mdx(\"li\",{parentName:\"ul\"},\"--secret site.key \\\\\"),mdx(\"li\",{parentName:\"ul\"},\"--secret site.crt \\\\\"),mdx(\"li\",{parentName:\"ul\"},\"--secret source=site.conf,target=/etc/nginx/conf.d/site.conf \\\\\"),mdx(\"li\",{parentName:\"ul\"},\"--publish published=3000,target=443 \\\\\"),mdx(\"li\",{parentName:\"ul\"},\"nginx:latest \\\\\"),mdx(\"li\",{parentName:\"ul\"},\"sh -c \\\"exec nginx -g \\\\'daemon off;\\\\'\\\"\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"Docker 17.05 and earlier\"),\":\"),mdx(\"li\",{parentName:\"ul\"},\"$ docker service create \\\\\"),mdx(\"li\",{parentName:\"ul\"},\"--name nginx \\\\\"),mdx(\"li\",{parentName:\"ul\"},\"--secret site.key \\\\\"),mdx(\"li\",{parentName:\"ul\"},\"--secret site.crt \\\\\"),mdx(\"li\",{parentName:\"ul\"},\"--secret site.conf \\\\\"),mdx(\"li\",{parentName:\"ul\"},\"--publish published=3000,target=443 \\\\\"),mdx(\"li\",{parentName:\"ul\"},\"nginx:latest \\\\\"),mdx(\"li\",{parentName:\"ul\"},\"sh -c \\\"ln -s /run/secrets/site.conf /etc/nginx/conf.d/site.conf && exec nginx -g \\\\'daemon off;\\\\'\\\"\")))),mdx(\"p\",null,\"The first example shows both the short and long syntax for secrets, and the second example shows only the short syntax. The short syntax creates files in\\xA0/run/secrets/\\xA0with the same name as the secret. Within the running containers, the following three files now exist:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},\"/run/secrets/site.key\"),mdx(\"li\",{parentName:\"ul\"},\"/run/secrets/site.crt\"),mdx(\"li\",{parentName:\"ul\"},\"/etc/nginx/conf.d/site.conf\\xA0(or\\xA0/run/secrets/site.conf\\xA0if you used the second example)\")))),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Verify that the Nginx service is running.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker service ls\"),mdx(\"li\",{parentName:\"ol\"},\"ID NAME MODE REPLICAS IMAGE\"),mdx(\"li\",{parentName:\"ol\"},\"zeskcec62q24 nginx replicated 1/1 nginx:latest\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker service ps nginx\"),mdx(\"li\",{parentName:\"ol\"},\"NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS\"),mdx(\"li\",{parentName:\"ol\"},\"nginx.1.9ls3yo9ugcls nginx:latest moby Running Running 3 minutes ago\"),mdx(\"li\",{parentName:\"ol\"},\"Verify that the service is operational: you can reach the Nginx server, and that the correct TLS certificate is being used.\"),mdx(\"li\",{parentName:\"ol\"},\"$ curl --cacert root-ca.crt https://localhost:3000\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<!DOCTYPE html>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<html>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<head>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<title>Welcome to nginx!</title>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<style>\")),mdx(\"li\",{parentName:\"ol\"},\"body {\"),mdx(\"li\",{parentName:\"ol\"},\"width: 35em;\"),mdx(\"li\",{parentName:\"ol\"},\"margin: 0 auto;\"),mdx(\"li\",{parentName:\"ol\"},\"font-family: Tahoma, Verdana, Arial, sans-serif;\"),mdx(\"li\",{parentName:\"ol\"},\"}\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"</style>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"</head>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<body>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<h1>Welcome to nginx!</h1>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<p>\"),\"If you see this page, the nginx web server is successfully installed and\"),mdx(\"li\",{parentName:\"ol\"},\"working. Further configuration is required.\",mdx(\"inlineCode\",{parentName:\"li\"},\"</p>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<p>\"),\"For online documentation and support. refer to\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<a href=\\\"http://nginx.org/\\\">nginx.org</a>.<br/>\")),mdx(\"li\",{parentName:\"ol\"},\"Commercial support is available at\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<a href=\\\"http://nginx.com/\\\">nginx.com</a>.</p>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<p><em>Thank you for using nginx.</em></p>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"</body>\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"</html>\")),mdx(\"li\",{parentName:\"ol\"},\"$ openssl s_client -connect localhost:3000 -CAfile root-ca.crt\"),mdx(\"li\",{parentName:\"ol\"},\"CONNECTED(00000003)\"),mdx(\"li\",{parentName:\"ol\"},\"depth=1 /C=US/ST=CA/L=San Francisco/O=Docker/CN=Swarm Secret Example CA\"),mdx(\"li\",{parentName:\"ol\"},\"verify return:1\"),mdx(\"li\",{parentName:\"ol\"},\"depth=0 /C=US/ST=CA/L=San Francisco/O=Docker/CN=localhost\"),mdx(\"li\",{parentName:\"ol\"},\"verify return:1\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"hr\",{parentName:\"li\"})),mdx(\"li\",{parentName:\"ol\"},\"Certificate chain\"),mdx(\"li\",{parentName:\"ol\"},\"0 s:/C=US/ST=CA/L=San Francisco/O=Docker/CN=localhost\"),mdx(\"li\",{parentName:\"ol\"},\"i:/C=US/ST=CA/L=San Francisco/O=Docker/CN=Swarm Secret Example CA\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"hr\",{parentName:\"li\"})),mdx(\"li\",{parentName:\"ol\"},\"Server certificate\"),mdx(\"li\",{parentName:\"ol\"},\"-----BEGIN CERTIFICATE-----\"),mdx(\"li\",{parentName:\"ol\"},\"...\"),mdx(\"li\",{parentName:\"ol\"},\"-----END CERTIFICATE-----\"),mdx(\"li\",{parentName:\"ol\"},\"subject=/C=US/ST=CA/L=San Francisco/O=Docker/CN=localhost\"),mdx(\"li\",{parentName:\"ol\"},\"issuer=/C=US/ST=CA/L=San Francisco/O=Docker/CN=Swarm Secret Example CA\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"hr\",{parentName:\"li\"})),mdx(\"li\",{parentName:\"ol\"},\"No client certificate CA names sent\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"hr\",{parentName:\"li\"})),mdx(\"li\",{parentName:\"ol\"},\"SSL handshake has read 1663 bytes and written 712 bytes\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"hr\",{parentName:\"li\"})),mdx(\"li\",{parentName:\"ol\"},\"New, TLSv1/SSLv3, Cipher is AES256-SHA\"),mdx(\"li\",{parentName:\"ol\"},\"Server public key is 4096 bit\"),mdx(\"li\",{parentName:\"ol\"},\"Secure Renegotiation IS supported\"),mdx(\"li\",{parentName:\"ol\"},\"Compression: NONE\"),mdx(\"li\",{parentName:\"ol\"},\"Expansion: NONE\"),mdx(\"li\",{parentName:\"ol\"},\"SSL-Session:\"),mdx(\"li\",{parentName:\"ol\"},\"Protocol : TLSv1\"),mdx(\"li\",{parentName:\"ol\"},\"Cipher : AES256-SHA\"),mdx(\"li\",{parentName:\"ol\"},\"Session-ID: A1A8BF35549C5715648A12FD7B7E3D861539316B03440187D9DA6C2E48822853\"),mdx(\"li\",{parentName:\"ol\"},\"Session-ID-ctx:\"),mdx(\"li\",{parentName:\"ol\"},\"Master-Key: F39D1B12274BA16D3A906F390A61438221E381952E9E1E05D3DD784F0135FB81353DA38C6D5C021CB926E844DFC49FC4\"),mdx(\"li\",{parentName:\"ol\"},\"Key-Arg : None\"),mdx(\"li\",{parentName:\"ol\"},\"Start Time: 1481685096\"),mdx(\"li\",{parentName:\"ol\"},\"Timeout : 300 (sec)\"),mdx(\"li\",{parentName:\"ol\"},\"Verify return code: 0 (ok)\"),mdx(\"li\",{parentName:\"ol\"},\"To clean up after running this example, remove the\\xA0nginx\\xA0service and the stored secrets.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker service rm nginx\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker secret rm site.crt site.key site.conf\")),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Advanced example: Use secrets with a WordPress service\")),mdx(\"p\",null,\"In this example, you create a single-node MySQL service with a custom root password, add the credentials as secrets, and create a single-node WordPress service which uses these credentials to connect to MySQL. The\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/secrets/#example-rotate-a-secret\"}),\"next example\"),\"\\xA0builds on this one and shows you how to rotate the MySQL password and update the services so that the WordPress service can still connect to MySQL.\"),mdx(\"p\",null,\"This example illustrates some techniques to use Docker secrets to avoid saving sensitive credentials within your image or passing them directly on the command line.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note: This example uses a single-Engine swarm for simplicity, and uses a single-node MySQL service because a single MySQL server instance cannot be scaled by simply using a replicated service, and setting up a MySQL cluster is beyond the scope of this example.\")),mdx(\"p\",null,\"Also, changing a MySQL root passphrase isn't as simple as changing a file on disk. You must use a query or a\\xA0mysqladmin\\xA0command to change the password in MySQL.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Generate a random alphanumeric password for MySQL and store it as a Docker secret with the name\\xA0mysql_password\\xA0using the\\xA0docker secret create\\xA0command. To make the password shorter or longer, adjust the last argument of the\\xA0openssl\\xA0command. This is just one way to create a relatively random password. You can use another command to generate the password if you choose.\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": After you create a secret, you cannot update it. You can only remove and re-create it, and you cannot remove a secret that a service is using. However, you can grant or revoke a running service's access to secrets using\\xA0docker service update. If you need the ability to update a secret, consider adding a version component to the secret name, so that you can later add a new version, update the service to use it, then remove the old version.\"),mdx(\"p\",null,\"The last argument is set to\\xA0-, which indicates that the input is read from standard input.\"),mdx(\"p\",null,\"$ openssl rand -base64 20 | docker secret create mysql_password -\"),mdx(\"p\",null,\"l1vinzevzhj4goakjap5ya409\"),mdx(\"p\",null,\"The value returned is not the password, but the ID of the secret. In the remainder of this tutorial, the ID output is omitted.\"),mdx(\"p\",null,\"Generate a second secret for the MySQL\\xA0root\\xA0user. This secret isn't shared with the WordPress service created later. It's only needed to bootstrap the\\xA0mysql\\xA0service.\"),mdx(\"p\",null,\"$ openssl rand -base64 20 | docker secret create mysql_root_password -\"),mdx(\"p\",null,\"List the secrets managed by Docker using\\xA0docker secret ls:\"),mdx(\"p\",null,\"$ docker secret ls\"),mdx(\"p\",null,\"ID NAME CREATED UPDATED\"),mdx(\"p\",null,\"l1vinzevzhj4goakjap5ya409 mysql_password 41 seconds ago 41 seconds ago\"),mdx(\"p\",null,\"yvsczlx9votfw3l0nz5rlidig mysql_root_password 12 seconds ago 12 seconds ago\"),mdx(\"p\",null,\"The secrets are stored in the encrypted Raft logs for the swarm.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Create a user-defined overlay network which is used for communication between the MySQL and WordPress services. There is no need to expose the MySQL service to any external host or container.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker network create -d overlay mysql_private\"),mdx(\"li\",{parentName:\"ol\"},\"Create the MySQL service. The MySQL service has the following characteristics:\",mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},\"Because the scale is set to\\xA01, only a single MySQL task runs. Load-balancing MySQL is left as an exercise to the reader and involves more than just scaling the service.\"),mdx(\"li\",{parentName:\"ul\"},\"Only reachable by other containers on the\\xA0mysql_private\\xA0network.\"),mdx(\"li\",{parentName:\"ul\"},\"Uses the volume\\xA0mydata\\xA0to store the MySQL data, so that it persists across restarts to the\\xA0mysql\\xA0service.\"),mdx(\"li\",{parentName:\"ul\"},\"The secrets are each mounted in a\\xA0tmpfs\\xA0filesystem at/run/secrets/mysql_password\\xA0and\\xA0/run/secrets/mysql_root_password. They are never exposed as environment variables, nor can they be committed to an image if the\\xA0docker commit\\xA0command is run. The\\xA0mysql_password\\xA0secret is the one used by the non-privileged WordPress container to connect to MySQL.\"),mdx(\"li\",{parentName:\"ul\"},\"Sets the environment variables\\xA0MYSQL_PASSWORD_FILE\\xA0andMYSQL_ROOT_PASSWORD_FILE\\xA0to point to the files\\xA0/run/secrets/mysql_password\\xA0and\\xA0/run/secrets/mysql_root_password. The\\xA0mysql\\xA0image reads the password strings from those files when initializing the system database for the first time. Afterward, the passwords are stored in the MySQL system database itself.\"),mdx(\"li\",{parentName:\"ul\"},\"Sets environment variables\\xA0MYSQL_USER\\xA0and\\xA0MYSQL_DATABASE. A new database called\\xA0wordpress\\xA0is created when the container starts, and the\\xA0wordpress\\xA0user has full permissions for this database only. This user cannot create or drop databases or change the MySQL configuration.\"),mdx(\"li\",{parentName:\"ul\"},\"$ docker service create \\\\\"),mdx(\"li\",{parentName:\"ul\"},\"--name mysql \\\\\"),mdx(\"li\",{parentName:\"ul\"},\"--replicas 1 \\\\\"),mdx(\"li\",{parentName:\"ul\"},\"--network mysql_private \\\\\"),mdx(\"li\",{parentName:\"ul\"},\"--mount type=volume,source=mydata,destination=/var/lib/mysql \\\\\"),mdx(\"li\",{parentName:\"ul\"},\"--secret source=mysql_root_password,target=mysql_root_password \\\\\"),mdx(\"li\",{parentName:\"ul\"},\"--secret source=mysql_password,target=mysql_password \\\\\"),mdx(\"li\",{parentName:\"ul\"},\"-e MYSQL_ROOT_PASSWORD_FILE=\\\"/run/secrets/mysql_root_password\\\" \\\\\"),mdx(\"li\",{parentName:\"ul\"},\"-e MYSQL_PASSWORD_FILE=\\\"/run/secrets/mysql_password\\\" \\\\\"),mdx(\"li\",{parentName:\"ul\"},\"-e MYSQL_USER=\\\"wordpress\\\" \\\\\"),mdx(\"li\",{parentName:\"ul\"},\"-e MYSQL_DATABASE=\\\"wordpress\\\" \\\\\"),mdx(\"li\",{parentName:\"ul\"},\"mysql:latest\"))),mdx(\"li\",{parentName:\"ol\"},\"Verify that the\\xA0mysql\\xA0container is running using the\\xA0docker service ls\\xA0command.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker service ls\"),mdx(\"li\",{parentName:\"ol\"},\"ID NAME MODE REPLICAS IMAGE\"),mdx(\"li\",{parentName:\"ol\"},\"wvnh0siktqr3 mysql replicated 1/1 mysql:latest\")),mdx(\"p\",null,\"At this point, you could actually revoke the\\xA0mysql\\xA0service's access to the\\xA0mysql_passwordand\\xA0mysql_root_password\\xA0secrets because the passwords have been saved in the MySQL system database. Don't do that for now, because we use them later to facilitate rotating the MySQL password.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Now that MySQL is set up, create a WordPress service that connects to the MySQL service. The WordPress service has the following characteristics:\",mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},\"Because the scale is set to\\xA01, only a single WordPress task runs. Load-balancing WordPress is left as an exercise to the reader, because of limitations with storing WordPress session data on the container filesystem.\"),mdx(\"li\",{parentName:\"ul\"},\"Exposes WordPress on port 30000 of the host machine, so that you can access it from external hosts. You can expose port 80 instead if you do not have a web server running on port 80 of the host machine.\"),mdx(\"li\",{parentName:\"ul\"},\"Connects to the\\xA0mysql_private\\xA0network so it can communicate with the\\xA0mysqlcontainer, and also publishes port 80 to port 30000 on all swarm nodes.\"),mdx(\"li\",{parentName:\"ul\"},\"Has access to the\\xA0mysql_password\\xA0secret, but specifies a different target file name within the container. The WordPress container uses the mount point\\xA0/run/secrets/wp_db_password. Also specifies that the secret is not group-or-world-readable, by setting the mode to\\xA00400.\"),mdx(\"li\",{parentName:\"ul\"},\"Sets the environment variable\\xA0WORDPRESS_DB_PASSWORD_FILE\\xA0to the file path where the secret is mounted. The WordPress service reads the MySQL password string from that file and add it to the\\xA0wp-config.php\\xA0configuration file.\"),mdx(\"li\",{parentName:\"ul\"},\"Connects to the MySQL container using the username\\xA0wordpress\\xA0and the password in\\xA0/run/secrets/wp_db_password\\xA0and creates the\\xA0wordpress\\xA0database if it does not yet exist.\"),mdx(\"li\",{parentName:\"ul\"},\"Stores its data, such as themes and plugins, in a volume called\\xA0wpdata\\xA0so these files persist when the service restarts.\"))),mdx(\"li\",{parentName:\"ol\"},\"$ docker service create \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--name wordpress \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--replicas 1 \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--network mysql_private \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--publish published=30000,target=80 \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--mount type=volume,source=wpdata,destination=/var/www/html \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--secret source=mysql_password,target=wp_db_password,mode=0400 \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"-e WORDPRESS_DB_USER=\\\"wordpress\\\" \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"-e WORDPRESS_DB_PASSWORD_FILE=\\\"/run/secrets/wp_db_password\\\" \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"-e WORDPRESS_DB_HOST=\\\"mysql:3306\\\" \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"-e WORDPRESS_DB_NAME=\\\"wordpress\\\" \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"wordpress:latest\"),mdx(\"li\",{parentName:\"ol\"},\"Verify the service is running using\\xA0docker service ls\\xA0and\\xA0docker service ps\\xA0commands.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker service ls\"),mdx(\"li\",{parentName:\"ol\"},\"ID NAME MODE REPLICAS IMAGE\"),mdx(\"li\",{parentName:\"ol\"},\"wvnh0siktqr3 mysql replicated 1/1 mysql:latest\"),mdx(\"li\",{parentName:\"ol\"},\"nzt5xzae4n62 wordpress replicated 1/1 wordpress:latest\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker service ps wordpress\"),mdx(\"li\",{parentName:\"ol\"},\"ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS\"),mdx(\"li\",{parentName:\"ol\"},\"aukx6hgs9gwc wordpress.1 wordpress:latest moby Running Running 52 seconds ago\")),mdx(\"p\",null,\"At this point, you could actually revoke the WordPress service's access to the\\xA0mysql_password\\xA0secret, because WordPress has copied the secret to its configuration file\\xA0wp-config.php. Don't do that for now, because we use it later to facilitate rotating the MySQL password.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Access\\xA0http://localhost:30000/\\xA0from any swarm node and set up WordPress using the web-based wizard. All of these settings are stored in the MySQL\\xA0wordpress\\xA0database. WordPress automatically generates a password for your WordPress user, which is completely different from the password WordPress uses to access MySQL. Store this password securely, such as in a password manager. You need it to log into WordPress after\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/secrets/#example-rotate-a-secret\"}),\"rotating the secret\"),\".\")),mdx(\"p\",null,\"Go ahead and write a blog post or two and install a WordPress plugin or theme to verify that WordPress is fully operational and its state is saved across service restarts.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Do not clean up any services or secrets if you intend to proceed to the next example, which demonstrates how to rotate the MySQL root password.\")),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Example: Rotate a secret\")),mdx(\"p\",null,\"This example builds upon the previous one. In this scenario, you create a new secret with a new MySQL password, update the\\xA0mysql\\xA0and\\xA0wordpress\\xA0services to use it, then remove the old secret.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": Changing the password on a MySQL database involves running extra queries or commands, as opposed to just changing a single environment variable or a file, since the image only sets the MySQL password if the database doesn't already exist, and MySQL stores the password within a MySQL database by default. Rotating passwords or other secrets may involve additional steps outside of Docker.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Create the new password and store it as a secret named\\xA0mysql_password_v2.\"),mdx(\"li\",{parentName:\"ol\"},\"$ openssl rand -base64 20 | docker secret create mysql_password_v2 -\"),mdx(\"li\",{parentName:\"ol\"},\"Update the MySQL service to give it access to both the old and new secrets. Remember that you cannot update or rename a secret, but you can revoke a secret and grant access to it using a new target filename.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker service update \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--secret-rm mysql_password mysql\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker service update \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--secret-add source=mysql_password,target=old_mysql_password \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--secret-add source=mysql_password_v2,target=mysql_password \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"mysql\")),mdx(\"p\",null,\"Updating a service causes it to restart, and when the MySQL service restarts the second time, it has access to the old secret under\\xA0/run/secrets/old_mysql_password\\xA0and the new secret under\\xA0/run/secrets/mysql_password.\"),mdx(\"p\",null,\"Even though the MySQL service has access to both the old and new secrets now, the MySQL password for the WordPress user has not yet been changed.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": This example does not rotate the MySQL\\xA0root\\xA0password.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Now, change the MySQL password for the\\xA0wordpress\\xA0user using the\\xA0mysqladmin\\xA0CLI. This command reads the old and new password from the files in\\xA0/run/secrets\\xA0but does not expose them on the command line or save them in the shell history.\")),mdx(\"p\",null,\"Do this quickly and move on to the next step, because WordPress loses the ability to connect to MySQL.\"),mdx(\"p\",null,\"First, find the ID of the\\xA0mysql\\xA0container task.\"),mdx(\"p\",null,\"$ docker ps --filter name=mysql -q\"),mdx(\"p\",null,\"c7705cf6176f\"),mdx(\"p\",null,\"Substitute the ID in the command below, or use the second variant which uses shell expansion to do it all in a single step.\"),mdx(\"p\",null,\"$ docker container exec \",mdx(\"inlineCode\",{parentName:\"p\"},\"<CONTAINER_ID>\"),\" \\\\\"),mdx(\"p\",null,\"bash -c \\\\'mysqladmin --user=wordpress --password=\\\"$(< /run/secrets/old_mysql_password)\\\" password \\\"$(< /run/secrets/mysql_password)\\\"\\\\'\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"or\"),\":\"),mdx(\"p\",null,\"$ docker container exec $(docker ps --filter name=mysql -q) \\\\\"),mdx(\"p\",null,\"bash -c \\\\'mysqladmin --user=wordpress --password=\\\"$(< /run/secrets/old_mysql_password)\\\" password \\\"$(< /run/secrets/mysql_password)\\\"\\\\'\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Update the\\xA0wordpress\\xA0service to use the new password, keeping the target path at\\xA0/run/secrets/wp_db_secret\\xA0and keeping the file permissions at\\xA00400. This triggers a rolling restart of the WordPress service and the new secret is used.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker service update \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--secret-rm mysql_password \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--secret-add source=mysql_password_v2,target=wp_db_password,mode=0400 \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"wordpress\"),mdx(\"li\",{parentName:\"ol\"},\"Verify that WordPress works by browsing to http://localhost:30000/ on any swarm node again. Use the WordPress username and password from when you ran through the WordPress wizard in the previous task.\")),mdx(\"p\",null,\"Verify that the blog post you wrote still exists, and if you changed any configuration values, verify that they are still changed.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Revoke access to the old secret from the MySQL service and remove the old secret from Docker.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker service update \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"--secret-rm mysql_password \\\\\"),mdx(\"li\",{parentName:\"ol\"},\"mysql\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker secret rm mysql_password\"),mdx(\"li\",{parentName:\"ol\"},\"If you want to try the running all of these examples again or just want to clean up after running through them, use these commands to remove the WordPress service, the MySQL container, the\\xA0mydata\\xA0and\\xA0wpdata\\xA0volumes, and the Docker secrets.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker service rm wordpress mysql\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker volume rm mydata wpdata\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker secret rm mysql_password_v2 mysql_root_password\")),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Build support for Docker Secrets into your images\")),mdx(\"p\",null,\"If you develop a container that can be deployed as a service and requires sensitive data, such as a credential, as an environment variable, consider adapting your image to take advantage of Docker secrets. One way to do this is to ensure that each parameter you pass to the image when creating the container can also be read from a file.\"),mdx(\"p\",null,\"Many of the official images in the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/docker-library/\"}),\"Docker library\"),\", such as the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/docker-library/wordpress/\"}),\"wordpress\"),\"\\xA0image used in the above examples, have been updated in this way.\"),mdx(\"p\",null,\"When you start a WordPress container, you provide it with the parameters it needs by setting them as environment variables. The WordPress image has been updated so that the environment variables which contain important data for WordPress, such as\\xA0WORDPRESS_DB_PASSWORD, also have variants which can read their values from a file (WORDPRESS_DB_PASSWORD_FILE). This strategy ensures that backward compatibility is preserved, while allowing your container to read the information from a Docker-managed secret instead of being passed directly.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": Docker secrets do not set environment variables directly. This was a conscious decision, because environment variables can unintentionally be leaked between containers (for instance, if you use\\xA0--link).\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Use Secrets in Compose\")),mdx(\"p\",null,\"version: \\\\'3.1\\\\'\"),mdx(\"p\",null,\"services:\"),mdx(\"p\",null,\"db:\"),mdx(\"p\",null,\"image: mysql:latest\"),mdx(\"p\",null,\"volumes:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"db_data:/var/lib/mysql\")),mdx(\"p\",null,\"environment:\"),mdx(\"p\",null,\"MYSQL_ROOT_PASSWORD_FILE: /run/secrets/db_root_password\"),mdx(\"p\",null,\"MYSQL_DATABASE: wordpress\"),mdx(\"p\",null,\"MYSQL_USER: wordpress\"),mdx(\"p\",null,\"MYSQL_PASSWORD_FILE: /run/secrets/db_password\"),mdx(\"p\",null,\"secrets:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},\"db_root_password\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},\"db_password\"))),mdx(\"p\",null,\"wordpress:\"),mdx(\"p\",null,\"depends_on:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"db\")),mdx(\"p\",null,\"image: wordpress:latest\"),mdx(\"p\",null,\"ports:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"\\\"8000:80\\\"\")),mdx(\"p\",null,\"environment:\"),mdx(\"p\",null,\"WORDPRESS_DB_HOST: db:3306\"),mdx(\"p\",null,\"WORDPRESS_DB_USER: wordpress\"),mdx(\"p\",null,\"WORDPRESS_DB_PASSWORD_FILE: /run/secrets/db_password\"),mdx(\"p\",null,\"secrets:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"db_password\")),mdx(\"p\",null,\"secrets:\"),mdx(\"p\",null,\"db_password:\"),mdx(\"p\",null,\"file: db_password.txt\"),mdx(\"p\",null,\"db_root_password:\"),mdx(\"p\",null,\"file: db_root_password.txt\"),mdx(\"p\",null,\"volumes:\"),mdx(\"p\",null,\"db_data:\"),mdx(\"p\",null,\"This example creates a simple WordPress site using two secrets in a compose file.\"),mdx(\"p\",null,\"The keyword\\xA0secrets:\\xA0defines two secrets\\xA0db_password:\\xA0and\\xA0db_root_password:.\"),mdx(\"p\",null,\"When deploying, Docker creates these two secrets and populate them with the content from the file specified in the compose file.\"),mdx(\"p\",null,\"The db service uses both secrets, and the wordpress is using one.\"),mdx(\"p\",null,\"When you deploy, Docker mounts a file under\\xA0/run/secrets/\",mdx(\"inlineCode\",{parentName:\"p\"},\"<secret_name>\"),\"\\xA0in the services. These files are never persisted in disk, but are managed in memory.\"),mdx(\"p\",null,\"Each service uses environment variables to specify where the service should look for that secret data.\"),mdx(\"p\",null,\"More information on short and long syntax for secrets can be found at\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/compose/compose-file/#secrets\"}),\"Compose file version 3 reference\"),\".\"),mdx(\"h4\",null,\"Lock your swarm to protect its encryption key\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA05 minutes\")),mdx(\"p\",null,\"In Docker 1.13 and higher, the Raft logs used by swarm managers are encrypted on disk by default. This at-rest encryption protects your service's configuration and data from attackers who gain access to the encrypted Raft logs. One of the reasons this feature was introduced was in support of the new\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/secrets/\"}),\"Docker secrets\"),\"\\xA0feature.\"),mdx(\"p\",null,\"When Docker restarts, both the TLS key used to encrypt communication among swarm nodes, and the key used to encrypt and decrypt Raft logs on disk, are loaded into each manager node's memory. Docker 1.13 introduces the ability to protect the mutual TLS encryption key and the key used to encrypt and decrypt Raft logs at rest, by allowing you to take ownership of these keys and to require manual unlocking of your managers. This feature is called\\xA0autolock.\"),mdx(\"p\",null,\"When Docker restarts, you must\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/swarm_manager_locking/#unlock-a-swarm\"}),\"unlock the swarm\"),\"\\xA0first, using a\\xA0key encryption key\\xA0generated by Docker when the swarm was locked. You can rotate this key encryption key at any time.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": You don't need to unlock the swarm when a new node joins the swarm, because the key is propagated to it over mutual TLS.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Initialize a swarm with autolocking enabled\")),mdx(\"p\",null,\"When you initialize a new swarm, you can use the\\xA0--autolock\\xA0flag to enable autolocking of swarm manager nodes when Docker restarts.\"),mdx(\"p\",null,\"$ docker swarm init --autolock\"),mdx(\"p\",null,\"Swarm initialized: current node (k1q27tfyx9rncpixhk69sa61v) is now a manager.\"),mdx(\"p\",null,\"To add a worker to this swarm, run the following command:\"),mdx(\"p\",null,\"docker swarm join \\\\\"),mdx(\"p\",null,\"--token SWMTKN-1-0j52ln6hxjpxk2wgk917abcnxywj3xed0y8vi1e5m9t3uttrtu-7bnxvvlz2mrcpfonjuztmtts9 \\\\\"),mdx(\"p\",null,\"172.31.46.109:2377\"),mdx(\"p\",null,\"To add a manager to this swarm, run \\\\'docker swarm join-token manager\\\\' and follow the instructions.\"),mdx(\"p\",null,\"To unlock a swarm manager after it restarts, run the \",mdx(\"inlineCode\",{parentName:\"p\"},\"docker swarm unlock\")),mdx(\"p\",null,\"command and provide the following key:\"),mdx(\"p\",null,\"SWMKEY-1-WuYH/IX284+lRcXuoVf38viIDK3HJEKY13MIHX+tTt8\"),mdx(\"p\",null,\"Store the key in a safe place, such as in a password manager.\"),mdx(\"p\",null,\"When Docker restarts, you need to\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/swarm_manager_locking/#unlock-a-swarm\"}),\"unlock the swarm\"),\". A locked swarm causes an error like the following when you try to start or restart a service:\"),mdx(\"p\",null,\"$ sudo service docker restart\"),mdx(\"p\",null,\"$ docker service ls\"),mdx(\"p\",null,\"Error response from daemon: Swarm is encrypted and needs to be unlocked before it can be used. Use \\\"docker swarm unlock\\\" to unlock it.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Enable or disable autolock on an existing swarm\")),mdx(\"p\",null,\"To enable autolock on an existing swarm, set the\\xA0autolock\\xA0flag to\\xA0true.\"),mdx(\"p\",null,\"$ docker swarm update --autolock=true\"),mdx(\"p\",null,\"Swarm updated.\"),mdx(\"p\",null,\"To unlock a swarm manager after it restarts, run the \",mdx(\"inlineCode\",{parentName:\"p\"},\"docker swarm unlock\")),mdx(\"p\",null,\"command and provide the following key:\"),mdx(\"p\",null,\"SWMKEY-1-+MrE8NgAyKj5r3NcR4FiQMdgu+7W72urH0EZeSmP/0Y\"),mdx(\"p\",null,\"Please remember to store this key in a password manager, since without it you\"),mdx(\"p\",null,\"will not be able to restart the manager.\"),mdx(\"p\",null,\"To disable autolock, set\\xA0--autolock\\xA0to\\xA0false. The mutual TLS key and the encryption key used to read and write Raft logs are stored unencrypted on disk. There is a trade-off between the risk of storing the encryption key unencrypted at rest and the convenience of restarting a swarm without needing to unlock each manager.\"),mdx(\"p\",null,\"$ docker swarm update --autolock=false\"),mdx(\"p\",null,\"Keep the unlock key around for a short time after disabling autolocking, in case a manager goes down while it is still configured to lock using the old key.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Unlock a swarm\")),mdx(\"p\",null,\"To unlock a locked swarm, use\\xA0docker swarm unlock.\"),mdx(\"p\",null,\"$ docker swarm unlock\"),mdx(\"p\",null,\"Please enter unlock key:\"),mdx(\"p\",null,\"Enter the encryption key that was generated and shown in the command output when you locked the swarm or rotated the key, and the swarm unlocks.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"View the current unlock key for a running swarm\")),mdx(\"p\",null,\"Consider a situation where your swarm is running as expected, then a manager node becomes unavailable. You troubleshoot the problem and bring the physical node back online, but you need to unlock the manager by providing the unlock key to read the encrypted credentials and Raft logs.\"),mdx(\"p\",null,\"If the key has not been rotated since the node left the swarm, and you have a quorum of functional manager nodes in the swarm, you can view the current unlock key using\\xA0docker swarm unlock-key\\xA0without any arguments.\"),mdx(\"p\",null,\"$ docker swarm unlock-key\"),mdx(\"p\",null,\"To unlock a swarm manager after it restarts, run the \",mdx(\"inlineCode\",{parentName:\"p\"},\"docker swarm unlock\")),mdx(\"p\",null,\"command and provide the following key:\"),mdx(\"p\",null,\"SWMKEY-1-8jDgbUNlJtUe5P/lcr9IXGVxqZpZUXPzd+qzcGp4ZYA\"),mdx(\"p\",null,\"Please remember to store this key in a password manager, since without it you\"),mdx(\"p\",null,\"will not be able to restart the manager.\"),mdx(\"p\",null,\"If the key was rotated after the swarm node became unavailable and you do not have a record of the previous key, you may need to force the manager to leave the swarm and join it back to the swarm as a new manager.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Rotate the unlock key\")),mdx(\"p\",null,\"You should rotate the locked swarm's unlock key on a regular schedule.\"),mdx(\"p\",null,\"$ docker swarm unlock-key --rotate\"),mdx(\"p\",null,\"Successfully rotated manager unlock key.\"),mdx(\"p\",null,\"To unlock a swarm manager after it restarts, run the \",mdx(\"inlineCode\",{parentName:\"p\"},\"docker swarm unlock\")),mdx(\"p\",null,\"command and provide the following key:\"),mdx(\"p\",null,\"SWMKEY-1-8jDgbUNlJtUe5P/lcr9IXGVxqZpZUXPzd+qzcGp4ZYA\"),mdx(\"p\",null,\"Please remember to store this key in a password manager, since without it you\"),mdx(\"p\",null,\"will not be able to restart the manager.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Warning\"),\": When you rotate the unlock key, keep a record of the old key around for a few minutes, so that if a manager goes down before it gets the new key, it may still be unlocked with the old one.\"),mdx(\"h4\",null,\"Administer and maintain a swarm of Docker Engines\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA016 minutes\")),mdx(\"p\",null,\"When you run a swarm of Docker Engines,\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"manager nodes\"),\"\\xA0are the key components for managing the swarm and storing the swarm state. It is important to understand some key features of manager nodes to properly deploy and maintain the swarm.\"),mdx(\"p\",null,\"Refer to\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/how-swarm-mode-works/nodes/\"}),\"How nodes work\"),\"\\xA0for a brief overview of Docker Swarm mode and the difference between manager and worker nodes.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Operate manager nodes in a swarm\")),mdx(\"p\",null,\"Swarm manager nodes use the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/raft/\"}),\"Raft Consensus Algorithm\"),\"\\xA0to manage the swarm state. You only need to understand some general concepts of Raft in order to manage a swarm.\"),mdx(\"p\",null,\"There is no limit on the number of manager nodes. The decision about how many manager nodes to implement is a trade-off between performance and fault-tolerance. Adding manager nodes to a swarm makes the swarm more fault-tolerant. However, additional manager nodes reduce write performance because more nodes must acknowledge proposals to update the swarm state. This means more network round-trip traffic.\"),mdx(\"p\",null,\"Raft requires a majority of managers, also called the quorum, to agree on proposed updates to the swarm, such as node additions or removals. Membership operations are subject to the same constraints as state replication.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Maintain the quorum of managers\")),mdx(\"p\",null,\"If the swarm loses the quorum of managers, the swarm cannot perform management tasks. If your swarm has multiple managers, always have more than two. To maintain quorum, a majority of managers must be available. An odd number of managers is recommended, because the next even number does not make the quorum easier to keep. For instance, whether you have 3 or 4 managers, you can still only lose 1 manager and maintain the quorum. If you have 5 or 6 managers, you can still only lose two.\"),mdx(\"p\",null,\"Even if a swarm loses the quorum of managers, swarm tasks on existing worker nodes continue to run. However, swarm nodes cannot be added, updated, or removed, and new or existing tasks cannot be started, stopped, moved, or updated.\"),mdx(\"p\",null,\"See\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/admin_guide/#recovering-from-losing-the-quorum\"}),\"Recovering from losing the quorum\"),\"\\xA0for troubleshooting steps if you do lose the quorum of managers.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Configure the manager to advertise on a static IP address\")),mdx(\"p\",null,\"When initiating a swarm, you must specify the\\xA0--advertise-addr\\xA0flag to advertise your address to other manager nodes in the swarm. For more information, see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/swarm-mode/#configure-the-advertise-address\"}),\"Run Docker Engine in swarm mode\"),\". Because manager nodes are meant to be a stable component of the infrastructure, you should use a\\xA0fixed IP address\\xA0for the advertise address to prevent the swarm from becoming unstable on machine reboot.\"),mdx(\"p\",null,\"If the whole swarm restarts and every manager node subsequently gets a new IP address, there is no way for any node to contact an existing manager. Therefore the swarm is hung while nodes try to contact one another at their old IP addresses.\"),mdx(\"p\",null,\"Dynamic IP addresses are OK for worker nodes.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Add manager nodes for fault tolerance\")),mdx(\"p\",null,\"You should maintain an odd number of managers in the swarm to support manager node failures. Having an odd number of managers ensures that during a network partition, there is a higher chance that the quorum remains available to process requests if the network is partitioned into two sets. Keeping the quorum is not guaranteed if you encounter more than two network partitions.\"),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Swarm Size\"),\"   \",mdx(\"strong\",{parentName:\"p\"},\"Majority\"),\"   \",mdx(\"strong\",{parentName:\"p\"},\"Fault Tolerance\")),mdx(\"hr\",null),mdx(\"p\",null,\"  1                1              0\\n2                2              0\\n\",mdx(\"strong\",{parentName:\"p\"},\"3\"),\"            2              \",mdx(\"strong\",{parentName:\"p\"},\"1\"),\"\\n4                3              1\\n\",mdx(\"strong\",{parentName:\"p\"},\"5\"),\"            3              \",mdx(\"strong\",{parentName:\"p\"},\"2\"),\"\\n6                4              2\\n\",mdx(\"strong\",{parentName:\"p\"},\"7\"),\"            4              \",mdx(\"strong\",{parentName:\"p\"},\"3\"),\"\\n8                5              3\\n\",mdx(\"strong\",{parentName:\"p\"},\"9\"),\"            5              \",mdx(\"strong\",{parentName:\"p\"},\"4\")),mdx(\"p\",null,\"For example, in a swarm with\\xA05 nodes, if you lose\\xA03 nodes, you don't have a quorum. Therefore you can't add or remove nodes until you recover one of the unavailable manager nodes or recover the swarm with disaster recovery commands. See\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/admin_guide/#recover-from-disaster\"}),\"Recover from disaster\"),\".\"),mdx(\"p\",null,\"While it is possible to scale a swarm down to a single manager node, it is impossible to demote the last manager node. This ensures you maintain access to the swarm and that the swarm can still process requests. Scaling down to a single manager is an unsafe operation and is not recommended. If the last node leaves the swarm unexpectedly during the demote operation, the swarm becomes unavailable until you reboot the node or restart with\\xA0--force-new-cluster.\"),mdx(\"p\",null,\"You manage swarm membership with the\\xA0docker swarm\\xA0and\\xA0docker node\\xA0subsystems. Refer to\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/join-nodes/\"}),\"Add nodes to a swarm\"),\"\\xA0for more information on how to add worker nodes and promote a worker node to be a manager.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Distribute manager nodes\")),mdx(\"p\",null,\"In addition to maintaining an odd number of manager nodes, pay attention to datacenter topology when placing managers. For optimal fault-tolerance, distribute manager nodes across a minimum of 3 availability-zones to support failures of an entire set of machines or common maintenance scenarios. If you suffer a failure in any of those zones, the swarm should maintain the quorum of manager nodes available to process requests and rebalance workloads.\"),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Swarm manager nodes\"),\"   \",mdx(\"strong\",{parentName:\"p\"},\"Repartition (on 3 Availability zones)\")),mdx(\"hr\",null),mdx(\"p\",null,\"  3                         1-1-1\\n5                         2-2-1\\n7                         3-2-2\\n9                         3-3-3\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Run manager-only nodes\")),mdx(\"p\",null,\"By default manager nodes also act as a worker nodes. This means the scheduler can assign tasks to a manager node. For small and non-critical swarms assigning tasks to managers is relatively low-risk as long as you schedule services using\\xA0\",mdx(\"strong\",{parentName:\"p\"},\"resource constraints\"),\"\\xA0for\\xA0cpu\\xA0and\\xA0memory.\"),mdx(\"p\",null,\"However, because manager nodes use the Raft consensus algorithm to replicate data in a consistent way, they are sensitive to resource starvation. You should isolate managers in your swarm from processes that might block swarm operations like swarm heartbeat or leader elections.\"),mdx(\"p\",null,\"To avoid interference with manager node operation, you can drain manager nodes to make them unavailable as worker nodes:\"),mdx(\"p\",null,\"docker node update --availability drain \",mdx(\"inlineCode\",{parentName:\"p\"},\"<NODE>\")),mdx(\"p\",null,\"When you drain a node, the scheduler reassigns any tasks running on the node to other available worker nodes in the swarm. It also prevents the scheduler from assigning tasks to the node.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Add worker nodes for load balancing\")),mdx(\"p\",null,mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/join-nodes/\"}),\"Add nodes to the swarm\"),\"\\xA0to balance your swarm's load. Replicated service tasks are distributed across the swarm as evenly as possible over time, as long as the worker nodes are matched to the requirements of the services. When limiting a service to run on only specific types of nodes, such as nodes with a specific number of CPUs or amount of memory, remember that worker nodes that do not meet these requirements cannot run these tasks.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Monitor swarm health\")),mdx(\"p\",null,\"You can monitor the health of manager nodes by querying the docker\\xA0nodes\\xA0API in JSON format through the\\xA0/nodes\\xA0HTTP endpoint. Refer to the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/api/v1.25/#tag/Node\"}),\"nodes API documentation\"),\"\\xA0for more information.\"),mdx(\"p\",null,\"From the command line, run\\xA0docker node inspect \",mdx(\"inlineCode\",{parentName:\"p\"},\"<id-node>\"),\"\\xA0to query the nodes. For instance, to query the reachability of the node as a manager:\"),mdx(\"p\",null,\"docker node inspect manager1 --format \\\"{{ .ManagerStatus.Reachability }}\\\"\"),mdx(\"p\",null,\"reachable\"),mdx(\"p\",null,\"To query the status of the node as a worker that accept tasks:\"),mdx(\"p\",null,\"docker node inspect manager1 --format \\\"{{ .Status.State }}\\\"\"),mdx(\"p\",null,\"ready\"),mdx(\"p\",null,\"From those commands, we can see that\\xA0manager1\\xA0is both at the status\\xA0reachable\\xA0as a manager and\\xA0ready\\xA0as a worker.\"),mdx(\"p\",null,\"An\\xA0unreachable\\xA0health status means that this particular manager node is unreachable from other manager nodes. In this case you need to take action to restore the unreachable manager:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Restart the daemon and see if the manager comes back as reachable.\"),mdx(\"li\",{parentName:\"ul\"},\"Reboot the machine.\"),mdx(\"li\",{parentName:\"ul\"},\"If neither restarting or rebooting work, you should add another manager node or promote a worker to be a manager node. You also need to cleanly remove the failed node entry from the manager set with\\xA0docker node demote \",mdx(\"inlineCode\",{parentName:\"li\"},\"<NODE>\\xA0and\\xA0docker node rm <id-node>\"),\".\")),mdx(\"p\",null,\"Alternatively you can also get an overview of the swarm health from a manager node with\\xA0docker node ls:\"),mdx(\"p\",null,\"docker node ls\"),mdx(\"p\",null,\"ID HOSTNAME MEMBERSHIP STATUS AVAILABILITY MANAGER STATUS\"),mdx(\"p\",null,\"1mhtdwhvsgr3c26xxbnzdc3yp node05 Accepted Ready Active\"),mdx(\"p\",null,\"516pacagkqp2xc3fk9t1dhjor node02 Accepted Ready Active Reachable\"),mdx(\"p\",null,\"9ifojw8of78kkusuc4a6c23fx * node01 Accepted Ready Active Leader\"),mdx(\"p\",null,\"ax11wdpwrrb6db3mfjydscgk7 node04 Accepted Ready Active\"),mdx(\"p\",null,\"bb1nrq2cswhtbg4mrsqnlx1ck node03 Accepted Ready Active Reachable\"),mdx(\"p\",null,\"di9wxgz8dtuh9d2hn089ecqkf node06 Accepted Ready Active\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Troubleshoot a manager node\")),mdx(\"p\",null,\"You should never restart a manager node by copying the\\xA0raft\\xA0directory from another node. The data directory is unique to a node ID. A node can only use a node ID once to join the swarm. The node ID space should be globally unique.\"),mdx(\"p\",null,\"To cleanly re-join a manager node to a cluster:\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"To demote the node to a worker, run\\xA0docker node demote \",mdx(\"inlineCode\",{parentName:\"li\"},\"<NODE>\"),\".\"),mdx(\"li\",{parentName:\"ol\"},\"To remove the node from the swarm, run\\xA0docker node rm \",mdx(\"inlineCode\",{parentName:\"li\"},\"<NODE>\"),\".\"),mdx(\"li\",{parentName:\"ol\"},\"Re-join the node to the swarm with a fresh state using\\xA0docker swarm join.\")),mdx(\"p\",null,\"For more information on joining a manager node to a swarm, refer to\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/join-nodes/\"}),\"Join nodes to a swarm\"),\".\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Forcibly remove a node\")),mdx(\"p\",null,\"In most cases, you should shut down a node before removing it from a swarm with the\\xA0docker node rm\\xA0command. If a node becomes unreachable, unresponsive, or compromised you can forcefully remove the node without shutting it down by passing the\\xA0--force\\xA0flag. For instance, if\\xA0node9\\xA0becomes compromised:\"),mdx(\"p\",null,\"$ docker node rm node9\"),mdx(\"p\",null,\"Error response from daemon: rpc error: code = 9 desc = node node9 is not down and can\\\\'t be removed\"),mdx(\"p\",null,\"$ docker node rm --force node9\"),mdx(\"p\",null,\"Node node9 removed from swarm\"),mdx(\"p\",null,\"Before you forcefully remove a manager node, you must first demote it to the worker role. Make sure that you always have an odd number of manager nodes if you demote or remove a manager.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Back up the swarm\")),mdx(\"p\",null,\"Docker manager nodes store the swarm state and manager logs in the\\xA0/var/lib/docker/swarm/directory. In 1.13 and higher, this data includes the keys used to encrypt the Raft logs. Without these keys, you cannot restore the swarm.\"),mdx(\"p\",null,\"You can back up the swarm using any manager. Use the following procedure.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"If the swarm has auto-lock enabled, you need the unlock key to restore the swarm from backup. Retrieve the unlock key if necessary and store it in a safe location. If you are unsure, read\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/swarm_manager_locking/\"}),\"Lock your swarm to protect its encryption key\"),\".\"),mdx(\"li\",{parentName:\"ol\"},\"Stop Docker on the manager before backing up the data, so that no data is being changed during the backup. It is possible to take a backup while the manager is running (a \\\"hot\\\" backup), but this is not recommended and your results are less predictable when restoring. While the manager is down, other nodes continue generating swarm data that is not part of this backup.\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": Be sure to maintain the quorum of swarm managers. During the time that a manager is shut down, your swarm is more vulnerable to losing the quorum if further nodes are lost. The number of managers you run is a trade-off. If you regularly take down managers to do backups, consider running a 5-manager swarm, so that you can lose an additional manager while the backup is running, without disrupting your services.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Back up the entire\\xA0/var/lib/docker/swarm\\xA0directory.\"),mdx(\"li\",{parentName:\"ol\"},\"Restart the manager.\")),mdx(\"p\",null,\"To restore, see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/admin_guide/#restore-from-a-backup\"}),\"Restore from a backup\"),\".\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Recover from disaster\")),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Restore from a backup\")),mdx(\"p\",null,\"After backing up the swarm as described in\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/admin_guide/#back-up-the-swarm\"}),\"Back up the swarm\"),\", use the following procedure to restore the data to a new swarm.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Shut down Docker on the target host machine for the restored swarm.\"),mdx(\"li\",{parentName:\"ol\"},\"Remove the contents of the\\xA0/var/lib/docker/swarm\\xA0directory on the new swarm.\"),mdx(\"li\",{parentName:\"ol\"},\"Restore the\\xA0/var/lib/docker/swarm\\xA0directory with the contents of the backup.\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note: The new node uses the same encryption key for on-disk storage as the old one. It is not possible to change the on-disk storage encryption keys at this time.\")),mdx(\"p\",null,\"In the case of a swarm with auto-lock enabled, the unlock key is also the same as on the old swarm, and the unlock key is needed to restore the swarm.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Start Docker on the new node. Unlock the swarm if necessary. Re-initialize the swarm using the following command, so that this node does not attempt to connect to nodes that were part of the old swarm, and presumably no longer exist.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker swarm init --force-new-cluster\"),mdx(\"li\",{parentName:\"ol\"},\"Verify that the state of the swarm is as expected. This may include application-specific tests or simply checking the output of\\xA0docker service ls\\xA0to be sure that all expected services are present.\"),mdx(\"li\",{parentName:\"ol\"},\"If you use auto-lock,\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/swarm/swarm_manager_locking/#rotate-the-unlock-key\"}),\"rotate the unlock key\"),\".\"),mdx(\"li\",{parentName:\"ol\"},\"Add manager and worker nodes to bring your new swarm up to operating capacity.\"),mdx(\"li\",{parentName:\"ol\"},\"Reinstate your previous backup regimen on the new swarm.\")),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Recover from losing the quorum\")),mdx(\"p\",null,\"Swarm is resilient to failures and the swarm can recover from any number of temporary node failures (machine reboots or crash with restart) or other transient errors. However, a swarm cannot automatically recover if it loses a quorum. Tasks on existing worker nodes continue to run, but administrative tasks are not possible, including scaling or updating services and joining or removing nodes from the swarm. The best way to recover is to bring the missing manager nodes back online. If that is not possible, continue reading for some options for recovering your swarm.\"),mdx(\"p\",null,\"In a swarm of\\xA0N\\xA0managers, a quorum (a majority) of manager nodes must always be available. For example, in a swarm with 5 managers, a minimum of 3 must be operational and in communication with each other. In other words, the swarm can tolerate up to\\xA0(N-1)/2permanent failures beyond which requests involving swarm management cannot be processed. These types of failures include data corruption or hardware failures.\"),mdx(\"p\",null,\"If you lose the quorum of managers, you cannot administer the swarm. If you have lost the quorum and you attempt to perform any management operation on the swarm, an error occurs:\"),mdx(\"p\",null,\"Error response from daemon: rpc error: code = 4 desc = context deadline exceeded\"),mdx(\"p\",null,\"The best way to recover from losing the quorum is to bring the failed nodes back online. If you can't do that, the only way to recover from this state is to use the\\xA0--force-new-cluster\\xA0action from a manager node. This removes all managers except the manager the command was run from. The quorum is achieved because there is now only one manager. Promote nodes to be managers until you have the desired number of managers.\"),mdx(\"h1\",null,\"From the node to recover\"),mdx(\"p\",null,\"docker swarm init --force-new-cluster --advertise-addr node01:2377\"),mdx(\"p\",null,\"When you run the\\xA0docker swarm init\\xA0command with the\\xA0--force-new-cluster\\xA0flag, the Docker Engine where you run the command becomes the manager node of a single-node swarm which is capable of managing and running services. The manager has all the previous information about services and tasks, worker nodes are still part of the swarm, and services are still running. You need to add or re-add manager nodes to achieve your previous task distribution and ensure that you have enough managers to maintain high availability and prevent losing the quorum.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Force the swarm to rebalance\")),mdx(\"p\",null,\"Generally, you do not need to force the swarm to rebalance its tasks. When you add a new node to a swarm, or a node reconnects to the swarm after a period of unavailability, the swarm does not automatically give a workload to the idle node. This is a design decision. If the swarm periodically shifted tasks to different nodes for the sake of balance, the clients using those tasks would be disrupted. The goal is to avoid disrupting running services for the sake of balance across the swarm. When new tasks start, or when a node with running tasks becomes unavailable, those tasks are given to less busy nodes. The goal is eventual balance, with minimal disruption to the end user.\"),mdx(\"p\",null,\"In Docker 1.13 and higher, you can use the\\xA0--force\\xA0or\\xA0-f\\xA0flag with thedocker service update\\xA0command to force the service to redistribute its tasks across the available worker nodes. This causes the service tasks to restart. Client applications may be disrupted. If you have configured it, your service uses a\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/swarm/swarm-tutorial/#rolling-update\"}),\"rolling update\"),\".\"),mdx(\"p\",null,\"If you use an earlier version and you want to achieve an even balance of load across workers and don't mind disrupting running tasks, you can force your swarm to re-balance by temporarily scaling the service upward. Use\\xA0docker service inspect --pretty \",mdx(\"inlineCode\",{parentName:\"p\"},\"<servicename>\"),\"\\xA0to see the configured scale of a service. When you use\\xA0docker service scale, the nodes with the lowest number of tasks are targeted to receive the new workloads. There may be multiple under-loaded nodes in your swarm. You may need to scale the service up by modest increments a few times to achieve the balance you want across all the nodes.\"),mdx(\"p\",null,\"When the load is balanced to your satisfaction, you can scale the service back down to the original scale. You can use\\xA0docker service ps\\xA0to assess the current balance of your service across nodes.\"),mdx(\"p\",null,\"See also\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/service_scale/\"}),\"docker service scale\"),\"\\xA0and\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/service_ps/\"}),\"docker service ps\"),\".\"),mdx(\"h4\",null,\"Raft consensus in swarm mode\"),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Estimated reading time:\\xA01 minute\")),mdx(\"p\",null,\"When the Docker Engine runs in swarm mode, manager nodes implement the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://thesecretlivesofdata.com/raft/\"}),\"Raft Consensus Algorithm\"),\"\\xA0to manage the global cluster state.\"),mdx(\"p\",null,\"The reason why\\xA0Docker swarm mode\\xA0is using a consensus algorithm is to make sure that all the manager nodes that are in charge of managing and scheduling tasks in the cluster, are storing the same consistent state.\"),mdx(\"p\",null,\"Having the same consistent state across the cluster means that in case of a failure, any Manager node can pick up the tasks and restore the services to a stable state. For example, if the\\xA0Leader Manager\\xA0which is responsible for scheduling tasks in the cluster dies unexpectedly, any other Manager can pick up the task of scheduling and re-balance tasks to match the desired state.\"),mdx(\"p\",null,\"Systems using consensus algorithms to replicate logs in a distributed systems do require special care. They ensure that the cluster state stays consistent in the presence of failures by requiring a majority of nodes to agree on values.\"),mdx(\"p\",null,\"Raft tolerates up to\\xA0(N-1)/2\\xA0failures and requires a majority or quorum of\\xA0(N/2)+1\\xA0members to agree on values proposed to the cluster. This means that in a cluster of 5 Managers running Raft, if 3 nodes are unavailable, the system cannot process any more requests to schedule additional tasks. The existing tasks keep running but the scheduler cannot rebalance tasks to cope with failures if the manager set is not healthy.\"),mdx(\"p\",null,\"The implementation of the consensus algorithm in swarm mode means it features the properties inherent to distributed systems:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"agreement on values\\xA0in a fault tolerant system. (Refer to\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"http://the-paper-trail.org/blog/a-brief-tour-of-flp-impossibility/\"}),\"FLP impossibility theorem\"),\"\\xA0and the\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://www.usenix.org/system/files/conference/atc14/atc14-paper-ongaro.pdf\"}),\"Raft Consensus Algorithm paper\"),\")\"),mdx(\"li\",{parentName:\"ul\"},\"mutual exclusion\\xA0through the leader election process\"),mdx(\"li\",{parentName:\"ul\"},\"cluster membership\\xA0management\"),mdx(\"li\",{parentName:\"ul\"},\"globally consistent object sequencing\\xA0and CAS (compare-and-swap) primitives\")),mdx(\"h3\",null,\"Extended Docker\"),mdx(\"h4\",null,\"Docker Engine managed plugin system\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/extend/#installing-and-using-a-plugin\"}),\"Installing and using a plugin\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/extend/#developing-a-plugin\"}),\"Developing a plugin\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/extend/#debugging-plugins\"}),\"Debugging plugins\"))),mdx(\"p\",null,\"Docker Engine's plugin system allows you to install, start, stop, and remove plugins using Docker Engine.\"),mdx(\"p\",null,\"For information about the legacy plugin system available in Docker Engine 1.12 and earlier, see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/extend/legacy_plugins/\"}),\"Understand legacy Docker Engine plugins\"),\".\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": Docker Engine managed plugins are currently not supported on Windows daemons.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Installing and using a plugin\")),mdx(\"p\",null,\"Plugins are distributed as Docker images and can be hosted on Docker Hub or on a private registry.\"),mdx(\"p\",null,\"To install a plugin, use the\\xA0docker plugin install\\xA0command, which pulls the plugin from Docker Hub or your private registry, prompts you to grant permissions or capabilities if necessary, and enables the plugin.\"),mdx(\"p\",null,\"To check the status of installed plugins, use the\\xA0docker plugin ls\\xA0command. Plugins that start successfully are listed as enabled in the output.\"),mdx(\"p\",null,\"After a plugin is installed, you can use it as an option for another Docker operation, such as creating a volume.\"),mdx(\"p\",null,\"In the following example, you install the\\xA0sshfs\\xA0plugin, verify that it is enabled, and use it to create a volume.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": This example is intended for instructional purposes only. Once the volume is created, your SSH password to the remote host will be exposed as plaintext when inspecting the volume. You should delete the volume as soon as you are done with the example.\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Install the\\xA0sshfs\\xA0plugin.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker plugin install vieux/sshfs\"),mdx(\"li\",{parentName:\"ol\"},\"Plugin \\\"vieux/sshfs\\\" is requesting the following privileges:\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},\"network: \",\"[host]\"))),mdx(\"li\",{parentName:\"ol\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},\"capabilities: \",\"[CAP_SYS_ADMIN]\"))),mdx(\"li\",{parentName:\"ol\"},\"Do you grant the above permissions? \",\"[y/N]\",\" y\"),mdx(\"li\",{parentName:\"ol\"},\"vieux/sshfs\")),mdx(\"p\",null,\"The plugin requests 2 privileges:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},\"It needs access to the\\xA0host\\xA0network.\"),mdx(\"li\",{parentName:\"ul\"},\"It needs the\\xA0CAP_SYS_ADMIN\\xA0capability, which allows the plugin to run the\\xA0mountcommand.\")))),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Check that the plugin is enabled in the output of\\xA0docker plugin ls.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker plugin ls\"),mdx(\"li\",{parentName:\"ol\"},\"ID NAME TAG DESCRIPTION ENABLED\"),mdx(\"li\",{parentName:\"ol\"},\"69553ca1d789 vieux/sshfs latest the \",mdx(\"inlineCode\",{parentName:\"li\"},\"sshfs\"),\" plugin true\"),mdx(\"li\",{parentName:\"ol\"},\"Create a volume using the plugin. This example mounts the\\xA0/remote\\xA0directory on host\\xA01.2.3.4\\xA0into a volume named\\xA0sshvolume.\")),mdx(\"p\",null,\"This volume can now be mounted into containers.\"),mdx(\"p\",null,\"$ docker volume create \\\\\"),mdx(\"p\",null,\"-d vieux/sshfs \\\\\"),mdx(\"p\",null,\"--name sshvolume \\\\\"),mdx(\"p\",null,\"-o sshcmd=user\\\\@1.2.3.4:/remote \\\\\"),mdx(\"p\",null,\"-o password=$(cat file_containing_password_for_remote_host)\"),mdx(\"p\",null,\"sshvolume\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"Verify that the volume was created successfully.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker volume ls\"),mdx(\"li\",{parentName:\"ol\"},\"DRIVER NAME\"),mdx(\"li\",{parentName:\"ol\"},\"vieux/sshfs sshvolume\"),mdx(\"li\",{parentName:\"ol\"},\"Start a container that uses the volume\\xA0sshvolume.\"),mdx(\"li\",{parentName:\"ol\"},\"$ docker run --rm -v sshvolume:/data busybox ls /data\"),mdx(\"li\",{parentName:\"ol\"},mdx(\"inlineCode\",{parentName:\"li\"},\"<content of /remote on machine 1.2.3.4>\")),mdx(\"li\",{parentName:\"ol\"},\"Remove the volume\\xA0sshvolume\"),mdx(\"li\",{parentName:\"ol\"},\"docker volume rm sshvolume\"),mdx(\"li\",{parentName:\"ol\"},\"sshvolume\")),mdx(\"p\",null,\"To disable a plugin, use the\\xA0docker plugin disable\\xA0command. To completely remove it, use the\\xA0docker plugin remove\\xA0command. For other available commands and options, see the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/\"}),\"command line reference\"),\".\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Developing a plugin\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"THE ROOTFS DIRECTORY\")),mdx(\"p\",null,\"The\\xA0rootfs\\xA0directory represents the root filesystem of the plugin. In this example, it was created from a Dockerfile:\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note:\"),\"\\xA0The\\xA0/run/docker/plugins\\xA0directory is mandatory inside of the plugin's filesystem for docker to communicate with the plugin.\"),mdx(\"p\",null,\"$ git clone \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/vieux/docker-volume-sshfs\"}),\"https://github.com/vieux/docker-volume-sshfs\")),mdx(\"p\",null,\"$ cd docker-volume-sshfs\"),mdx(\"p\",null,\"$ docker build -t rootfsimage .\"),mdx(\"p\",null,\"$ id=$(docker create rootfsimage true) # id was cd851ce43a403 when the image was created\"),mdx(\"p\",null,\"$ sudo mkdir -p myplugin/rootfs\"),mdx(\"p\",null,\"$ sudo docker export \\\"$id\\\" | sudo tar -x -C myplugin/rootfs\"),mdx(\"p\",null,\"$ docker rm -vf \\\"$id\\\"\"),mdx(\"p\",null,\"$ docker rmi rootfsimage\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"THE CONFIG.JSON FILE\")),mdx(\"p\",null,\"The\\xA0config.json\\xA0file describes the plugin. See the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/extend/config/\"}),\"plugins config reference\"),\".\"),mdx(\"p\",null,\"Consider the following\\xA0config.json\\xA0file.\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"description\\\": \\\"sshFS plugin for Docker\\\",\"),mdx(\"p\",null,\"\\\"documentation\\\": \\\"\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/extend/plugins/%22\"}),\"https://docs.docker.com/engine/extend/plugins/\\\"\"),\",\"),mdx(\"p\",null,\"\\\"entrypoint\\\": \",\"[\\\"/docker-volume-sshfs\\\"]\",\",\"),mdx(\"p\",null,\"\\\"network\\\": {\"),mdx(\"p\",null,\"\\\"type\\\": \\\"host\\\"\"),mdx(\"p\",null,\"},\"),mdx(\"p\",null,\"\\\"interface\\\" : {\"),mdx(\"p\",null,\"\\\"types\\\": \",\"[\\\"docker.volumedriver/1.0\\\"]\",\",\"),mdx(\"p\",null,\"\\\"socket\\\": \\\"sshfs.sock\\\"\"),mdx(\"p\",null,\"},\"),mdx(\"p\",null,\"\\\"linux\\\": {\"),mdx(\"p\",null,\"\\\"capabilities\\\": \",\"[\\\"CAP_SYS_ADMIN\\\"]\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"This plugin is a volume driver. It requires a\\xA0host\\xA0network and the\\xA0CAP_SYS_ADMIN\\xA0capability. It depends upon the\\xA0/docker-volume-sshfs\\xA0entrypoint and uses the\\xA0/run/docker/plugins/sshfs.sock\\xA0socket to communicate with Docker Engine. This plugin has no runtime parameters.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"CREATING THE PLUGIN\")),mdx(\"p\",null,\"A new plugin can be created by runningdocker plugin create \",mdx(\"inlineCode\",{parentName:\"p\"},\"<plugin-name>\"),\" ./path/to/plugin/data\\xA0where the plugin data contains a plugin configuration file\\xA0config.json\\xA0and a root filesystem in subdirectory\\xA0rootfs.\"),mdx(\"p\",null,\"After that the plugin\\xA0\",mdx(\"inlineCode\",{parentName:\"p\"},\"<plugin-name>\\xA0will show up in\\xA0docker plugin ls. Plugins can be pushed to remote registries with\\xA0docker plugin push <plugin-name>\"),\".\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Debugging plugins\")),mdx(\"p\",null,\"Stdout of a plugin is redirected to dockerd logs. Such entries have a\\xA0plugin=\",mdx(\"inlineCode\",{parentName:\"p\"},\"<ID>\"),\"\\xA0suffix. Here are a few examples of commands for pluginIDf52a3df433b9aceee436eaada0752f5797aab1de47e5485f1690a073b860ff62\\xA0and their corresponding log entries in the docker daemon logs.\"),mdx(\"p\",null,\"$ docker plugin install tiborvass/sample-volume-plugin\"),mdx(\"p\",null,\"INFO\",\"[0036]\",\" Starting... Found 0 volumes on startup plugin=f52a3df433b9aceee436eaada0752f5797aab1de47e5485f1690a073b860ff62\"),mdx(\"p\",null,\"$ docker volume create -d tiborvass/sample-volume-plugin samplevol\"),mdx(\"p\",null,\"INFO\",\"[0193]\",\" Create Called... Ensuring directory /data/samplevol exists on host... plugin=f52a3df433b9aceee436eaada0752f5797aab1de47e5485f1690a073b860ff62\"),mdx(\"p\",null,\"INFO\",\"[0193]\",\" open /var/lib/docker/plugin-data/local-persist.json: no such file or directory plugin=f52a3df433b9aceee436eaada0752f5797aab1de47e5485f1690a073b860ff62\"),mdx(\"p\",null,\"INFO\",\"[0193]\",\" Created volume samplevol with mountpoint /data/samplevol plugin=f52a3df433b9aceee436eaada0752f5797aab1de47e5485f1690a073b860ff62\"),mdx(\"p\",null,\"INFO\",\"[0193]\",\" Path Called... Returned path /data/samplevol plugin=f52a3df433b9aceee436eaada0752f5797aab1de47e5485f1690a073b860ff62\"),mdx(\"p\",null,\"$ docker run -v samplevol:/tmp busybox sh\"),mdx(\"p\",null,\"INFO\",\"[0421]\",\" Get Called... Found samplevol plugin=f52a3df433b9aceee436eaada0752f5797aab1de47e5485f1690a073b860ff62\"),mdx(\"p\",null,\"INFO\",\"[0421]\",\" Mount Called... Mounted samplevol plugin=f52a3df433b9aceee436eaada0752f5797aab1de47e5485f1690a073b860ff62\"),mdx(\"p\",null,\"INFO\",\"[0421]\",\" Path Called... Returned path /data/samplevol plugin=f52a3df433b9aceee436eaada0752f5797aab1de47e5485f1690a073b860ff62\"),mdx(\"p\",null,\"INFO\",\"[0421]\",\" Unmount Called... Unmounted samplevol plugin=f52a3df433b9aceee436eaada0752f5797aab1de47e5485f1690a073b860ff62\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"USING DOCKER-RUNC TO OBTAIN LOGFILES AND SHELL INTO THE PLUGIN.\")),mdx(\"p\",null,\"docker-runc, the default docker container runtime can be used for debugging plugins. This is specifically useful to collect plugin logs if they are redirected to a file.\"),mdx(\"p\",null,\"$ docker-runc list\"),mdx(\"p\",null,\"ID PID STATUS BUNDLE CREATED\"),mdx(\"p\",null,\"f52a3df433b9aceee436eaada0752f5797aab1de47e5485f1690a073b860ff62 2679 running /run/docker/libcontainerd/f52a3df433b9aceee436eaada0752f5797aab1de47e5485f1690a073b860ff62 2017-02-06T21:53:03.031537592Z\"),mdx(\"p\",null,\"r\"),mdx(\"p\",null,\"$ docker-runc exec f52a3df433b9aceee436eaada0752f5797aab1de47e5485f1690a073b860ff62 cat /var/log/plugin.log\"),mdx(\"p\",null,\"If the plugin has a built-in shell, then exec into the plugin can be done as follows:\"),mdx(\"p\",null,\"$ docker-runc exec -t f52a3df433b9aceee436eaada0752f5797aab1de47e5485f1690a073b860ff62 sh\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"USING CURL TO DEBUG PLUGIN SOCKET ISSUES.\")),mdx(\"p\",null,\"To verify if the plugin API socket that the docker daemon communicates with is responsive, use curl. In this example, we will make API calls from the docker host to volume and network plugins using curl 7.47.0 to ensure that the plugin is listening on the said socket. For a well functioning plugin, these basic requests should work. Note that plugin sockets are available on the host under\\xA0/var/run/docker/plugins/\",mdx(\"inlineCode\",{parentName:\"p\"},\"<pluginID>\")),mdx(\"p\",null,\"curl -H \\\"Content-Type: application/json\\\" -XPOST -d \\\\'{}\\\\' --unix-socket /var/run/docker/plugins/e8a37ba56fc879c991f7d7921901723c64df6b42b87e6a0b055771ecf8477a6d/plugin.sock http:/VolumeDriver.List\"),mdx(\"p\",null,\"{\\\"Mountpoint\\\":\\\"\\\",\\\"Err\\\":\\\"\\\",\\\"Volumes\\\":\",\"[{\\\"Name\\\":\\\"myvol1\\\",\\\"Mountpoint\\\":\\\"/data/myvol1\\\"},{\\\"Name\\\":\\\"myvol2\\\",\\\"Mountpoint\\\":\\\"/data/myvol2\\\"}]\",\",\\\"Volume\\\":null}\"),mdx(\"p\",null,\"curl -H \\\"Content-Type: application/json\\\" -XPOST -d \\\\'{}\\\\' --unix-socket /var/run/docker/plugins/45e00a7ce6185d6e365904c8bcf62eb724b1fe307e0d4e7ecc9f6c1eb7bcdb70/plugin.sock http:/NetworkDriver.GetCapabilities\"),mdx(\"p\",null,\"{\\\"Scope\\\":\\\"local\\\"}\"),mdx(\"p\",null,\"When using curl 7.5 and above, the URL should be of the form\\xA0http://hostname/APICall, where\\xA0hostname\\xA0is the valid hostname where the plugin is installed and\\xA0APICall\\xA0is the call to the plugin API.\"),mdx(\"p\",null,\"For example,\\xA0http://localhost/VolumeDriver.List\"),mdx(\"h4\",null,\"Access authorization plugin\"),mdx(\"p\",null,\"This document describes the Docker Engine plugins generally available in Docker Engine. To view information on plugins managed by Docker Engine, refer to\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/extend/\"}),\"Docker Engine plugin system\"),\".\"),mdx(\"p\",null,\"Docker's out-of-the-box authorization model is all or nothing. Any user with permission to access the Docker daemon can run any Docker client command. The same is true for callers using Docker's Engine API to contact the daemon. If you require greater access control, you can create authorization plugins and add them to your Docker daemon configuration. Using an authorization plugin, a Docker administrator can configure granular access policies for managing access to the Docker daemon.\"),mdx(\"p\",null,\"Anyone with the appropriate skills can develop an authorization plugin. These skills, at their most basic, are knowledge of Docker, understanding of REST, and sound programming knowledge. This document describes the architecture, state, and methods information available to an authorization plugin developer.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Basic principles\")),mdx(\"p\",null,\"Docker's\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/extend/plugin_api/\"}),\"plugin infrastructure\"),\"\\xA0enables extending Docker by loading, removing and communicating with third-party components using a generic API. The access authorization subsystem was built using this mechanism.\"),mdx(\"p\",null,\"Using this subsystem, you don't need to rebuild the Docker daemon to add an authorization plugin. You can add a plugin to an installed Docker daemon. You do need to restart the Docker daemon to add a new plugin.\"),mdx(\"p\",null,\"An authorization plugin approves or denies requests to the Docker daemon based on both the current authentication context and the command context. The authentication context contains all user details and the authentication method. The command context contains all the relevant request data.\"),mdx(\"p\",null,\"Authorization plugins must follow the rules described in\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/extend/plugin_api/\"}),\"Docker Plugin API\"),\". Each plugin must reside within directories described under the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/extend/plugin_api/#plugin-discovery\"}),\"Plugin discovery\"),\"\\xA0section.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": the abbreviations\\xA0AuthZ\\xA0and\\xA0AuthN\\xA0mean authorization and authentication respectively.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Default user authorization mechanism\")),mdx(\"p\",null,\"If TLS is enabled in the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/security/https/\"}),\"Docker daemon\"),\", the default user authorization flow extracts the user details from the certificate subject name. That is, the\\xA0User\\xA0field is set to the client certificate subject common name, and the\\xA0AuthenticationMethod\\xA0field is set to\\xA0TLS.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Basic architecture\")),mdx(\"p\",null,\"You are responsible for registering your plugin as part of the Docker daemon startup. You can install multiple plugins and chain them together. This chain can be ordered. Each request to the daemon passes in order through the chain. Only when all the plugins grant access to the resource, is the access granted.\"),mdx(\"p\",null,\"When an HTTP request is made to the Docker daemon through the CLI or via the Engine API, the authentication subsystem passes the request to the installed authentication plugin(s). The request contains the user (caller) and command context. The plugin is responsible for deciding whether to allow or deny the request.\"),mdx(\"p\",null,\"The sequence diagrams below depict an allow and deny authorization flow:\"),mdx(\"p\",null,\"Each request sent to the plugin includes the authenticated user, the HTTP headers, and the request/response body. Only the user name and the authentication method used are passed to the plugin. Most importantly, no user credentials or tokens are passed. Finally, not all request/response bodies are sent to the authorization plugin. Only those request/response bodies where the\\xA0Content-Type\\xA0is either\\xA0text/*\\xA0or\\xA0application/json\\xA0are sent.\"),mdx(\"p\",null,\"For commands that can potentially hijack the HTTP connection (HTTP Upgrade), such as\\xA0exec, the authorization plugin is only called for the initial HTTP requests. Once the plugin approves the command, authorization is not applied to the rest of the flow. Specifically, the streaming data is not passed to the authorization plugins. For commands that return chunked HTTP response, such as\\xA0logs\\xA0and\\xA0events, only the HTTP request is sent to the authorization plugins.\"),mdx(\"p\",null,\"During request/response processing, some authorization flows might need to do additional queries to the Docker daemon. To complete such flows, plugins can call the daemon API similar to a regular user. To enable these additional queries, the plugin must provide the means for an administrator to configure proper authentication and security policies.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Docker client flows\")),mdx(\"p\",null,\"To enable and configure the authorization plugin, the plugin developer must support the Docker client interactions detailed in this section.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Setting up Docker daemon\")),mdx(\"p\",null,\"Enable the authorization plugin with a dedicated command line flag in the--authorization-plugin=PLUGIN_ID\\xA0format. The flag supplies a\\xA0PLUGIN_ID\\xA0value. This value can be the plugin's socket or a path to a specification file. Authorization plugins can be loaded without restarting the daemon. Refer to the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/commandline/dockerd/#configuration-reloading\"}),\"dockerd\\xA0documentation\"),\"\\xA0for more information.\"),mdx(\"p\",null,\"$ dockerd --authorization-plugin=plugin1 --authorization-plugin=plugin2,...\"),mdx(\"p\",null,\"Docker's authorization subsystem supports multiple\\xA0--authorization-plugin\\xA0parameters.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Calling authorized command (allow)\")),mdx(\"p\",null,\"$ docker pull centos\"),mdx(\"p\",null,\"...\"),mdx(\"p\",null,\"f1b10cd84249: Pull complete\"),mdx(\"p\",null,\"...\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Calling unauthorized command (deny)\")),mdx(\"p\",null,\"$ docker pull centos\"),mdx(\"p\",null,\"...\"),mdx(\"p\",null,\"docker: Error response from daemon: authorization denied by plugin PLUGIN_NAME: volumes are not allowed.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Error from plugins\")),mdx(\"p\",null,\"$ docker pull centos\"),mdx(\"p\",null,\"...\"),mdx(\"p\",null,\"docker: Error response from daemon: plugin PLUGIN_NAME failed with error: AuthZPlugin.AuthZReq: Cannot connect to the Docker daemon. Is the docker daemon running on this host?.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"API schema and implementation\")),mdx(\"p\",null,\"In addition to Docker's standard plugin registration method, each plugin should implement the following two methods:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"/AuthZPlugin.AuthZReq\\xA0This authorize request method is called before the Docker daemon processes the client request.\"),mdx(\"li\",{parentName:\"ul\"},\"/AuthZPlugin.AuthZRes\\xA0This authorize response method is called before the response is returned from Docker daemon to the client.\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"/AUTHZPLUGIN.AUTHZREQ\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Request\"),\":\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"User\\\": \\\"The user identification\\\",\"),mdx(\"p\",null,\"\\\"UserAuthNMethod\\\": \\\"The authentication method used\\\",\"),mdx(\"p\",null,\"\\\"RequestMethod\\\": \\\"The HTTP method\\\",\"),mdx(\"p\",null,\"\\\"RequestURI\\\": \\\"The HTTP request URI\\\",\"),mdx(\"p\",null,\"\\\"RequestBody\\\": \\\"Byte array containing the raw HTTP request body\\\",\"),mdx(\"p\",null,\"\\\"RequestHeader\\\": \\\"Byte array containing the raw HTTP request header as a map\",\"[string][]\",\"string \\\"\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Response\"),\":\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"Allow\\\": \\\"Determined whether the user is allowed or not\\\",\"),mdx(\"p\",null,\"\\\"Msg\\\": \\\"The authorization message\\\",\"),mdx(\"p\",null,\"\\\"Err\\\": \\\"The error message if things go wrong\\\"\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"/AUTHZPLUGIN.AUTHZRES\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Request\"),\":\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"User\\\": \\\"The user identification\\\",\"),mdx(\"p\",null,\"\\\"UserAuthNMethod\\\": \\\"The authentication method used\\\",\"),mdx(\"p\",null,\"\\\"RequestMethod\\\": \\\"The HTTP method\\\",\"),mdx(\"p\",null,\"\\\"RequestURI\\\": \\\"The HTTP request URI\\\",\"),mdx(\"p\",null,\"\\\"RequestBody\\\": \\\"Byte array containing the raw HTTP request body\\\",\"),mdx(\"p\",null,\"\\\"RequestHeader\\\": \\\"Byte array containing the raw HTTP request header as a map\",\"[string][]\",\"string\\\",\"),mdx(\"p\",null,\"\\\"ResponseBody\\\": \\\"Byte array containing the raw HTTP response body\\\",\"),mdx(\"p\",null,\"\\\"ResponseHeader\\\": \\\"Byte array containing the raw HTTP response header as a map\",\"[string][]\",\"string\\\",\"),mdx(\"p\",null,\"\\\"ResponseStatusCode\\\":\\\"Response status code\\\"\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Response\"),\":\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"Allow\\\": \\\"Determined whether the user is allowed or not\\\",\"),mdx(\"p\",null,\"\\\"Msg\\\": \\\"The authorization message\\\",\"),mdx(\"p\",null,\"\\\"Err\\\": \\\"The error message if things go wrong\\\"\"),mdx(\"p\",null,\"}\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Request authorization\")),mdx(\"p\",null,\"Each plugin must support two request authorization messages formats, one from the daemon to the plugin and then from the plugin to the daemon. The tables below detail the content expected in each message.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"DAEMON -> PLUGIN\")),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Name\"),\"                \",mdx(\"strong\",{parentName:\"p\"},\"Type\"),\"              \",mdx(\"strong\",{parentName:\"p\"},\"Description\")),mdx(\"hr\",null),mdx(\"p\",null,\"  User                    string                The user identification\\nAuthentication method   string                The authentication method used\\nRequest method          enum                  The HTTP method (GET/DELETE/POST)\\nRequest URI             string                The HTTP request URI including API version (e.g., v.1.17/containers/json)\\nRequest headers         map\",\"[string]\",\"string   Request headers as key value pairs (without the authorization header)\\nRequest body            []byte              Raw request body\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"PLUGIN -> DAEMON\")),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Name\"),\"   \",mdx(\"strong\",{parentName:\"p\"},\"Type\"),\"   \",mdx(\"strong\",{parentName:\"p\"},\"Description\")),mdx(\"hr\",null),mdx(\"p\",null,\"  Allow      bool       Boolean value indicating whether the request is allowed or denied\\nMsg        string     Authorization message (will be returned to the client in case the access is denied)\\nErr        string     Error message (will be returned to the client in case the plugin encounter an error. The string value supplied may appear in logs, so should not include confidential information)\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Response authorization\")),mdx(\"p\",null,\"The plugin must support two authorization messages formats, one from the daemon to the plugin and then from the plugin to the daemon. The tables below detail the content expected in each message.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"DAEMON -> PLUGIN\")),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Name\"),\"                \",mdx(\"strong\",{parentName:\"p\"},\"Type\"),\"              \",mdx(\"strong\",{parentName:\"p\"},\"Description\")),mdx(\"hr\",null),mdx(\"p\",null,\"  User                    string                The user identification\\nAuthentication method   string                The authentication method used\\nRequest method          string                The HTTP method (GET/DELETE/POST)\\nRequest URI             string                The HTTP request URI including API version (e.g., v.1.17/containers/json)\\nRequest headers         map\",\"[string]\",\"string   Request headers as key value pairs (without the authorization header)\\nRequest body            []byte              Raw request body\\nResponse status code    int                   Status code from the docker daemon\\nResponse headers        map\",\"[string]\",\"string   Response headers as key value pairs\\nResponse body           []byte              Raw docker daemon response body\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"PLUGIN -> DAEMON\")),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Name\"),\"   \",mdx(\"strong\",{parentName:\"p\"},\"Type\"),\"   \",mdx(\"strong\",{parentName:\"p\"},\"Description\")),mdx(\"hr\",null),mdx(\"p\",null,\"  Allow      bool       Boolean value indicating whether the response is allowed or denied\\nMsg        string     Authorization message (will be returned to the client in case the access is denied)\\nErr        string     Error message (will be returned to the client in case the plugin encounter an error. The string value supplied may appear in logs, so should not include confidential information)\"),mdx(\"h4\",null,\"Use Docker Engine plugins\"),mdx(\"p\",null,\"This document describes the Docker Engine plugins generally available in Docker Engine. To view information on plugins managed by Docker, refer to\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/extend/\"}),\"Docker Engine plugin system\"),\".\"),mdx(\"p\",null,\"You can extend the capabilities of the Docker Engine by loading third-party plugins. This page explains the types of plugins and provides links to several volume and network plugins for Docker.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Types of plugins\")),mdx(\"p\",null,\"Plugins extend Docker's functionality. They come in specific types. For example, a\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/extend/plugins_volume/\"}),\"volume plugin\"),\"might enable Docker volumes to persist across multiple Docker hosts and a\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/extend/plugins_network/\"}),\"network plugin\"),\"\\xA0might provide network plumbing.\"),mdx(\"p\",null,\"Currently Docker supports authorization, volume and network driver plugins. In the future it will support additional plugin types.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Installing a plugin\")),mdx(\"p\",null,\"Follow the instructions in the plugin's documentation.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Finding a plugin\")),mdx(\"p\",null,\"The sections below provide an inexhaustive overview of available plugins.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Network plugins\")),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Plugin\"),\"                                                                           \",mdx(\"strong\",{parentName:\"p\"},\"Description\")),mdx(\"hr\",null),mdx(\"p\",null,\"  \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/contiv/netplugin\"}),\"Contiv Networking\"),\"                             An open source network plugin to provide infrastructure and security policies for a multi-tenant micro services deployment, while providing an integration to physical network for non-container workload. Contiv Networking implements the remote driver and IPAM APIs available in Docker 1.9 onwards.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/openstack/kuryr\"}),\"Kuryr Network Plugin\"),\"                           A network plugin is developed as part of the OpenStack Kuryr project and implements the Docker networking (libnetwork) remote driver API by utilizing Neutron, the OpenStack networking service. It includes an IPAM driver as well.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://www.weave.works/docs/net/latest/introducing-weave/\"}),\"Weave Network Plugin\"),\"   A network plugin that creates a virtual network that connects your Docker containers - across multiple hosts or clouds and enables automatic discovery of applications. Weave networks are resilient, partition tolerant, secure and work in partially connected networks, and other adverse environments - all configured with delightful simplicity.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Volume plugins\")),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Plugin\"),\"                                                                                           \",mdx(\"strong\",{parentName:\"p\"},\"Description\")),mdx(\"hr\",null),mdx(\"p\",null,\"  \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/Azure/azurefile-dockervolumedriver\"}),\"Azure File Storage plugin\"),\"                   Lets you mount Microsoft\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://azure.microsoft.com/blog/azure-file-storage-now-generally-available/\"}),\"Azure File Storage\"),\"\\xA0shares to Docker containers as volumes using the SMB 3.0 protocol.\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://azure.microsoft.com/blog/persistent-docker-volumes-with-azure-file-storage/\"}),\"Learn more\"),\".\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/RedCoolBeans/docker-volume-beegfs\"}),\"BeeGFS Volume Plugin\"),\"                         An open source volume plugin to create persistent volumes in a BeeGFS parallel file system.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/blockbridge/blockbridge-docker-volume\"}),\"Blockbridge plugin\"),\"                       A volume plugin that provides access to an extensible set of container-based persistent storage options. It supports single and multi-host Docker environments with features that include tenant isolation, automated provisioning, encryption, secure deletion, snapshots and QoS.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/contiv/volplugin\"}),\"Contiv Volume Plugin\"),\"                                          An open source volume plugin that provides multi-tenant, persistent, distributed storage with intent based consumption. It has support for Ceph and NFS.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/rancher/convoy\"}),\"Convoy plugin\"),\"                                                   A volume plugin for a variety of storage back-ends including device mapper and NFS. It's a simple standalone executable written in Go and provides the framework to support vendor-specific extensions such as snapshots, backups and restore.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/omallo/docker-volume-plugin-dostorage\"}),\"DigitalOcean Block Storage plugin\"),\"        Integrates DigitalOcean's\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://www.digitalocean.com/products/storage/\"}),\"block storage solution\"),\"\\xA0into the Docker ecosystem by automatically attaching a given block storage volume to a DigitalOcean droplet and making the contents of the volume available to Docker containers running on that droplet.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://www.drbd.org/en/supported-projects/docker\"}),\"DRBD plugin\"),\"                                     A volume plugin that provides highly available storage replicated by\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://www.drbd.org/\"}),\"DRBD\"),\". Data written to the docker volume is replicated in a cluster of DRBD nodes.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/ScatterHQ/flocker\"}),\"Flocker plugin\"),\"                                               A volume plugin that provides multi-host portable volumes for Docker, enabling you to run databases and other stateful containers and move them around across a cluster of machines.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/openstack/fuxi\"}),\"Fuxi Volume Plugin\"),\"                                              A volume plugin that is developed as part of the OpenStack Kuryr project and implements the Docker volume plugin API by utilizing Cinder, the OpenStack block storage service.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/mcuadros/gce-docker\"}),\"gce-docker plugin\"),\"                                          A volume plugin able to attach, format and mount Google Compute\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://cloud.google.com/compute/docs/disks/persistent-disks\"}),\"persistent-disks\"),\".\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/calavera/docker-volume-glusterfs\"}),\"GlusterFS plugin\"),\"                              A volume plugin that provides multi-host volumes management for Docker using GlusterFS.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/muthu-r/horcrux\"}),\"Horcrux Volume Plugin\"),\"                                          A volume plugin that allows on-demand, version controlled access to your data. Horcrux is an open-source plugin, written in Go, and supports SCP,\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://www.minio.io/\"}),\"Minio\"),\"\\xA0and Amazon S3.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/hpe-storage/python-hpedockerplugin/\"}),\"HPE 3Par Volume Plugin\"),\"                     A volume plugin that supports HPE 3Par and StoreVirtual iSCSI storage arrays.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://infinit.sh/documentation/docker/volume-plugin\"}),\"Infinit volume plugin\"),\"                       A volume plugin that makes it easy to mount and manage Infinit volumes using Docker.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://github.com/vdemeester/docker-volume-ipfs\"}),\"IPFS Volume Plugin\"),\"                                An open source volume plugin that allows using an\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://ipfs.io/\"}),\"ipfs\"),\"\\xA0filesystem as a volume.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/calavera/docker-volume-keywhiz\"}),\"Keywhiz plugin\"),\"                                  A plugin that provides credentials and secret management using Keywhiz as a central repository.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/CWSpear/local-persist\"}),\"Local Persist Plugin\"),\"                                     A volume plugin that extends the default\\xA0local\\xA0driver's functionality by allowing you specify a mountpoint anywhere on the host, which enables the files to\\xA0always persist, even if the volume is removed via\\xA0docker volume rm.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/NetApp/netappdvp\"}),\"NetApp Plugin\"),\"(nDVP)                                           A volume plugin that provides direct integration with the Docker ecosystem for the NetApp storage portfolio. The nDVP package supports the provisioning and management of storage resources from the storage platform to Docker hosts, with a robust framework for adding additional platforms in the future.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/ContainX/docker-volume-netshare\"}),\"Netshare plugin\"),\"                                A volume plugin that provides volume management for NFS 3/4, AWS EFS and CIFS file systems.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://connect.nimblestorage.com/community/app-integration/docker\"}),\"Nimble Storage Volume Plugin\"),\"   A volume plug-in that integrates with Nimble Storage Unified Flash Fabric arrays. The plug-in abstracts array volume capabilities to the Docker administrator to allow self-provisioning of secure multi-tenant volumes and clones.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/libopenstorage/openstorage\"}),\"OpenStorage Plugin\"),\"                                  A cluster-aware volume plugin that provides volume management for file and block storage solutions. It implements a vendor neutral specification for implementing extensions such as CoS, encryption, and snapshots. It has example drivers based on FUSE, NFS, NBD and EBS to name a few.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/portworx/px-dev\"}),\"Portworx Volume Plugin\"),\"                                         A volume plugin that turns any server into a scale-out converged compute/storage node, providing container granular storage and highly available volumes across any node, using a shared-nothing storage backend that works with any docker scheduler.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/quobyte/docker-volume\"}),\"Quobyte Volume Plugin\"),\"                                    A volume plugin that connects Docker to\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://www.quobyte.com/containers\"}),\"Quobyte\"),\"'s data center file system, a general-purpose scalable and fault-tolerant storage platform.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/emccode/rexray\"}),\"REX-Ray plugin\"),\"                                                  A volume plugin which is written in Go and provides advanced storage functionality for many platforms including VirtualBox, EC2, Google Compute Engine, OpenStack, and EMC.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/virtuozzo/docker-volume-ploop\"}),\"Virtuozzo Storage and Ploop plugin\"),\"               A volume plugin with support for Virtuozzo Storage distributed cloud file system as well as ploop devices.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/vmware/docker-volume-vsphere\"}),\"VMware vSphere Storage Plugin\"),\"                     Docker Volume Driver for vSphere enables customers to address persistent storage requirements for Docker containers in vSphere environments.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"Authorization plugins\")),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Plugin\"),\"                                                             \",mdx(\"strong\",{parentName:\"p\"},\"Description\")),mdx(\"hr\",null),mdx(\"p\",null,\"  \",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/casbin/casbin-authz-plugin\"}),\"Casbin AuthZ Plugin\"),\"   An authorization plugin based on\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/casbin/casbin\"}),\"Casbin\"),\", which supports access control models like ACL, RBAC, ABAC. The access control model can be customized. The policy can be persisted into file or DB.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/kassisol/hbm\"}),\"HBM plugin\"),\"                          An authorization plugin that prevents from executing commands with certains parameters.\\n\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/twistlock/authz\"}),\"Twistlock AuthZ Broker\"),\"           A basic extendable authorization plugin that runs directly on the host or inside a container. This plugin allows you to define user policies that it evaluates during authorization. Basic authorization is provided if Docker daemon is started with the --tlsverify flag (username is extracted from the certificate common name).\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Troubleshooting a plugin\")),mdx(\"p\",null,\"If you are having problems with Docker after loading a plugin, ask the authors of the plugin for help. The Docker team may not be able to assist you.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Writing a plugin\")),mdx(\"p\",null,\"If you are interested in writing a plugin for Docker, or seeing how they work under the hood, see the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/extend/plugin_api/\"}),\"docker plugins reference\"),\".\"),mdx(\"h4\",null,\"Docker network driver plugins\"),mdx(\"p\",null,\"This document describes Docker Engine network driver plugins generally available in Docker Engine. To view information on plugins managed by Docker Engine, refer to\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/extend/\"}),\"Docker Engine plugin system\"),\".\"),mdx(\"p\",null,\"Docker Engine network plugins enable Engine deployments to be extended to support a wide range of networking technologies, such as VXLAN, IPVLAN, MACVLAN or something completely different. Network driver plugins are supported via the LibNetwork project. Each plugin is implemented as a \\\"remote driver\\\" for LibNetwork, which shares plugin infrastructure with Engine. Effectively, network driver plugins are activated in the same way as other plugins, and use the same kind of protocol.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Network plugins and swarm mode\")),mdx(\"p\",null,mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/extend/legacy_plugins/\"}),\"Legacy plugins\"),\"\\xA0do not work in swarm mode. However, plugins written using the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/extend/\"}),\"v2 plugin system\"),\"do work in swarm mode, as long as they are installed on each swarm worker node.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Use network driver plugins\")),mdx(\"p\",null,\"The means of installing and running a network driver plugin depend on the particular plugin. So, be sure to install your plugin according to the instructions obtained from the plugin developer.\"),mdx(\"p\",null,\"Once running however, network driver plugins are used just like the built-in network drivers: by being mentioned as a driver in network-oriented Docker commands. For example,\"),mdx(\"p\",null,\"$ docker network create --driver weave mynet\"),mdx(\"p\",null,\"Some network driver plugins are listed in\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/extend/legacy_plugins/\"}),\"plugins\")),mdx(\"p\",null,\"The\\xA0mynet\\xA0network is now owned by\\xA0weave, so subsequent commands referring to that network will be sent to the plugin,\"),mdx(\"p\",null,\"$ docker run --network=mynet busybox top\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Find network plugins\")),mdx(\"p\",null,\"Network plugins are written by third parties, and are published by those third parties, either on\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://store.docker.com/search?category=network&q=&type=plugin\"}),\"Docker Store\"),\"\\xA0or on the third party's site.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Write a network plugin\")),mdx(\"p\",null,\"Network plugins implement the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/extend/plugin_api/\"}),\"Docker plugin API\"),\"\\xA0and the network plugin protocol\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Network plugin protocol\")),mdx(\"p\",null,\"The network driver protocol, in addition to the plugin activation call, is documented as part of libnetwork:\\xA0\",mdx(\"inlineCode\",{parentName:\"p\"},\"<https://github.com/docker/libnetwork/blob/master/docs/remote.md>\"),\".\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Related Information\")),mdx(\"p\",null,\"To interact with the Docker maintainers and other interested users, see the IRC channel\\xA0#docker-network.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/userguide/networking/\"}),\"Docker networks feature overview\")),mdx(\"li\",{parentName:\"ul\"},\"The\\xA0\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://github.com/docker/libnetwork\"}),\"LibNetwork\"),\"\\xA0project\")),mdx(\"h4\",null,\"Docker volume plugins\"),mdx(\"p\",null,\"Docker Engine volume plugins enable Engine deployments to be integrated with external storage systems such as Amazon EBS, and enable data volumes to persist beyond the lifetime of a single Docker host. See the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/extend/legacy_plugins/\"}),\"plugin documentation\"),\"\\xA0for more information.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Changelog\")),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"1.13.0\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"If used as part of the v2 plugin architecture, mountpoints that are part of paths returned by the plugin must be mounted under the directory specified by\\xA0PropagatedMount\\xA0in the plugin configuration (\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://github.com/docker/docker/pull/26398\"}),\"#26398\"),\")\")),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"1.12.0\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Add\\xA0Status\\xA0field to\\xA0VolumeDriver.Get\\xA0response (\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://github.com/docker/docker/pull/21006\"}),\"#21006\"),\")\"),mdx(\"li\",{parentName:\"ul\"},\"Add\\xA0VolumeDriver.Capabilities\\xA0to get capabilities of the volume driver (\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://github.com/docker/docker/pull/22077\"}),\"#22077\"),\")\")),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"1.10.0\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Add\\xA0VolumeDriver.Get\\xA0which gets the details about the volume (\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://github.com/docker/docker/pull/16534\"}),\"#16534\"),\")\"),mdx(\"li\",{parentName:\"ul\"},\"Add\\xA0VolumeDriver.List\\xA0which lists all volumes owned by the driver (\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://github.com/docker/docker/pull/16534\"}),\"#16534\"),\")\")),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"1.8.0\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Initial support for volume driver plugins (\",mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://github.com/docker/docker/pull/14659\"}),\"#14659\"),\")\")),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Command-line changes\")),mdx(\"p\",null,\"To give a container access to a volume, use the\\xA0--volume\\xA0and\\xA0--volume-driver\\xA0flags on the\\xA0docker container run\\xA0command. The\\xA0--volume\\xA0(or\\xA0-v) flag accepts a volume name and path on the host, and the\\xA0--volume-driver\\xA0flag accepts a driver type.\"),mdx(\"p\",null,\"$ docker volume create --driver=flocker volumename\"),mdx(\"p\",null,\"$ docker container run -it --volume volumename:/data busybox sh\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"--volume\")),mdx(\"p\",null,\"The\\xA0--volume\\xA0(or\\xA0-v) flag takes a value that is in the format\\xA0\",mdx(\"inlineCode\",{parentName:\"p\"},\"<volume_name>:<mountpoint>\"),\". The two parts of the value are separated by a colon (:) character.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"The volume name is a human-readable name for the volume, and cannot begin with a\\xA0/character. It is referred to as\\xA0volume_name\\xA0in the rest of this topic.\"),mdx(\"li\",{parentName:\"ul\"},\"The\\xA0Mountpoint\\xA0is the path on the host (v1) or in the plugin (v2) where the volume has been made available.\")),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"volumedriver\")),mdx(\"p\",null,\"Specifying a\\xA0volumedriver\\xA0in conjunction with a\\xA0volumename\\xA0allows you to use plugins such as\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/ScatterHQ/flocker\"}),\"Flocker\"),\"\\xA0to manage volumes external to a single host, such as those on EBS.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Create a VolumeDriver\")),mdx(\"p\",null,\"The container creation endpoint (/containers/create) accepts a\\xA0VolumeDriver\\xA0field of type\\xA0string\\xA0allowing to specify the name of the driver. If not specified, it defaults to\\xA0\\\"local\\\"\\xA0(the default driver for local volumes).\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Volume plugin protocol\")),mdx(\"p\",null,\"If a plugin registers itself as a\\xA0VolumeDriver\\xA0when activated, it must provide the Docker Daemon with writeable paths on the host filesystem. The Docker daemon provides these paths to containers to consume. The Docker daemon makes the volumes available by bind-mounting the provided paths into the containers.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Note\"),\": Volume plugins should\\xA0not\\xA0write data to the\\xA0/var/lib/docker/\\xA0directory, including\\xA0/var/lib/docker/volumes. The\\xA0/var/lib/docker/\\xA0directory is reserved for Docker.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"/VolumeDriver.Create\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Request\"),\":\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"Name\\\": \\\"volume_name\\\",\"),mdx(\"p\",null,\"\\\"Opts\\\": {}\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"Instruct the plugin that the user wants to create a volume, given a user specified volume name. The plugin does not need to actually manifest the volume on the filesystem yet (until\\xA0Mount\\xA0is called).\\xA0Opts\\xA0is a map of driver specific options passed through from the user request.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Response\"),\":\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"Err\\\": \\\"\\\"\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"Respond with a string error if an error occurred.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"/VolumeDriver.Remove\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Request\"),\":\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"Name\\\": \\\"volume_name\\\"\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"Delete the specified volume from disk. This request is issued when a user invokes\\xA0docker rm -vto remove volumes associated with a container.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Response\"),\":\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"Err\\\": \\\"\\\"\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"Respond with a string error if an error occurred.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"/VolumeDriver.Mount\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Request\"),\":\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"Name\\\": \\\"volume_name\\\",\"),mdx(\"p\",null,\"\\\"ID\\\": \\\"b87d7442095999a92b65b3d9691e697b61713829cc0ffd1bb72e4ccd51aa4d6c\\\"\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"Docker requires the plugin to provide a volume, given a user specified volume name.\\xA0Mount\\xA0is called once per container start. If the same\\xA0volume_name\\xA0is requested more than once, the plugin may need to keep track of each new mount request and provision at the first mount request and deprovision at the last corresponding unmount request.\"),mdx(\"p\",null,\"ID\\xA0is a unique ID for the caller that is requesting the mount.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Response\"),\":\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"v1\"),\":\"),mdx(\"li\",{parentName:\"ul\"},\"{\"),mdx(\"li\",{parentName:\"ul\"},\"\\\"Mountpoint\\\": \\\"/path/to/directory/on/host\\\",\"),mdx(\"li\",{parentName:\"ul\"},\"\\\"Err\\\": \\\"\\\"\"),mdx(\"li\",{parentName:\"ul\"},\"}\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"v2\"),\":\"),mdx(\"li\",{parentName:\"ul\"},\"{\"),mdx(\"li\",{parentName:\"ul\"},\"\\\"Mountpoint\\\": \\\"/path/under/PropagatedMount\\\",\"),mdx(\"li\",{parentName:\"ul\"},\"\\\"Err\\\": \\\"\\\"\"),mdx(\"li\",{parentName:\"ul\"},\"}\")),mdx(\"p\",null,\"Mountpoint\\xA0is the path on the host (v1) or in the plugin (v2) where the volume has been made available.\"),mdx(\"p\",null,\"Err\\xA0is either empty or contains an error string.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"/VolumeDriver.Path\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Request\"),\":\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"Name\\\": \\\"volume_name\\\"\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"Request the path to the volume with the given\\xA0volume_name.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Response\"),\":\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"v1\"),\":\"),mdx(\"li\",{parentName:\"ul\"},\"{\"),mdx(\"li\",{parentName:\"ul\"},\"\\\"Mountpoint\\\": \\\"/path/to/directory/on/host\\\",\"),mdx(\"li\",{parentName:\"ul\"},\"\\\"Err\\\": \\\"\\\"\"),mdx(\"li\",{parentName:\"ul\"},\"}\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"v2\"),\":\"),mdx(\"li\",{parentName:\"ul\"},\"{\"),mdx(\"li\",{parentName:\"ul\"},\"\\\"Mountpoint\\\": \\\"/path/under/PropagatedMount\\\",\"),mdx(\"li\",{parentName:\"ul\"},\"\\\"Err\\\": \\\"\\\"\"),mdx(\"li\",{parentName:\"ul\"},\"}\")),mdx(\"p\",null,\"Respond with the path on the host (v1) or inside the plugin (v2) where the volume has been made available, and/or a string error if an error occurred.\"),mdx(\"p\",null,\"Mountpoint\\xA0is optional. However, the plugin may be queried again later if one is not provided.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"/VolumeDriver.Unmount\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Request\"),\":\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"Name\\\": \\\"volume_name\\\",\"),mdx(\"p\",null,\"\\\"ID\\\": \\\"b87d7442095999a92b65b3d9691e697b61713829cc0ffd1bb72e4ccd51aa4d6c\\\"\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"Docker is no longer using the named volume.\\xA0Unmount\\xA0is called once per container stop. Plugin may deduce that it is safe to deprovision the volume at this point.\"),mdx(\"p\",null,\"ID\\xA0is a unique ID for the caller that is requesting the mount.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Response\"),\":\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"Err\\\": \\\"\\\"\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"Respond with a string error if an error occurred.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"/VolumeDriver.Get\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Request\"),\":\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"Name\\\": \\\"volume_name\\\"\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"Get info about\\xA0volume_name.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Response\"),\":\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"v1\"),\":\"),mdx(\"li\",{parentName:\"ul\"},\"{\"),mdx(\"li\",{parentName:\"ul\"},\"\\\"Volume\\\": {\"),mdx(\"li\",{parentName:\"ul\"},\"\\\"Name\\\": \\\"volume_name\\\",\"),mdx(\"li\",{parentName:\"ul\"},\"\\\"Mountpoint\\\": \\\"/path/to/directory/on/host\\\",\"),mdx(\"li\",{parentName:\"ul\"},\"\\\"Status\\\": {}\"),mdx(\"li\",{parentName:\"ul\"},\"},\"),mdx(\"li\",{parentName:\"ul\"},\"\\\"Err\\\": \\\"\\\"\"),mdx(\"li\",{parentName:\"ul\"},\"}\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"v2\"),\":\"),mdx(\"li\",{parentName:\"ul\"},\"{\"),mdx(\"li\",{parentName:\"ul\"},\"\\\"Volume\\\": {\"),mdx(\"li\",{parentName:\"ul\"},\"\\\"Name\\\": \\\"volume_name\\\",\"),mdx(\"li\",{parentName:\"ul\"},\"\\\"Mountpoint\\\": \\\"/path/under/PropagatedMount\\\",\"),mdx(\"li\",{parentName:\"ul\"},\"\\\"Status\\\": {}\"),mdx(\"li\",{parentName:\"ul\"},\"},\"),mdx(\"li\",{parentName:\"ul\"},\"\\\"Err\\\": \\\"\\\"\"),mdx(\"li\",{parentName:\"ul\"},\"}\")),mdx(\"p\",null,\"Respond with a string error if an error occurred.\\xA0Mountpoint\\xA0and\\xA0Status\\xA0are optional.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"/VolumeDriver.List\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Request\"),\":\"),mdx(\"p\",null,\"{}\"),mdx(\"p\",null,\"Get the list of volumes registered with the plugin.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Response\"),\":\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"v1\"),\":\"),mdx(\"li\",{parentName:\"ul\"},\"{\"),mdx(\"li\",{parentName:\"ul\"},\"\\\"Volumes\\\": [\"),mdx(\"li\",{parentName:\"ul\"},\"{\"),mdx(\"li\",{parentName:\"ul\"},\"\\\"Name\\\": \\\"volume_name\\\",\"),mdx(\"li\",{parentName:\"ul\"},\"\\\"Mountpoint\\\": \\\"/path/to/directory/on/host\\\"\"),mdx(\"li\",{parentName:\"ul\"},\"}\"),mdx(\"li\",{parentName:\"ul\"},\"],\"),mdx(\"li\",{parentName:\"ul\"},\"\\\"Err\\\": \\\"\\\"\"),mdx(\"li\",{parentName:\"ul\"},\"}\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"v2\"),\":\"),mdx(\"li\",{parentName:\"ul\"},\"{\"),mdx(\"li\",{parentName:\"ul\"},\"\\\"Volumes\\\": [\"),mdx(\"li\",{parentName:\"ul\"},\"{\"),mdx(\"li\",{parentName:\"ul\"},\"\\\"Name\\\": \\\"volume_name\\\",\"),mdx(\"li\",{parentName:\"ul\"},\"\\\"Mountpoint\\\": \\\"/path/under/PropagatedMount\\\"\"),mdx(\"li\",{parentName:\"ul\"},\"}\"),mdx(\"li\",{parentName:\"ul\"},\"],\"),mdx(\"li\",{parentName:\"ul\"},\"\\\"Err\\\": \\\"\\\"\"),mdx(\"li\",{parentName:\"ul\"},\"}\")),mdx(\"p\",null,\"Respond with a string error if an error occurred.\\xA0Mountpoint\\xA0is optional.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"/VolumeDriver.Capabilities\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Request\"),\":\"),mdx(\"p\",null,\"{}\"),mdx(\"p\",null,\"Get the list of capabilities the driver supports.\"),mdx(\"p\",null,\"The driver is not required to implement\\xA0Capabilities. If it is not implemented, the default values are used.\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Response\"),\":\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"Capabilities\\\": {\"),mdx(\"p\",null,\"\\\"Scope\\\": \\\"global\\\"\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"Supported scopes are\\xA0global\\xA0and\\xA0local. Any other value in\\xA0Scope\\xA0will be ignored, and\\xA0local\\xA0is used.\\xA0Scope\\xA0allows cluster managers to handle the volume in different ways. For instance, a scope of\\xA0global, signals to the cluster manager that it only needs to create the volume once instead of on each Docker host. More capabilities may be added in the future.\"),mdx(\"h4\",null,\"Plugin Config Version 1 of Plugin V2\"),mdx(\"p\",null,\"This document outlines the format of the V0 plugin configuration. The plugin config described herein was introduced in the Docker daemon in the\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/docker/docker/commit/f37117045c5398fd3dca8016ea8ca0cb47e7312b\"}),\"v1.12.0 release\"),\".\"),mdx(\"p\",null,\"Plugin configs describe the various constituents of a docker plugin. Plugin configs can be serialized to JSON format with the following media types:\"),mdx(\"p\",null,\"  \",mdx(\"strong\",{parentName:\"p\"},\"Config Type\"),\"   \",mdx(\"strong\",{parentName:\"p\"},\"Media Type\")),mdx(\"hr\",null),mdx(\"p\",null,\"  config            \\\"application/vnd.docker.plugin.v1+json\\\"\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Config\\xA0Field Descriptions\")),mdx(\"p\",null,\"Config provides the base accessible fields for working with V0 plugin format in the registry.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"description\"),\"\\xA0string\")),mdx(\"p\",null,\"description of the plugin\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"documentation\"),\"\\xA0string\"),mdx(\"li\",{parentName:\"ul\"},\"link to the documentation about the plugin\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"interface\"),\"\\xA0PluginInterface\")),mdx(\"p\",null,\"interface implemented by the plugins, struct consisting of the following fields\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"types\"),\"\\xA0string array\")))),mdx(\"p\",null,\"types indicate what interface(s) the plugin currently implements.\"),mdx(\"p\",null,\"currently supported:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"docker.volumedriver/1.0\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"docker.networkdriver/1.0\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"docker.ipamdriver/1.0\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"docker.authz/1.0\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"docker.logdriver/1.0\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"docker.metricscollector/1.0\")))),mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},mdx(\"strong\",{parentName:\"p\"},\"socket\"),\"\\xA0string\"))))),mdx(\"p\",null,\"socket is the name of the socket the engine should use to communicate with the plugins. the socket will be created in\\xA0/run/docker/plugins.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"entrypoint\"),\"\\xA0string array\")),mdx(\"p\",null,\"entrypoint of the plugin, see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/builder/#entrypoint\"}),\"ENTRYPOINT\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"workdir\"),\"\\xA0string\")),mdx(\"p\",null,\"workdir of the plugin, see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/reference/builder/#workdir\"}),\"WORKDIR\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"network\"),\"\\xA0PluginNetwork\")),mdx(\"p\",null,\"network of the plugin, struct consisting of the following fields\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"type\"),\"\\xA0string\")))),mdx(\"p\",null,\"network type.\"),mdx(\"p\",null,\"currently supported:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},mdx(\"strong\",{parentName:\"p\"},\"bridge\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},mdx(\"strong\",{parentName:\"p\"},\"host\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},mdx(\"strong\",{parentName:\"p\"},\"none\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},mdx(\"strong\",{parentName:\"p\"},\"mounts\"),\"\\xA0PluginMount array\"))),mdx(\"p\",null,\"mount of the plugin, struct consisting of the following fields, see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/opencontainers/runtime-spec/blob/master/config.md#mounts\"}),\"MOUNTS\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"name\"),\"\\xA0string\")))),mdx(\"p\",null,\"name of the mount.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"description\"),\"\\xA0string\")))),mdx(\"p\",null,\"description of the mount.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"source\"),\"\\xA0string\")))),mdx(\"p\",null,\"source of the mount.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"destination\"),\"\\xA0string\")))),mdx(\"p\",null,\"destination of the mount.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"type\"),\"\\xA0string\")))),mdx(\"p\",null,\"mount type.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"options\"),\"\\xA0string array\")))),mdx(\"p\",null,\"options of the mount.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"ipchost\"),\"\\xA0boolean\\xA0Access to host ipc namespace.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"pidhost\"),\"\\xA0boolean\\xA0Access to host pid namespace.\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"propagatedMount\"),\"\\xA0string\")),mdx(\"p\",null,\"path to be mounted as rshared, so that mounts under that path are visible to docker. This is useful for volume plugins. This path will be bind-mounted outside of the plugin rootfs so it's contents are preserved on upgrade.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"env\"),\"\\xA0PluginEnv array\")),mdx(\"p\",null,\"env of the plugin, struct consisting of the following fields\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"name\"),\"\\xA0string\")))),mdx(\"p\",null,\"name of the env.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"description\"),\"\\xA0string\")))),mdx(\"p\",null,\"description of the env.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"value\"),\"\\xA0string\")))),mdx(\"p\",null,\"value of the env.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"args\"),\"\\xA0PluginArgs\")),mdx(\"p\",null,\"args of the plugin, struct consisting of the following fields\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"name\"),\"\\xA0string\")))),mdx(\"p\",null,\"name of the args.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"description\"),\"\\xA0string\")))),mdx(\"p\",null,\"description of the args.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"value\"),\"\\xA0string array\")))),mdx(\"p\",null,\"values of the args.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"linux\"),\"\\xA0PluginLinux\",mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"capabilities\"),\"\\xA0string array\")))),mdx(\"p\",null,\"capabilities of the plugin (Linux only), see list\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/opencontainers/runc/blob/master/libcontainer/SPEC.md#security\"}),\"here\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"allowAllDevices\"),\"\\xA0boolean\")))),mdx(\"p\",null,\"If\\xA0/dev\\xA0is bind mounted from the host, and allowAllDevices is set to true, the plugin will have\\xA0rwm\\xA0access to all devices on the host.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"devices\"),\"\\xA0PluginDevice array\")))),mdx(\"p\",null,\"device of the plugin, (Linux only), struct consisting of the following fields, see\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/opencontainers/runtime-spec/blob/master/config-linux.md#devices\"}),\"DEVICES\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"name\"),\"\\xA0string\")))))),mdx(\"p\",null,\"name of the device.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"description\"),\"\\xA0string\")))))),mdx(\"p\",null,\"description of the device.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"ul\",{parentName:\"li\"},mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"path\"),\"\\xA0string\")))))),mdx(\"p\",null,\"path of the device.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Example Config\")),mdx(\"p\",null,\"Example showing the 'tiborvass/sample-volume-plugin' plugin config.\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"Args\\\": {\"),mdx(\"p\",null,\"\\\"Description\\\": \\\"\\\",\"),mdx(\"p\",null,\"\\\"Name\\\": \\\"\\\",\"),mdx(\"p\",null,\"\\\"Settable\\\": null,\"),mdx(\"p\",null,\"\\\"Value\\\": null\"),mdx(\"p\",null,\"},\"),mdx(\"p\",null,\"\\\"Description\\\": \\\"A sample volume plugin for Docker\\\",\"),mdx(\"p\",null,\"\\\"Documentation\\\": \\\"\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/extend/plugins/%22\"}),\"https://docs.docker.com/engine/extend/plugins/\\\"\"),\",\"),mdx(\"p\",null,\"\\\"Entrypoint\\\": [\"),mdx(\"p\",null,\"\\\"/usr/bin/sample-volume-plugin\\\",\"),mdx(\"p\",null,\"\\\"/data\\\"\"),mdx(\"p\",null,\"],\"),mdx(\"p\",null,\"\\\"Env\\\": [\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"Description\\\": \\\"\\\",\"),mdx(\"p\",null,\"\\\"Name\\\": \\\"DEBUG\\\",\"),mdx(\"p\",null,\"\\\"Settable\\\": [\"),mdx(\"p\",null,\"\\\"value\\\"\"),mdx(\"p\",null,\"],\"),mdx(\"p\",null,\"\\\"Value\\\": \\\"0\\\"\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"],\"),mdx(\"p\",null,\"\\\"Interface\\\": {\"),mdx(\"p\",null,\"\\\"Socket\\\": \\\"plugin.sock\\\",\"),mdx(\"p\",null,\"\\\"Types\\\": [\"),mdx(\"p\",null,\"\\\"docker.volumedriver/1.0\\\"\"),mdx(\"p\",null,\"]\"),mdx(\"p\",null,\"},\"),mdx(\"p\",null,\"\\\"Linux\\\": {\"),mdx(\"p\",null,\"\\\"Capabilities\\\": null,\"),mdx(\"p\",null,\"\\\"AllowAllDevices\\\": false,\"),mdx(\"p\",null,\"\\\"Devices\\\": null\"),mdx(\"p\",null,\"},\"),mdx(\"p\",null,\"\\\"Mounts\\\": null,\"),mdx(\"p\",null,\"\\\"Network\\\": {\"),mdx(\"p\",null,\"\\\"Type\\\": \\\"\\\"\"),mdx(\"p\",null,\"},\"),mdx(\"p\",null,\"\\\"PropagatedMount\\\": \\\"/data\\\",\"),mdx(\"p\",null,\"\\\"User\\\": {},\"),mdx(\"p\",null,\"\\\"Workdir\\\": \\\"\\\"\"),mdx(\"p\",null,\"}\"),mdx(\"h4\",null,\"Docker Plugin API\"),mdx(\"p\",null,\"Docker plugins are out-of-process extensions which add capabilities to the Docker Engine.\"),mdx(\"p\",null,\"This document describes the Docker Engine plugin API. To view information on plugins managed by Docker Engine, refer to\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/extend/\"}),\"Docker Engine plugin system\"),\".\"),mdx(\"p\",null,\"This page is intended for people who want to develop their own Docker plugin. If you just want to learn about or use Docker plugins, look\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/extend/legacy_plugins/\"}),\"here\"),\".\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"What plugins are\")),mdx(\"p\",null,\"A plugin is a process running on the same or a different host as the docker daemon, which registers itself by placing a file on the same docker host in one of the plugin directories described in\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://docs.docker.com/engine/extend/plugin_api/#plugin-discovery\"}),\"Plugin discovery\"),\".\"),mdx(\"p\",null,\"Plugins have human-readable names, which are short, lowercase strings. For example,\\xA0flockeror\\xA0weave.\"),mdx(\"p\",null,\"Plugins can run inside or outside containers. Currently running them outside containers is recommended.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Plugin discovery\")),mdx(\"p\",null,\"Docker discovers plugins by looking for them in the plugin directory whenever a user or container tries to use one by name.\"),mdx(\"p\",null,\"There are three types of files which can be put in the plugin directory.\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\".sock\\xA0files are UNIX domain sockets.\"),mdx(\"li\",{parentName:\"ul\"},\".spec\\xA0files are text files containing a URL, such as\\xA0unix:///other.sock\\xA0or\\xA0tcp://localhost:8080.\"),mdx(\"li\",{parentName:\"ul\"},\".json\\xA0files are text files containing a full json specification for the plugin.\")),mdx(\"p\",null,\"Plugins with UNIX domain socket files must run on the same docker host, whereas plugins with spec or json files can run on a different host if a remote URL is specified.\"),mdx(\"p\",null,\"UNIX domain socket files must be located under\\xA0/run/docker/plugins, whereas spec files can be located either under\\xA0/etc/docker/plugins\\xA0or\\xA0/usr/lib/docker/plugins.\"),mdx(\"p\",null,\"The name of the file (excluding the extension) determines the plugin name.\"),mdx(\"p\",null,\"For example, the\\xA0flocker\\xA0plugin might create a UNIX socket at/run/docker/plugins/flocker.sock.\"),mdx(\"p\",null,\"You can define each plugin into a separated subdirectory if you want to isolate definitions from each other. For example, you can create the\\xA0flocker\\xA0socket under\\xA0/run/docker/plugins/flocker/flocker.sock\\xA0and only mount\\xA0/run/docker/plugins/flockerinside the\\xA0flocker\\xA0container.\"),mdx(\"p\",null,\"Docker always searches for unix sockets in\\xA0/run/docker/plugins\\xA0first. It checks for spec or json files under\\xA0/etc/docker/plugins\\xA0and\\xA0/usr/lib/docker/plugins\\xA0if the socket doesn't exist. The directory scan stops as soon as it finds the first plugin definition with the given name.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"JSON specification\")),mdx(\"p\",null,\"This is the JSON format for a plugin:\"),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"Name\\\": \\\"plugin-example\\\",\"),mdx(\"p\",null,\"\\\"Addr\\\": \\\"\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://example.com/docker/plugin%22\"}),\"https://example.com/docker/plugin\\\"\"),\",\"),mdx(\"p\",null,\"\\\"TLSConfig\\\": {\"),mdx(\"p\",null,\"\\\"InsecureSkipVerify\\\": false,\"),mdx(\"p\",null,\"\\\"CAFile\\\": \\\"/usr/shared/docker/certs/example-ca.pem\\\",\"),mdx(\"p\",null,\"\\\"CertFile\\\": \\\"/usr/shared/docker/certs/example-cert.pem\\\",\"),mdx(\"p\",null,\"\\\"KeyFile\\\": \\\"/usr/shared/docker/certs/example-key.pem\\\"\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"The\\xA0TLSConfig\\xA0field is optional and TLS will only be verified if this configuration is present.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Plugin lifecycle\")),mdx(\"p\",null,\"Plugins should be started before Docker, and stopped after Docker. For example, when packaging a plugin for a platform which supports\\xA0systemd, you might use\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"http://www.freedesktop.org/software/systemd/man/systemd.unit.html#Before=\"}),\"systemd\\xA0dependencies\"),\"\\xA0to manage startup and shutdown order.\"),mdx(\"p\",null,\"When upgrading a plugin, you should first stop the Docker daemon, upgrade the plugin, then start Docker again.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Plugin activation\")),mdx(\"p\",null,\"When a plugin is first referred to -- either by a user referring to it by name (e.g.docker run --volume-driver=foo) or a container already configured to use a plugin being started -- Docker looks for the named plugin in the plugin directory and activates it with a handshake. See Handshake API below.\"),mdx(\"p\",null,\"Plugins are\\xA0not\\xA0activated automatically at Docker daemon startup. Rather, they are activated only lazily, or on-demand, when they are needed.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Systemd socket activation\")),mdx(\"p\",null,\"Plugins may also be socket activated by\\xA0systemd. The official\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/docker/go-plugins-helpers\"}),\"Plugins helpers\"),\"\\xA0natively supports socket activation. In order for a plugin to be socket activated it needs a\\xA0service\\xA0file and a\\xA0socket\\xA0file.\"),mdx(\"p\",null,\"The\\xA0service\\xA0file (for example\\xA0/lib/systemd/system/your-plugin.service):\"),mdx(\"p\",null,\"[Unit]\"),mdx(\"p\",null,\"Description=Your plugin\"),mdx(\"p\",null,\"Before=docker.service\"),mdx(\"p\",null,\"After=network.target your-plugin.socket\"),mdx(\"p\",null,\"Requires=your-plugin.socket docker.service\"),mdx(\"p\",null,\"[Service]\"),mdx(\"p\",null,\"ExecStart=/usr/lib/docker/your-plugin\"),mdx(\"p\",null,\"[Install]\"),mdx(\"p\",null,\"WantedBy=multi-user.target\"),mdx(\"p\",null,\"The\\xA0socket\\xA0file (for example\\xA0/lib/systemd/system/your-plugin.socket):\"),mdx(\"p\",null,\"[Unit]\"),mdx(\"p\",null,\"Description=Your plugin\"),mdx(\"p\",null,\"[Socket]\"),mdx(\"p\",null,\"ListenStream=/run/docker/plugins/your-plugin.sock\"),mdx(\"p\",null,\"[Install]\"),mdx(\"p\",null,\"WantedBy=sockets.target\"),mdx(\"p\",null,\"This will allow plugins to be actually started when the Docker daemon connects to the sockets they're listening on (for instance the first time the daemon uses them or if one of the plugin goes down accidentally).\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"API design\")),mdx(\"p\",null,\"The Plugin API is RPC-style JSON over HTTP, much like webhooks.\"),mdx(\"p\",null,\"Requests flow\\xA0from\\xA0the Docker daemon\\xA0to\\xA0the plugin. So the plugin needs to implement an HTTP server and bind this to the UNIX socket mentioned in the \\\"plugin discovery\\\" section.\"),mdx(\"p\",null,\"All requests are HTTP\\xA0POST\\xA0requests.\"),mdx(\"p\",null,\"The API is versioned via an Accept header, which currently is always set toapplication/vnd.docker.plugins.v1+json.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Handshake API\")),mdx(\"p\",null,\"Plugins are activated via the following \\\"handshake\\\" API call.\"),mdx(\"h6\",null,mdx(\"strong\",{parentName:\"h6\"},\"/Plugin.Activate\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Request:\"),\"\\xA0empty body\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Response:\")),mdx(\"p\",null,\"{\"),mdx(\"p\",null,\"\\\"Implements\\\": \",\"[\\\"VolumeDriver\\\"]\"),mdx(\"p\",null,\"}\"),mdx(\"p\",null,\"Responds with a list of Docker subsystems which this plugin implements. After activation, the plugin will then be sent events from this subsystem.\"),mdx(\"p\",null,\"Possible values are:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/extend/plugins_authorization/\"}),\"authz\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/extend/plugins_network/\"}),\"NetworkDriver\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",_extends({parentName:\"li\"},{\"href\":\"https://docs.docker.com/engine/extend/plugins_volume/\"}),\"VolumeDriver\"))),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Plugin retries\")),mdx(\"p\",null,\"Attempts to call a method on a plugin are retried with an exponential backoff for up to 30 seconds. This may help when packaging plugins as containers, since it gives plugin containers a chance to start up before failing any user containers which depend on them.\"),mdx(\"h5\",null,mdx(\"strong\",{parentName:\"h5\"},\"Plugins helpers\")),mdx(\"p\",null,\"To ease plugins development, we're providing an\\xA0sdk\\xA0for each kind of plugins currently supported by Docker at\\xA0\",mdx(\"a\",_extends({parentName:\"p\"},{\"href\":\"https://github.com/docker/go-plugins-helpers\"}),\"docker/go-plugins-helpers\"),\".\"));};MDXContent.isMDXComponent=true;"}},"pageContext":{"slug":"/docker/"}},"staticQueryHashes":["4080856488"]}